
(function(l, r) { if (l.getElementById('livereloadscript')) return; r = l.createElement('script'); r.async = 1; r.src = '//' + (window.location.host || 'localhost').split(':')[0] + ':35729/livereload.js?snipver=1'; r.id = 'livereloadscript'; l.getElementsByTagName('head')[0].appendChild(r) })(window.document);
var app = (function () {
    'use strict';

    function noop() { }
    function add_location(element, file, line, column, char) {
        element.__svelte_meta = {
            loc: { file, line, column, char }
        };
    }
    function run(fn) {
        return fn();
    }
    function blank_object() {
        return Object.create(null);
    }
    function run_all(fns) {
        fns.forEach(run);
    }
    function is_function(thing) {
        return typeof thing === 'function';
    }
    function safe_not_equal(a, b) {
        return a != a ? b == b : a !== b || ((a && typeof a === 'object') || typeof a === 'function');
    }
    function is_empty(obj) {
        return Object.keys(obj).length === 0;
    }

    function append(target, node) {
        target.appendChild(node);
    }
    function insert(target, node, anchor) {
        target.insertBefore(node, anchor || null);
    }
    function detach(node) {
        node.parentNode.removeChild(node);
    }
    function element(name) {
        return document.createElement(name);
    }
    function text(data) {
        return document.createTextNode(data);
    }
    function space() {
        return text(' ');
    }
    function attr(node, attribute, value) {
        if (value == null)
            node.removeAttribute(attribute);
        else if (node.getAttribute(attribute) !== value)
            node.setAttribute(attribute, value);
    }
    function children(element) {
        return Array.from(element.childNodes);
    }
    function custom_event(type, detail) {
        const e = document.createEvent('CustomEvent');
        e.initCustomEvent(type, false, false, detail);
        return e;
    }

    let current_component;
    function set_current_component(component) {
        current_component = component;
    }
    function get_current_component() {
        if (!current_component)
            throw new Error('Function called outside component initialization');
        return current_component;
    }
    function onMount(fn) {
        get_current_component().$$.on_mount.push(fn);
    }

    const dirty_components = [];
    const binding_callbacks = [];
    const render_callbacks = [];
    const flush_callbacks = [];
    const resolved_promise = Promise.resolve();
    let update_scheduled = false;
    function schedule_update() {
        if (!update_scheduled) {
            update_scheduled = true;
            resolved_promise.then(flush);
        }
    }
    function add_render_callback(fn) {
        render_callbacks.push(fn);
    }
    let flushing = false;
    const seen_callbacks = new Set();
    function flush() {
        if (flushing)
            return;
        flushing = true;
        do {
            // first, call beforeUpdate functions
            // and update components
            for (let i = 0; i < dirty_components.length; i += 1) {
                const component = dirty_components[i];
                set_current_component(component);
                update(component.$$);
            }
            set_current_component(null);
            dirty_components.length = 0;
            while (binding_callbacks.length)
                binding_callbacks.pop()();
            // then, once components are updated, call
            // afterUpdate functions. This may cause
            // subsequent updates...
            for (let i = 0; i < render_callbacks.length; i += 1) {
                const callback = render_callbacks[i];
                if (!seen_callbacks.has(callback)) {
                    // ...so guard against infinite loops
                    seen_callbacks.add(callback);
                    callback();
                }
            }
            render_callbacks.length = 0;
        } while (dirty_components.length);
        while (flush_callbacks.length) {
            flush_callbacks.pop()();
        }
        update_scheduled = false;
        flushing = false;
        seen_callbacks.clear();
    }
    function update($$) {
        if ($$.fragment !== null) {
            $$.update();
            run_all($$.before_update);
            const dirty = $$.dirty;
            $$.dirty = [-1];
            $$.fragment && $$.fragment.p($$.ctx, dirty);
            $$.after_update.forEach(add_render_callback);
        }
    }
    const outroing = new Set();
    function transition_in(block, local) {
        if (block && block.i) {
            outroing.delete(block);
            block.i(local);
        }
    }

    const globals = (typeof window !== 'undefined'
        ? window
        : typeof globalThis !== 'undefined'
            ? globalThis
            : global);
    function mount_component(component, target, anchor) {
        const { fragment, on_mount, on_destroy, after_update } = component.$$;
        fragment && fragment.m(target, anchor);
        // onMount happens before the initial afterUpdate
        add_render_callback(() => {
            const new_on_destroy = on_mount.map(run).filter(is_function);
            if (on_destroy) {
                on_destroy.push(...new_on_destroy);
            }
            else {
                // Edge case - component was destroyed immediately,
                // most likely as a result of a binding initialising
                run_all(new_on_destroy);
            }
            component.$$.on_mount = [];
        });
        after_update.forEach(add_render_callback);
    }
    function destroy_component(component, detaching) {
        const $$ = component.$$;
        if ($$.fragment !== null) {
            run_all($$.on_destroy);
            $$.fragment && $$.fragment.d(detaching);
            // TODO null out other refs, including component.$$ (but need to
            // preserve final state?)
            $$.on_destroy = $$.fragment = null;
            $$.ctx = [];
        }
    }
    function make_dirty(component, i) {
        if (component.$$.dirty[0] === -1) {
            dirty_components.push(component);
            schedule_update();
            component.$$.dirty.fill(0);
        }
        component.$$.dirty[(i / 31) | 0] |= (1 << (i % 31));
    }
    function init(component, options, instance, create_fragment, not_equal, props, dirty = [-1]) {
        const parent_component = current_component;
        set_current_component(component);
        const prop_values = options.props || {};
        const $$ = component.$$ = {
            fragment: null,
            ctx: null,
            // state
            props,
            update: noop,
            not_equal,
            bound: blank_object(),
            // lifecycle
            on_mount: [],
            on_destroy: [],
            before_update: [],
            after_update: [],
            context: new Map(parent_component ? parent_component.$$.context : []),
            // everything else
            callbacks: blank_object(),
            dirty,
            skip_bound: false
        };
        let ready = false;
        $$.ctx = instance
            ? instance(component, prop_values, (i, ret, ...rest) => {
                const value = rest.length ? rest[0] : ret;
                if ($$.ctx && not_equal($$.ctx[i], $$.ctx[i] = value)) {
                    if (!$$.skip_bound && $$.bound[i])
                        $$.bound[i](value);
                    if (ready)
                        make_dirty(component, i);
                }
                return ret;
            })
            : [];
        $$.update();
        ready = true;
        run_all($$.before_update);
        // `false` as a special case of no DOM component
        $$.fragment = create_fragment ? create_fragment($$.ctx) : false;
        if (options.target) {
            if (options.hydrate) {
                const nodes = children(options.target);
                // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
                $$.fragment && $$.fragment.l(nodes);
                nodes.forEach(detach);
            }
            else {
                // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
                $$.fragment && $$.fragment.c();
            }
            if (options.intro)
                transition_in(component.$$.fragment);
            mount_component(component, options.target, options.anchor);
            flush();
        }
        set_current_component(parent_component);
    }
    class SvelteComponent {
        $destroy() {
            destroy_component(this, 1);
            this.$destroy = noop;
        }
        $on(type, callback) {
            const callbacks = (this.$$.callbacks[type] || (this.$$.callbacks[type] = []));
            callbacks.push(callback);
            return () => {
                const index = callbacks.indexOf(callback);
                if (index !== -1)
                    callbacks.splice(index, 1);
            };
        }
        $set($$props) {
            if (this.$$set && !is_empty($$props)) {
                this.$$.skip_bound = true;
                this.$$set($$props);
                this.$$.skip_bound = false;
            }
        }
    }

    function dispatch_dev(type, detail) {
        document.dispatchEvent(custom_event(type, Object.assign({ version: '3.30.0' }, detail)));
    }
    function append_dev(target, node) {
        dispatch_dev('SvelteDOMInsert', { target, node });
        append(target, node);
    }
    function insert_dev(target, node, anchor) {
        dispatch_dev('SvelteDOMInsert', { target, node, anchor });
        insert(target, node, anchor);
    }
    function detach_dev(node) {
        dispatch_dev('SvelteDOMRemove', { node });
        detach(node);
    }
    function attr_dev(node, attribute, value) {
        attr(node, attribute, value);
        if (value == null)
            dispatch_dev('SvelteDOMRemoveAttribute', { node, attribute });
        else
            dispatch_dev('SvelteDOMSetAttribute', { node, attribute, value });
    }
    function set_data_dev(text, data) {
        data = '' + data;
        if (text.wholeText === data)
            return;
        dispatch_dev('SvelteDOMSetData', { node: text, data });
        text.data = data;
    }
    function validate_slots(name, slot, keys) {
        for (const slot_key of Object.keys(slot)) {
            if (!~keys.indexOf(slot_key)) {
                console.warn(`<${name}> received an unexpected slot "${slot_key}".`);
            }
        }
    }
    class SvelteComponentDev extends SvelteComponent {
        constructor(options) {
            if (!options || (!options.target && !options.$$inline)) {
                throw new Error("'target' is a required option");
            }
            super();
        }
        $destroy() {
            super.$destroy();
            this.$destroy = () => {
                console.warn('Component was already destroyed'); // eslint-disable-line no-console
            };
        }
        $capture_state() { }
        $inject_state() { }
    }

    const version = "14.7.58";

    var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

    function createCommonjsModule(fn, basedir, module) {
    	return module = {
    		path: basedir,
    		exports: {},
    		require: function (path, base) {
    			return commonjsRequire(path, (base === undefined || base === null) ? module.path : base);
    		}
    	}, fn(module, module.exports), module.exports;
    }

    function commonjsRequire () {
    	throw new Error('Dynamic requires are not currently supported by @rollup/plugin-commonjs');
    }

    function _arrayWithHoles(arr) {
      if (Array.isArray(arr)) return arr;
    }

    var arrayWithHoles = _arrayWithHoles;

    function _iterableToArrayLimit(arr, i) {
      if (typeof Symbol === "undefined" || !(Symbol.iterator in Object(arr))) return;
      var _arr = [];
      var _n = true;
      var _d = false;
      var _e = undefined;

      try {
        for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) {
          _arr.push(_s.value);

          if (i && _arr.length === i) break;
        }
      } catch (err) {
        _d = true;
        _e = err;
      } finally {
        try {
          if (!_n && _i["return"] != null) _i["return"]();
        } finally {
          if (_d) throw _e;
        }
      }

      return _arr;
    }

    var iterableToArrayLimit = _iterableToArrayLimit;

    function _arrayLikeToArray(arr, len) {
      if (len == null || len > arr.length) len = arr.length;

      for (var i = 0, arr2 = new Array(len); i < len; i++) {
        arr2[i] = arr[i];
      }

      return arr2;
    }

    var arrayLikeToArray = _arrayLikeToArray;

    function _unsupportedIterableToArray(o, minLen) {
      if (!o) return;
      if (typeof o === "string") return arrayLikeToArray(o, minLen);
      var n = Object.prototype.toString.call(o).slice(8, -1);
      if (n === "Object" && o.constructor) n = o.constructor.name;
      if (n === "Map" || n === "Set") return Array.from(o);
      if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return arrayLikeToArray(o, minLen);
    }

    var unsupportedIterableToArray = _unsupportedIterableToArray;

    function _nonIterableRest() {
      throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.");
    }

    var nonIterableRest = _nonIterableRest;

    function _slicedToArray(arr, i) {
      return arrayWithHoles(arr) || iterableToArrayLimit(arr, i) || unsupportedIterableToArray(arr, i) || nonIterableRest();
    }

    var slicedToArray = _slicedToArray;

    function _classCallCheck(instance, Constructor) {
      if (!(instance instanceof Constructor)) {
        throw new TypeError("Cannot call a class as a function");
      }
    }

    var classCallCheck = _classCallCheck;

    function _defineProperties(target, props) {
      for (var i = 0; i < props.length; i++) {
        var descriptor = props[i];
        descriptor.enumerable = descriptor.enumerable || false;
        descriptor.configurable = true;
        if ("value" in descriptor) descriptor.writable = true;
        Object.defineProperty(target, descriptor.key, descriptor);
      }
    }

    function _createClass(Constructor, protoProps, staticProps) {
      if (protoProps) _defineProperties(Constructor.prototype, protoProps);
      if (staticProps) _defineProperties(Constructor, staticProps);
      return Constructor;
    }

    var createClass = _createClass;

    var bundle = createCommonjsModule(function (module, exports) {
    (function (global, factory) {
         factory(exports, slicedToArray, classCallCheck, createClass) ;
    }(commonjsGlobal, (function (exports, _slicedToArray, _classCallCheck, _createClass) {
        function _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }

        var _slicedToArray__default = /*#__PURE__*/_interopDefaultLegacy(_slicedToArray);
        var _classCallCheck__default = /*#__PURE__*/_interopDefaultLegacy(_classCallCheck);
        var _createClass__default = /*#__PURE__*/_interopDefaultLegacy(_createClass);

        var createExtendedExponentialRampToValueAutomationEvent = function createExtendedExponentialRampToValueAutomationEvent(value, endTime, insertTime) {
          return {
            endTime: endTime,
            insertTime: insertTime,
            type: 'exponentialRampToValue',
            value: value
          };
        };

        var createExtendedLinearRampToValueAutomationEvent = function createExtendedLinearRampToValueAutomationEvent(value, endTime, insertTime) {
          return {
            endTime: endTime,
            insertTime: insertTime,
            type: 'linearRampToValue',
            value: value
          };
        };

        var createSetValueAutomationEvent = function createSetValueAutomationEvent(value, startTime) {
          return {
            startTime: startTime,
            type: 'setValue',
            value: value
          };
        };

        var createSetValueCurveAutomationEvent = function createSetValueCurveAutomationEvent(values, startTime, duration) {
          return {
            duration: duration,
            startTime: startTime,
            type: 'setValueCurve',
            values: values
          };
        };

        var getTargetValueAtTime = function getTargetValueAtTime(time, valueAtStartTime, _ref) {
          var startTime = _ref.startTime,
              target = _ref.target,
              timeConstant = _ref.timeConstant;
          return target + (valueAtStartTime - target) * Math.exp((startTime - time) / timeConstant);
        };

        var isExponentialRampToValueAutomationEvent = function isExponentialRampToValueAutomationEvent(automationEvent) {
          return automationEvent.type === 'exponentialRampToValue';
        };

        var isLinearRampToValueAutomationEvent = function isLinearRampToValueAutomationEvent(automationEvent) {
          return automationEvent.type === 'linearRampToValue';
        };

        var isAnyRampToValueAutomationEvent = function isAnyRampToValueAutomationEvent(automationEvent) {
          return isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent);
        };

        var isSetValueAutomationEvent = function isSetValueAutomationEvent(automationEvent) {
          return automationEvent.type === 'setValue';
        };

        var isSetValueCurveAutomationEvent = function isSetValueCurveAutomationEvent(automationEvent) {
          return automationEvent.type === 'setValueCurve';
        };

        var getValueOfAutomationEventAtIndexAtTime = function getValueOfAutomationEventAtIndexAtTime(automationEvents, index, time, defaultValue) {
          var automationEvent = automationEvents[index];
          return automationEvent === undefined ? defaultValue : isAnyRampToValueAutomationEvent(automationEvent) || isSetValueAutomationEvent(automationEvent) ? automationEvent.value : isSetValueCurveAutomationEvent(automationEvent) ? automationEvent.values[automationEvent.values.length - 1] : getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, automationEvent.startTime, defaultValue), automationEvent);
        };

        var getEndTimeAndValueOfPreviousAutomationEvent = function getEndTimeAndValueOfPreviousAutomationEvent(automationEvents, index, currentAutomationEvent, nextAutomationEvent, defaultValue) {
          return currentAutomationEvent === undefined ? [nextAutomationEvent.insertTime, defaultValue] : isAnyRampToValueAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.endTime, currentAutomationEvent.value] : isSetValueAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.startTime, currentAutomationEvent.value] : isSetValueCurveAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.startTime + currentAutomationEvent.duration, currentAutomationEvent.values[currentAutomationEvent.values.length - 1]] : [currentAutomationEvent.startTime, getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, currentAutomationEvent.startTime, defaultValue)];
        };

        var isCancelAndHoldAutomationEvent = function isCancelAndHoldAutomationEvent(automationEvent) {
          return automationEvent.type === 'cancelAndHold';
        };

        var isCancelScheduledValuesAutomationEvent = function isCancelScheduledValuesAutomationEvent(automationEvent) {
          return automationEvent.type === 'cancelScheduledValues';
        };

        var getEventTime = function getEventTime(automationEvent) {
          if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) {
            return automationEvent.cancelTime;
          }

          if (isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent)) {
            return automationEvent.endTime;
          }

          return automationEvent.startTime;
        };

        var getExponentialRampValueAtTime = function getExponentialRampValueAtTime(time, startTime, valueAtStartTime, _ref) {
          var endTime = _ref.endTime,
              value = _ref.value;

          if (valueAtStartTime === value) {
            return value;
          }

          if (0 < valueAtStartTime && 0 < value || valueAtStartTime < 0 && value < 0) {
            return valueAtStartTime * Math.pow(value / valueAtStartTime, (time - startTime) / (endTime - startTime));
          }

          return 0;
        };

        var getLinearRampValueAtTime = function getLinearRampValueAtTime(time, startTime, valueAtStartTime, _ref) {
          var endTime = _ref.endTime,
              value = _ref.value;
          return valueAtStartTime + (time - startTime) / (endTime - startTime) * (value - valueAtStartTime);
        };

        var interpolateValue = function interpolateValue(values, theoreticIndex) {
          var lowerIndex = Math.floor(theoreticIndex);
          var upperIndex = Math.ceil(theoreticIndex);

          if (lowerIndex === upperIndex) {
            return values[lowerIndex];
          }

          return (1 - (theoreticIndex - lowerIndex)) * values[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * values[upperIndex];
        };

        var getValueCurveValueAtTime = function getValueCurveValueAtTime(time, _ref) {
          var duration = _ref.duration,
              startTime = _ref.startTime,
              values = _ref.values;
          var theoreticIndex = (time - startTime) / duration * (values.length - 1);
          return interpolateValue(values, theoreticIndex);
        };

        var isSetTargetAutomationEvent = function isSetTargetAutomationEvent(automationEvent) {
          return automationEvent.type === 'setTarget';
        };

        var AutomationEventList = /*#__PURE__*/function () {
          function AutomationEventList(defaultValue) {
            _classCallCheck__default['default'](this, AutomationEventList);

            this._automationEvents = [];
            this._currenTime = 0;
            this._defaultValue = defaultValue;
          }

          _createClass__default['default'](AutomationEventList, [{
            key: Symbol.iterator,
            value: function value() {
              return this._automationEvents[Symbol.iterator]();
            }
          }, {
            key: "add",
            value: function add(automationEvent) {
              var eventTime = getEventTime(automationEvent);

              if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) {
                var index = this._automationEvents.findIndex(function (currentAutomationEvent) {
                  if (isCancelScheduledValuesAutomationEvent(automationEvent) && isSetValueCurveAutomationEvent(currentAutomationEvent)) {
                    return currentAutomationEvent.startTime + currentAutomationEvent.duration >= eventTime;
                  }

                  return getEventTime(currentAutomationEvent) >= eventTime;
                });

                var removedAutomationEvent = this._automationEvents[index];

                if (index !== -1) {
                  this._automationEvents = this._automationEvents.slice(0, index);
                }

                if (isCancelAndHoldAutomationEvent(automationEvent)) {
                  var lastAutomationEvent = this._automationEvents[this._automationEvents.length - 1];

                  if (removedAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(removedAutomationEvent)) {
                    if (isSetTargetAutomationEvent(lastAutomationEvent)) {
                      throw new Error('The internal list is malformed.');
                    }

                    var startTime = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.startTime + lastAutomationEvent.duration : getEventTime(lastAutomationEvent);
                    var startValue = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.values[lastAutomationEvent.values.length - 1] : lastAutomationEvent.value;
                    var value = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? getExponentialRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent) : getLinearRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent);
                    var truncatedAutomationEvent = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? createExtendedExponentialRampToValueAutomationEvent(value, eventTime, this._currenTime) : createExtendedLinearRampToValueAutomationEvent(value, eventTime, this._currenTime);

                    this._automationEvents.push(truncatedAutomationEvent);
                  }

                  if (lastAutomationEvent !== undefined && isSetTargetAutomationEvent(lastAutomationEvent)) {
                    this._automationEvents.push(createSetValueAutomationEvent(this.getValue(eventTime), eventTime));
                  }

                  if (lastAutomationEvent !== undefined && isSetValueCurveAutomationEvent(lastAutomationEvent) && lastAutomationEvent.startTime + lastAutomationEvent.duration > eventTime) {
                    this._automationEvents[this._automationEvents.length - 1] = createSetValueCurveAutomationEvent(new Float32Array([6, 7]), lastAutomationEvent.startTime, eventTime - lastAutomationEvent.startTime);
                  }
                }
              } else {
                var _index = this._automationEvents.findIndex(function (currentAutomationEvent) {
                  return getEventTime(currentAutomationEvent) > eventTime;
                });

                var previousAutomationEvent = _index === -1 ? this._automationEvents[this._automationEvents.length - 1] : this._automationEvents[_index - 1];

                if (previousAutomationEvent !== undefined && isSetValueCurveAutomationEvent(previousAutomationEvent) && getEventTime(previousAutomationEvent) + previousAutomationEvent.duration > eventTime) {
                  return false;
                }

                var persistentAutomationEvent = isExponentialRampToValueAutomationEvent(automationEvent) ? createExtendedExponentialRampToValueAutomationEvent(automationEvent.value, automationEvent.endTime, this._currenTime) : isLinearRampToValueAutomationEvent(automationEvent) ? createExtendedLinearRampToValueAutomationEvent(automationEvent.value, eventTime, this._currenTime) : automationEvent;

                if (_index === -1) {
                  this._automationEvents.push(persistentAutomationEvent);
                } else {
                  if (isSetValueCurveAutomationEvent(automationEvent) && eventTime + automationEvent.duration > getEventTime(this._automationEvents[_index])) {
                    return false;
                  }

                  this._automationEvents.splice(_index, 0, persistentAutomationEvent);
                }
              }

              return true;
            }
          }, {
            key: "flush",
            value: function flush(time) {
              var index = this._automationEvents.findIndex(function (currentAutomationEvent) {
                return getEventTime(currentAutomationEvent) > time;
              });

              if (index > 1) {
                var remainingAutomationEvents = this._automationEvents.slice(index - 1);

                var firstRemainingAutomationEvent = remainingAutomationEvents[0];

                if (isSetTargetAutomationEvent(firstRemainingAutomationEvent)) {
                  remainingAutomationEvents.unshift(createSetValueAutomationEvent(getValueOfAutomationEventAtIndexAtTime(this._automationEvents, index - 2, firstRemainingAutomationEvent.startTime, this._defaultValue), firstRemainingAutomationEvent.startTime));
                }

                this._automationEvents = remainingAutomationEvents;
              }
            }
          }, {
            key: "getValue",
            value: function getValue(time) {
              if (this._automationEvents.length === 0) {
                return this._defaultValue;
              }

              var lastAutomationEvent = this._automationEvents[this._automationEvents.length - 1];

              var index = this._automationEvents.findIndex(function (automationEvent) {
                return getEventTime(automationEvent) > time;
              });

              var nextAutomationEvent = this._automationEvents[index];
              var currentAutomationEvent = getEventTime(lastAutomationEvent) <= time ? lastAutomationEvent : this._automationEvents[index - 1];

              if (currentAutomationEvent !== undefined && isSetTargetAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || nextAutomationEvent.insertTime > time)) {
                return getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(this._automationEvents, index - 2, currentAutomationEvent.startTime, this._defaultValue), currentAutomationEvent);
              }

              if (currentAutomationEvent !== undefined && isSetValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) {
                return currentAutomationEvent.value;
              }

              if (currentAutomationEvent !== undefined && isSetValueCurveAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || currentAutomationEvent.startTime + currentAutomationEvent.duration > time)) {
                if (time < currentAutomationEvent.startTime + currentAutomationEvent.duration) {
                  return getValueCurveValueAtTime(time, currentAutomationEvent);
                }

                return currentAutomationEvent.values[currentAutomationEvent.values.length - 1];
              }

              if (currentAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) {
                return currentAutomationEvent.value;
              }

              if (nextAutomationEvent !== undefined && isExponentialRampToValueAutomationEvent(nextAutomationEvent)) {
                var _getEndTimeAndValueOf = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, index - 1, currentAutomationEvent, nextAutomationEvent, this._defaultValue),
                    _getEndTimeAndValueOf2 = _slicedToArray__default['default'](_getEndTimeAndValueOf, 2),
                    startTime = _getEndTimeAndValueOf2[0],
                    value = _getEndTimeAndValueOf2[1];

                return getExponentialRampValueAtTime(time, startTime, value, nextAutomationEvent);
              }

              if (nextAutomationEvent !== undefined && isLinearRampToValueAutomationEvent(nextAutomationEvent)) {
                var _getEndTimeAndValueOf3 = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, index - 1, currentAutomationEvent, nextAutomationEvent, this._defaultValue),
                    _getEndTimeAndValueOf4 = _slicedToArray__default['default'](_getEndTimeAndValueOf3, 2),
                    _startTime = _getEndTimeAndValueOf4[0],
                    _value = _getEndTimeAndValueOf4[1];

                return getLinearRampValueAtTime(time, _startTime, _value, nextAutomationEvent);
              }

              return this._defaultValue;
            }
          }]);

          return AutomationEventList;
        }();

        var createCancelAndHoldAutomationEvent = function createCancelAndHoldAutomationEvent(cancelTime) {
          return {
            cancelTime: cancelTime,
            type: 'cancelAndHold'
          };
        };

        var createCancelScheduledValuesAutomationEvent = function createCancelScheduledValuesAutomationEvent(cancelTime) {
          return {
            cancelTime: cancelTime,
            type: 'cancelScheduledValues'
          };
        };

        var createExponentialRampToValueAutomationEvent = function createExponentialRampToValueAutomationEvent(value, endTime) {
          return {
            endTime: endTime,
            type: 'exponentialRampToValue',
            value: value
          };
        };

        var createLinearRampToValueAutomationEvent = function createLinearRampToValueAutomationEvent(value, endTime) {
          return {
            endTime: endTime,
            type: 'linearRampToValue',
            value: value
          };
        };

        var createSetTargetAutomationEvent = function createSetTargetAutomationEvent(target, startTime, timeConstant) {
          return {
            startTime: startTime,
            target: target,
            timeConstant: timeConstant,
            type: 'setTarget'
          };
        };

        exports.AutomationEventList = AutomationEventList;
        exports.createCancelAndHoldAutomationEvent = createCancelAndHoldAutomationEvent;
        exports.createCancelScheduledValuesAutomationEvent = createCancelScheduledValuesAutomationEvent;
        exports.createExponentialRampToValueAutomationEvent = createExponentialRampToValueAutomationEvent;
        exports.createLinearRampToValueAutomationEvent = createLinearRampToValueAutomationEvent;
        exports.createSetTargetAutomationEvent = createSetTargetAutomationEvent;
        exports.createSetValueAutomationEvent = createSetValueAutomationEvent;
        exports.createSetValueCurveAutomationEvent = createSetValueCurveAutomationEvent;

        Object.defineProperty(exports, '__esModule', { value: true });

    })));
    });

    const createAbortError = () => new DOMException('', 'AbortError');

    const createAddActiveInputConnectionToAudioNode = (insertElementInSet) => {
        return (activeInputs, source, [output, input, eventListener], ignoreDuplicates) => {
            insertElementInSet(activeInputs[input], [source, output, eventListener], (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output, ignoreDuplicates);
        };
    };

    const createAddAudioNodeConnections = (audioNodeConnectionsStore) => {
        return (audioNode, audioNodeRenderer, nativeAudioNode) => {
            const activeInputs = [];
            for (let i = 0; i < nativeAudioNode.numberOfInputs; i += 1) {
                activeInputs.push(new Set());
            }
            audioNodeConnectionsStore.set(audioNode, {
                activeInputs,
                outputs: new Set(),
                passiveInputs: new WeakMap(),
                renderer: audioNodeRenderer
            });
        };
    };

    const createAddAudioParamConnections = (audioParamConnectionsStore) => {
        return (audioParam, audioParamRenderer) => {
            audioParamConnectionsStore.set(audioParam, { activeInputs: new Set(), passiveInputs: new WeakMap(), renderer: audioParamRenderer });
        };
    };

    const ACTIVE_AUDIO_NODE_STORE = new WeakSet();
    const AUDIO_NODE_CONNECTIONS_STORE = new WeakMap();
    const AUDIO_NODE_STORE = new WeakMap();
    const AUDIO_PARAM_CONNECTIONS_STORE = new WeakMap();
    const AUDIO_PARAM_STORE = new WeakMap();
    const CONTEXT_STORE = new WeakMap();
    const EVENT_LISTENERS = new WeakMap();
    const CYCLE_COUNTERS = new WeakMap();
    // This clunky name is borrowed from the spec. :-)
    const NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS = new WeakMap();
    const NODE_TO_PROCESSOR_MAPS = new WeakMap();

    const handler = {
        construct() {
            return handler;
        }
    };
    const isConstructible = (constructible) => {
        try {
            const proxy = new Proxy(constructible, handler);
            new proxy(); // tslint:disable-line:no-unused-expression
        }
        catch {
            return false;
        }
        return true;
    };

    /*
     * This massive regex tries to cover all the following cases.
     *
     * import './path';
     * import defaultImport from './path';
     * import { namedImport } from './path';
     * import { namedImport as renamendImport } from './path';
     * import * as namespaceImport from './path';
     * import defaultImport, { namedImport } from './path';
     * import defaultImport, { namedImport as renamendImport } from './path';
     * import defaultImport, * as namespaceImport from './path';
     */
    const IMPORT_STATEMENT_REGEX = /^import(?:(?:[\s]+[\w]+|(?:[\s]+[\w]+[\s]*,)?[\s]*\{[\s]*[\w]+(?:[\s]+as[\s]+[\w]+)?(?:[\s]*,[\s]*[\w]+(?:[\s]+as[\s]+[\w]+)?)*[\s]*}|(?:[\s]+[\w]+[\s]*,)?[\s]*\*[\s]+as[\s]+[\w]+)[\s]+from)?(?:[\s]*)("([^"\\]|\\.)+"|'([^'\\]|\\.)+')(?:[\s]*);?/; // tslint:disable-line:max-line-length
    const splitImportStatements = (source, url) => {
        const importStatements = [];
        let sourceWithoutImportStatements = source.replace(/^[\s]+/, '');
        let result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);
        while (result !== null) {
            const unresolvedUrl = result[1].slice(1, -1);
            const importStatementWithResolvedUrl = result[0]
                .replace(/([\s]+)?;?$/, '')
                .replace(unresolvedUrl, new URL(unresolvedUrl, url).toString());
            importStatements.push(importStatementWithResolvedUrl);
            sourceWithoutImportStatements = sourceWithoutImportStatements.slice(result[0].length).replace(/^[\s]+/, '');
            result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);
        }
        return [importStatements.join(';'), sourceWithoutImportStatements];
    };

    const verifyParameterDescriptors = (parameterDescriptors) => {
        if (parameterDescriptors !== undefined && !Array.isArray(parameterDescriptors)) {
            throw new TypeError('The parameterDescriptors property of given value for processorCtor is not an array.');
        }
    };
    const verifyProcessorCtor = (processorCtor) => {
        if (!isConstructible(processorCtor)) {
            throw new TypeError('The given value for processorCtor should be a constructor.');
        }
        if (processorCtor.prototype === null || typeof processorCtor.prototype !== 'object') {
            throw new TypeError('The given value for processorCtor should have a prototype.');
        }
    };
    const createAddAudioWorkletModule = (cacheTestResult, createNotSupportedError, evaluateSource, exposeCurrentFrameAndCurrentTime, fetchSource, getNativeContext, getOrCreateBackupOfflineAudioContext, isNativeOfflineAudioContext, ongoingRequests, resolvedRequests, testAudioWorkletProcessorPostMessageSupport, window) => {
        return (context, moduleURL, options = { credentials: 'omit' }) => {
            const nativeContext = getNativeContext(context);
            const absoluteUrl = new URL(moduleURL, window.location.href).toString();
            // Bug #59: Safari does not implement the audioWorklet property.
            if (nativeContext.audioWorklet !== undefined) {
                return Promise.all([
                    fetchSource(moduleURL),
                    Promise.resolve(cacheTestResult(testAudioWorkletProcessorPostMessageSupport, testAudioWorkletProcessorPostMessageSupport))
                ]).then(([source, isSupportingPostMessage]) => {
                    const [importStatements, sourceWithoutImportStatements] = splitImportStatements(source, absoluteUrl);
                    /*
                     * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.
                     *
                     * This is the unminified version of the code used below.
                     *
                     * ```js
                     * class extends AudioWorkletProcessor {
                     *
                     *     __buffers = new WeakSet();
                     *
                     *     constructor () {
                     *         super();
                     *
                     *         this.port.postMessage = ((postMessage) => {
                     *             return (message, transferables) => {
                     *                 const filteredTransferables = (transferables)
                     *                     ? transferables.filter((transferable) => !this.__buffers.has(transferable))
                     *                     : transferables;
                     *
                     *                 return postMessage.call(this.port, message, filteredTransferables);
                     *              };
                     *         })(this.port.postMessage);
                     *     }
                     * }
                     * ```
                     */
                    const patchedSourceWithoutImportStatements = isSupportingPostMessage
                        ? sourceWithoutImportStatements
                        : sourceWithoutImportStatements.replace(/\s+extends\s+AudioWorkletProcessor\s*{/, ` extends (class extends AudioWorkletProcessor {__b=new WeakSet();constructor(){super();(p=>p.postMessage=(q=>(m,t)=>q.call(p,m,t?t.filter(u=>!this.__b.has(u)):t))(p.postMessage))(this.port)}}){`);
                    /*
                     * Bug #170: Chrome and Edge do call process() with an array with empty channelData for each input if no input is connected.
                     *
                     * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.
                     *
                     * This is the unminified version of the code used below:
                     *
                     * ```js
                     * `${ importStatements };
                     * ((registerProcessor) => {${ sourceWithoutImportStatements }
                     * })((name, processorCtor) => registerProcessor(name, class extends processorCtor {
                     *
                     *     __collectBuffers = (array) => {
                     *         array.forEach((element) => this.__buffers.add(element.buffer));
                     *     };
                     *
                     *     process (inputs, outputs, parameters) {
                     *         inputs.forEach(this.__collectBuffers);
                     *         outputs.forEach(this.__collectBuffers);
                     *         this.__collectBuffers(Object.values(parameters));
                     *
                     *         return super.process(
                     *             (inputs.map((input) => input.some((channelData) => channelData.length === 0)) ? [ ] : input),
                     *             outputs,
                     *             parameters
                     *         );
                     *     }
                     *
                     * }))`
                     * ```
                     */
                    const memberDefinition = isSupportingPostMessage ? '' : '__c = (a) => a.forEach(e=>this.__b.add(e.buffer));';
                    const bufferRegistration = isSupportingPostMessage
                        ? ''
                        : 'i.forEach(this.__c);o.forEach(this.__c);this.__c(Object.values(p));';
                    const wrappedSource = `${importStatements};(registerProcessor=>{${patchedSourceWithoutImportStatements}
})((n,p)=>registerProcessor(n,class extends p{${memberDefinition}process(i,o,p){${bufferRegistration}return super.process(i.map(j=>j.some(k=>k.length===0)?[]:j),o,p)}}))`;
                    const blob = new Blob([wrappedSource], { type: 'application/javascript; charset=utf-8' });
                    const url = URL.createObjectURL(blob);
                    return nativeContext.audioWorklet
                        .addModule(url, options)
                        .then(() => {
                        if (isNativeOfflineAudioContext(nativeContext)) {
                            return;
                        }
                        // Bug #186: Chrome, Edge and Opera do not allow to create an AudioWorkletNode on a closed AudioContext.
                        const backupOfflineAudioContext = getOrCreateBackupOfflineAudioContext(nativeContext);
                        return backupOfflineAudioContext.audioWorklet.addModule(url, options);
                    })
                        .finally(() => URL.revokeObjectURL(url));
                });
            }
            const resolvedRequestsOfContext = resolvedRequests.get(context);
            if (resolvedRequestsOfContext !== undefined && resolvedRequestsOfContext.has(moduleURL)) {
                return Promise.resolve();
            }
            const ongoingRequestsOfContext = ongoingRequests.get(context);
            if (ongoingRequestsOfContext !== undefined) {
                const promiseOfOngoingRequest = ongoingRequestsOfContext.get(moduleURL);
                if (promiseOfOngoingRequest !== undefined) {
                    return promiseOfOngoingRequest;
                }
            }
            const promise = fetchSource(moduleURL)
                .then((source) => {
                const [importStatements, sourceWithoutImportStatements] = splitImportStatements(source, absoluteUrl);
                /*
                 * This is the unminified version of the code used below:
                 *
                 * ```js
                 * ${ importStatements };
                 * ((a, b) => {
                 *     (a[b] = a[b] || [ ]).push(
                 *         (AudioWorkletProcessor, global, registerProcessor, sampleRate, self, window) => {
                 *             ${ sourceWithoutImportStatements }
                 *         }
                 *     );
                 * })(window, '_AWGS');
                 * ```
                 */
                // tslint:disable-next-line:max-line-length
                const wrappedSource = `${importStatements};((a,b)=>{(a[b]=a[b]||[]).push((AudioWorkletProcessor,global,registerProcessor,sampleRate,self,window)=>{${sourceWithoutImportStatements}
})})(window,'_AWGS')`;
                // @todo Evaluating the given source code is a possible security problem.
                return evaluateSource(wrappedSource);
            })
                .then(() => {
                const evaluateAudioWorkletGlobalScope = window._AWGS.pop();
                if (evaluateAudioWorkletGlobalScope === undefined) {
                    // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
                    throw new SyntaxError();
                }
                exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, () => evaluateAudioWorkletGlobalScope(class AudioWorkletProcessor {
                }, undefined, (name, processorCtor) => {
                    if (name.trim() === '') {
                        throw createNotSupportedError();
                    }
                    const nodeNameToProcessorConstructorMap = NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.get(nativeContext);
                    if (nodeNameToProcessorConstructorMap !== undefined) {
                        if (nodeNameToProcessorConstructorMap.has(name)) {
                            throw createNotSupportedError();
                        }
                        verifyProcessorCtor(processorCtor);
                        verifyParameterDescriptors(processorCtor.parameterDescriptors);
                        nodeNameToProcessorConstructorMap.set(name, processorCtor);
                    }
                    else {
                        verifyProcessorCtor(processorCtor);
                        verifyParameterDescriptors(processorCtor.parameterDescriptors);
                        NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.set(nativeContext, new Map([[name, processorCtor]]));
                    }
                }, nativeContext.sampleRate, undefined, undefined));
            });
            if (ongoingRequestsOfContext === undefined) {
                ongoingRequests.set(context, new Map([[moduleURL, promise]]));
            }
            else {
                ongoingRequestsOfContext.set(moduleURL, promise);
            }
            promise
                .then(() => {
                const rslvdRqstsFCntxt = resolvedRequests.get(context);
                if (rslvdRqstsFCntxt === undefined) {
                    resolvedRequests.set(context, new Set([moduleURL]));
                }
                else {
                    rslvdRqstsFCntxt.add(moduleURL);
                }
            })
                .finally(() => {
                const ngngRqstsFCntxt = ongoingRequests.get(context);
                if (ngngRqstsFCntxt !== undefined) {
                    ngngRqstsFCntxt.delete(moduleURL);
                }
            });
            return promise;
        };
    };

    const getValueForKey = (map, key) => {
        const value = map.get(key);
        if (value === undefined) {
            throw new Error('A value with the given key could not be found.');
        }
        return value;
    };

    const pickElementFromSet = (set, predicate) => {
        const matchingElements = Array.from(set).filter(predicate);
        if (matchingElements.length > 1) {
            throw Error('More than one element was found.');
        }
        if (matchingElements.length === 0) {
            throw Error('No element was found.');
        }
        const [matchingElement] = matchingElements;
        set.delete(matchingElement);
        return matchingElement;
    };

    const deletePassiveInputConnectionToAudioNode = (passiveInputs, source, output, input) => {
        const passiveInputConnections = getValueForKey(passiveInputs, source);
        const matchingConnection = pickElementFromSet(passiveInputConnections, (passiveInputConnection) => passiveInputConnection[0] === output && passiveInputConnection[1] === input);
        if (passiveInputConnections.size === 0) {
            passiveInputs.delete(source);
        }
        return matchingConnection;
    };

    const getEventListenersOfAudioNode = (audioNode) => {
        return getValueForKey(EVENT_LISTENERS, audioNode);
    };

    const setInternalStateToActive = (audioNode) => {
        if (ACTIVE_AUDIO_NODE_STORE.has(audioNode)) {
            throw new Error('The AudioNode is already stored.');
        }
        ACTIVE_AUDIO_NODE_STORE.add(audioNode);
        getEventListenersOfAudioNode(audioNode).forEach((eventListener) => eventListener(true));
    };

    const isAudioWorkletNode = (audioNode) => {
        return 'port' in audioNode;
    };

    const setInternalStateToPassive = (audioNode) => {
        if (!ACTIVE_AUDIO_NODE_STORE.has(audioNode)) {
            throw new Error('The AudioNode is not stored.');
        }
        ACTIVE_AUDIO_NODE_STORE.delete(audioNode);
        getEventListenersOfAudioNode(audioNode).forEach((eventListener) => eventListener(false));
    };

    // Set the internalState of the audioNode to 'passive' if it is not an AudioWorkletNode and if it has no 'active' input connections.
    const setInternalStateToPassiveWhenNecessary = (audioNode, activeInputs) => {
        if (!isAudioWorkletNode(audioNode) && activeInputs.every((connections) => connections.size === 0)) {
            setInternalStateToPassive(audioNode);
        }
    };

    const createAddConnectionToAudioNode = (addActiveInputConnectionToAudioNode, addPassiveInputConnectionToAudioNode, connectNativeAudioNodeToNativeAudioNode, deleteActiveInputConnectionToAudioNode, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getAudioNodeTailTime, getEventListenersOfAudioNode, getNativeAudioNode, insertElementInSet, isActiveAudioNode, isPartOfACycle, isPassiveAudioNode) => {
        return (source, destination, output, input, isOffline) => {
            const { activeInputs, passiveInputs } = getAudioNodeConnections(destination);
            const { outputs } = getAudioNodeConnections(source);
            const eventListeners = getEventListenersOfAudioNode(source);
            const eventListener = (isActive) => {
                const nativeDestinationAudioNode = getNativeAudioNode(destination);
                const nativeSourceAudioNode = getNativeAudioNode(source);
                if (isActive) {
                    const partialConnection = deletePassiveInputConnectionToAudioNode(passiveInputs, source, output, input);
                    addActiveInputConnectionToAudioNode(activeInputs, source, partialConnection, false);
                    if (!isOffline && !isPartOfACycle(source)) {
                        connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);
                    }
                    if (isPassiveAudioNode(destination)) {
                        setInternalStateToActive(destination);
                    }
                }
                else {
                    const partialConnection = deleteActiveInputConnectionToAudioNode(activeInputs, source, output, input);
                    addPassiveInputConnectionToAudioNode(passiveInputs, input, partialConnection, false);
                    if (!isOffline && !isPartOfACycle(source)) {
                        disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);
                    }
                    const tailTime = getAudioNodeTailTime(destination);
                    if (tailTime === 0) {
                        if (isActiveAudioNode(destination)) {
                            setInternalStateToPassiveWhenNecessary(destination, activeInputs);
                        }
                    }
                    else {
                        setTimeout(() => {
                            if (isActiveAudioNode(destination)) {
                                setInternalStateToPassiveWhenNecessary(destination, activeInputs);
                            }
                        }, tailTime * 1000);
                    }
                }
            };
            if (insertElementInSet(outputs, [destination, output, input], (outputConnection) => outputConnection[0] === destination && outputConnection[1] === output && outputConnection[2] === input, true)) {
                eventListeners.add(eventListener);
                if (isActiveAudioNode(source)) {
                    addActiveInputConnectionToAudioNode(activeInputs, source, [output, input, eventListener], true);
                }
                else {
                    addPassiveInputConnectionToAudioNode(passiveInputs, input, [source, output, eventListener], true);
                }
                return true;
            }
            return false;
        };
    };

    const createAddPassiveInputConnectionToAudioNode = (insertElementInSet) => {
        return (passiveInputs, input, [source, output, eventListener], ignoreDuplicates) => {
            const passiveInputConnections = passiveInputs.get(source);
            if (passiveInputConnections === undefined) {
                passiveInputs.set(source, new Set([[output, input, eventListener]]));
            }
            else {
                insertElementInSet(passiveInputConnections, [output, input, eventListener], (passiveInputConnection) => passiveInputConnection[0] === output && passiveInputConnection[1] === input, ignoreDuplicates);
            }
        };
    };

    const createAddSilentConnection = (createNativeGainNode) => {
        return (nativeContext, nativeAudioScheduledSourceNode) => {
            const nativeGainNode = createNativeGainNode(nativeContext, {
                channelCount: 1,
                channelCountMode: 'explicit',
                channelInterpretation: 'discrete',
                gain: 0
            });
            nativeAudioScheduledSourceNode.connect(nativeGainNode).connect(nativeContext.destination);
            const disconnect = () => {
                nativeAudioScheduledSourceNode.removeEventListener('ended', disconnect);
                nativeAudioScheduledSourceNode.disconnect(nativeGainNode);
                nativeGainNode.disconnect();
            };
            nativeAudioScheduledSourceNode.addEventListener('ended', disconnect);
        };
    };

    const createAddUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes) => {
        return (nativeContext, audioWorkletNode) => {
            getUnrenderedAudioWorkletNodes(nativeContext).add(audioWorkletNode);
        };
    };

    const DEFAULT_OPTIONS = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        fftSize: 2048,
        maxDecibels: -30,
        minDecibels: -100,
        smoothingTimeConstant: 0.8
    };
    const createAnalyserNodeConstructor = (audionNodeConstructor, createAnalyserNodeRenderer, createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext) => {
        return class AnalyserNode extends audionNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS, ...options };
                const nativeAnalyserNode = createNativeAnalyserNode(nativeContext, mergedOptions);
                const analyserNodeRenderer = ((isNativeOfflineAudioContext(nativeContext) ? createAnalyserNodeRenderer() : null));
                super(context, false, nativeAnalyserNode, analyserNodeRenderer);
                this._nativeAnalyserNode = nativeAnalyserNode;
            }
            get fftSize() {
                return this._nativeAnalyserNode.fftSize;
            }
            set fftSize(value) {
                this._nativeAnalyserNode.fftSize = value;
            }
            get frequencyBinCount() {
                return this._nativeAnalyserNode.frequencyBinCount;
            }
            get maxDecibels() {
                return this._nativeAnalyserNode.maxDecibels;
            }
            set maxDecibels(value) {
                // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
                const maxDecibels = this._nativeAnalyserNode.maxDecibels;
                this._nativeAnalyserNode.maxDecibels = value;
                if (!(value > this._nativeAnalyserNode.minDecibels)) {
                    this._nativeAnalyserNode.maxDecibels = maxDecibels;
                    throw createIndexSizeError();
                }
            }
            get minDecibels() {
                return this._nativeAnalyserNode.minDecibels;
            }
            set minDecibels(value) {
                // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
                const minDecibels = this._nativeAnalyserNode.minDecibels;
                this._nativeAnalyserNode.minDecibels = value;
                if (!(this._nativeAnalyserNode.maxDecibels > value)) {
                    this._nativeAnalyserNode.minDecibels = minDecibels;
                    throw createIndexSizeError();
                }
            }
            get smoothingTimeConstant() {
                return this._nativeAnalyserNode.smoothingTimeConstant;
            }
            set smoothingTimeConstant(value) {
                this._nativeAnalyserNode.smoothingTimeConstant = value;
            }
            getByteFrequencyData(array) {
                this._nativeAnalyserNode.getByteFrequencyData(array);
            }
            getByteTimeDomainData(array) {
                this._nativeAnalyserNode.getByteTimeDomainData(array);
            }
            getFloatFrequencyData(array) {
                this._nativeAnalyserNode.getFloatFrequencyData(array);
            }
            getFloatTimeDomainData(array) {
                this._nativeAnalyserNode.getFloatTimeDomainData(array);
            }
        };
    };

    const isOwnedByContext = (nativeAudioNode, nativeContext) => {
        return nativeAudioNode.context === nativeContext;
    };

    const createAnalyserNodeRendererFactory = (createNativeAnalyserNode, getNativeAudioNode, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeAnalyserNodes = new WeakMap();
            const createAnalyserNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeAnalyserNode = getNativeAudioNode(proxy);
                // If the initially used nativeAnalyserNode was not constructed on the same OfflineAudioContext it needs to be created again.
                const nativeAnalyserNodeIsOwnedByContext = isOwnedByContext(nativeAnalyserNode, nativeOfflineAudioContext);
                if (!nativeAnalyserNodeIsOwnedByContext) {
                    const options = {
                        channelCount: nativeAnalyserNode.channelCount,
                        channelCountMode: nativeAnalyserNode.channelCountMode,
                        channelInterpretation: nativeAnalyserNode.channelInterpretation,
                        fftSize: nativeAnalyserNode.fftSize,
                        maxDecibels: nativeAnalyserNode.maxDecibels,
                        minDecibels: nativeAnalyserNode.minDecibels,
                        smoothingTimeConstant: nativeAnalyserNode.smoothingTimeConstant
                    };
                    nativeAnalyserNode = createNativeAnalyserNode(nativeOfflineAudioContext, options);
                }
                renderedNativeAnalyserNodes.set(nativeOfflineAudioContext, nativeAnalyserNode);
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAnalyserNode, trace);
                return nativeAnalyserNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeAnalyserNode = renderedNativeAnalyserNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeAnalyserNode !== undefined) {
                        return Promise.resolve(renderedNativeAnalyserNode);
                    }
                    return createAnalyserNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const testAudioBufferCopyChannelMethodsOutOfBoundsSupport = (nativeAudioBuffer) => {
        try {
            nativeAudioBuffer.copyToChannel(new Float32Array(1), 0, -1);
        }
        catch {
            return false;
        }
        return true;
    };

    const createIndexSizeError = () => new DOMException('', 'IndexSizeError');

    const wrapAudioBufferGetChannelDataMethod = (audioBuffer) => {
        audioBuffer.getChannelData = ((getChannelData) => {
            return (channel) => {
                try {
                    return getChannelData.call(audioBuffer, channel);
                }
                catch (err) {
                    if (err.code === 12) {
                        throw createIndexSizeError();
                    }
                    throw err;
                }
            };
        })(audioBuffer.getChannelData);
    };

    const DEFAULT_OPTIONS$1 = {
        numberOfChannels: 1
    };
    const createAudioBufferConstructor = (audioBufferStore, cacheTestResult, createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, testNativeAudioBufferConstructorSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {
        let nativeOfflineAudioContext = null;
        return class AudioBuffer {
            constructor(options) {
                if (nativeOfflineAudioContextConstructor === null) {
                    throw new Error('Missing the native OfflineAudioContext constructor.');
                }
                const { length, numberOfChannels, sampleRate } = { ...DEFAULT_OPTIONS$1, ...options };
                if (nativeOfflineAudioContext === null) {
                    nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
                }
                /*
                 * Bug #99: Firefox does not throw a NotSupportedError when the numberOfChannels is zero. But it only does it when using the
                 * factory function. But since Firefox also supports the constructor everything should be fine.
                 */
                const audioBuffer = nativeAudioBufferConstructor !== null &&
                    cacheTestResult(testNativeAudioBufferConstructorSupport, testNativeAudioBufferConstructorSupport)
                    ? new nativeAudioBufferConstructor({ length, numberOfChannels, sampleRate })
                    : nativeOfflineAudioContext.createBuffer(numberOfChannels, length, sampleRate);
                // Bug #99: Safari does not throw an error when the numberOfChannels is zero.
                if (audioBuffer.numberOfChannels === 0) {
                    throw createNotSupportedError();
                }
                // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
                // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
                if (typeof audioBuffer.copyFromChannel !== 'function') {
                    wrapAudioBufferCopyChannelMethods(audioBuffer);
                    wrapAudioBufferGetChannelDataMethod(audioBuffer);
                    // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
                }
                else if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) {
                    wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
                }
                audioBufferStore.add(audioBuffer);
                /*
                 * This does violate all good pratices but it is necessary to allow this AudioBuffer to be used with native
                 * (Offline)AudioContexts.
                 */
                return audioBuffer;
            }
            static [Symbol.hasInstance](instance) {
                return ((instance !== null && typeof instance === 'object' && Object.getPrototypeOf(instance) === AudioBuffer.prototype) ||
                    audioBufferStore.has(instance));
            }
        };
    };

    const MOST_NEGATIVE_SINGLE_FLOAT = -3.4028234663852886e38;
    const MOST_POSITIVE_SINGLE_FLOAT = -MOST_NEGATIVE_SINGLE_FLOAT;

    const isActiveAudioNode = (audioNode) => ACTIVE_AUDIO_NODE_STORE.has(audioNode);

    const DEFAULT_OPTIONS$2 = {
        buffer: null,
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        // Bug #149: Safari does not yet support the detune AudioParam.
        loop: false,
        loopEnd: 0,
        loopStart: 0,
        playbackRate: 1
    };
    const createAudioBufferSourceNodeConstructor = (audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {
        return class AudioBufferSourceNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$2, ...options };
                const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, mergedOptions);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const audioBufferSourceNodeRenderer = ((isOffline ? createAudioBufferSourceNodeRenderer() : null));
                super(context, false, nativeAudioBufferSourceNode, audioBufferSourceNodeRenderer);
                this._audioBufferSourceNodeRenderer = audioBufferSourceNodeRenderer;
                this._isBufferNullified = false;
                this._isBufferSet = mergedOptions.buffer !== null;
                this._nativeAudioBufferSourceNode = nativeAudioBufferSourceNode;
                this._onended = null;
                // Bug #73: Safari does not export the correct values for maxValue and minValue.
                this._playbackRate = createAudioParam(this, isOffline, nativeAudioBufferSourceNode.playbackRate, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);
            }
            get buffer() {
                if (this._isBufferNullified) {
                    return null;
                }
                return this._nativeAudioBufferSourceNode.buffer;
            }
            set buffer(value) {
                this._nativeAudioBufferSourceNode.buffer = value;
                // Bug #72: Only Chrome, Edge & Opera do not allow to reassign the buffer yet.
                if (value !== null) {
                    if (this._isBufferSet) {
                        throw createInvalidStateError();
                    }
                    this._isBufferSet = true;
                }
            }
            get loop() {
                return this._nativeAudioBufferSourceNode.loop;
            }
            set loop(value) {
                this._nativeAudioBufferSourceNode.loop = value;
            }
            get loopEnd() {
                return this._nativeAudioBufferSourceNode.loopEnd;
            }
            set loopEnd(value) {
                this._nativeAudioBufferSourceNode.loopEnd = value;
            }
            get loopStart() {
                return this._nativeAudioBufferSourceNode.loopStart;
            }
            set loopStart(value) {
                this._nativeAudioBufferSourceNode.loopStart = value;
            }
            get onended() {
                return this._onended;
            }
            set onended(value) {
                const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;
                this._nativeAudioBufferSourceNode.onended = wrappedListener;
                const nativeOnEnded = this._nativeAudioBufferSourceNode.onended;
                this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
            }
            get playbackRate() {
                return this._playbackRate;
            }
            start(when = 0, offset = 0, duration) {
                this._nativeAudioBufferSourceNode.start(when, offset, duration);
                if (this._audioBufferSourceNodeRenderer !== null) {
                    this._audioBufferSourceNodeRenderer.start = duration === undefined ? [when, offset] : [when, offset, duration];
                }
                if (this.context.state !== 'closed') {
                    setInternalStateToActive(this);
                    const resetInternalStateToPassive = () => {
                        this._nativeAudioBufferSourceNode.removeEventListener('ended', resetInternalStateToPassive);
                        if (isActiveAudioNode(this)) {
                            setInternalStateToPassive(this);
                        }
                    };
                    this._nativeAudioBufferSourceNode.addEventListener('ended', resetInternalStateToPassive);
                }
            }
            stop(when = 0) {
                this._nativeAudioBufferSourceNode.stop(when);
                if (this._audioBufferSourceNodeRenderer !== null) {
                    this._audioBufferSourceNodeRenderer.stop = when;
                }
            }
        };
    };

    const createAudioBufferSourceNodeRendererFactory = (connectAudioParam, createNativeAudioBufferSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeAudioBufferSourceNodes = new WeakMap();
            let start = null;
            let stop = null;
            const createAudioBufferSourceNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeAudioBufferSourceNode = getNativeAudioNode(proxy);
                /*
                 * If the initially used nativeAudioBufferSourceNode was not constructed on the same OfflineAudioContext it needs to be created
                 * again.
                 */
                const nativeAudioBufferSourceNodeIsOwnedByContext = isOwnedByContext(nativeAudioBufferSourceNode, nativeOfflineAudioContext);
                if (!nativeAudioBufferSourceNodeIsOwnedByContext) {
                    const options = {
                        buffer: nativeAudioBufferSourceNode.buffer,
                        channelCount: nativeAudioBufferSourceNode.channelCount,
                        channelCountMode: nativeAudioBufferSourceNode.channelCountMode,
                        channelInterpretation: nativeAudioBufferSourceNode.channelInterpretation,
                        // Bug #149: Safari does not yet support the detune AudioParam.
                        loop: nativeAudioBufferSourceNode.loop,
                        loopEnd: nativeAudioBufferSourceNode.loopEnd,
                        loopStart: nativeAudioBufferSourceNode.loopStart,
                        playbackRate: nativeAudioBufferSourceNode.playbackRate.value
                    };
                    nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, options);
                    if (start !== null) {
                        nativeAudioBufferSourceNode.start(...start);
                    }
                    if (stop !== null) {
                        nativeAudioBufferSourceNode.stop(stop);
                    }
                }
                renderedNativeAudioBufferSourceNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode);
                if (!nativeAudioBufferSourceNodeIsOwnedByContext) {
                    // Bug #149: Safari does not yet support the detune AudioParam.
                    await renderAutomation(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate, trace);
                }
                else {
                    // Bug #149: Safari does not yet support the detune AudioParam.
                    await connectAudioParam(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate, trace);
                }
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioBufferSourceNode, trace);
                return nativeAudioBufferSourceNode;
            };
            return {
                set start(value) {
                    start = value;
                },
                set stop(value) {
                    stop = value;
                },
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeAudioBufferSourceNode = renderedNativeAudioBufferSourceNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeAudioBufferSourceNode !== undefined) {
                        return Promise.resolve(renderedNativeAudioBufferSourceNode);
                    }
                    return createAudioBufferSourceNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const isAudioBufferSourceNode = (audioNode) => {
        return 'playbackRate' in audioNode;
    };

    const isBiquadFilterNode = (audioNode) => {
        return 'frequency' in audioNode && 'gain' in audioNode;
    };

    const isConstantSourceNode = (audioNode) => {
        return 'offset' in audioNode;
    };

    const isGainNode = (audioNode) => {
        return !('frequency' in audioNode) && 'gain' in audioNode;
    };

    const isOscillatorNode = (audioNode) => {
        return 'detune' in audioNode && 'frequency' in audioNode;
    };

    const isStereoPannerNode = (audioNode) => {
        return 'pan' in audioNode;
    };

    const getAudioNodeConnections = (audioNode) => {
        return getValueForKey(AUDIO_NODE_CONNECTIONS_STORE, audioNode);
    };

    const getAudioParamConnections = (audioParam) => {
        return getValueForKey(AUDIO_PARAM_CONNECTIONS_STORE, audioParam);
    };

    const deactivateActiveAudioNodeInputConnections = (audioNode, trace) => {
        const { activeInputs } = getAudioNodeConnections(audioNode);
        activeInputs.forEach((connections) => connections.forEach(([source]) => {
            if (!trace.includes(audioNode)) {
                deactivateActiveAudioNodeInputConnections(source, [...trace, audioNode]);
            }
        }));
        const audioParams = isAudioBufferSourceNode(audioNode)
            ? [
                // Bug #149: Safari does not yet support the detune AudioParam.
                audioNode.playbackRate
            ]
            : isAudioWorkletNode(audioNode)
                ? Array.from(audioNode.parameters.values())
                : isBiquadFilterNode(audioNode)
                    ? [audioNode.Q, audioNode.detune, audioNode.frequency, audioNode.gain]
                    : isConstantSourceNode(audioNode)
                        ? [audioNode.offset]
                        : isGainNode(audioNode)
                            ? [audioNode.gain]
                            : isOscillatorNode(audioNode)
                                ? [audioNode.detune, audioNode.frequency]
                                : isStereoPannerNode(audioNode)
                                    ? [audioNode.pan]
                                    : [];
        for (const audioParam of audioParams) {
            const audioParamConnections = getAudioParamConnections(audioParam);
            if (audioParamConnections !== undefined) {
                audioParamConnections.activeInputs.forEach(([source]) => deactivateActiveAudioNodeInputConnections(source, trace));
            }
        }
        if (isActiveAudioNode(audioNode)) {
            setInternalStateToPassive(audioNode);
        }
    };

    const deactivateAudioGraph = (context) => {
        deactivateActiveAudioNodeInputConnections(context.destination, []);
    };

    const isValidLatencyHint = (latencyHint) => {
        return (latencyHint === undefined ||
            typeof latencyHint === 'number' ||
            (typeof latencyHint === 'string' && (latencyHint === 'balanced' || latencyHint === 'interactive' || latencyHint === 'playback')));
    };

    const createAudioContextConstructor = (baseAudioContextConstructor, createInvalidStateError, createNotSupportedError, createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor) => {
        return class AudioContext extends baseAudioContextConstructor {
            constructor(options = {}) {
                if (nativeAudioContextConstructor === null) {
                    throw new Error('Missing the native AudioContext constructor.');
                }
                const nativeAudioContext = new nativeAudioContextConstructor(options);
                // Bug #131 Safari returns null when there are four other AudioContexts running already.
                if (nativeAudioContext === null) {
                    throw createUnknownError();
                }
                // Bug #51 Only Chrome, Edge and Opera throw an error if the given latencyHint is invalid.
                if (!isValidLatencyHint(options.latencyHint)) {
                    throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);
                }
                // Bug #150 Safari does not support setting the sampleRate.
                if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) {
                    throw createNotSupportedError();
                }
                super(nativeAudioContext, 2);
                const { latencyHint } = options;
                const { sampleRate } = nativeAudioContext;
                // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.
                this._baseLatency =
                    typeof nativeAudioContext.baseLatency === 'number'
                        ? nativeAudioContext.baseLatency
                        : latencyHint === 'balanced'
                            ? 512 / sampleRate
                            : latencyHint === 'interactive' || latencyHint === undefined
                                ? 256 / sampleRate
                                : latencyHint === 'playback'
                                    ? 1024 / sampleRate
                                    : /*
                                       * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a
                                       * ScriptProcessorNode.
                                       */
                                        (Math.max(2, Math.min(128, Math.round((latencyHint * sampleRate) / 128))) * 128) / sampleRate;
                this._nativeAudioContext = nativeAudioContext;
                // Bug #188: Safari will set the context's state to 'interrupted' in case the user switches tabs.
                if (nativeAudioContextConstructor.name === 'webkitAudioContext') {
                    this._nativeGainNode = nativeAudioContext.createGain();
                    this._nativeOscillatorNode = nativeAudioContext.createOscillator();
                    this._nativeGainNode.gain.value = 1e-37;
                    this._nativeOscillatorNode.connect(this._nativeGainNode).connect(nativeAudioContext.destination);
                    this._nativeOscillatorNode.start();
                }
                else {
                    this._nativeGainNode = null;
                    this._nativeOscillatorNode = null;
                }
                this._state = null;
                /*
                 * Bug #34: Chrome, Edge and Opera pretend to be running right away, but fire an onstatechange event when the state actually
                 * changes to 'running'.
                 */
                if (nativeAudioContext.state === 'running') {
                    this._state = 'suspended';
                    const revokeState = () => {
                        if (this._state === 'suspended') {
                            this._state = null;
                        }
                        nativeAudioContext.removeEventListener('statechange', revokeState);
                    };
                    nativeAudioContext.addEventListener('statechange', revokeState);
                }
            }
            get baseLatency() {
                return this._baseLatency;
            }
            get state() {
                return this._state !== null ? this._state : this._nativeAudioContext.state;
            }
            close() {
                // Bug #35: Firefox does not throw an error if the AudioContext was closed before.
                if (this.state === 'closed') {
                    return this._nativeAudioContext.close().then(() => {
                        throw createInvalidStateError();
                    });
                }
                // Bug #34: If the state was set to suspended before it should be revoked now.
                if (this._state === 'suspended') {
                    this._state = null;
                }
                return this._nativeAudioContext.close().then(() => {
                    if (this._nativeGainNode !== null && this._nativeOscillatorNode !== null) {
                        this._nativeOscillatorNode.stop();
                        this._nativeGainNode.disconnect();
                        this._nativeOscillatorNode.disconnect();
                    }
                    deactivateAudioGraph(this);
                });
            }
            createMediaElementSource(mediaElement) {
                return new mediaElementAudioSourceNodeConstructor(this, { mediaElement });
            }
            createMediaStreamDestination() {
                return new mediaStreamAudioDestinationNodeConstructor(this);
            }
            createMediaStreamSource(mediaStream) {
                return new mediaStreamAudioSourceNodeConstructor(this, { mediaStream });
            }
            createMediaStreamTrackSource(mediaStreamTrack) {
                return new mediaStreamTrackAudioSourceNodeConstructor(this, { mediaStreamTrack });
            }
            resume() {
                if (this._state === 'suspended') {
                    return new Promise((resolve, reject) => {
                        const resolvePromise = () => {
                            this._nativeAudioContext.removeEventListener('statechange', resolvePromise);
                            if (this._nativeAudioContext.state === 'running') {
                                resolve();
                            }
                            else {
                                this.resume().then(resolve, reject);
                            }
                        };
                        this._nativeAudioContext.addEventListener('statechange', resolvePromise);
                    });
                }
                return this._nativeAudioContext.resume().catch((err) => {
                    // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.
                    // Bug #56: Safari invokes the catch handler but without an error.
                    if (err === undefined || err.code === 15) {
                        throw createInvalidStateError();
                    }
                    throw err;
                });
            }
            suspend() {
                return this._nativeAudioContext.suspend().catch((err) => {
                    // Bug #56: Safari invokes the catch handler but without an error.
                    if (err === undefined) {
                        throw createInvalidStateError();
                    }
                    throw err;
                });
            }
        };
    };

    const createAudioDestinationNodeConstructor = (audioNodeConstructor, createAudioDestinationNodeRenderer, createIndexSizeError, createInvalidStateError, createNativeAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode) => {
        return class AudioDestinationNode extends audioNodeConstructor {
            constructor(context, channelCount) {
                const nativeContext = getNativeContext(context);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const nativeAudioDestinationNode = createNativeAudioDestinationNode(nativeContext, channelCount, isOffline);
                const audioDestinationNodeRenderer = ((isOffline ? createAudioDestinationNodeRenderer(renderInputsOfAudioNode) : null));
                super(context, false, nativeAudioDestinationNode, audioDestinationNodeRenderer);
                this._isNodeOfNativeOfflineAudioContext = isOffline;
                this._nativeAudioDestinationNode = nativeAudioDestinationNode;
            }
            get channelCount() {
                return this._nativeAudioDestinationNode.channelCount;
            }
            set channelCount(value) {
                // Bug #52: Chrome, Edge, Opera & Safari do not throw an exception at all.
                // Bug #54: Firefox does throw an IndexSizeError.
                if (this._isNodeOfNativeOfflineAudioContext) {
                    throw createInvalidStateError();
                }
                // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.
                if (value > this._nativeAudioDestinationNode.maxChannelCount) {
                    throw createIndexSizeError();
                }
                this._nativeAudioDestinationNode.channelCount = value;
            }
            get channelCountMode() {
                return this._nativeAudioDestinationNode.channelCountMode;
            }
            set channelCountMode(value) {
                // Bug #53: No browser does throw an exception yet.
                if (this._isNodeOfNativeOfflineAudioContext) {
                    throw createInvalidStateError();
                }
                this._nativeAudioDestinationNode.channelCountMode = value;
            }
            get maxChannelCount() {
                return this._nativeAudioDestinationNode.maxChannelCount;
            }
        };
    };

    const createAudioDestinationNodeRenderer = (renderInputsOfAudioNode) => {
        let nativeAudioDestinationNodePromise = null;
        const createAudioDestinationNode = async (proxy, nativeOfflineAudioContext, trace) => {
            const nativeAudioDestinationNode = nativeOfflineAudioContext.destination;
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioDestinationNode, trace);
            return nativeAudioDestinationNode;
        };
        return {
            render(proxy, nativeOfflineAudioContext, trace) {
                if (nativeAudioDestinationNodePromise === null) {
                    nativeAudioDestinationNodePromise = createAudioDestinationNode(proxy, nativeOfflineAudioContext, trace);
                }
                return nativeAudioDestinationNodePromise;
            }
        };
    };

    const createAudioListenerFactory = (createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeScriptProcessorNode, isNativeOfflineAudioContext) => {
        return (context, nativeContext) => {
            const nativeListener = nativeContext.listener;
            // Bug #117: Only Chrome, Edge & Opera support the new interface already.
            const createFakeAudioParams = () => {
                const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
                    channelCount: 1,
                    channelCountMode: 'explicit',
                    channelInterpretation: 'speakers',
                    numberOfInputs: 9
                });
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 9, 0);
                const createFakeAudioParam = (input, value) => {
                    const constantSourceNode = createNativeConstantSourceNode(nativeContext, {
                        channelCount: 1,
                        channelCountMode: 'explicit',
                        channelInterpretation: 'discrete',
                        offset: value
                    });
                    constantSourceNode.connect(channelMergerNode, 0, input);
                    // @todo This should be stopped when the context is closed.
                    constantSourceNode.start();
                    Object.defineProperty(constantSourceNode.offset, 'defaultValue', {
                        get() {
                            return value;
                        }
                    });
                    /*
                     * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and
                     * minValue for GainNodes.
                     */
                    return createAudioParam({ context }, isOffline, constantSourceNode.offset, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);
                };
                let lastOrientation = [0, 0, -1, 0, 1, 0];
                let lastPosition = [0, 0, 0];
                // tslint:disable-next-line:deprecation
                scriptProcessorNode.onaudioprocess = ({ inputBuffer }) => {
                    const orientation = [
                        inputBuffer.getChannelData(0)[0],
                        inputBuffer.getChannelData(1)[0],
                        inputBuffer.getChannelData(2)[0],
                        inputBuffer.getChannelData(3)[0],
                        inputBuffer.getChannelData(4)[0],
                        inputBuffer.getChannelData(5)[0]
                    ];
                    if (orientation.some((value, index) => value !== lastOrientation[index])) {
                        nativeListener.setOrientation(...orientation); // tslint:disable-line:deprecation
                        lastOrientation = orientation;
                    }
                    const positon = [
                        inputBuffer.getChannelData(6)[0],
                        inputBuffer.getChannelData(7)[0],
                        inputBuffer.getChannelData(8)[0]
                    ];
                    if (positon.some((value, index) => value !== lastPosition[index])) {
                        nativeListener.setPosition(...positon); // tslint:disable-line:deprecation
                        lastPosition = positon;
                    }
                };
                channelMergerNode.connect(scriptProcessorNode);
                return {
                    forwardX: createFakeAudioParam(0, 0),
                    forwardY: createFakeAudioParam(1, 0),
                    forwardZ: createFakeAudioParam(2, -1),
                    positionX: createFakeAudioParam(6, 0),
                    positionY: createFakeAudioParam(7, 0),
                    positionZ: createFakeAudioParam(8, 0),
                    upX: createFakeAudioParam(3, 0),
                    upY: createFakeAudioParam(4, 1),
                    upZ: createFakeAudioParam(5, 0)
                };
            };
            const { forwardX, forwardY, forwardZ, positionX, positionY, positionZ, upX, upY, upZ } = nativeListener.forwardX === undefined ? createFakeAudioParams() : nativeListener;
            return {
                get forwardX() {
                    return forwardX;
                },
                get forwardY() {
                    return forwardY;
                },
                get forwardZ() {
                    return forwardZ;
                },
                get positionX() {
                    return positionX;
                },
                get positionY() {
                    return positionY;
                },
                get positionZ() {
                    return positionZ;
                },
                get upX() {
                    return upX;
                },
                get upY() {
                    return upY;
                },
                get upZ() {
                    return upZ;
                }
            };
        };
    };

    const isAudioNode = (audioNodeOrAudioParam) => {
        return 'context' in audioNodeOrAudioParam;
    };

    const isAudioNodeOutputConnection = (outputConnection) => {
        return isAudioNode(outputConnection[0]);
    };

    const insertElementInSet = (set, element, predicate, ignoreDuplicates) => {
        for (const lmnt of set) {
            if (predicate(lmnt)) {
                if (ignoreDuplicates) {
                    return false;
                }
                throw Error('The set contains at least one similar element.');
            }
        }
        set.add(element);
        return true;
    };

    const addActiveInputConnectionToAudioParam = (activeInputs, source, [output, eventListener], ignoreDuplicates) => {
        insertElementInSet(activeInputs, [source, output, eventListener], (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output, ignoreDuplicates);
    };

    const addPassiveInputConnectionToAudioParam = (passiveInputs, [source, output, eventListener], ignoreDuplicates) => {
        const passiveInputConnections = passiveInputs.get(source);
        if (passiveInputConnections === undefined) {
            passiveInputs.set(source, new Set([[output, eventListener]]));
        }
        else {
            insertElementInSet(passiveInputConnections, [output, eventListener], (passiveInputConnection) => passiveInputConnection[0] === output, ignoreDuplicates);
        }
    };

    const isNativeAudioNodeFaker = (nativeAudioNodeOrNativeAudioNodeFaker) => {
        return 'inputs' in nativeAudioNodeOrNativeAudioNodeFaker;
    };

    const connectNativeAudioNodeToNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input) => {
        if (isNativeAudioNodeFaker(nativeDestinationAudioNode)) {
            const fakeNativeDestinationAudioNode = nativeDestinationAudioNode.inputs[input];
            nativeSourceAudioNode.connect(fakeNativeDestinationAudioNode, output, 0);
            return [fakeNativeDestinationAudioNode, output, 0];
        }
        nativeSourceAudioNode.connect(nativeDestinationAudioNode, output, input);
        return [nativeDestinationAudioNode, output, input];
    };

    const deleteActiveInputConnection = (activeInputConnections, source, output) => {
        for (const activeInputConnection of activeInputConnections) {
            if (activeInputConnection[0] === source && activeInputConnection[1] === output) {
                activeInputConnections.delete(activeInputConnection);
                return activeInputConnection;
            }
        }
        return null;
    };

    const deleteActiveInputConnectionToAudioParam = (activeInputs, source, output) => {
        return pickElementFromSet(activeInputs, (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output);
    };

    const deleteEventListenerOfAudioNode = (audioNode, eventListener) => {
        const eventListeners = getEventListenersOfAudioNode(audioNode);
        if (!eventListeners.delete(eventListener)) {
            throw new Error('Missing the expected event listener.');
        }
    };

    const deletePassiveInputConnectionToAudioParam = (passiveInputs, source, output) => {
        const passiveInputConnections = getValueForKey(passiveInputs, source);
        const matchingConnection = pickElementFromSet(passiveInputConnections, (passiveInputConnection) => passiveInputConnection[0] === output);
        if (passiveInputConnections.size === 0) {
            passiveInputs.delete(source);
        }
        return matchingConnection;
    };

    const disconnectNativeAudioNodeFromNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input) => {
        if (isNativeAudioNodeFaker(nativeDestinationAudioNode)) {
            nativeSourceAudioNode.disconnect(nativeDestinationAudioNode.inputs[input], output, 0);
        }
        else {
            nativeSourceAudioNode.disconnect(nativeDestinationAudioNode, output, input);
        }
    };

    const getNativeAudioNode = (audioNode) => {
        return getValueForKey(AUDIO_NODE_STORE, audioNode);
    };

    const getNativeAudioParam = (audioParam) => {
        return getValueForKey(AUDIO_PARAM_STORE, audioParam);
    };

    const isPartOfACycle = (audioNode) => {
        return CYCLE_COUNTERS.has(audioNode);
    };

    const isPassiveAudioNode = (audioNode) => {
        return !ACTIVE_AUDIO_NODE_STORE.has(audioNode);
    };

    const testAudioNodeDisconnectMethodSupport = (nativeAudioContext) => {
        return new Promise((resolve) => {
            const analyzer = nativeAudioContext.createScriptProcessor(256, 1, 1);
            const dummy = nativeAudioContext.createGain();
            // Bug #95: Safari does not play one sample buffers.
            const ones = nativeAudioContext.createBuffer(1, 2, 44100);
            const channelData = ones.getChannelData(0);
            channelData[0] = 1;
            channelData[1] = 1;
            const source = nativeAudioContext.createBufferSource();
            source.buffer = ones;
            source.loop = true;
            source.connect(analyzer).connect(nativeAudioContext.destination);
            source.connect(dummy);
            source.disconnect(dummy);
            // tslint:disable-next-line:deprecation
            analyzer.onaudioprocess = (event) => {
                const chnnlDt = event.inputBuffer.getChannelData(0);
                if (Array.prototype.some.call(chnnlDt, (sample) => sample === 1)) {
                    resolve(true);
                }
                else {
                    resolve(false);
                }
                source.stop();
                analyzer.onaudioprocess = null; // tslint:disable-line:deprecation
                source.disconnect(analyzer);
                analyzer.disconnect(nativeAudioContext.destination);
            };
            source.start();
        });
    };

    const visitEachAudioNodeOnce = (cycles, visitor) => {
        const counts = new Map();
        for (const cycle of cycles) {
            for (const audioNode of cycle) {
                const count = counts.get(audioNode);
                counts.set(audioNode, count === undefined ? 1 : count + 1);
            }
        }
        counts.forEach((count, audioNode) => visitor(audioNode, count));
    };

    const isNativeAudioNode = (nativeAudioNodeOrAudioParam) => {
        return 'context' in nativeAudioNodeOrAudioParam;
    };

    const wrapAudioNodeDisconnectMethod = (nativeAudioNode) => {
        const connections = new Map();
        nativeAudioNode.connect = ((connect) => {
            // tslint:disable-next-line:invalid-void
            return (destination, output = 0, input = 0) => {
                const returnValue = isNativeAudioNode(destination) ? connect(destination, output, input) : connect(destination, output);
                // Save the new connection only if the calls to connect above didn't throw an error.
                const connectionsToDestination = connections.get(destination);
                if (connectionsToDestination === undefined) {
                    connections.set(destination, [{ input, output }]);
                }
                else {
                    if (connectionsToDestination.every((connection) => connection.input !== input || connection.output !== output)) {
                        connectionsToDestination.push({ input, output });
                    }
                }
                return returnValue;
            };
        })(nativeAudioNode.connect.bind(nativeAudioNode));
        nativeAudioNode.disconnect = ((disconnect) => {
            return (destinationOrOutput, output, input) => {
                disconnect.apply(nativeAudioNode);
                if (destinationOrOutput === undefined) {
                    connections.clear();
                }
                else if (typeof destinationOrOutput === 'number') {
                    for (const [destination, connectionsToDestination] of connections) {
                        const filteredConnections = connectionsToDestination.filter((connection) => connection.output !== destinationOrOutput);
                        if (filteredConnections.length === 0) {
                            connections.delete(destination);
                        }
                        else {
                            connections.set(destination, filteredConnections);
                        }
                    }
                }
                else if (connections.has(destinationOrOutput)) {
                    if (output === undefined) {
                        connections.delete(destinationOrOutput);
                    }
                    else {
                        const connectionsToDestination = connections.get(destinationOrOutput);
                        if (connectionsToDestination !== undefined) {
                            const filteredConnections = connectionsToDestination.filter((connection) => connection.output !== output && (connection.input !== input || input === undefined));
                            if (filteredConnections.length === 0) {
                                connections.delete(destinationOrOutput);
                            }
                            else {
                                connections.set(destinationOrOutput, filteredConnections);
                            }
                        }
                    }
                }
                for (const [destination, connectionsToDestination] of connections) {
                    connectionsToDestination.forEach((connection) => {
                        if (isNativeAudioNode(destination)) {
                            nativeAudioNode.connect(destination, connection.output, connection.input);
                        }
                        else {
                            nativeAudioNode.connect(destination, connection.output);
                        }
                    });
                }
            };
        })(nativeAudioNode.disconnect);
    };

    const addConnectionToAudioParamOfAudioContext = (source, destination, output, isOffline) => {
        const { activeInputs, passiveInputs } = getAudioParamConnections(destination);
        const { outputs } = getAudioNodeConnections(source);
        const eventListeners = getEventListenersOfAudioNode(source);
        const eventListener = (isActive) => {
            const nativeAudioNode = getNativeAudioNode(source);
            const nativeAudioParam = getNativeAudioParam(destination);
            if (isActive) {
                const partialConnection = deletePassiveInputConnectionToAudioParam(passiveInputs, source, output);
                addActiveInputConnectionToAudioParam(activeInputs, source, partialConnection, false);
                if (!isOffline && !isPartOfACycle(source)) {
                    nativeAudioNode.connect(nativeAudioParam, output);
                }
            }
            else {
                const partialConnection = deleteActiveInputConnectionToAudioParam(activeInputs, source, output);
                addPassiveInputConnectionToAudioParam(passiveInputs, partialConnection, false);
                if (!isOffline && !isPartOfACycle(source)) {
                    nativeAudioNode.disconnect(nativeAudioParam, output);
                }
            }
        };
        if (insertElementInSet(outputs, [destination, output], (outputConnection) => outputConnection[0] === destination && outputConnection[1] === output, true)) {
            eventListeners.add(eventListener);
            if (isActiveAudioNode(source)) {
                addActiveInputConnectionToAudioParam(activeInputs, source, [output, eventListener], true);
            }
            else {
                addPassiveInputConnectionToAudioParam(passiveInputs, [source, output, eventListener], true);
            }
            return true;
        }
        return false;
    };
    const deleteInputConnectionOfAudioNode = (source, destination, output, input) => {
        const { activeInputs, passiveInputs } = getAudioNodeConnections(destination);
        const activeInputConnection = deleteActiveInputConnection(activeInputs[input], source, output);
        if (activeInputConnection === null) {
            const passiveInputConnection = deletePassiveInputConnectionToAudioNode(passiveInputs, source, output, input);
            return [passiveInputConnection[2], false];
        }
        return [activeInputConnection[2], true];
    };
    const deleteInputConnectionOfAudioParam = (source, destination, output) => {
        const { activeInputs, passiveInputs } = getAudioParamConnections(destination);
        const activeInputConnection = deleteActiveInputConnection(activeInputs, source, output);
        if (activeInputConnection === null) {
            const passiveInputConnection = deletePassiveInputConnectionToAudioParam(passiveInputs, source, output);
            return [passiveInputConnection[1], false];
        }
        return [activeInputConnection[2], true];
    };
    const deleteInputsOfAudioNode = (source, isOffline, destination, output, input) => {
        const [listener, isActive] = deleteInputConnectionOfAudioNode(source, destination, output, input);
        if (listener !== null) {
            deleteEventListenerOfAudioNode(source, listener);
            if (isActive && !isOffline && !isPartOfACycle(source)) {
                disconnectNativeAudioNodeFromNativeAudioNode(getNativeAudioNode(source), getNativeAudioNode(destination), output, input);
            }
        }
        if (isActiveAudioNode(destination)) {
            const { activeInputs } = getAudioNodeConnections(destination);
            setInternalStateToPassiveWhenNecessary(destination, activeInputs);
        }
    };
    const deleteInputsOfAudioParam = (source, isOffline, destination, output) => {
        const [listener, isActive] = deleteInputConnectionOfAudioParam(source, destination, output);
        if (listener !== null) {
            deleteEventListenerOfAudioNode(source, listener);
            if (isActive && !isOffline && !isPartOfACycle(source)) {
                getNativeAudioNode(source).disconnect(getNativeAudioParam(destination), output);
            }
        }
    };
    const deleteAnyConnection = (source, isOffline) => {
        const audioNodeConnectionsOfSource = getAudioNodeConnections(source);
        const destinations = [];
        for (const outputConnection of audioNodeConnectionsOfSource.outputs) {
            if (isAudioNodeOutputConnection(outputConnection)) {
                deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
            }
            else {
                deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
            }
            destinations.push(outputConnection[0]);
        }
        audioNodeConnectionsOfSource.outputs.clear();
        return destinations;
    };
    const deleteConnectionAtOutput = (source, isOffline, output) => {
        const audioNodeConnectionsOfSource = getAudioNodeConnections(source);
        const destinations = [];
        for (const outputConnection of audioNodeConnectionsOfSource.outputs) {
            if (outputConnection[1] === output) {
                if (isAudioNodeOutputConnection(outputConnection)) {
                    deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
                }
                else {
                    deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
                }
                destinations.push(outputConnection[0]);
                audioNodeConnectionsOfSource.outputs.delete(outputConnection);
            }
        }
        return destinations;
    };
    const deleteConnectionToDestination = (source, isOffline, destination, output, input) => {
        const audioNodeConnectionsOfSource = getAudioNodeConnections(source);
        return Array.from(audioNodeConnectionsOfSource.outputs)
            .filter((outputConnection) => outputConnection[0] === destination &&
            (output === undefined || outputConnection[1] === output) &&
            (input === undefined || outputConnection[2] === input))
            .map((outputConnection) => {
            if (isAudioNodeOutputConnection(outputConnection)) {
                deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
            }
            else {
                deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
            }
            audioNodeConnectionsOfSource.outputs.delete(outputConnection);
            return outputConnection[0];
        });
    };
    const createAudioNodeConstructor = (addAudioNodeConnections, addConnectionToAudioNode, cacheTestResult, createIncrementCycleCounter, createIndexSizeError, createInvalidAccessError, createNotSupportedError, decrementCycleCounter, detectCycles, eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext) => {
        return class AudioNode extends eventTargetConstructor {
            constructor(context, isActive, nativeAudioNode, audioNodeRenderer) {
                super(nativeAudioNode);
                this._context = context;
                this._nativeAudioNode = nativeAudioNode;
                const nativeContext = getNativeContext(context);
                // Bug #12: Safari does not support to disconnect a specific destination.
                if (isNativeAudioContext(nativeContext) &&
                    true !==
                        cacheTestResult(testAudioNodeDisconnectMethodSupport, () => {
                            return testAudioNodeDisconnectMethodSupport(nativeContext);
                        })) {
                    wrapAudioNodeDisconnectMethod(nativeAudioNode);
                }
                AUDIO_NODE_STORE.set(this, nativeAudioNode);
                EVENT_LISTENERS.set(this, new Set());
                if (context.state !== 'closed' && isActive) {
                    setInternalStateToActive(this);
                }
                addAudioNodeConnections(this, audioNodeRenderer, nativeAudioNode);
            }
            get channelCount() {
                return this._nativeAudioNode.channelCount;
            }
            set channelCount(value) {
                this._nativeAudioNode.channelCount = value;
            }
            get channelCountMode() {
                return this._nativeAudioNode.channelCountMode;
            }
            set channelCountMode(value) {
                this._nativeAudioNode.channelCountMode = value;
            }
            get channelInterpretation() {
                return this._nativeAudioNode.channelInterpretation;
            }
            set channelInterpretation(value) {
                this._nativeAudioNode.channelInterpretation = value;
            }
            get context() {
                return this._context;
            }
            get numberOfInputs() {
                return this._nativeAudioNode.numberOfInputs;
            }
            get numberOfOutputs() {
                return this._nativeAudioNode.numberOfOutputs;
            }
            // tslint:disable-next-line:invalid-void
            connect(destination, output = 0, input = 0) {
                // Bug #174: Safari does expose a wrong numberOfOutputs for MediaStreamAudioDestinationNodes.
                if (output < 0 || output >= this._nativeAudioNode.numberOfOutputs) {
                    throw createIndexSizeError();
                }
                const nativeContext = getNativeContext(this._context);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                if (isNativeAudioNode(destination) || isNativeAudioParam(destination)) {
                    throw createInvalidAccessError();
                }
                if (isAudioNode(destination)) {
                    const nativeDestinationAudioNode = getNativeAudioNode(destination);
                    try {
                        const connection = connectNativeAudioNodeToNativeAudioNode(this._nativeAudioNode, nativeDestinationAudioNode, output, input);
                        const isPassive = isPassiveAudioNode(this);
                        if (isOffline || isPassive) {
                            this._nativeAudioNode.disconnect(...connection);
                        }
                        if (this.context.state !== 'closed' && !isPassive && isPassiveAudioNode(destination)) {
                            setInternalStateToActive(destination);
                        }
                    }
                    catch (err) {
                        // Bug #41: Safari does not throw the correct exception so far.
                        if (err.code === 12) {
                            throw createInvalidAccessError();
                        }
                        throw err;
                    }
                    const isNewConnectionToAudioNode = addConnectionToAudioNode(this, destination, output, input, isOffline);
                    // Bug #164: Only Firefox detects cycles so far.
                    if (isNewConnectionToAudioNode) {
                        const cycles = detectCycles([this], destination);
                        visitEachAudioNodeOnce(cycles, createIncrementCycleCounter(isOffline));
                    }
                    return destination;
                }
                const nativeAudioParam = getNativeAudioParam(destination);
                /*
                 * Bug #147 & #153: Safari does not support to connect an input signal to the playbackRate AudioParam of an
                 * AudioBufferSourceNode. This can't be easily detected and that's why the outdated name property is used here to identify
                 * Safari.
                 */
                if (nativeAudioParam.name === 'playbackRate') {
                    throw createNotSupportedError();
                }
                try {
                    this._nativeAudioNode.connect(nativeAudioParam, output);
                    if (isOffline || isPassiveAudioNode(this)) {
                        this._nativeAudioNode.disconnect(nativeAudioParam, output);
                    }
                }
                catch (err) {
                    // Bug #58: Only Firefox does throw an InvalidStateError yet.
                    if (err.code === 12) {
                        throw createInvalidAccessError();
                    }
                    throw err;
                }
                const isNewConnectionToAudioParam = addConnectionToAudioParamOfAudioContext(this, destination, output, isOffline);
                // Bug #164: Only Firefox detects cycles so far.
                if (isNewConnectionToAudioParam) {
                    const cycles = detectCycles([this], destination);
                    visitEachAudioNodeOnce(cycles, createIncrementCycleCounter(isOffline));
                }
            }
            disconnect(destinationOrOutput, output, input) {
                let destinations;
                const nativeContext = getNativeContext(this._context);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                if (destinationOrOutput === undefined) {
                    destinations = deleteAnyConnection(this, isOffline);
                }
                else if (typeof destinationOrOutput === 'number') {
                    if (destinationOrOutput < 0 || destinationOrOutput >= this.numberOfOutputs) {
                        throw createIndexSizeError();
                    }
                    destinations = deleteConnectionAtOutput(this, isOffline, destinationOrOutput);
                }
                else {
                    if (output !== undefined && (output < 0 || output >= this.numberOfOutputs)) {
                        throw createIndexSizeError();
                    }
                    if (isAudioNode(destinationOrOutput) && input !== undefined && (input < 0 || input >= destinationOrOutput.numberOfInputs)) {
                        throw createIndexSizeError();
                    }
                    destinations = deleteConnectionToDestination(this, isOffline, destinationOrOutput, output, input);
                    if (destinations.length === 0) {
                        throw createInvalidAccessError();
                    }
                }
                // Bug #164: Only Firefox detects cycles so far.
                for (const destination of destinations) {
                    const cycles = detectCycles([this], destination);
                    visitEachAudioNodeOnce(cycles, decrementCycleCounter);
                }
            }
        };
    };

    const createAudioParamFactory = (addAudioParamConnections, audioParamAudioNodeStore, audioParamStore, createAudioParamRenderer, createCancelAndHoldAutomationEvent, createCancelScheduledValuesAutomationEvent, createExponentialRampToValueAutomationEvent, createLinearRampToValueAutomationEvent, createSetTargetAutomationEvent, createSetValueAutomationEvent, createSetValueCurveAutomationEvent, nativeAudioContextConstructor) => {
        return (audioNode, isAudioParamOfOfflineAudioContext, nativeAudioParam, maxValue = null, minValue = null) => {
            const automationEventList = new bundle.AutomationEventList(nativeAudioParam.defaultValue);
            const audioParamRenderer = isAudioParamOfOfflineAudioContext ? createAudioParamRenderer(automationEventList) : null;
            const audioParam = {
                get defaultValue() {
                    return nativeAudioParam.defaultValue;
                },
                get maxValue() {
                    return maxValue === null ? nativeAudioParam.maxValue : maxValue;
                },
                get minValue() {
                    return minValue === null ? nativeAudioParam.minValue : minValue;
                },
                get value() {
                    return nativeAudioParam.value;
                },
                set value(value) {
                    nativeAudioParam.value = value;
                    // Bug #98: Firefox & Safari do not yet treat the value setter like a call to setValueAtTime().
                    audioParam.setValueAtTime(value, audioNode.context.currentTime);
                },
                cancelAndHoldAtTime(cancelTime) {
                    // Bug #28: Firefox & Safari do not yet implement cancelAndHoldAtTime().
                    if (typeof nativeAudioParam.cancelAndHoldAtTime === 'function') {
                        if (audioParamRenderer === null) {
                            automationEventList.flush(audioNode.context.currentTime);
                        }
                        automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));
                        nativeAudioParam.cancelAndHoldAtTime(cancelTime);
                    }
                    else {
                        const previousLastEvent = Array.from(automationEventList).pop();
                        if (audioParamRenderer === null) {
                            automationEventList.flush(audioNode.context.currentTime);
                        }
                        automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));
                        const currentLastEvent = Array.from(automationEventList).pop();
                        nativeAudioParam.cancelScheduledValues(cancelTime);
                        if (previousLastEvent !== currentLastEvent && currentLastEvent !== undefined) {
                            if (currentLastEvent.type === 'exponentialRampToValue') {
                                nativeAudioParam.exponentialRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);
                            }
                            else if (currentLastEvent.type === 'linearRampToValue') {
                                nativeAudioParam.linearRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);
                            }
                            else if (currentLastEvent.type === 'setValue') {
                                nativeAudioParam.setValueAtTime(currentLastEvent.value, currentLastEvent.startTime);
                            }
                            else if (currentLastEvent.type === 'setValueCurve') {
                                nativeAudioParam.setValueCurveAtTime(currentLastEvent.values, currentLastEvent.startTime, currentLastEvent.duration);
                            }
                        }
                    }
                    return audioParam;
                },
                cancelScheduledValues(cancelTime) {
                    if (audioParamRenderer === null) {
                        automationEventList.flush(audioNode.context.currentTime);
                    }
                    automationEventList.add(createCancelScheduledValuesAutomationEvent(cancelTime));
                    nativeAudioParam.cancelScheduledValues(cancelTime);
                    return audioParam;
                },
                exponentialRampToValueAtTime(value, endTime) {
                    // Bug #45: Safari does not throw an error yet.
                    if (value === 0) {
                        throw new RangeError();
                    }
                    // Bug #187: Safari does not throw an error yet.
                    if (!Number.isFinite(endTime) || endTime < 0) {
                        throw new RangeError();
                    }
                    if (audioParamRenderer === null) {
                        automationEventList.flush(audioNode.context.currentTime);
                    }
                    automationEventList.add(createExponentialRampToValueAutomationEvent(value, endTime));
                    nativeAudioParam.exponentialRampToValueAtTime(value, endTime);
                    return audioParam;
                },
                linearRampToValueAtTime(value, endTime) {
                    if (audioParamRenderer === null) {
                        automationEventList.flush(audioNode.context.currentTime);
                    }
                    automationEventList.add(createLinearRampToValueAutomationEvent(value, endTime));
                    nativeAudioParam.linearRampToValueAtTime(value, endTime);
                    return audioParam;
                },
                setTargetAtTime(target, startTime, timeConstant) {
                    if (audioParamRenderer === null) {
                        automationEventList.flush(audioNode.context.currentTime);
                    }
                    automationEventList.add(createSetTargetAutomationEvent(target, startTime, timeConstant));
                    nativeAudioParam.setTargetAtTime(target, startTime, timeConstant);
                    return audioParam;
                },
                setValueAtTime(value, startTime) {
                    if (audioParamRenderer === null) {
                        automationEventList.flush(audioNode.context.currentTime);
                    }
                    automationEventList.add(createSetValueAutomationEvent(value, startTime));
                    nativeAudioParam.setValueAtTime(value, startTime);
                    return audioParam;
                },
                setValueCurveAtTime(values, startTime, duration) {
                    // Bug 183: Safari only accepts a Float32Array.
                    const convertedValues = values instanceof Float32Array ? values : new Float32Array(values);
                    /*
                     * Bug #152: Safari does not correctly interpolate the values of the curve.
                     * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the
                     * existence of the webkitAudioContext is used as a workaround here.
                     */
                    if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === 'webkitAudioContext') {
                        const endTime = startTime + duration;
                        const sampleRate = audioNode.context.sampleRate;
                        const firstSample = Math.ceil(startTime * sampleRate);
                        const lastSample = Math.floor(endTime * sampleRate);
                        const numberOfInterpolatedValues = lastSample - firstSample;
                        const interpolatedValues = new Float32Array(numberOfInterpolatedValues);
                        for (let i = 0; i < numberOfInterpolatedValues; i += 1) {
                            const theoreticIndex = ((convertedValues.length - 1) / duration) * ((firstSample + i) / sampleRate - startTime);
                            const lowerIndex = Math.floor(theoreticIndex);
                            const upperIndex = Math.ceil(theoreticIndex);
                            interpolatedValues[i] =
                                lowerIndex === upperIndex
                                    ? convertedValues[lowerIndex]
                                    : (1 - (theoreticIndex - lowerIndex)) * convertedValues[lowerIndex] +
                                        (1 - (upperIndex - theoreticIndex)) * convertedValues[upperIndex];
                        }
                        if (audioParamRenderer === null) {
                            automationEventList.flush(audioNode.context.currentTime);
                        }
                        automationEventList.add(createSetValueCurveAutomationEvent(interpolatedValues, startTime, duration));
                        nativeAudioParam.setValueCurveAtTime(interpolatedValues, startTime, duration);
                        const timeOfLastSample = lastSample / sampleRate;
                        if (timeOfLastSample < endTime) {
                            audioParam.setValueAtTime(interpolatedValues[interpolatedValues.length - 1], timeOfLastSample);
                        }
                        audioParam.setValueAtTime(convertedValues[convertedValues.length - 1], endTime);
                    }
                    else {
                        if (audioParamRenderer === null) {
                            automationEventList.flush(audioNode.context.currentTime);
                        }
                        automationEventList.add(createSetValueCurveAutomationEvent(convertedValues, startTime, duration));
                        nativeAudioParam.setValueCurveAtTime(convertedValues, startTime, duration);
                    }
                    return audioParam;
                }
            };
            audioParamStore.set(audioParam, nativeAudioParam);
            audioParamAudioNodeStore.set(audioParam, audioNode);
            addAudioParamConnections(audioParam, audioParamRenderer);
            return audioParam;
        };
    };

    const createAudioParamRenderer = (automationEventList) => {
        return {
            replay(audioParam) {
                for (const automationEvent of automationEventList) {
                    if (automationEvent.type === 'exponentialRampToValue') {
                        const { endTime, value } = automationEvent;
                        audioParam.exponentialRampToValueAtTime(value, endTime);
                    }
                    else if (automationEvent.type === 'linearRampToValue') {
                        const { endTime, value } = automationEvent;
                        audioParam.linearRampToValueAtTime(value, endTime);
                    }
                    else if (automationEvent.type === 'setTarget') {
                        const { startTime, target, timeConstant } = automationEvent;
                        audioParam.setTargetAtTime(target, startTime, timeConstant);
                    }
                    else if (automationEvent.type === 'setValue') {
                        const { startTime, value } = automationEvent;
                        audioParam.setValueAtTime(value, startTime);
                    }
                    else if (automationEvent.type === 'setValueCurve') {
                        const { duration, startTime, values } = automationEvent;
                        audioParam.setValueCurveAtTime(values, startTime, duration);
                    }
                    else {
                        throw new Error("Can't apply an unknown automation.");
                    }
                }
            }
        };
    };

    class ReadOnlyMap {
        constructor(parameters) {
            this._map = new Map(parameters);
        }
        get size() {
            return this._map.size;
        }
        entries() {
            return this._map.entries();
        }
        forEach(callback, thisArg = null) {
            return this._map.forEach((value, key) => callback.call(thisArg, value, key, this));
        }
        get(name) {
            return this._map.get(name);
        }
        has(name) {
            return this._map.has(name);
        }
        keys() {
            return this._map.keys();
        }
        values() {
            return this._map.values();
        }
    }

    const DEFAULT_OPTIONS$3 = {
        channelCount: 2,
        // Bug #61: The channelCountMode should be 'max' according to the spec but is set to 'explicit' to achieve consistent behavior.
        channelCountMode: 'explicit',
        channelInterpretation: 'speakers',
        numberOfInputs: 1,
        numberOfOutputs: 1,
        parameterData: {},
        processorOptions: {}
    };
    const createAudioWorkletNodeConstructor = (addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, getAudioNodeConnections, getBackupOfflineAudioContext, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, sanitizeAudioWorkletNodeOptions, setActiveAudioWorkletNodeInputs, wrapEventListener) => {
        return class AudioWorkletNode extends audioNodeConstructor {
            constructor(context, name, options) {
                var _a;
                const nativeContext = getNativeContext(context);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const mergedOptions = sanitizeAudioWorkletNodeOptions({ ...DEFAULT_OPTIONS$3, ...options });
                const nodeNameToProcessorConstructorMap = NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.get(nativeContext);
                const processorConstructor = nodeNameToProcessorConstructorMap === null || nodeNameToProcessorConstructorMap === void 0 ? void 0 : nodeNameToProcessorConstructorMap.get(name);
                // Bug #186: Chrome, Edge and Opera do not allow to create an AudioWorkletNode on a closed AudioContext.
                const nativeContextOrBackupOfflineAudioContext = isOffline || nativeContext.state !== 'closed'
                    ? nativeContext
                    : (_a = getBackupOfflineAudioContext(nativeContext)) !== null && _a !== void 0 ? _a : nativeContext;
                const nativeAudioWorkletNode = createNativeAudioWorkletNode(nativeContextOrBackupOfflineAudioContext, isOffline ? null : context.baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, mergedOptions);
                const audioWorkletNodeRenderer = ((isOffline ? createAudioWorkletNodeRenderer(name, mergedOptions, processorConstructor) : null));
                /*
                 * @todo Add a mechanism to switch an AudioWorkletNode to passive once the process() function of the AudioWorkletProcessor
                 * returns false.
                 */
                super(context, true, nativeAudioWorkletNode, audioWorkletNodeRenderer);
                const parameters = [];
                nativeAudioWorkletNode.parameters.forEach((nativeAudioParam, nm) => {
                    const audioParam = createAudioParam(this, isOffline, nativeAudioParam);
                    parameters.push([nm, audioParam]);
                });
                this._nativeAudioWorkletNode = nativeAudioWorkletNode;
                this._onprocessorerror = null;
                this._parameters = new ReadOnlyMap(parameters);
                /*
                 * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to
                 * the destination.
                 */
                if (isOffline) {
                    addUnrenderedAudioWorkletNode(nativeContext, this);
                }
                const { activeInputs } = getAudioNodeConnections(this);
                setActiveAudioWorkletNodeInputs(nativeAudioWorkletNode, activeInputs);
            }
            get onprocessorerror() {
                return this._onprocessorerror;
            }
            set onprocessorerror(value) {
                const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;
                this._nativeAudioWorkletNode.onprocessorerror = wrappedListener;
                const nativeOnProcessorError = this._nativeAudioWorkletNode.onprocessorerror;
                this._onprocessorerror =
                    nativeOnProcessorError !== null && nativeOnProcessorError === wrappedListener
                        ? value
                        : nativeOnProcessorError;
            }
            get parameters() {
                if (this._parameters === null) {
                    // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
                    return this._nativeAudioWorkletNode.parameters;
                }
                return this._parameters;
            }
            get port() {
                return this._nativeAudioWorkletNode.port;
            }
        };
    };

    function copyFromChannel(audioBuffer, 
    // @todo There is currently no way to define something like { [ key: number | string ]: Float32Array }
    parent, key, channelNumber, bufferOffset) {
        if (typeof audioBuffer.copyFromChannel === 'function') {
            // The byteLength will be 0 when the ArrayBuffer was transferred.
            if (parent[key].byteLength === 0) {
                parent[key] = new Float32Array(128);
            }
            audioBuffer.copyFromChannel(parent[key], channelNumber, bufferOffset);
            // Bug #5: Safari does not support copyFromChannel().
        }
        else {
            const channelData = audioBuffer.getChannelData(channelNumber);
            // The byteLength will be 0 when the ArrayBuffer was transferred.
            if (parent[key].byteLength === 0) {
                parent[key] = channelData.slice(bufferOffset, bufferOffset + 128);
            }
            else {
                const slicedInput = new Float32Array(channelData.buffer, bufferOffset * Float32Array.BYTES_PER_ELEMENT, 128);
                parent[key].set(slicedInput);
            }
        }
    }

    const copyToChannel = (audioBuffer, parent, key, channelNumber, bufferOffset) => {
        if (typeof audioBuffer.copyToChannel === 'function') {
            // The byteLength will be 0 when the ArrayBuffer was transferred.
            if (parent[key].byteLength !== 0) {
                audioBuffer.copyToChannel(parent[key], channelNumber, bufferOffset);
            }
            // Bug #5: Safari does not support copyToChannel().
        }
        else {
            // The byteLength will be 0 when the ArrayBuffer was transferred.
            if (parent[key].byteLength !== 0) {
                audioBuffer.getChannelData(channelNumber).set(parent[key], bufferOffset);
            }
        }
    };

    const createNestedArrays = (x, y) => {
        const arrays = [];
        for (let i = 0; i < x; i += 1) {
            const array = [];
            const length = typeof y === 'number' ? y : y[i];
            for (let j = 0; j < length; j += 1) {
                array.push(new Float32Array(128));
            }
            arrays.push(array);
        }
        return arrays;
    };

    const getAudioWorkletProcessor = (nativeOfflineAudioContext, proxy) => {
        const nodeToProcessorMap = getValueForKey(NODE_TO_PROCESSOR_MAPS, nativeOfflineAudioContext);
        const nativeAudioWorkletNode = getNativeAudioNode(proxy);
        return getValueForKey(nodeToProcessorMap, nativeAudioWorkletNode);
    };

    const processBuffer = async (proxy, renderedBuffer, nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime) => {
        // Ceil the length to the next full render quantum.
        // Bug #17: Safari does not yet expose the length.
        const length = renderedBuffer === null ? Math.ceil(proxy.context.length / 128) * 128 : renderedBuffer.length;
        const numberOfInputChannels = options.channelCount * options.numberOfInputs;
        const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);
        const processedBuffer = numberOfOutputChannels === 0
            ? null
            : nativeOfflineAudioContext.createBuffer(numberOfOutputChannels, length, nativeOfflineAudioContext.sampleRate);
        if (processorConstructor === undefined) {
            throw new Error('Missing the processor constructor.');
        }
        const audioNodeConnections = getAudioNodeConnections(proxy);
        const audioWorkletProcessor = await getAudioWorkletProcessor(nativeOfflineAudioContext, proxy);
        const inputs = createNestedArrays(options.numberOfInputs, options.channelCount);
        const outputs = createNestedArrays(options.numberOfOutputs, outputChannelCount);
        const parameters = Array.from(proxy.parameters.keys()).reduce((prmtrs, name) => ({ ...prmtrs, [name]: new Float32Array(128) }), {});
        for (let i = 0; i < length; i += 128) {
            if (options.numberOfInputs > 0 && renderedBuffer !== null) {
                for (let j = 0; j < options.numberOfInputs; j += 1) {
                    for (let k = 0; k < options.channelCount; k += 1) {
                        copyFromChannel(renderedBuffer, inputs[j], k, k, i);
                    }
                }
            }
            if (processorConstructor.parameterDescriptors !== undefined && renderedBuffer !== null) {
                processorConstructor.parameterDescriptors.forEach(({ name }, index) => {
                    copyFromChannel(renderedBuffer, parameters, name, numberOfInputChannels + index, i);
                });
            }
            for (let j = 0; j < options.numberOfInputs; j += 1) {
                for (let k = 0; k < outputChannelCount[j]; k += 1) {
                    // The byteLength will be 0 when the ArrayBuffer was transferred.
                    if (outputs[j][k].byteLength === 0) {
                        outputs[j][k] = new Float32Array(128);
                    }
                }
            }
            try {
                const potentiallyEmptyInputs = inputs.map((input, index) => {
                    if (audioNodeConnections.activeInputs[index].size === 0) {
                        return [];
                    }
                    return input;
                });
                const activeSourceFlag = exposeCurrentFrameAndCurrentTime(i / nativeOfflineAudioContext.sampleRate, nativeOfflineAudioContext.sampleRate, () => audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));
                if (processedBuffer !== null) {
                    for (let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1) {
                        for (let k = 0; k < outputChannelCount[j]; k += 1) {
                            copyToChannel(processedBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);
                        }
                        outputChannelSplitterNodeOutput += outputChannelCount[j];
                    }
                }
                if (!activeSourceFlag) {
                    break;
                }
            }
            catch (error) {
                proxy.dispatchEvent(new ErrorEvent('processorerror', {
                    colno: error.colno,
                    filename: error.filename,
                    lineno: error.lineno,
                    message: error.message
                }));
                break;
            }
        }
        return processedBuffer;
    };
    const createAudioWorkletNodeRendererFactory = (connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {
        return (name, options, processorConstructor) => {
            const renderedNativeAudioNodes = new WeakMap();
            let processedBufferPromise = null;
            const createAudioNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeAudioWorkletNode = getNativeAudioNode(proxy);
                let nativeOutputNodes = null;
                const nativeAudioWorkletNodeIsOwnedByContext = isOwnedByContext(nativeAudioWorkletNode, nativeOfflineAudioContext);
                const outputChannelCount = Array.isArray(options.outputChannelCount)
                    ? options.outputChannelCount
                    : Array.from(options.outputChannelCount);
                // Bug #61: Only Chrome, Edge, Firefox & Opera have an implementation of the AudioWorkletNode yet.
                if (nativeAudioWorkletNodeConstructor === null) {
                    const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);
                    const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, {
                        channelCount: Math.max(1, numberOfOutputChannels),
                        channelCountMode: 'explicit',
                        channelInterpretation: 'discrete',
                        numberOfOutputs: Math.max(1, numberOfOutputChannels)
                    });
                    const outputChannelMergerNodes = [];
                    for (let i = 0; i < proxy.numberOfOutputs; i += 1) {
                        outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeOfflineAudioContext, {
                            channelCount: 1,
                            channelCountMode: 'explicit',
                            channelInterpretation: 'speakers',
                            numberOfInputs: outputChannelCount[i]
                        }));
                    }
                    const outputGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                        channelCount: options.channelCount,
                        channelCountMode: options.channelCountMode,
                        channelInterpretation: options.channelInterpretation,
                        gain: 1
                    });
                    outputGainNode.connect = connectMultipleOutputs.bind(null, outputChannelMergerNodes);
                    outputGainNode.disconnect = disconnectMultipleOutputs.bind(null, outputChannelMergerNodes);
                    nativeOutputNodes = [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode];
                }
                else if (!nativeAudioWorkletNodeIsOwnedByContext) {
                    nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeOfflineAudioContext, name);
                }
                renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeOutputNodes === null ? nativeAudioWorkletNode : nativeOutputNodes[2]);
                if (nativeOutputNodes !== null) {
                    if (processedBufferPromise === null) {
                        if (processorConstructor === undefined) {
                            throw new Error('Missing the processor constructor.');
                        }
                        if (nativeOfflineAudioContextConstructor === null) {
                            throw new Error('Missing the native OfflineAudioContext constructor.');
                        }
                        // Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.
                        const numberOfInputChannels = proxy.channelCount * proxy.numberOfInputs;
                        const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;
                        const numberOfChannels = numberOfInputChannels + numberOfParameters;
                        const renderBuffer = async () => {
                            const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfChannels, 
                            // Ceil the length to the next full render quantum.
                            // Bug #17: Safari does not yet expose the length.
                            Math.ceil(proxy.context.length / 128) * 128, nativeOfflineAudioContext.sampleRate);
                            const gainNodes = [];
                            const inputChannelSplitterNodes = [];
                            for (let i = 0; i < options.numberOfInputs; i += 1) {
                                gainNodes.push(createNativeGainNode(partialOfflineAudioContext, {
                                    channelCount: options.channelCount,
                                    channelCountMode: options.channelCountMode,
                                    channelInterpretation: options.channelInterpretation,
                                    gain: 1
                                }));
                                inputChannelSplitterNodes.push(createNativeChannelSplitterNode(partialOfflineAudioContext, {
                                    channelCount: options.channelCount,
                                    channelCountMode: 'explicit',
                                    channelInterpretation: 'discrete',
                                    numberOfOutputs: options.channelCount
                                }));
                            }
                            const constantSourceNodes = await Promise.all(Array.from(proxy.parameters.values()).map(async (audioParam) => {
                                const constantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {
                                    channelCount: 1,
                                    channelCountMode: 'explicit',
                                    channelInterpretation: 'discrete',
                                    offset: audioParam.value
                                });
                                await renderAutomation(partialOfflineAudioContext, audioParam, constantSourceNode.offset, trace);
                                return constantSourceNode;
                            }));
                            const inputChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {
                                channelCount: 1,
                                channelCountMode: 'explicit',
                                channelInterpretation: 'speakers',
                                numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)
                            });
                            for (let i = 0; i < options.numberOfInputs; i += 1) {
                                gainNodes[i].connect(inputChannelSplitterNodes[i]);
                                for (let j = 0; j < options.channelCount; j += 1) {
                                    inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, i * options.channelCount + j);
                                }
                            }
                            for (const [index, constantSourceNode] of constantSourceNodes.entries()) {
                                constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);
                                constantSourceNode.start(0);
                            }
                            inputChannelMergerNode.connect(partialOfflineAudioContext.destination);
                            await Promise.all(gainNodes.map((gainNode) => renderInputsOfAudioNode(proxy, partialOfflineAudioContext, gainNode, trace)));
                            return renderNativeOfflineAudioContext(partialOfflineAudioContext);
                        };
                        processedBufferPromise = processBuffer(proxy, numberOfChannels === 0 ? null : await renderBuffer(), nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime);
                    }
                    const processedBuffer = await processedBufferPromise;
                    const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {
                        buffer: null,
                        channelCount: 2,
                        channelCountMode: 'max',
                        channelInterpretation: 'speakers',
                        loop: false,
                        loopEnd: 0,
                        loopStart: 0,
                        playbackRate: 1
                    });
                    const [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode] = nativeOutputNodes;
                    if (processedBuffer !== null) {
                        audioBufferSourceNode.buffer = processedBuffer;
                        audioBufferSourceNode.start(0);
                    }
                    audioBufferSourceNode.connect(outputChannelSplitterNode);
                    for (let i = 0, outputChannelSplitterNodeOutput = 0; i < proxy.numberOfOutputs; i += 1) {
                        const outputChannelMergerNode = outputChannelMergerNodes[i];
                        for (let j = 0; j < outputChannelCount[i]; j += 1) {
                            outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                        }
                        outputChannelSplitterNodeOutput += outputChannelCount[i];
                    }
                    return outputGainNode;
                }
                if (!nativeAudioWorkletNodeIsOwnedByContext) {
                    for (const [nm, audioParam] of proxy.parameters.entries()) {
                        await renderAutomation(nativeOfflineAudioContext, audioParam, 
                        // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
                        nativeAudioWorkletNode.parameters.get(nm), trace);
                    }
                }
                else {
                    for (const [nm, audioParam] of proxy.parameters.entries()) {
                        await connectAudioParam(nativeOfflineAudioContext, audioParam, 
                        // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
                        nativeAudioWorkletNode.parameters.get(nm), trace);
                    }
                }
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioWorkletNode, trace);
                return nativeAudioWorkletNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    deleteUnrenderedAudioWorkletNode(nativeOfflineAudioContext, proxy);
                    const renderedNativeAudioWorkletNodeOrGainNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeAudioWorkletNodeOrGainNode !== undefined) {
                        return Promise.resolve(renderedNativeAudioWorkletNodeOrGainNode);
                    }
                    return createAudioNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const createBaseAudioContextConstructor = (addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor) => {
        return class BaseAudioContext extends minimalBaseAudioContextConstructor {
            constructor(_nativeContext, numberOfChannels) {
                super(_nativeContext, numberOfChannels);
                this._nativeContext = _nativeContext;
                this._audioWorklet =
                    addAudioWorkletModule === undefined
                        ? undefined
                        : {
                            addModule: (moduleURL, options) => {
                                return addAudioWorkletModule(this, moduleURL, options);
                            }
                        };
            }
            get audioWorklet() {
                return this._audioWorklet;
            }
            createAnalyser() {
                return new analyserNodeConstructor(this);
            }
            createBiquadFilter() {
                return new biquadFilterNodeConstructor(this);
            }
            createBuffer(numberOfChannels, length, sampleRate) {
                return new audioBufferConstructor({ length, numberOfChannels, sampleRate });
            }
            createBufferSource() {
                return new audioBufferSourceNodeConstructor(this);
            }
            createChannelMerger(numberOfInputs = 6) {
                return new channelMergerNodeConstructor(this, { numberOfInputs });
            }
            createChannelSplitter(numberOfOutputs = 6) {
                return new channelSplitterNodeConstructor(this, { numberOfOutputs });
            }
            createConstantSource() {
                return new constantSourceNodeConstructor(this);
            }
            createConvolver() {
                return new convolverNodeConstructor(this);
            }
            createDelay(maxDelayTime = 1) {
                return new delayNodeConstructor(this, { maxDelayTime });
            }
            createDynamicsCompressor() {
                return new dynamicsCompressorNodeConstructor(this);
            }
            createGain() {
                return new gainNodeConstructor(this);
            }
            createIIRFilter(feedforward, feedback) {
                return new iIRFilterNodeConstructor(this, { feedback, feedforward });
            }
            createOscillator() {
                return new oscillatorNodeConstructor(this);
            }
            createPanner() {
                return new pannerNodeConstructor(this);
            }
            createPeriodicWave(real, imag, constraints = { disableNormalization: false }) {
                return new periodicWaveConstructor(this, { ...constraints, imag, real });
            }
            createStereoPanner() {
                return new stereoPannerNodeConstructor(this);
            }
            createWaveShaper() {
                return new waveShaperNodeConstructor(this);
            }
            decodeAudioData(audioData, successCallback, errorCallback) {
                return decodeAudioData(this._nativeContext, audioData)
                    .then((audioBuffer) => {
                    if (typeof successCallback === 'function') {
                        successCallback(audioBuffer);
                    }
                    return audioBuffer;
                })
                    .catch((err) => {
                    if (typeof errorCallback === 'function') {
                        errorCallback(err);
                    }
                    throw err;
                });
            }
        };
    };

    const DEFAULT_OPTIONS$4 = {
        Q: 1,
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        detune: 0,
        frequency: 350,
        gain: 0,
        type: 'lowpass'
    };
    const createBiquadFilterNodeConstructor = (audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, createInvalidAccessError, createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {
        return class BiquadFilterNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$4, ...options };
                const nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeContext, mergedOptions);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const biquadFilterNodeRenderer = (isOffline ? createBiquadFilterNodeRenderer() : null);
                super(context, false, nativeBiquadFilterNode, biquadFilterNodeRenderer);
                // Bug #80: Safari does not export the correct values for maxValue and minValue.
                this._Q = createAudioParam(this, isOffline, nativeBiquadFilterNode.Q, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);
                // Bug #78: Firefox & Safari do not export the correct values for maxValue and minValue.
                this._detune = createAudioParam(this, isOffline, nativeBiquadFilterNode.detune, 1200 * Math.log2(MOST_POSITIVE_SINGLE_FLOAT), -1200 * Math.log2(MOST_POSITIVE_SINGLE_FLOAT));
                // Bug #77: Firefox & Safari do not export the correct value for minValue.
                this._frequency = createAudioParam(this, isOffline, nativeBiquadFilterNode.frequency, context.sampleRate / 2, 0);
                // Bug #79: Firefox & Safari do not export the correct values for maxValue and minValue.
                this._gain = createAudioParam(this, isOffline, nativeBiquadFilterNode.gain, 40 * Math.log10(MOST_POSITIVE_SINGLE_FLOAT), MOST_NEGATIVE_SINGLE_FLOAT);
                this._nativeBiquadFilterNode = nativeBiquadFilterNode;
                // @todo Determine a meaningful tail-time instead of just using one second.
                setAudioNodeTailTime(this, 1);
            }
            get detune() {
                return this._detune;
            }
            get frequency() {
                return this._frequency;
            }
            get gain() {
                return this._gain;
            }
            get Q() {
                return this._Q;
            }
            get type() {
                return this._nativeBiquadFilterNode.type;
            }
            set type(value) {
                this._nativeBiquadFilterNode.type = value;
            }
            getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
                this._nativeBiquadFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);
                // Bug #68: Safari does not throw an error if the parameters differ in their length.
                if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {
                    throw createInvalidAccessError();
                }
            }
        };
    };

    const createBiquadFilterNodeRendererFactory = (connectAudioParam, createNativeBiquadFilterNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeBiquadFilterNodes = new WeakMap();
            const createBiquadFilterNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeBiquadFilterNode = getNativeAudioNode(proxy);
                /*
                 * If the initially used nativeBiquadFilterNode was not constructed on the same OfflineAudioContext it needs to be created
                 * again.
                 */
                const nativeBiquadFilterNodeIsOwnedByContext = isOwnedByContext(nativeBiquadFilterNode, nativeOfflineAudioContext);
                if (!nativeBiquadFilterNodeIsOwnedByContext) {
                    const options = {
                        Q: nativeBiquadFilterNode.Q.value,
                        channelCount: nativeBiquadFilterNode.channelCount,
                        channelCountMode: nativeBiquadFilterNode.channelCountMode,
                        channelInterpretation: nativeBiquadFilterNode.channelInterpretation,
                        detune: nativeBiquadFilterNode.detune.value,
                        frequency: nativeBiquadFilterNode.frequency.value,
                        gain: nativeBiquadFilterNode.gain.value,
                        type: nativeBiquadFilterNode.type
                    };
                    nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeOfflineAudioContext, options);
                }
                renderedNativeBiquadFilterNodes.set(nativeOfflineAudioContext, nativeBiquadFilterNode);
                if (!nativeBiquadFilterNodeIsOwnedByContext) {
                    await renderAutomation(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain, trace);
                }
                else {
                    await connectAudioParam(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain, trace);
                }
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeBiquadFilterNode, trace);
                return nativeBiquadFilterNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeBiquadFilterNode = renderedNativeBiquadFilterNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeBiquadFilterNode !== undefined) {
                        return Promise.resolve(renderedNativeBiquadFilterNode);
                    }
                    return createBiquadFilterNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const createCacheTestResult = (ongoingTests, testResults) => {
        return (tester, test) => {
            const cachedTestResult = testResults.get(tester);
            if (cachedTestResult !== undefined) {
                return cachedTestResult;
            }
            const ongoingTest = ongoingTests.get(tester);
            if (ongoingTest !== undefined) {
                return ongoingTest;
            }
            try {
                const synchronousTestResult = test();
                if (synchronousTestResult instanceof Promise) {
                    ongoingTests.set(tester, synchronousTestResult);
                    return synchronousTestResult
                        .catch(() => false)
                        .then((finalTestResult) => {
                        ongoingTests.delete(tester);
                        testResults.set(tester, finalTestResult);
                        return finalTestResult;
                    });
                }
                testResults.set(tester, synchronousTestResult);
                return synchronousTestResult;
            }
            catch {
                testResults.set(tester, false);
                return false;
            }
        };
    };

    const DEFAULT_OPTIONS$5 = {
        channelCount: 1,
        channelCountMode: 'explicit',
        channelInterpretation: 'speakers',
        numberOfInputs: 6
    };
    const createChannelMergerNodeConstructor = (audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext) => {
        return class ChannelMergerNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$5, ...options };
                const nativeChannelMergerNode = createNativeChannelMergerNode(nativeContext, mergedOptions);
                const channelMergerNodeRenderer = ((isNativeOfflineAudioContext(nativeContext) ? createChannelMergerNodeRenderer() : null));
                super(context, false, nativeChannelMergerNode, channelMergerNodeRenderer);
            }
        };
    };

    const createChannelMergerNodeRendererFactory = (createNativeChannelMergerNode, getNativeAudioNode, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeAudioNodes = new WeakMap();
            const createAudioNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeAudioNode = getNativeAudioNode(proxy);
                // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.
                const nativeAudioNodeIsOwnedByContext = isOwnedByContext(nativeAudioNode, nativeOfflineAudioContext);
                if (!nativeAudioNodeIsOwnedByContext) {
                    const options = {
                        channelCount: nativeAudioNode.channelCount,
                        channelCountMode: nativeAudioNode.channelCountMode,
                        channelInterpretation: nativeAudioNode.channelInterpretation,
                        numberOfInputs: nativeAudioNode.numberOfInputs
                    };
                    nativeAudioNode = createNativeChannelMergerNode(nativeOfflineAudioContext, options);
                }
                renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode, trace);
                return nativeAudioNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeAudioNode !== undefined) {
                        return Promise.resolve(renderedNativeAudioNode);
                    }
                    return createAudioNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const DEFAULT_OPTIONS$6 = {
        channelCount: 6,
        channelCountMode: 'explicit',
        channelInterpretation: 'discrete',
        numberOfOutputs: 6
    };
    const createChannelSplitterNodeConstructor = (audioNodeConstructor, createChannelSplitterNodeRenderer, createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext, sanitizeChannelSplitterOptions) => {
        return class ChannelSplitterNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = sanitizeChannelSplitterOptions({ ...DEFAULT_OPTIONS$6, ...options });
                const nativeChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, mergedOptions);
                const channelSplitterNodeRenderer = ((isNativeOfflineAudioContext(nativeContext) ? createChannelSplitterNodeRenderer() : null));
                super(context, false, nativeChannelSplitterNode, channelSplitterNodeRenderer);
            }
        };
    };

    const createChannelSplitterNodeRendererFactory = (createNativeChannelSplitterNode, getNativeAudioNode, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeAudioNodes = new WeakMap();
            const createAudioNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeAudioNode = getNativeAudioNode(proxy);
                // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.
                const nativeAudioNodeIsOwnedByContext = isOwnedByContext(nativeAudioNode, nativeOfflineAudioContext);
                if (!nativeAudioNodeIsOwnedByContext) {
                    const options = {
                        channelCount: nativeAudioNode.channelCount,
                        channelCountMode: nativeAudioNode.channelCountMode,
                        channelInterpretation: nativeAudioNode.channelInterpretation,
                        numberOfOutputs: nativeAudioNode.numberOfOutputs
                    };
                    nativeAudioNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, options);
                }
                renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode, trace);
                return nativeAudioNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeAudioNode !== undefined) {
                        return Promise.resolve(renderedNativeAudioNode);
                    }
                    return createAudioNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const createConnectAudioParam = (renderInputsOfAudioParam) => {
        return (nativeOfflineAudioContext, audioParam, nativeAudioParam, trace) => {
            return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam, trace);
        };
    };

    const createConnectMultipleOutputs = (createIndexSizeError) => {
        return (outputAudioNodes, destination, output = 0, input = 0) => {
            const outputAudioNode = outputAudioNodes[output];
            if (outputAudioNode === undefined) {
                throw createIndexSizeError();
            }
            if (isNativeAudioNode(destination)) {
                return outputAudioNode.connect(destination, 0, input);
            }
            return outputAudioNode.connect(destination, 0);
        };
    };

    const createConnectedNativeAudioBufferSourceNodeFactory = (createNativeAudioBufferSourceNode) => {
        return (nativeContext, nativeAudioNode) => {
            const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {
                buffer: null,
                channelCount: 2,
                channelCountMode: 'max',
                channelInterpretation: 'speakers',
                loop: false,
                loopEnd: 0,
                loopStart: 0,
                playbackRate: 1
            });
            const nativeAudioBuffer = nativeContext.createBuffer(1, 2, 44100);
            nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
            nativeAudioBufferSourceNode.loop = true;
            nativeAudioBufferSourceNode.connect(nativeAudioNode);
            nativeAudioBufferSourceNode.start();
            return () => {
                nativeAudioBufferSourceNode.stop();
                nativeAudioBufferSourceNode.disconnect(nativeAudioNode);
            };
        };
    };

    const DEFAULT_OPTIONS$7 = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        offset: 1
    };
    const createConstantSourceNodeConstructor = (audioNodeConstructor, createAudioParam, createConstantSourceNodeRendererFactory, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {
        return class ConstantSourceNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$7, ...options };
                const nativeConstantSourceNode = createNativeConstantSourceNode(nativeContext, mergedOptions);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const constantSourceNodeRenderer = ((isOffline ? createConstantSourceNodeRendererFactory() : null));
                super(context, false, nativeConstantSourceNode, constantSourceNodeRenderer);
                this._constantSourceNodeRenderer = constantSourceNodeRenderer;
                this._nativeConstantSourceNode = nativeConstantSourceNode;
                /*
                 * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and minValue
                 * for GainNodes.
                 */
                this._offset = createAudioParam(this, isOffline, nativeConstantSourceNode.offset, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);
                this._onended = null;
            }
            get offset() {
                return this._offset;
            }
            get onended() {
                return this._onended;
            }
            set onended(value) {
                const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;
                this._nativeConstantSourceNode.onended = wrappedListener;
                const nativeOnEnded = this._nativeConstantSourceNode.onended;
                this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
            }
            start(when = 0) {
                this._nativeConstantSourceNode.start(when);
                if (this._constantSourceNodeRenderer !== null) {
                    this._constantSourceNodeRenderer.start = when;
                }
                if (this.context.state !== 'closed') {
                    setInternalStateToActive(this);
                    const resetInternalStateToPassive = () => {
                        this._nativeConstantSourceNode.removeEventListener('ended', resetInternalStateToPassive);
                        if (isActiveAudioNode(this)) {
                            setInternalStateToPassive(this);
                        }
                    };
                    this._nativeConstantSourceNode.addEventListener('ended', resetInternalStateToPassive);
                }
            }
            stop(when = 0) {
                this._nativeConstantSourceNode.stop(when);
                if (this._constantSourceNodeRenderer !== null) {
                    this._constantSourceNodeRenderer.stop = when;
                }
            }
        };
    };

    const createConstantSourceNodeRendererFactory = (connectAudioParam, createNativeConstantSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeConstantSourceNodes = new WeakMap();
            let start = null;
            let stop = null;
            const createConstantSourceNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeConstantSourceNode = getNativeAudioNode(proxy);
                /*
                 * If the initially used nativeConstantSourceNode was not constructed on the same OfflineAudioContext it needs to be created
                 * again.
                 */
                const nativeConstantSourceNodeIsOwnedByContext = isOwnedByContext(nativeConstantSourceNode, nativeOfflineAudioContext);
                if (!nativeConstantSourceNodeIsOwnedByContext) {
                    const options = {
                        channelCount: nativeConstantSourceNode.channelCount,
                        channelCountMode: nativeConstantSourceNode.channelCountMode,
                        channelInterpretation: nativeConstantSourceNode.channelInterpretation,
                        offset: nativeConstantSourceNode.offset.value
                    };
                    nativeConstantSourceNode = createNativeConstantSourceNode(nativeOfflineAudioContext, options);
                    if (start !== null) {
                        nativeConstantSourceNode.start(start);
                    }
                    if (stop !== null) {
                        nativeConstantSourceNode.stop(stop);
                    }
                }
                renderedNativeConstantSourceNodes.set(nativeOfflineAudioContext, nativeConstantSourceNode);
                if (!nativeConstantSourceNodeIsOwnedByContext) {
                    await renderAutomation(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset, trace);
                }
                else {
                    await connectAudioParam(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset, trace);
                }
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConstantSourceNode, trace);
                return nativeConstantSourceNode;
            };
            return {
                set start(value) {
                    start = value;
                },
                set stop(value) {
                    stop = value;
                },
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeConstantSourceNode = renderedNativeConstantSourceNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeConstantSourceNode !== undefined) {
                        return Promise.resolve(renderedNativeConstantSourceNode);
                    }
                    return createConstantSourceNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const createConvertNumberToUnsignedLong = (unit32Array) => {
        return (value) => {
            unit32Array[0] = value;
            return unit32Array[0];
        };
    };

    const DEFAULT_OPTIONS$8 = {
        buffer: null,
        channelCount: 2,
        channelCountMode: 'clamped-max',
        channelInterpretation: 'speakers',
        disableNormalization: false
    };
    const createConvolverNodeConstructor = (audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {
        return class ConvolverNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$8, ...options };
                const nativeConvolverNode = createNativeConvolverNode(nativeContext, mergedOptions);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const convolverNodeRenderer = (isOffline ? createConvolverNodeRenderer() : null);
                super(context, false, nativeConvolverNode, convolverNodeRenderer);
                this._isBufferNullified = false;
                this._nativeConvolverNode = nativeConvolverNode;
                if (mergedOptions.buffer !== null) {
                    setAudioNodeTailTime(this, mergedOptions.buffer.duration);
                }
            }
            get buffer() {
                if (this._isBufferNullified) {
                    return null;
                }
                return this._nativeConvolverNode.buffer;
            }
            set buffer(value) {
                this._nativeConvolverNode.buffer = value;
                // Bug #115: Safari does not allow to set the buffer to null.
                if (value === null && this._nativeConvolverNode.buffer !== null) {
                    const nativeContext = this._nativeConvolverNode.context;
                    this._nativeConvolverNode.buffer = nativeContext.createBuffer(1, 1, 44100);
                    this._isBufferNullified = true;
                    setAudioNodeTailTime(this, 0);
                }
                else {
                    this._isBufferNullified = false;
                    setAudioNodeTailTime(this, this._nativeConvolverNode.buffer === null ? 0 : this._nativeConvolverNode.buffer.duration);
                }
            }
            get normalize() {
                return this._nativeConvolverNode.normalize;
            }
            set normalize(value) {
                this._nativeConvolverNode.normalize = value;
            }
        };
    };

    const createConvolverNodeRendererFactory = (createNativeConvolverNode, getNativeAudioNode, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeConvolverNodes = new WeakMap();
            const createConvolverNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeConvolverNode = getNativeAudioNode(proxy);
                // If the initially used nativeConvolverNode was not constructed on the same OfflineAudioContext it needs to be created again.
                const nativeConvolverNodeIsOwnedByContext = isOwnedByContext(nativeConvolverNode, nativeOfflineAudioContext);
                if (!nativeConvolverNodeIsOwnedByContext) {
                    const options = {
                        buffer: nativeConvolverNode.buffer,
                        channelCount: nativeConvolverNode.channelCount,
                        channelCountMode: nativeConvolverNode.channelCountMode,
                        channelInterpretation: nativeConvolverNode.channelInterpretation,
                        disableNormalization: !nativeConvolverNode.normalize
                    };
                    nativeConvolverNode = createNativeConvolverNode(nativeOfflineAudioContext, options);
                }
                renderedNativeConvolverNodes.set(nativeOfflineAudioContext, nativeConvolverNode);
                if (isNativeAudioNodeFaker(nativeConvolverNode)) {
                    await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode.inputs[0], trace);
                }
                else {
                    await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode, trace);
                }
                return nativeConvolverNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeConvolverNode = renderedNativeConvolverNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeConvolverNode !== undefined) {
                        return Promise.resolve(renderedNativeConvolverNode);
                    }
                    return createConvolverNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const createCreateNativeOfflineAudioContext = (createNotSupportedError, nativeOfflineAudioContextConstructor) => {
        return (numberOfChannels, length, sampleRate) => {
            if (nativeOfflineAudioContextConstructor === null) {
                throw new Error('Missing the native OfflineAudioContext constructor.');
            }
            try {
                return new nativeOfflineAudioContextConstructor(numberOfChannels, length, sampleRate);
            }
            catch (err) {
                // Bug #143, #144 & #146: Safari throws a SyntaxError when numberOfChannels, length or sampleRate are invalid.
                if (err.name === 'SyntaxError') {
                    throw createNotSupportedError();
                }
                throw err;
            }
        };
    };

    const createDataCloneError = () => new DOMException('', 'DataCloneError');

    const detachArrayBuffer = (arrayBuffer) => {
        const { port1 } = new MessageChannel();
        port1.postMessage(arrayBuffer, [arrayBuffer]);
    };

    const createDecodeAudioData = (audioBufferStore, cacheTestResult, createDataCloneError, createEncodingError, detachedArrayBuffers, getNativeContext, isNativeContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {
        return (anyContext, audioData) => {
            const nativeContext = isNativeContext(anyContext) ? anyContext : getNativeContext(anyContext);
            // Bug #43: Only Chrome, Edge and Opera do throw a DataCloneError.
            if (detachedArrayBuffers.has(audioData)) {
                const err = createDataCloneError();
                return Promise.reject(err);
            }
            // The audioData parameter maybe of a type which can't be added to a WeakSet.
            try {
                detachedArrayBuffers.add(audioData);
            }
            catch {
                // Ignore errors.
            }
            // Bug #21: Safari does not support promises yet.
            if (cacheTestResult(testPromiseSupport, () => testPromiseSupport(nativeContext))) {
                return nativeContext.decodeAudioData(audioData).then((audioBuffer) => {
                    // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
                    if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) {
                        wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
                    }
                    audioBufferStore.add(audioBuffer);
                    return audioBuffer;
                });
            }
            // Bug #21: Safari does not return a Promise yet.
            return new Promise((resolve, reject) => {
                const complete = () => {
                    // Bug #133: Safari does neuter the ArrayBuffer.
                    try {
                        detachArrayBuffer(audioData);
                    }
                    catch {
                        // Ignore errors.
                    }
                };
                const fail = (err) => {
                    reject(err);
                    complete();
                };
                // Bug #26: Safari throws a synchronous error.
                try {
                    // Bug #1: Safari requires a successCallback.
                    nativeContext.decodeAudioData(audioData, (audioBuffer) => {
                        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
                        // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
                        if (typeof audioBuffer.copyFromChannel !== 'function') {
                            wrapAudioBufferCopyChannelMethods(audioBuffer);
                            wrapAudioBufferGetChannelDataMethod(audioBuffer);
                        }
                        audioBufferStore.add(audioBuffer);
                        complete();
                        resolve(audioBuffer);
                    }, (err) => {
                        // Bug #4: Safari returns null instead of an error.
                        if (err === null) {
                            fail(createEncodingError());
                        }
                        else {
                            fail(err);
                        }
                    });
                }
                catch (err) {
                    fail(err);
                }
            });
        };
    };

    const createDecrementCycleCounter = (connectNativeAudioNodeToNativeAudioNode, cycleCounters, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, getNativeContext, isActiveAudioNode, isNativeOfflineAudioContext) => {
        return (audioNode, count) => {
            const cycleCounter = cycleCounters.get(audioNode);
            if (cycleCounter === undefined) {
                throw new Error('Missing the expected cycle count.');
            }
            const nativeContext = getNativeContext(audioNode.context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            if (cycleCounter === count) {
                cycleCounters.delete(audioNode);
                if (!isOffline && isActiveAudioNode(audioNode)) {
                    const nativeSourceAudioNode = getNativeAudioNode(audioNode);
                    const { outputs } = getAudioNodeConnections(audioNode);
                    for (const output of outputs) {
                        if (isAudioNodeOutputConnection(output)) {
                            const nativeDestinationAudioNode = getNativeAudioNode(output[0]);
                            connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);
                        }
                        else {
                            const nativeDestinationAudioParam = getNativeAudioParam(output[0]);
                            nativeSourceAudioNode.connect(nativeDestinationAudioParam, output[1]);
                        }
                    }
                }
            }
            else {
                cycleCounters.set(audioNode, cycleCounter - count);
            }
        };
    };

    const DEFAULT_OPTIONS$9 = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        delayTime: 0,
        maxDelayTime: 1
    };
    const createDelayNodeConstructor = (audioNodeConstructor, createAudioParam, createDelayNodeRenderer, createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {
        return class DelayNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$9, ...options };
                const nativeDelayNode = createNativeDelayNode(nativeContext, mergedOptions);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const delayNodeRenderer = (isOffline ? createDelayNodeRenderer(mergedOptions.maxDelayTime) : null);
                super(context, false, nativeDelayNode, delayNodeRenderer);
                this._delayTime = createAudioParam(this, isOffline, nativeDelayNode.delayTime);
                setAudioNodeTailTime(this, mergedOptions.maxDelayTime);
            }
            get delayTime() {
                return this._delayTime;
            }
        };
    };

    const createDelayNodeRendererFactory = (connectAudioParam, createNativeDelayNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {
        return (maxDelayTime) => {
            const renderedNativeDelayNodes = new WeakMap();
            const createDelayNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeDelayNode = getNativeAudioNode(proxy);
                // If the initially used nativeDelayNode was not constructed on the same OfflineAudioContext it needs to be created again.
                const nativeDelayNodeIsOwnedByContext = isOwnedByContext(nativeDelayNode, nativeOfflineAudioContext);
                if (!nativeDelayNodeIsOwnedByContext) {
                    const options = {
                        channelCount: nativeDelayNode.channelCount,
                        channelCountMode: nativeDelayNode.channelCountMode,
                        channelInterpretation: nativeDelayNode.channelInterpretation,
                        delayTime: nativeDelayNode.delayTime.value,
                        maxDelayTime
                    };
                    nativeDelayNode = createNativeDelayNode(nativeOfflineAudioContext, options);
                }
                renderedNativeDelayNodes.set(nativeOfflineAudioContext, nativeDelayNode);
                if (!nativeDelayNodeIsOwnedByContext) {
                    await renderAutomation(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime, trace);
                }
                else {
                    await connectAudioParam(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime, trace);
                }
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDelayNode, trace);
                return nativeDelayNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeDelayNode = renderedNativeDelayNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeDelayNode !== undefined) {
                        return Promise.resolve(renderedNativeDelayNode);
                    }
                    return createDelayNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const createDeleteActiveInputConnectionToAudioNode = (pickElementFromSet) => {
        return (activeInputs, source, output, input) => {
            return pickElementFromSet(activeInputs[input], (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output);
        };
    };

    const createDeleteUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes) => {
        return (nativeContext, audioWorkletNode) => {
            getUnrenderedAudioWorkletNodes(nativeContext).delete(audioWorkletNode);
        };
    };

    const isDelayNode = (audioNode) => {
        return 'delayTime' in audioNode;
    };

    const createDetectCycles = (audioParamAudioNodeStore, getAudioNodeConnections, getValueForKey) => {
        return function detectCycles(chain, nextLink) {
            const audioNode = isAudioNode(nextLink) ? nextLink : getValueForKey(audioParamAudioNodeStore, nextLink);
            if (isDelayNode(audioNode)) {
                return [];
            }
            if (chain[0] === audioNode) {
                return [chain];
            }
            if (chain.includes(audioNode)) {
                return [];
            }
            const { outputs } = getAudioNodeConnections(audioNode);
            return Array.from(outputs)
                .map((outputConnection) => detectCycles([...chain, audioNode], outputConnection[0]))
                .reduce((mergedCycles, nestedCycles) => mergedCycles.concat(nestedCycles), []);
        };
    };

    const getOutputAudioNodeAtIndex = (createIndexSizeError, outputAudioNodes, output) => {
        const outputAudioNode = outputAudioNodes[output];
        if (outputAudioNode === undefined) {
            throw createIndexSizeError();
        }
        return outputAudioNode;
    };
    const createDisconnectMultipleOutputs = (createIndexSizeError) => {
        return (outputAudioNodes, destinationOrOutput = undefined, output = undefined, input = 0) => {
            if (destinationOrOutput === undefined) {
                return outputAudioNodes.forEach((outputAudioNode) => outputAudioNode.disconnect());
            }
            if (typeof destinationOrOutput === 'number') {
                return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, destinationOrOutput).disconnect();
            }
            if (isNativeAudioNode(destinationOrOutput)) {
                if (output === undefined) {
                    return outputAudioNodes.forEach((outputAudioNode) => outputAudioNode.disconnect(destinationOrOutput));
                }
                if (input === undefined) {
                    return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);
                }
                return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0, input);
            }
            if (output === undefined) {
                return outputAudioNodes.forEach((outputAudioNode) => outputAudioNode.disconnect(destinationOrOutput));
            }
            return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);
        };
    };

    const DEFAULT_OPTIONS$a = {
        attack: 0.003,
        channelCount: 2,
        channelCountMode: 'clamped-max',
        channelInterpretation: 'speakers',
        knee: 30,
        ratio: 12,
        release: 0.25,
        threshold: -24
    };
    const createDynamicsCompressorNodeConstructor = (audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, createNotSupportedError, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {
        return class DynamicsCompressorNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$a, ...options };
                const nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeContext, mergedOptions);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const dynamicsCompressorNodeRenderer = (isOffline ? createDynamicsCompressorNodeRenderer() : null);
                super(context, false, nativeDynamicsCompressorNode, dynamicsCompressorNodeRenderer);
                this._attack = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.attack);
                this._knee = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.knee);
                this._nativeDynamicsCompressorNode = nativeDynamicsCompressorNode;
                this._ratio = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.ratio);
                this._release = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.release);
                this._threshold = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.threshold);
                setAudioNodeTailTime(this, 0.006);
            }
            get attack() {
                return this._attack;
            }
            // Bug #108: Safari allows a channelCount of three and above which is why the getter and setter needs to be overwritten here.
            get channelCount() {
                return this._nativeDynamicsCompressorNode.channelCount;
            }
            set channelCount(value) {
                const previousChannelCount = this._nativeDynamicsCompressorNode.channelCount;
                this._nativeDynamicsCompressorNode.channelCount = value;
                if (value > 2) {
                    this._nativeDynamicsCompressorNode.channelCount = previousChannelCount;
                    throw createNotSupportedError();
                }
            }
            /*
             * Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max' yet which is why the getter and setter needs to be
             * overwritten here.
             */
            get channelCountMode() {
                return this._nativeDynamicsCompressorNode.channelCountMode;
            }
            set channelCountMode(value) {
                const previousChannelCount = this._nativeDynamicsCompressorNode.channelCountMode;
                this._nativeDynamicsCompressorNode.channelCountMode = value;
                if (value === 'max') {
                    this._nativeDynamicsCompressorNode.channelCountMode = previousChannelCount;
                    throw createNotSupportedError();
                }
            }
            get knee() {
                return this._knee;
            }
            get ratio() {
                return this._ratio;
            }
            get reduction() {
                // Bug #111: Safari returns an AudioParam instead of a number.
                if (typeof this._nativeDynamicsCompressorNode.reduction.value === 'number') {
                    return this._nativeDynamicsCompressorNode.reduction.value;
                }
                return this._nativeDynamicsCompressorNode.reduction;
            }
            get release() {
                return this._release;
            }
            get threshold() {
                return this._threshold;
            }
        };
    };

    const createDynamicsCompressorNodeRendererFactory = (connectAudioParam, createNativeDynamicsCompressorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeDynamicsCompressorNodes = new WeakMap();
            const createDynamicsCompressorNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeDynamicsCompressorNode = getNativeAudioNode(proxy);
                /*
                 * If the initially used nativeDynamicsCompressorNode was not constructed on the same OfflineAudioContext it needs to be
                 * created again.
                 */
                const nativeDynamicsCompressorNodeIsOwnedByContext = isOwnedByContext(nativeDynamicsCompressorNode, nativeOfflineAudioContext);
                if (!nativeDynamicsCompressorNodeIsOwnedByContext) {
                    const options = {
                        attack: nativeDynamicsCompressorNode.attack.value,
                        channelCount: nativeDynamicsCompressorNode.channelCount,
                        channelCountMode: nativeDynamicsCompressorNode.channelCountMode,
                        channelInterpretation: nativeDynamicsCompressorNode.channelInterpretation,
                        knee: nativeDynamicsCompressorNode.knee.value,
                        ratio: nativeDynamicsCompressorNode.ratio.value,
                        release: nativeDynamicsCompressorNode.release.value,
                        threshold: nativeDynamicsCompressorNode.threshold.value
                    };
                    nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeOfflineAudioContext, options);
                }
                renderedNativeDynamicsCompressorNodes.set(nativeOfflineAudioContext, nativeDynamicsCompressorNode);
                if (!nativeDynamicsCompressorNodeIsOwnedByContext) {
                    await renderAutomation(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold, trace);
                }
                else {
                    await connectAudioParam(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold, trace);
                }
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDynamicsCompressorNode, trace);
                return nativeDynamicsCompressorNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeDynamicsCompressorNode = renderedNativeDynamicsCompressorNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeDynamicsCompressorNode !== undefined) {
                        return Promise.resolve(renderedNativeDynamicsCompressorNode);
                    }
                    return createDynamicsCompressorNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const createEncodingError = () => new DOMException('', 'EncodingError');

    const createEvaluateSource = (window) => {
        return (source) => new Promise((resolve, reject) => {
            if (window === null) {
                // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
                reject(new SyntaxError());
                return;
            }
            const head = window.document.head;
            if (head === null) {
                // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
                reject(new SyntaxError());
            }
            else {
                const script = window.document.createElement('script');
                // @todo Safari doesn't like URLs with a type of 'application/javascript; charset=utf-8'.
                const blob = new Blob([source], { type: 'application/javascript' });
                const url = URL.createObjectURL(blob);
                const originalOnErrorHandler = window.onerror;
                const removeErrorEventListenerAndRevokeUrl = () => {
                    window.onerror = originalOnErrorHandler;
                    URL.revokeObjectURL(url);
                };
                window.onerror = (message, src, lineno, colno, error) => {
                    // @todo Edge thinks the source is the one of the html document.
                    if (src === url || (src === window.location.href && lineno === 1 && colno === 1)) {
                        removeErrorEventListenerAndRevokeUrl();
                        reject(error);
                        return false;
                    }
                    if (originalOnErrorHandler !== null) {
                        return originalOnErrorHandler(message, src, lineno, colno, error);
                    }
                };
                script.onerror = () => {
                    removeErrorEventListenerAndRevokeUrl();
                    // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
                    reject(new SyntaxError());
                };
                script.onload = () => {
                    removeErrorEventListenerAndRevokeUrl();
                    resolve();
                };
                script.src = url;
                script.type = 'module';
                head.appendChild(script);
            }
        });
    };

    const createEventTargetConstructor = (wrapEventListener) => {
        return class EventTarget {
            constructor(_nativeEventTarget) {
                this._nativeEventTarget = _nativeEventTarget;
                this._listeners = new WeakMap();
            }
            addEventListener(type, listener, options) {
                if (listener !== null) {
                    let wrappedEventListener = this._listeners.get(listener);
                    if (wrappedEventListener === undefined) {
                        wrappedEventListener = wrapEventListener(this, listener);
                        if (typeof listener === 'function') {
                            this._listeners.set(listener, wrappedEventListener);
                        }
                    }
                    this._nativeEventTarget.addEventListener(type, wrappedEventListener, options);
                }
            }
            dispatchEvent(event) {
                return this._nativeEventTarget.dispatchEvent(event);
            }
            removeEventListener(type, listener, options) {
                const wrappedEventListener = listener === null ? undefined : this._listeners.get(listener);
                this._nativeEventTarget.removeEventListener(type, wrappedEventListener === undefined ? null : wrappedEventListener, options);
            }
        };
    };

    const createExposeCurrentFrameAndCurrentTime = (window) => {
        return (currentTime, sampleRate, fn) => {
            Object.defineProperties(window, {
                currentFrame: {
                    configurable: true,
                    get() {
                        return Math.round(currentTime * sampleRate);
                    }
                },
                currentTime: {
                    configurable: true,
                    get() {
                        return currentTime;
                    }
                }
            });
            try {
                return fn();
            }
            finally {
                if (window !== null) {
                    delete window.currentFrame;
                    delete window.currentTime;
                }
            }
        };
    };

    const createFetchSource = (createAbortError) => {
        return async (url) => {
            try {
                const response = await fetch(url);
                if (response.ok) {
                    return response.text();
                }
            }
            catch {
                // Ignore errors.
            } // tslint:disable-line:no-empty
            throw createAbortError();
        };
    };

    const DEFAULT_OPTIONS$b = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        gain: 1
    };
    const createGainNodeConstructor = (audioNodeConstructor, createAudioParam, createGainNodeRenderer, createNativeGainNode, getNativeContext, isNativeOfflineAudioContext) => {
        return class GainNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$b, ...options };
                const nativeGainNode = createNativeGainNode(nativeContext, mergedOptions);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const gainNodeRenderer = (isOffline ? createGainNodeRenderer() : null);
                super(context, false, nativeGainNode, gainNodeRenderer);
                // Bug #74: Safari does not export the correct values for maxValue and minValue.
                this._gain = createAudioParam(this, isOffline, nativeGainNode.gain, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);
            }
            get gain() {
                return this._gain;
            }
        };
    };

    const createGainNodeRendererFactory = (connectAudioParam, createNativeGainNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeGainNodes = new WeakMap();
            const createGainNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeGainNode = getNativeAudioNode(proxy);
                // If the initially used nativeGainNode was not constructed on the same OfflineAudioContext it needs to be created again.
                const nativeGainNodeIsOwnedByContext = isOwnedByContext(nativeGainNode, nativeOfflineAudioContext);
                if (!nativeGainNodeIsOwnedByContext) {
                    const options = {
                        channelCount: nativeGainNode.channelCount,
                        channelCountMode: nativeGainNode.channelCountMode,
                        channelInterpretation: nativeGainNode.channelInterpretation,
                        gain: nativeGainNode.gain.value
                    };
                    nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, options);
                }
                renderedNativeGainNodes.set(nativeOfflineAudioContext, nativeGainNode);
                if (!nativeGainNodeIsOwnedByContext) {
                    await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain, trace);
                }
                else {
                    await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain, trace);
                }
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeGainNode, trace);
                return nativeGainNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeGainNode = renderedNativeGainNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeGainNode !== undefined) {
                        return Promise.resolve(renderedNativeGainNode);
                    }
                    return createGainNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const createGetActiveAudioWorkletNodeInputs = (activeAudioWorkletNodeInputsStore, getValueForKey) => {
        return (nativeAudioWorkletNode) => getValueForKey(activeAudioWorkletNodeInputsStore, nativeAudioWorkletNode);
    };

    const createGetAudioNodeRenderer = (getAudioNodeConnections) => {
        return (audioNode) => {
            const audioNodeConnections = getAudioNodeConnections(audioNode);
            if (audioNodeConnections.renderer === null) {
                throw new Error('Missing the renderer of the given AudioNode in the audio graph.');
            }
            return audioNodeConnections.renderer;
        };
    };

    const createGetAudioNodeTailTime = (audioNodeTailTimeStore) => {
        return (audioNode) => { var _a; return (_a = audioNodeTailTimeStore.get(audioNode)) !== null && _a !== void 0 ? _a : 0; };
    };

    const createGetAudioParamRenderer = (getAudioParamConnections) => {
        return (audioParam) => {
            const audioParamConnections = getAudioParamConnections(audioParam);
            if (audioParamConnections.renderer === null) {
                throw new Error('Missing the renderer of the given AudioParam in the audio graph.');
            }
            return audioParamConnections.renderer;
        };
    };

    const createGetBackupOfflineAudioContext = (backupOfflineAudioContextStore) => {
        return (nativeContext) => {
            return backupOfflineAudioContextStore.get(nativeContext);
        };
    };

    const createInvalidStateError = () => new DOMException('', 'InvalidStateError');

    const createGetNativeContext = (contextStore) => {
        return (context) => {
            const nativeContext = contextStore.get(context);
            if (nativeContext === undefined) {
                throw createInvalidStateError();
            }
            return (nativeContext);
        };
    };

    const createGetOrCreateBackupOfflineAudioContext = (backupOfflineAudioContextStore, nativeOfflineAudioContextConstructor) => {
        return (nativeContext) => {
            let backupOfflineAudioContext = backupOfflineAudioContextStore.get(nativeContext);
            if (backupOfflineAudioContext !== undefined) {
                return backupOfflineAudioContext;
            }
            if (nativeOfflineAudioContextConstructor === null) {
                throw new Error('Missing the native OfflineAudioContext constructor.');
            }
            backupOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 8000);
            backupOfflineAudioContextStore.set(nativeContext, backupOfflineAudioContext);
            return backupOfflineAudioContext;
        };
    };

    const createGetUnrenderedAudioWorkletNodes = (unrenderedAudioWorkletNodeStore) => {
        return (nativeContext) => {
            const unrenderedAudioWorkletNodes = unrenderedAudioWorkletNodeStore.get(nativeContext);
            if (unrenderedAudioWorkletNodes === undefined) {
                throw new Error('The context has no set of AudioWorkletNodes.');
            }
            return unrenderedAudioWorkletNodes;
        };
    };

    const createInvalidAccessError = () => new DOMException('', 'InvalidAccessError');

    const wrapIIRFilterNodeGetFrequencyResponseMethod = (nativeIIRFilterNode) => {
        nativeIIRFilterNode.getFrequencyResponse = ((getFrequencyResponse) => {
            return (frequencyHz, magResponse, phaseResponse) => {
                if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {
                    throw createInvalidAccessError();
                }
                return getFrequencyResponse.call(nativeIIRFilterNode, frequencyHz, magResponse, phaseResponse);
            };
        })(nativeIIRFilterNode.getFrequencyResponse);
    };

    const DEFAULT_OPTIONS$c = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers'
    };
    const createIIRFilterNodeConstructor = (audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {
        return class IIRFilterNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const mergedOptions = { ...DEFAULT_OPTIONS$c, ...options };
                const nativeIIRFilterNode = createNativeIIRFilterNode(nativeContext, isOffline ? null : context.baseLatency, mergedOptions);
                const iirFilterNodeRenderer = ((isOffline ? createIIRFilterNodeRenderer(mergedOptions.feedback, mergedOptions.feedforward) : null));
                super(context, false, nativeIIRFilterNode, iirFilterNodeRenderer);
                // Bug #23 & #24: FirefoxDeveloper does not throw an InvalidAccessError.
                // @todo Write a test which allows other browsers to remain unpatched.
                wrapIIRFilterNodeGetFrequencyResponseMethod(nativeIIRFilterNode);
                this._nativeIIRFilterNode = nativeIIRFilterNode;
                // @todo Determine a meaningful tail-time instead of just using one second.
                setAudioNodeTailTime(this, 1);
            }
            getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
                return this._nativeIIRFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);
            }
        };
    };

    // This implementation as shamelessly inspired by source code of
    // tslint:disable-next-line:max-line-length
    // {@link https://chromium.googlesource.com/chromium/src.git/+/master/third_party/WebKit/Source/platform/audio/IIRFilter.cpp|Chromium's IIRFilter}.
    const filterBuffer = (feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffer, yBuffer, bufferIndex, bufferLength, input, output) => {
        const inputLength = input.length;
        let i = bufferIndex;
        for (let j = 0; j < inputLength; j += 1) {
            let y = feedforward[0] * input[j];
            for (let k = 1; k < minLength; k += 1) {
                const x = (i - k) & (bufferLength - 1); // tslint:disable-line:no-bitwise
                y += feedforward[k] * xBuffer[x];
                y -= feedback[k] * yBuffer[x];
            }
            for (let k = minLength; k < feedforwardLength; k += 1) {
                y += feedforward[k] * xBuffer[(i - k) & (bufferLength - 1)]; // tslint:disable-line:no-bitwise
            }
            for (let k = minLength; k < feedbackLength; k += 1) {
                y -= feedback[k] * yBuffer[(i - k) & (bufferLength - 1)]; // tslint:disable-line:no-bitwise
            }
            xBuffer[i] = input[j];
            yBuffer[i] = y;
            i = (i + 1) & (bufferLength - 1); // tslint:disable-line:no-bitwise
            output[j] = y;
        }
        return i;
    };

    const filterFullBuffer = (renderedBuffer, nativeOfflineAudioContext, feedback, feedforward) => {
        const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);
        const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);
        const feedbackLength = convertedFeedback.length;
        const feedforwardLength = convertedFeedforward.length;
        const minLength = Math.min(feedbackLength, feedforwardLength);
        if (convertedFeedback[0] !== 1) {
            for (let i = 0; i < feedbackLength; i += 1) {
                convertedFeedforward[i] /= convertedFeedback[0];
            }
            for (let i = 1; i < feedforwardLength; i += 1) {
                convertedFeedback[i] /= convertedFeedback[0];
            }
        }
        const bufferLength = 32;
        const xBuffer = new Float32Array(bufferLength);
        const yBuffer = new Float32Array(bufferLength);
        const filteredBuffer = nativeOfflineAudioContext.createBuffer(renderedBuffer.numberOfChannels, renderedBuffer.length, renderedBuffer.sampleRate);
        const numberOfChannels = renderedBuffer.numberOfChannels;
        for (let i = 0; i < numberOfChannels; i += 1) {
            const input = renderedBuffer.getChannelData(i);
            const output = filteredBuffer.getChannelData(i);
            xBuffer.fill(0);
            yBuffer.fill(0);
            filterBuffer(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffer, yBuffer, 0, bufferLength, input, output);
        }
        return filteredBuffer;
    };
    const createIIRFilterNodeRendererFactory = (createNativeAudioBufferSourceNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {
        return (feedback, feedforward) => {
            const renderedNativeAudioNodes = new WeakMap();
            let filteredBufferPromise = null;
            const createAudioNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeAudioBufferSourceNode = null;
                let nativeIIRFilterNode = getNativeAudioNode(proxy);
                // If the initially used nativeIIRFilterNode was not constructed on the same OfflineAudioContext it needs to be created again.
                const nativeIIRFilterNodeIsOwnedByContext = isOwnedByContext(nativeIIRFilterNode, nativeOfflineAudioContext);
                // Bug #9: Safari does not support IIRFilterNodes.
                if (nativeOfflineAudioContext.createIIRFilter === undefined) {
                    nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {
                        buffer: null,
                        channelCount: 2,
                        channelCountMode: 'max',
                        channelInterpretation: 'speakers',
                        loop: false,
                        loopEnd: 0,
                        loopStart: 0,
                        playbackRate: 1
                    });
                }
                else if (!nativeIIRFilterNodeIsOwnedByContext) {
                    // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.
                    nativeIIRFilterNode = nativeOfflineAudioContext.createIIRFilter(feedforward, feedback);
                }
                renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode === null ? nativeIIRFilterNode : nativeAudioBufferSourceNode);
                if (nativeAudioBufferSourceNode !== null) {
                    if (filteredBufferPromise === null) {
                        if (nativeOfflineAudioContextConstructor === null) {
                            throw new Error('Missing the native OfflineAudioContext constructor.');
                        }
                        const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(
                        // Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.
                        proxy.context.destination.channelCount, 
                        // Bug #17: Safari does not yet expose the length.
                        proxy.context.length, nativeOfflineAudioContext.sampleRate);
                        filteredBufferPromise = (async () => {
                            await renderInputsOfAudioNode(proxy, partialOfflineAudioContext, partialOfflineAudioContext.destination, trace);
                            const renderedBuffer = await renderNativeOfflineAudioContext(partialOfflineAudioContext);
                            return filterFullBuffer(renderedBuffer, nativeOfflineAudioContext, feedback, feedforward);
                        })();
                    }
                    const filteredBuffer = await filteredBufferPromise;
                    nativeAudioBufferSourceNode.buffer = filteredBuffer;
                    nativeAudioBufferSourceNode.start(0);
                    return nativeAudioBufferSourceNode;
                }
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeIIRFilterNode, trace);
                return nativeIIRFilterNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeAudioNode !== undefined) {
                        return Promise.resolve(renderedNativeAudioNode);
                    }
                    return createAudioNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const createIncrementCycleCounterFactory = (cycleCounters, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, isActiveAudioNode) => {
        return (isOffline) => {
            return (audioNode, count) => {
                const cycleCounter = cycleCounters.get(audioNode);
                if (cycleCounter === undefined) {
                    if (!isOffline && isActiveAudioNode(audioNode)) {
                        const nativeSourceAudioNode = getNativeAudioNode(audioNode);
                        const { outputs } = getAudioNodeConnections(audioNode);
                        for (const output of outputs) {
                            if (isAudioNodeOutputConnection(output)) {
                                const nativeDestinationAudioNode = getNativeAudioNode(output[0]);
                                disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);
                            }
                            else {
                                const nativeDestinationAudioParam = getNativeAudioParam(output[0]);
                                nativeSourceAudioNode.disconnect(nativeDestinationAudioParam, output[1]);
                            }
                        }
                    }
                    cycleCounters.set(audioNode, count);
                }
                else {
                    cycleCounters.set(audioNode, cycleCounter + count);
                }
            };
        };
    };

    const createIsAnyAudioContext = (contextStore, isNativeAudioContext) => {
        return (anything) => {
            const nativeContext = contextStore.get(anything);
            return isNativeAudioContext(nativeContext) || isNativeAudioContext(anything);
        };
    };

    const createIsAnyAudioNode = (audioNodeStore, isNativeAudioNode) => {
        return (anything) => audioNodeStore.has(anything) || isNativeAudioNode(anything);
    };

    const createIsAnyAudioParam = (audioParamStore, isNativeAudioParam) => {
        return (anything) => audioParamStore.has(anything) || isNativeAudioParam(anything);
    };

    const createIsAnyOfflineAudioContext = (contextStore, isNativeOfflineAudioContext) => {
        return (anything) => {
            const nativeContext = contextStore.get(anything);
            return isNativeOfflineAudioContext(nativeContext) || isNativeOfflineAudioContext(anything);
        };
    };

    const createIsNativeAudioContext = (nativeAudioContextConstructor) => {
        return (anything) => {
            return nativeAudioContextConstructor !== null && anything instanceof nativeAudioContextConstructor;
        };
    };

    const createIsNativeAudioNode = (window) => {
        return (anything) => {
            return window !== null && typeof window.AudioNode === 'function' && anything instanceof window.AudioNode;
        };
    };

    const createIsNativeAudioParam = (window) => {
        return (anything) => {
            return window !== null && typeof window.AudioParam === 'function' && anything instanceof window.AudioParam;
        };
    };

    const createIsNativeContext = (isNativeAudioContext, isNativeOfflineAudioContext) => {
        return (anything) => {
            return isNativeAudioContext(anything) || isNativeOfflineAudioContext(anything);
        };
    };

    const createIsNativeOfflineAudioContext = (nativeOfflineAudioContextConstructor) => {
        return (anything) => {
            return nativeOfflineAudioContextConstructor !== null && anything instanceof nativeOfflineAudioContextConstructor;
        };
    };

    const createIsSecureContext = (window) => window !== null && window.isSecureContext;

    const createIsSupportedPromise = async (cacheTestResult, testAudioBufferCopyChannelMethodsSubarraySupport, testAudioContextCloseMethodSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextOptionsSupport, testAudioNodeConnectMethodSupport, testAudioWorkletProcessorNoOutputsSupport, testChannelMergerNodeChannelCountSupport, testConstantSourceNodeAccurateSchedulingSupport, testConvolverNodeBufferReassignabilitySupport, testConvolverNodeChannelCountSupport, testDomExceptionContrucorSupport, testIsSecureContextSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testStereoPannerNodeDefaultValueSupport, testTransferablesSupport) => {
        if (cacheTestResult(testAudioBufferCopyChannelMethodsSubarraySupport, testAudioBufferCopyChannelMethodsSubarraySupport) &&
            cacheTestResult(testAudioContextCloseMethodSupport, testAudioContextCloseMethodSupport) &&
            cacheTestResult(testAudioContextOptionsSupport, testAudioContextOptionsSupport) &&
            cacheTestResult(testAudioNodeConnectMethodSupport, testAudioNodeConnectMethodSupport) &&
            cacheTestResult(testChannelMergerNodeChannelCountSupport, testChannelMergerNodeChannelCountSupport) &&
            cacheTestResult(testConstantSourceNodeAccurateSchedulingSupport, testConstantSourceNodeAccurateSchedulingSupport) &&
            cacheTestResult(testConvolverNodeBufferReassignabilitySupport, testConvolverNodeBufferReassignabilitySupport) &&
            cacheTestResult(testConvolverNodeChannelCountSupport, testConvolverNodeChannelCountSupport) &&
            cacheTestResult(testDomExceptionContrucorSupport, testDomExceptionContrucorSupport) &&
            cacheTestResult(testIsSecureContextSupport, testIsSecureContextSupport) &&
            cacheTestResult(testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)) {
            const results = await Promise.all([
                cacheTestResult(testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport),
                cacheTestResult(testAudioWorkletProcessorNoOutputsSupport, testAudioWorkletProcessorNoOutputsSupport),
                cacheTestResult(testStereoPannerNodeDefaultValueSupport, testStereoPannerNodeDefaultValueSupport),
                cacheTestResult(testTransferablesSupport, testTransferablesSupport)
            ]);
            return results.every((result) => result);
        }
        return false;
    };

    const createMediaElementAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext) => {
        return class MediaElementAudioSourceNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const nativeMediaElementAudioSourceNode = createNativeMediaElementAudioSourceNode(nativeContext, options);
                // Bug #171: Safari allows to create a MediaElementAudioSourceNode with an OfflineAudioContext.
                if (isNativeOfflineAudioContext(nativeContext)) {
                    throw TypeError();
                }
                super(context, true, nativeMediaElementAudioSourceNode, null);
                this._nativeMediaElementAudioSourceNode = nativeMediaElementAudioSourceNode;
            }
            get mediaElement() {
                return this._nativeMediaElementAudioSourceNode.mediaElement;
            }
        };
    };

    const DEFAULT_OPTIONS$d = {
        channelCount: 2,
        channelCountMode: 'explicit',
        channelInterpretation: 'speakers'
    };
    const createMediaStreamAudioDestinationNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext) => {
        return class MediaStreamAudioDestinationNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                // Bug #173: Safari allows to create a MediaStreamAudioDestinationNode with an OfflineAudioContext.
                if (isNativeOfflineAudioContext(nativeContext)) {
                    throw new TypeError();
                }
                const mergedOptions = { ...DEFAULT_OPTIONS$d, ...options };
                const nativeMediaStreamAudioDestinationNode = createNativeMediaStreamAudioDestinationNode(nativeContext, mergedOptions);
                super(context, false, nativeMediaStreamAudioDestinationNode, null);
                this._nativeMediaStreamAudioDestinationNode = nativeMediaStreamAudioDestinationNode;
            }
            get stream() {
                return this._nativeMediaStreamAudioDestinationNode.stream;
            }
        };
    };

    const createMediaStreamAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext) => {
        return class MediaStreamAudioSourceNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const nativeMediaStreamAudioSourceNode = createNativeMediaStreamAudioSourceNode(nativeContext, options);
                // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.
                if (isNativeOfflineAudioContext(nativeContext)) {
                    throw new TypeError();
                }
                super(context, true, nativeMediaStreamAudioSourceNode, null);
                this._nativeMediaStreamAudioSourceNode = nativeMediaStreamAudioSourceNode;
            }
            get mediaStream() {
                return this._nativeMediaStreamAudioSourceNode.mediaStream;
            }
        };
    };

    const createMediaStreamTrackAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext) => {
        return class MediaStreamTrackAudioSourceNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const nativeMediaStreamTrackAudioSourceNode = createNativeMediaStreamTrackAudioSourceNode(nativeContext, options);
                super(context, true, nativeMediaStreamTrackAudioSourceNode, null);
            }
        };
    };

    const createMinimalBaseAudioContextConstructor = (audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, wrapEventListener) => {
        return class MinimalBaseAudioContext extends eventTargetConstructor {
            constructor(_nativeContext, numberOfChannels) {
                super(_nativeContext);
                this._nativeContext = _nativeContext;
                CONTEXT_STORE.set(this, _nativeContext);
                if (isNativeOfflineAudioContext(_nativeContext)) {
                    unrenderedAudioWorkletNodeStore.set(_nativeContext, new Set());
                }
                this._destination = new audioDestinationNodeConstructor(this, numberOfChannels);
                this._listener = createAudioListener(this, _nativeContext);
                this._onstatechange = null;
            }
            get currentTime() {
                return this._nativeContext.currentTime;
            }
            get destination() {
                return this._destination;
            }
            get listener() {
                return this._listener;
            }
            get onstatechange() {
                return this._onstatechange;
            }
            set onstatechange(value) {
                const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;
                this._nativeContext.onstatechange = wrappedListener;
                const nativeOnStateChange = this._nativeContext.onstatechange;
                this._onstatechange =
                    nativeOnStateChange !== null && nativeOnStateChange === wrappedListener
                        ? value
                        : nativeOnStateChange;
            }
            get sampleRate() {
                return this._nativeContext.sampleRate;
            }
            get state() {
                return this._nativeContext.state;
            }
        };
    };

    const testPromiseSupport = (nativeContext) => {
        // This 12 numbers represent the 48 bytes of an empty WAVE file with a single sample.
        const uint32Array = new Uint32Array([1179011410, 40, 1163280727, 544501094, 16, 131073, 44100, 176400, 1048580, 1635017060, 4, 0]);
        try {
            // Bug #1: Safari requires a successCallback.
            const promise = nativeContext.decodeAudioData(uint32Array.buffer, () => {
                // Ignore the success callback.
            });
            if (promise === undefined) {
                return false;
            }
            promise.catch(() => {
                // Ignore rejected errors.
            });
            return true;
        }
        catch {
            // Ignore errors.
        }
        return false;
    };

    const createMonitorConnections = (insertElementInSet, isNativeAudioNode) => {
        return (nativeAudioNode, whenConnected, whenDisconnected) => {
            const connections = new Set();
            nativeAudioNode.connect = ((connect) => {
                // tslint:disable-next-line:invalid-void
                return (destination, output = 0, input = 0) => {
                    const wasDisconnected = connections.size === 0;
                    if (isNativeAudioNode(destination)) {
                        // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
                        connect.call(nativeAudioNode, destination, output, input);
                        insertElementInSet(connections, [destination, output, input], (connection) => connection[0] === destination && connection[1] === output && connection[2] === input, true);
                        if (wasDisconnected) {
                            whenConnected();
                        }
                        return destination;
                    }
                    connect.call(nativeAudioNode, destination, output);
                    insertElementInSet(connections, [destination, output], (connection) => connection[0] === destination && connection[1] === output, true);
                    if (wasDisconnected) {
                        whenConnected();
                    }
                    return;
                };
            })(nativeAudioNode.connect);
            nativeAudioNode.disconnect = ((disconnect) => {
                return (destinationOrOutput, output, input) => {
                    const wasConnected = connections.size > 0;
                    if (destinationOrOutput === undefined) {
                        disconnect.apply(nativeAudioNode);
                        connections.clear();
                    }
                    else if (typeof destinationOrOutput === 'number') {
                        // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.
                        disconnect.call(nativeAudioNode, destinationOrOutput);
                        for (const connection of connections) {
                            if (connection[1] === destinationOrOutput) {
                                connections.delete(connection);
                            }
                        }
                    }
                    else {
                        if (isNativeAudioNode(destinationOrOutput)) {
                            // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
                            disconnect.call(nativeAudioNode, destinationOrOutput, output, input);
                        }
                        else {
                            // @todo TypeScript cannot infer the overloaded signature with 2 arguments yet.
                            disconnect.call(nativeAudioNode, destinationOrOutput, output);
                        }
                        for (const connection of connections) {
                            if (connection[0] === destinationOrOutput &&
                                (output === undefined || connection[1] === output) &&
                                (input === undefined || connection[2] === input)) {
                                connections.delete(connection);
                            }
                        }
                    }
                    const isDisconnected = connections.size === 0;
                    if (wasConnected && isDisconnected) {
                        whenDisconnected();
                    }
                };
            })(nativeAudioNode.disconnect);
            return nativeAudioNode;
        };
    };

    const assignNativeAudioNodeOption = (nativeAudioNode, options, option) => {
        const value = options[option];
        if (value !== undefined && value !== nativeAudioNode[option]) {
            nativeAudioNode[option] = value;
        }
    };

    const assignNativeAudioNodeOptions = (nativeAudioNode, options) => {
        assignNativeAudioNodeOption(nativeAudioNode, options, 'channelCount');
        assignNativeAudioNodeOption(nativeAudioNode, options, 'channelCountMode');
        assignNativeAudioNodeOption(nativeAudioNode, options, 'channelInterpretation');
    };

    const testAnalyserNodeGetFloatTimeDomainDataMethodSupport = (nativeAnalyserNode) => {
        return typeof nativeAnalyserNode.getFloatTimeDomainData === 'function';
    };

    const wrapAnalyserNodeGetFloatTimeDomainDataMethod = (nativeAnalyserNode) => {
        nativeAnalyserNode.getFloatTimeDomainData = (array) => {
            const byteTimeDomainData = new Uint8Array(array.length);
            nativeAnalyserNode.getByteTimeDomainData(byteTimeDomainData);
            const length = Math.max(byteTimeDomainData.length, nativeAnalyserNode.fftSize);
            for (let i = 0; i < length; i += 1) {
                array[i] = (byteTimeDomainData[i] - 128) * 0.0078125;
            }
            return array;
        };
    };

    const createNativeAnalyserNodeFactory = (cacheTestResult, createIndexSizeError) => {
        return (nativeContext, options) => {
            const nativeAnalyserNode = nativeContext.createAnalyser();
            // Bug #37: Firefox does not create an AnalyserNode with the default properties.
            assignNativeAudioNodeOptions(nativeAnalyserNode, options);
            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
            if (!(options.maxDecibels > options.minDecibels)) {
                throw createIndexSizeError();
            }
            assignNativeAudioNodeOption(nativeAnalyserNode, options, 'fftSize');
            assignNativeAudioNodeOption(nativeAnalyserNode, options, 'maxDecibels');
            assignNativeAudioNodeOption(nativeAnalyserNode, options, 'minDecibels');
            assignNativeAudioNodeOption(nativeAnalyserNode, options, 'smoothingTimeConstant');
            // Bug #36: Safari does not support getFloatTimeDomainData() yet.
            if (!cacheTestResult(testAnalyserNodeGetFloatTimeDomainDataMethodSupport, () => testAnalyserNodeGetFloatTimeDomainDataMethodSupport(nativeAnalyserNode))) {
                wrapAnalyserNodeGetFloatTimeDomainDataMethod(nativeAnalyserNode);
            }
            return nativeAnalyserNode;
        };
    };

    const createNativeAudioBufferConstructor = (window) => {
        if (window === null) {
            return null;
        }
        if (window.hasOwnProperty('AudioBuffer')) {
            return window.AudioBuffer;
        }
        return null;
    };

    const assignNativeAudioNodeAudioParamValue = (nativeAudioNode, options, audioParam) => {
        const value = options[audioParam];
        if (value !== undefined && value !== nativeAudioNode[audioParam].value) {
            nativeAudioNode[audioParam].value = value;
        }
    };

    const wrapAudioBufferSourceNodeStartMethodConsecutiveCalls = (nativeAudioBufferSourceNode) => {
        nativeAudioBufferSourceNode.start = ((start) => {
            let isScheduled = false;
            return (when = 0, offset = 0, duration) => {
                if (isScheduled) {
                    throw createInvalidStateError();
                }
                start.call(nativeAudioBufferSourceNode, when, offset, duration);
                isScheduled = true;
            };
        })(nativeAudioBufferSourceNode.start);
    };

    const wrapAudioScheduledSourceNodeStartMethodNegativeParameters = (nativeAudioScheduledSourceNode) => {
        nativeAudioScheduledSourceNode.start = ((start) => {
            return (when = 0, offset = 0, duration) => {
                if ((typeof duration === 'number' && duration < 0) || offset < 0 || when < 0) {
                    throw new RangeError("The parameters can't be negative.");
                }
                // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
                start.call(nativeAudioScheduledSourceNode, when, offset, duration);
            };
        })(nativeAudioScheduledSourceNode.start);
    };

    const wrapAudioScheduledSourceNodeStopMethodNegativeParameters = (nativeAudioScheduledSourceNode) => {
        nativeAudioScheduledSourceNode.stop = ((stop) => {
            return (when = 0) => {
                if (when < 0) {
                    throw new RangeError("The parameter can't be negative.");
                }
                stop.call(nativeAudioScheduledSourceNode, when);
            };
        })(nativeAudioScheduledSourceNode.stop);
    };

    const createNativeAudioBufferSourceNodeFactory = (addSilentConnection, cacheTestResult, testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, testAudioBufferSourceNodeStartMethodOffsetClampingSupport, testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioBufferSourceNodeStartMethodOffsetClampling, wrapAudioBufferSourceNodeStopMethodNullifiedBuffer, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls) => {
        return (nativeContext, options) => {
            const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
            assignNativeAudioNodeOptions(nativeAudioBufferSourceNode, options);
            assignNativeAudioNodeAudioParamValue(nativeAudioBufferSourceNode, options, 'playbackRate');
            assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'buffer');
            // Bug #149: Safari does not yet support the detune AudioParam.
            assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'loop');
            assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'loopEnd');
            assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'loopStart');
            // Bug #69: Safari does allow calls to start() of an already scheduled AudioBufferSourceNode.
            if (!cacheTestResult(testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, () => testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport(nativeContext))) {
                wrapAudioBufferSourceNodeStartMethodConsecutiveCalls(nativeAudioBufferSourceNode);
            }
            // Bug #154 & #155: Safari does not handle offsets which are equal to or greater than the duration of the buffer.
            if (!cacheTestResult(testAudioBufferSourceNodeStartMethodOffsetClampingSupport, () => testAudioBufferSourceNodeStartMethodOffsetClampingSupport(nativeContext))) {
                wrapAudioBufferSourceNodeStartMethodOffsetClampling(nativeAudioBufferSourceNode);
            }
            // Bug #162: Safari does throw an error when stop() is called on an AudioBufferSourceNode which has no buffer assigned to it.
            if (!cacheTestResult(testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, () => testAudioBufferSourceNodeStopMethodNullifiedBufferSupport(nativeContext))) {
                wrapAudioBufferSourceNodeStopMethodNullifiedBuffer(nativeAudioBufferSourceNode, nativeContext);
            }
            // Bug #44: Safari does not throw a RangeError yet.
            if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {
                wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeAudioBufferSourceNode);
            }
            // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.
            if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, () => testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) {
                wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeAudioBufferSourceNode, nativeContext);
            }
            // Bug #44: Only Firefox does not throw a RangeError yet.
            if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {
                wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeAudioBufferSourceNode);
            }
            // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.
            addSilentConnection(nativeContext, nativeAudioBufferSourceNode);
            return nativeAudioBufferSourceNode;
        };
    };

    const createNativeAudioContextConstructor = (window) => {
        if (window === null) {
            return null;
        }
        if (window.hasOwnProperty('AudioContext')) {
            return window.AudioContext;
        }
        return window.hasOwnProperty('webkitAudioContext') ? window.webkitAudioContext : null;
    };

    const createNativeAudioDestinationNodeFactory = (createNativeGainNode, overwriteAccessors) => {
        return (nativeContext, channelCount, isNodeOfNativeOfflineAudioContext) => {
            const nativeAudioDestinationNode = nativeContext.destination;
            // Bug #132: Safari does not have the correct channelCount.
            if (nativeAudioDestinationNode.channelCount !== channelCount) {
                try {
                    nativeAudioDestinationNode.channelCount = channelCount;
                }
                catch {
                    // Bug #169: Safari throws an error on each attempt to change the channelCount.
                }
            }
            // Bug #83: Safari does not have the correct channelCountMode.
            if (isNodeOfNativeOfflineAudioContext && nativeAudioDestinationNode.channelCountMode !== 'explicit') {
                nativeAudioDestinationNode.channelCountMode = 'explicit';
            }
            // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.
            if (nativeAudioDestinationNode.maxChannelCount === 0) {
                Object.defineProperty(nativeAudioDestinationNode, 'maxChannelCount', {
                    value: channelCount
                });
            }
            // Bug #168: No browser does yet have an AudioDestinationNode with an output.
            const gainNode = createNativeGainNode(nativeContext, {
                channelCount,
                channelCountMode: nativeAudioDestinationNode.channelCountMode,
                channelInterpretation: nativeAudioDestinationNode.channelInterpretation,
                gain: 1
            });
            overwriteAccessors(gainNode, 'channelCount', (get) => () => get.call(gainNode), (set) => (value) => {
                set.call(gainNode, value);
                try {
                    nativeAudioDestinationNode.channelCount = value;
                }
                catch (err) {
                    // Bug #169: Safari throws an error on each attempt to change the channelCount.
                    if (value > nativeAudioDestinationNode.maxChannelCount) {
                        throw err;
                    }
                }
            });
            overwriteAccessors(gainNode, 'channelCountMode', (get) => () => get.call(gainNode), (set) => (value) => {
                set.call(gainNode, value);
                nativeAudioDestinationNode.channelCountMode = value;
            });
            overwriteAccessors(gainNode, 'channelInterpretation', (get) => () => get.call(gainNode), (set) => (value) => {
                set.call(gainNode, value);
                nativeAudioDestinationNode.channelInterpretation = value;
            });
            Object.defineProperty(gainNode, 'maxChannelCount', {
                get: () => nativeAudioDestinationNode.maxChannelCount
            });
            // @todo This should be disconnected when the context is closed.
            gainNode.connect(nativeAudioDestinationNode);
            return gainNode;
        };
    };

    const createNativeAudioWorkletNodeConstructor = (window) => {
        if (window === null) {
            return null;
        }
        return window.hasOwnProperty('AudioWorkletNode') ? window.AudioWorkletNode : null;
    };

    const testClonabilityOfAudioWorkletNodeOptions = (audioWorkletNodeOptions) => {
        const { port1 } = new MessageChannel();
        try {
            // This will throw an error if the audioWorkletNodeOptions are not clonable.
            port1.postMessage(audioWorkletNodeOptions);
        }
        finally {
            port1.close();
        }
    };

    const createNativeAudioWorkletNodeFactory = (createInvalidStateError, createNativeAudioWorkletNodeFaker, createNativeGainNode, createNotSupportedError, monitorConnections) => {
        return (nativeContext, baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, options) => {
            if (nativeAudioWorkletNodeConstructor !== null) {
                try {
                    const nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeContext, name, options);
                    const patchedEventListeners = new Map();
                    let onprocessorerror = null;
                    Object.defineProperties(nativeAudioWorkletNode, {
                        /*
                         * Bug #61: Overwriting the property accessors for channelCount and channelCountMode is necessary as long as some
                         * browsers have no native implementation to achieve a consistent behavior.
                         */
                        channelCount: {
                            get: () => options.channelCount,
                            set: () => {
                                throw createInvalidStateError();
                            }
                        },
                        channelCountMode: {
                            get: () => 'explicit',
                            set: () => {
                                throw createInvalidStateError();
                            }
                        },
                        // Bug #156: Chrome and Edge do not yet fire an ErrorEvent.
                        onprocessorerror: {
                            get: () => onprocessorerror,
                            set: (value) => {
                                if (typeof onprocessorerror === 'function') {
                                    nativeAudioWorkletNode.removeEventListener('processorerror', onprocessorerror);
                                }
                                onprocessorerror = typeof value === 'function' ? value : null;
                                if (typeof onprocessorerror === 'function') {
                                    nativeAudioWorkletNode.addEventListener('processorerror', onprocessorerror);
                                }
                            }
                        }
                    });
                    nativeAudioWorkletNode.addEventListener = ((addEventListener) => {
                        return (...args) => {
                            if (args[0] === 'processorerror') {
                                const unpatchedEventListener = typeof args[1] === 'function'
                                    ? args[1]
                                    : typeof args[1] === 'object' && args[1] !== null && typeof args[1].handleEvent === 'function'
                                        ? args[1].handleEvent
                                        : null;
                                if (unpatchedEventListener !== null) {
                                    const patchedEventListener = patchedEventListeners.get(args[1]);
                                    if (patchedEventListener !== undefined) {
                                        args[1] = patchedEventListener;
                                    }
                                    else {
                                        args[1] = (event) => {
                                            // Bug #178: Chrome, Edge and Opera do fire an event of type error.
                                            if (event.type === 'error') {
                                                Object.defineProperties(event, {
                                                    type: { value: 'processorerror' }
                                                });
                                                unpatchedEventListener(event);
                                            }
                                            else {
                                                unpatchedEventListener(new ErrorEvent(args[0], { ...event }));
                                            }
                                        };
                                        patchedEventListeners.set(unpatchedEventListener, args[1]);
                                    }
                                }
                            }
                            // Bug #178: Chrome, Edge and Opera do fire an event of type error.
                            addEventListener.call(nativeAudioWorkletNode, 'error', args[1], args[2]);
                            return addEventListener.call(nativeAudioWorkletNode, ...args);
                        };
                    })(nativeAudioWorkletNode.addEventListener);
                    nativeAudioWorkletNode.removeEventListener = ((removeEventListener) => {
                        return (...args) => {
                            if (args[0] === 'processorerror') {
                                const patchedEventListener = patchedEventListeners.get(args[1]);
                                if (patchedEventListener !== undefined) {
                                    patchedEventListeners.delete(args[1]);
                                    args[1] = patchedEventListener;
                                }
                            }
                            // Bug #178: Chrome, Edge and Opera do fire an event of type error.
                            removeEventListener.call(nativeAudioWorkletNode, 'error', args[1], args[2]);
                            return removeEventListener.call(nativeAudioWorkletNode, args[0], args[1], args[2]);
                        };
                    })(nativeAudioWorkletNode.removeEventListener);
                    /*
                     * Bug #86: Chrome and Edge do not invoke the process() function if the corresponding AudioWorkletNode is unconnected but
                     * has an output.
                     */
                    if (options.numberOfOutputs !== 0) {
                        const nativeGainNode = createNativeGainNode(nativeContext, {
                            channelCount: 1,
                            channelCountMode: 'explicit',
                            channelInterpretation: 'discrete',
                            gain: 0
                        });
                        nativeAudioWorkletNode.connect(nativeGainNode).connect(nativeContext.destination);
                        const whenConnected = () => nativeGainNode.disconnect();
                        const whenDisconnected = () => nativeGainNode.connect(nativeContext.destination);
                        // @todo Disconnect the connection when the process() function of the AudioWorkletNode returns false.
                        return monitorConnections(nativeAudioWorkletNode, whenConnected, whenDisconnected);
                    }
                    return nativeAudioWorkletNode;
                }
                catch (err) {
                    // Bug #60: Chrome, Edge & Opera throw an InvalidStateError instead of a NotSupportedError.
                    if (err.code === 11) {
                        throw createNotSupportedError();
                    }
                    throw err;
                }
            }
            // Bug #61: Only Chrome & Opera have an implementation of the AudioWorkletNode yet.
            if (processorConstructor === undefined) {
                throw createNotSupportedError();
            }
            testClonabilityOfAudioWorkletNodeOptions(options);
            return createNativeAudioWorkletNodeFaker(nativeContext, baseLatency, processorConstructor, options);
        };
    };

    const computeBufferSize = (baseLatency, sampleRate) => {
        if (baseLatency === null) {
            return 512;
        }
        return Math.max(512, Math.min(16384, Math.pow(2, Math.round(Math.log2(baseLatency * sampleRate)))));
    };

    const cloneAudioWorkletNodeOptions = (audioWorkletNodeOptions) => {
        return new Promise((resolve, reject) => {
            const { port1, port2 } = new MessageChannel();
            port1.onmessage = ({ data }) => {
                port1.close();
                port2.close();
                resolve(data);
            };
            port1.onmessageerror = ({ data }) => {
                port1.close();
                port2.close();
                reject(data);
            };
            // This will throw an error if the audioWorkletNodeOptions are not clonable.
            port2.postMessage(audioWorkletNodeOptions);
        });
    };

    const createAudioWorkletProcessorPromise = async (processorConstructor, audioWorkletNodeOptions) => {
        const clonedAudioWorkletNodeOptions = await cloneAudioWorkletNodeOptions(audioWorkletNodeOptions);
        return new processorConstructor(clonedAudioWorkletNodeOptions);
    };

    const createAudioWorkletProcessor = (nativeContext, nativeAudioWorkletNode, processorConstructor, audioWorkletNodeOptions) => {
        let nodeToProcessorMap = NODE_TO_PROCESSOR_MAPS.get(nativeContext);
        if (nodeToProcessorMap === undefined) {
            nodeToProcessorMap = new WeakMap();
            NODE_TO_PROCESSOR_MAPS.set(nativeContext, nodeToProcessorMap);
        }
        const audioWorkletProcessorPromise = createAudioWorkletProcessorPromise(processorConstructor, audioWorkletNodeOptions);
        nodeToProcessorMap.set(nativeAudioWorkletNode, audioWorkletProcessorPromise);
        return audioWorkletProcessorPromise;
    };

    const createNativeAudioWorkletNodeFakerFactory = (connectMultipleOutputs, createIndexSizeError, createInvalidStateError, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, createNativeScriptProcessorNode, createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getActiveAudioWorkletNodeInputs, monitorConnections) => {
        return (nativeContext, baseLatency, processorConstructor, options) => {
            if (options.numberOfInputs === 0 && options.numberOfOutputs === 0) {
                throw createNotSupportedError();
            }
            const outputChannelCount = Array.isArray(options.outputChannelCount)
                ? options.outputChannelCount
                : Array.from(options.outputChannelCount);
            // @todo Check if any of the channelCount values is greater than the implementation's maximum number of channels.
            if (outputChannelCount.some((channelCount) => channelCount < 1)) {
                throw createNotSupportedError();
            }
            if (outputChannelCount.length !== options.numberOfOutputs) {
                throw createIndexSizeError();
            }
            // Bug #61: This is not part of the standard but required for the faker to work.
            if (options.channelCountMode !== 'explicit') {
                throw createNotSupportedError();
            }
            const numberOfInputChannels = options.channelCount * options.numberOfInputs;
            const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);
            const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;
            // Bug #61: This is not part of the standard but required for the faker to work.
            if (numberOfInputChannels + numberOfParameters > 6 || numberOfOutputChannels > 6) {
                throw createNotSupportedError();
            }
            const messageChannel = new MessageChannel();
            const gainNodes = [];
            const inputChannelSplitterNodes = [];
            for (let i = 0; i < options.numberOfInputs; i += 1) {
                gainNodes.push(createNativeGainNode(nativeContext, {
                    channelCount: options.channelCount,
                    channelCountMode: options.channelCountMode,
                    channelInterpretation: options.channelInterpretation,
                    gain: 1
                }));
                inputChannelSplitterNodes.push(createNativeChannelSplitterNode(nativeContext, {
                    channelCount: options.channelCount,
                    channelCountMode: 'explicit',
                    channelInterpretation: 'discrete',
                    numberOfOutputs: options.channelCount
                }));
            }
            const constantSourceNodes = [];
            if (processorConstructor.parameterDescriptors !== undefined) {
                for (const { defaultValue, maxValue, minValue, name } of processorConstructor.parameterDescriptors) {
                    const constantSourceNode = createNativeConstantSourceNode(nativeContext, {
                        channelCount: 1,
                        channelCountMode: 'explicit',
                        channelInterpretation: 'discrete',
                        offset: options.parameterData[name] !== undefined
                            ? options.parameterData[name]
                            : defaultValue === undefined
                                ? 0
                                : defaultValue
                    });
                    Object.defineProperties(constantSourceNode.offset, {
                        defaultValue: {
                            get: () => (defaultValue === undefined ? 0 : defaultValue)
                        },
                        maxValue: {
                            get: () => (maxValue === undefined ? MOST_POSITIVE_SINGLE_FLOAT : maxValue)
                        },
                        minValue: {
                            get: () => (minValue === undefined ? MOST_NEGATIVE_SINGLE_FLOAT : minValue)
                        }
                    });
                    constantSourceNodes.push(constantSourceNode);
                }
            }
            const inputChannelMergerNode = createNativeChannelMergerNode(nativeContext, {
                channelCount: 1,
                channelCountMode: 'explicit',
                channelInterpretation: 'speakers',
                numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)
            });
            const bufferSize = computeBufferSize(baseLatency, nativeContext.sampleRate);
            const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, numberOfInputChannels + numberOfParameters, 
            // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.
            Math.max(1, numberOfOutputChannels));
            const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, {
                channelCount: Math.max(1, numberOfOutputChannels),
                channelCountMode: 'explicit',
                channelInterpretation: 'discrete',
                numberOfOutputs: Math.max(1, numberOfOutputChannels)
            });
            const outputChannelMergerNodes = [];
            for (let i = 0; i < options.numberOfOutputs; i += 1) {
                outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeContext, {
                    channelCount: 1,
                    channelCountMode: 'explicit',
                    channelInterpretation: 'speakers',
                    numberOfInputs: outputChannelCount[i]
                }));
            }
            for (let i = 0; i < options.numberOfInputs; i += 1) {
                gainNodes[i].connect(inputChannelSplitterNodes[i]);
                for (let j = 0; j < options.channelCount; j += 1) {
                    inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, i * options.channelCount + j);
                }
            }
            const parameterMap = new ReadOnlyMap(processorConstructor.parameterDescriptors === undefined
                ? []
                : processorConstructor.parameterDescriptors.map(({ name }, index) => {
                    const constantSourceNode = constantSourceNodes[index];
                    constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);
                    constantSourceNode.start(0);
                    return [name, constantSourceNode.offset];
                }));
            inputChannelMergerNode.connect(scriptProcessorNode);
            let channelInterpretation = options.channelInterpretation;
            let onprocessorerror = null;
            // Bug #87: Expose at least one output to make this node connectable.
            const outputAudioNodes = options.numberOfOutputs === 0 ? [scriptProcessorNode] : outputChannelMergerNodes;
            const nativeAudioWorkletNodeFaker = {
                get bufferSize() {
                    return bufferSize;
                },
                get channelCount() {
                    return options.channelCount;
                },
                set channelCount(_) {
                    // Bug #61: This is not part of the standard but required for the faker to work.
                    throw createInvalidStateError();
                },
                get channelCountMode() {
                    return options.channelCountMode;
                },
                set channelCountMode(_) {
                    // Bug #61: This is not part of the standard but required for the faker to work.
                    throw createInvalidStateError();
                },
                get channelInterpretation() {
                    return channelInterpretation;
                },
                set channelInterpretation(value) {
                    for (const gainNode of gainNodes) {
                        gainNode.channelInterpretation = value;
                    }
                    channelInterpretation = value;
                },
                get context() {
                    return scriptProcessorNode.context;
                },
                get inputs() {
                    return gainNodes;
                },
                get numberOfInputs() {
                    return options.numberOfInputs;
                },
                get numberOfOutputs() {
                    return options.numberOfOutputs;
                },
                get onprocessorerror() {
                    return onprocessorerror;
                },
                set onprocessorerror(value) {
                    if (typeof onprocessorerror === 'function') {
                        nativeAudioWorkletNodeFaker.removeEventListener('processorerror', onprocessorerror);
                    }
                    onprocessorerror = typeof value === 'function' ? value : null;
                    if (typeof onprocessorerror === 'function') {
                        nativeAudioWorkletNodeFaker.addEventListener('processorerror', onprocessorerror);
                    }
                },
                get parameters() {
                    return parameterMap;
                },
                get port() {
                    return messageChannel.port2;
                },
                addEventListener(...args) {
                    return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);
                },
                connect: connectMultipleOutputs.bind(null, outputAudioNodes),
                disconnect: disconnectMultipleOutputs.bind(null, outputAudioNodes),
                dispatchEvent(...args) {
                    return scriptProcessorNode.dispatchEvent(args[0]);
                },
                removeEventListener(...args) {
                    return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);
                }
            };
            const patchedEventListeners = new Map();
            messageChannel.port1.addEventListener = ((addEventListener) => {
                return (...args) => {
                    if (args[0] === 'message') {
                        const unpatchedEventListener = typeof args[1] === 'function'
                            ? args[1]
                            : typeof args[1] === 'object' && args[1] !== null && typeof args[1].handleEvent === 'function'
                                ? args[1].handleEvent
                                : null;
                        if (unpatchedEventListener !== null) {
                            const patchedEventListener = patchedEventListeners.get(args[1]);
                            if (patchedEventListener !== undefined) {
                                args[1] = patchedEventListener;
                            }
                            else {
                                args[1] = (event) => {
                                    exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, () => unpatchedEventListener(event));
                                };
                                patchedEventListeners.set(unpatchedEventListener, args[1]);
                            }
                        }
                    }
                    return addEventListener.call(messageChannel.port1, args[0], args[1], args[2]);
                };
            })(messageChannel.port1.addEventListener);
            messageChannel.port1.removeEventListener = ((removeEventListener) => {
                return (...args) => {
                    if (args[0] === 'message') {
                        const patchedEventListener = patchedEventListeners.get(args[1]);
                        if (patchedEventListener !== undefined) {
                            patchedEventListeners.delete(args[1]);
                            args[1] = patchedEventListener;
                        }
                    }
                    return removeEventListener.call(messageChannel.port1, args[0], args[1], args[2]);
                };
            })(messageChannel.port1.removeEventListener);
            let onmessage = null;
            Object.defineProperty(messageChannel.port1, 'onmessage', {
                get: () => onmessage,
                set: (value) => {
                    if (typeof onmessage === 'function') {
                        messageChannel.port1.removeEventListener('message', onmessage);
                    }
                    onmessage = typeof value === 'function' ? value : null;
                    if (typeof onmessage === 'function') {
                        messageChannel.port1.addEventListener('message', onmessage);
                        messageChannel.port1.start();
                    }
                }
            });
            processorConstructor.prototype.port = messageChannel.port1;
            let audioWorkletProcessor = null;
            const audioWorkletProcessorPromise = createAudioWorkletProcessor(nativeContext, nativeAudioWorkletNodeFaker, processorConstructor, options);
            audioWorkletProcessorPromise.then((dWrkltPrcssr) => (audioWorkletProcessor = dWrkltPrcssr));
            const inputs = createNestedArrays(options.numberOfInputs, options.channelCount);
            const outputs = createNestedArrays(options.numberOfOutputs, outputChannelCount);
            const parameters = processorConstructor.parameterDescriptors === undefined
                ? []
                : processorConstructor.parameterDescriptors.reduce((prmtrs, { name }) => ({ ...prmtrs, [name]: new Float32Array(128) }), {});
            let isActive = true;
            const disconnectOutputsGraph = () => {
                if (options.numberOfOutputs > 0) {
                    scriptProcessorNode.disconnect(outputChannelSplitterNode);
                }
                for (let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1) {
                    const outputChannelMergerNode = outputChannelMergerNodes[i];
                    for (let j = 0; j < outputChannelCount[i]; j += 1) {
                        outputChannelSplitterNode.disconnect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                    }
                    outputChannelSplitterNodeOutput += outputChannelCount[i];
                }
            };
            const activeInputIndexes = new Map();
            // tslint:disable-next-line:deprecation
            scriptProcessorNode.onaudioprocess = ({ inputBuffer, outputBuffer }) => {
                if (audioWorkletProcessor !== null) {
                    const activeInputs = getActiveAudioWorkletNodeInputs(nativeAudioWorkletNodeFaker);
                    for (let i = 0; i < bufferSize; i += 128) {
                        for (let j = 0; j < options.numberOfInputs; j += 1) {
                            for (let k = 0; k < options.channelCount; k += 1) {
                                copyFromChannel(inputBuffer, inputs[j], k, k, i);
                            }
                        }
                        if (processorConstructor.parameterDescriptors !== undefined) {
                            processorConstructor.parameterDescriptors.forEach(({ name }, index) => {
                                copyFromChannel(inputBuffer, parameters, name, numberOfInputChannels + index, i);
                            });
                        }
                        for (let j = 0; j < options.numberOfInputs; j += 1) {
                            for (let k = 0; k < outputChannelCount[j]; k += 1) {
                                // The byteLength will be 0 when the ArrayBuffer was transferred.
                                if (outputs[j][k].byteLength === 0) {
                                    outputs[j][k] = new Float32Array(128);
                                }
                            }
                        }
                        try {
                            const potentiallyEmptyInputs = inputs.map((input, index) => {
                                const activeInput = activeInputs[index];
                                if (activeInput.size > 0) {
                                    activeInputIndexes.set(index, bufferSize / 128);
                                    return input;
                                }
                                const count = activeInputIndexes.get(index);
                                if (count === undefined) {
                                    return [];
                                }
                                if (input.every((channelData) => channelData.every((sample) => sample === 0))) {
                                    if (count === 1) {
                                        activeInputIndexes.delete(index);
                                    }
                                    else {
                                        activeInputIndexes.set(index, count - 1);
                                    }
                                }
                                return input;
                            });
                            const activeSourceFlag = exposeCurrentFrameAndCurrentTime(nativeContext.currentTime + i / nativeContext.sampleRate, nativeContext.sampleRate, () => audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));
                            isActive = activeSourceFlag;
                            for (let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1) {
                                for (let k = 0; k < outputChannelCount[j]; k += 1) {
                                    copyToChannel(outputBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);
                                }
                                outputChannelSplitterNodeOutput += outputChannelCount[j];
                            }
                        }
                        catch (error) {
                            isActive = false;
                            nativeAudioWorkletNodeFaker.dispatchEvent(new ErrorEvent('processorerror', {
                                colno: error.colno,
                                filename: error.filename,
                                lineno: error.lineno,
                                message: error.message
                            }));
                        }
                        if (!isActive) {
                            for (let j = 0; j < options.numberOfInputs; j += 1) {
                                gainNodes[j].disconnect(inputChannelSplitterNodes[j]);
                                for (let k = 0; k < options.channelCount; k += 1) {
                                    inputChannelSplitterNodes[i].disconnect(inputChannelMergerNode, k, j * options.channelCount + k);
                                }
                            }
                            if (processorConstructor.parameterDescriptors !== undefined) {
                                const length = processorConstructor.parameterDescriptors.length;
                                for (let j = 0; j < length; j += 1) {
                                    const constantSourceNode = constantSourceNodes[j];
                                    constantSourceNode.disconnect(inputChannelMergerNode, 0, numberOfInputChannels + j);
                                    constantSourceNode.stop();
                                }
                            }
                            inputChannelMergerNode.disconnect(scriptProcessorNode);
                            scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation
                            if (isConnected) {
                                disconnectOutputsGraph();
                            }
                            else {
                                disconnectFakeGraph();
                            }
                            break;
                        }
                    }
                }
            };
            let isConnected = false;
            // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.
            const nativeGainNode = createNativeGainNode(nativeContext, {
                channelCount: 1,
                channelCountMode: 'explicit',
                channelInterpretation: 'discrete',
                gain: 0
            });
            const connectFakeGraph = () => scriptProcessorNode.connect(nativeGainNode).connect(nativeContext.destination);
            const disconnectFakeGraph = () => {
                scriptProcessorNode.disconnect(nativeGainNode);
                nativeGainNode.disconnect();
            };
            const whenConnected = () => {
                if (isActive) {
                    disconnectFakeGraph();
                    if (options.numberOfOutputs > 0) {
                        scriptProcessorNode.connect(outputChannelSplitterNode);
                    }
                    for (let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1) {
                        const outputChannelMergerNode = outputChannelMergerNodes[i];
                        for (let j = 0; j < outputChannelCount[i]; j += 1) {
                            outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                        }
                        outputChannelSplitterNodeOutput += outputChannelCount[i];
                    }
                }
                isConnected = true;
            };
            const whenDisconnected = () => {
                if (isActive) {
                    connectFakeGraph();
                    disconnectOutputsGraph();
                }
                isConnected = false;
            };
            connectFakeGraph();
            return monitorConnections(nativeAudioWorkletNodeFaker, whenConnected, whenDisconnected);
        };
    };

    const createNativeBiquadFilterNode = (nativeContext, options) => {
        const nativeBiquadFilterNode = nativeContext.createBiquadFilter();
        assignNativeAudioNodeOptions(nativeBiquadFilterNode, options);
        assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'Q');
        assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'detune');
        assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'frequency');
        assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'gain');
        assignNativeAudioNodeOption(nativeBiquadFilterNode, options, 'type');
        return nativeBiquadFilterNode;
    };

    const createNativeChannelMergerNodeFactory = (nativeAudioContextConstructor, wrapChannelMergerNode) => {
        return (nativeContext, options) => {
            const nativeChannelMergerNode = nativeContext.createChannelMerger(options.numberOfInputs);
            /*
             * Bug #20: Safari requires a connection of any kind to treat the input signal correctly.
             * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of
             * the webkitAudioContext is used as a workaround here.
             */
            if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === 'webkitAudioContext') {
                wrapChannelMergerNode(nativeContext, nativeChannelMergerNode);
            }
            assignNativeAudioNodeOptions(nativeChannelMergerNode, options);
            return nativeChannelMergerNode;
        };
    };

    const wrapChannelSplitterNode = (channelSplitterNode) => {
        const channelCount = channelSplitterNode.numberOfOutputs;
        // Bug #97: Safari does not throw an error when attempting to change the channelCount to something other than its initial value.
        Object.defineProperty(channelSplitterNode, 'channelCount', {
            get: () => channelCount,
            set: (value) => {
                if (value !== channelCount) {
                    throw createInvalidStateError();
                }
            }
        });
        // Bug #30: Safari does not throw an error when attempting to change the channelCountMode to something other than explicit.
        Object.defineProperty(channelSplitterNode, 'channelCountMode', {
            get: () => 'explicit',
            set: (value) => {
                if (value !== 'explicit') {
                    throw createInvalidStateError();
                }
            }
        });
        // Bug #32: Safari does not throw an error when attempting to change the channelInterpretation to something other than discrete.
        Object.defineProperty(channelSplitterNode, 'channelInterpretation', {
            get: () => 'discrete',
            set: (value) => {
                if (value !== 'discrete') {
                    throw createInvalidStateError();
                }
            }
        });
    };

    const createNativeChannelSplitterNode = (nativeContext, options) => {
        const nativeChannelSplitterNode = nativeContext.createChannelSplitter(options.numberOfOutputs);
        // Bug #96: Safari does not have the correct channelCount.
        // Bug #29: Safari does not have the correct channelCountMode.
        // Bug #31: Safari does not have the correct channelInterpretation.
        assignNativeAudioNodeOptions(nativeChannelSplitterNode, options);
        // Bug #29, #30, #31, #32, #96 & #97: Only Chrome, Edge, Firefox & Opera partially support the spec yet.
        wrapChannelSplitterNode(nativeChannelSplitterNode);
        return nativeChannelSplitterNode;
    };

    const createNativeConstantSourceNodeFactory = (addSilentConnection, cacheTestResult, createNativeConstantSourceNodeFaker, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport) => {
        return (nativeContext, options) => {
            // Bug #62: Safari does not support ConstantSourceNodes.
            if (nativeContext.createConstantSource === undefined) {
                return createNativeConstantSourceNodeFaker(nativeContext, options);
            }
            const nativeConstantSourceNode = nativeContext.createConstantSource();
            assignNativeAudioNodeOptions(nativeConstantSourceNode, options);
            assignNativeAudioNodeAudioParamValue(nativeConstantSourceNode, options, 'offset');
            // Bug #44: Safari does not throw a RangeError yet.
            if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {
                wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeConstantSourceNode);
            }
            // Bug #44: Only Firefox does not throw a RangeError yet.
            if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {
                wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeConstantSourceNode);
            }
            // Bug #175: Safari will not fire an ended event if the ConstantSourceNode is unconnected.
            addSilentConnection(nativeContext, nativeConstantSourceNode);
            return nativeConstantSourceNode;
        };
    };

    const interceptConnections = (original, interceptor) => {
        original.connect = interceptor.connect.bind(interceptor);
        original.disconnect = interceptor.disconnect.bind(interceptor);
        return original;
    };

    const createNativeConstantSourceNodeFakerFactory = (addSilentConnection, createNativeAudioBufferSourceNode, createNativeGainNode, monitorConnections) => {
        return (nativeContext, { offset, ...audioNodeOptions }) => {
            const audioBuffer = nativeContext.createBuffer(1, 2, 44100);
            const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {
                buffer: null,
                channelCount: 2,
                channelCountMode: 'max',
                channelInterpretation: 'speakers',
                loop: false,
                loopEnd: 0,
                loopStart: 0,
                playbackRate: 1
            });
            const gainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: offset });
            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
            const channelData = audioBuffer.getChannelData(0);
            // Bug #95: Safari does not play or loop one sample buffers.
            channelData[0] = 1;
            channelData[1] = 1;
            audioBufferSourceNode.buffer = audioBuffer;
            audioBufferSourceNode.loop = true;
            const nativeConstantSourceNodeFaker = {
                get bufferSize() {
                    return undefined;
                },
                get channelCount() {
                    return gainNode.channelCount;
                },
                set channelCount(value) {
                    gainNode.channelCount = value;
                },
                get channelCountMode() {
                    return gainNode.channelCountMode;
                },
                set channelCountMode(value) {
                    gainNode.channelCountMode = value;
                },
                get channelInterpretation() {
                    return gainNode.channelInterpretation;
                },
                set channelInterpretation(value) {
                    gainNode.channelInterpretation = value;
                },
                get context() {
                    return gainNode.context;
                },
                get inputs() {
                    return [];
                },
                get numberOfInputs() {
                    return audioBufferSourceNode.numberOfInputs;
                },
                get numberOfOutputs() {
                    return gainNode.numberOfOutputs;
                },
                get offset() {
                    return gainNode.gain;
                },
                get onended() {
                    return audioBufferSourceNode.onended;
                },
                set onended(value) {
                    audioBufferSourceNode.onended = value;
                },
                addEventListener(...args) {
                    return audioBufferSourceNode.addEventListener(args[0], args[1], args[2]);
                },
                dispatchEvent(...args) {
                    return audioBufferSourceNode.dispatchEvent(args[0]);
                },
                removeEventListener(...args) {
                    return audioBufferSourceNode.removeEventListener(args[0], args[1], args[2]);
                },
                start(when = 0) {
                    audioBufferSourceNode.start.call(audioBufferSourceNode, when);
                },
                stop(when = 0) {
                    audioBufferSourceNode.stop.call(audioBufferSourceNode, when);
                }
            };
            const whenConnected = () => audioBufferSourceNode.connect(gainNode);
            const whenDisconnected = () => audioBufferSourceNode.disconnect(gainNode);
            // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.
            addSilentConnection(nativeContext, audioBufferSourceNode);
            return monitorConnections(interceptConnections(nativeConstantSourceNodeFaker, gainNode), whenConnected, whenDisconnected);
        };
    };

    const createNativeConvolverNodeFactory = (createNotSupportedError, overwriteAccessors) => {
        return (nativeContext, options) => {
            const nativeConvolverNode = nativeContext.createConvolver();
            assignNativeAudioNodeOptions(nativeConvolverNode, options);
            // The normalize property needs to be set before setting the buffer.
            if (options.disableNormalization === nativeConvolverNode.normalize) {
                nativeConvolverNode.normalize = !options.disableNormalization;
            }
            assignNativeAudioNodeOption(nativeConvolverNode, options, 'buffer');
            // Bug #113: Safari does allow to set the channelCount to a value larger than 2.
            if (options.channelCount > 2) {
                throw createNotSupportedError();
            }
            overwriteAccessors(nativeConvolverNode, 'channelCount', (get) => () => get.call(nativeConvolverNode), (set) => (value) => {
                if (value > 2) {
                    throw createNotSupportedError();
                }
                return set.call(nativeConvolverNode, value);
            });
            // Bug #114: Safari allows to set the channelCountMode to 'max'.
            if (options.channelCountMode === 'max') {
                throw createNotSupportedError();
            }
            overwriteAccessors(nativeConvolverNode, 'channelCountMode', (get) => () => get.call(nativeConvolverNode), (set) => (value) => {
                if (value === 'max') {
                    throw createNotSupportedError();
                }
                return set.call(nativeConvolverNode, value);
            });
            return nativeConvolverNode;
        };
    };

    const createNativeDelayNode = (nativeContext, options) => {
        const nativeDelayNode = nativeContext.createDelay(options.maxDelayTime);
        assignNativeAudioNodeOptions(nativeDelayNode, options);
        assignNativeAudioNodeAudioParamValue(nativeDelayNode, options, 'delayTime');
        return nativeDelayNode;
    };

    const createNativeDynamicsCompressorNodeFactory = (createNotSupportedError) => {
        return (nativeContext, options) => {
            const nativeDynamicsCompressorNode = nativeContext.createDynamicsCompressor();
            assignNativeAudioNodeOptions(nativeDynamicsCompressorNode, options);
            // Bug #108: Safari allows a channelCount of three and above.
            if (options.channelCount > 2) {
                throw createNotSupportedError();
            }
            // Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max'.
            if (options.channelCountMode === 'max') {
                throw createNotSupportedError();
            }
            assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'attack');
            assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'knee');
            assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'ratio');
            assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'release');
            assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'threshold');
            return nativeDynamicsCompressorNode;
        };
    };

    const createNativeGainNode = (nativeContext, options) => {
        const nativeGainNode = nativeContext.createGain();
        assignNativeAudioNodeOptions(nativeGainNode, options);
        assignNativeAudioNodeAudioParamValue(nativeGainNode, options, 'gain');
        return nativeGainNode;
    };

    const createNativeIIRFilterNodeFactory = (createNativeIIRFilterNodeFaker) => {
        return (nativeContext, baseLatency, options) => {
            // Bug #9: Safari does not support IIRFilterNodes.
            if (nativeContext.createIIRFilter === undefined) {
                return createNativeIIRFilterNodeFaker(nativeContext, baseLatency, options);
            }
            // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.
            const nativeIIRFilterNode = nativeContext.createIIRFilter(options.feedforward, options.feedback);
            assignNativeAudioNodeOptions(nativeIIRFilterNode, options);
            return nativeIIRFilterNode;
        };
    };

    function divide(a, b) {
        const denominator = b[0] * b[0] + b[1] * b[1];
        return [(a[0] * b[0] + a[1] * b[1]) / denominator, (a[1] * b[0] - a[0] * b[1]) / denominator];
    }
    function multiply(a, b) {
        return [a[0] * b[0] - a[1] * b[1], a[0] * b[1] + a[1] * b[0]];
    }
    function evaluatePolynomial(coefficient, z) {
        let result = [0, 0];
        for (let i = coefficient.length - 1; i >= 0; i -= 1) {
            result = multiply(result, z);
            result[0] += coefficient[i];
        }
        return result;
    }
    const createNativeIIRFilterNodeFakerFactory = (createInvalidAccessError, createInvalidStateError, createNativeScriptProcessorNode, createNotSupportedError) => {
        return (nativeContext, baseLatency, { channelCount, channelCountMode, channelInterpretation, feedback, feedforward }) => {
            const bufferSize = computeBufferSize(baseLatency, nativeContext.sampleRate);
            const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);
            const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);
            const feedbackLength = convertedFeedback.length;
            const feedforwardLength = convertedFeedforward.length;
            const minLength = Math.min(feedbackLength, feedforwardLength);
            if (feedbackLength === 0 || feedbackLength > 20) {
                throw createNotSupportedError();
            }
            if (convertedFeedback[0] === 0) {
                throw createInvalidStateError();
            }
            if (feedforwardLength === 0 || feedforwardLength > 20) {
                throw createNotSupportedError();
            }
            if (convertedFeedforward[0] === 0) {
                throw createInvalidStateError();
            }
            if (convertedFeedback[0] !== 1) {
                for (let i = 0; i < feedforwardLength; i += 1) {
                    convertedFeedforward[i] /= convertedFeedback[0];
                }
                for (let i = 1; i < feedbackLength; i += 1) {
                    convertedFeedback[i] /= convertedFeedback[0];
                }
            }
            const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, channelCount, channelCount);
            scriptProcessorNode.channelCount = channelCount;
            scriptProcessorNode.channelCountMode = channelCountMode;
            scriptProcessorNode.channelInterpretation = channelInterpretation;
            const bufferLength = 32;
            const bufferIndexes = [];
            const xBuffers = [];
            const yBuffers = [];
            for (let i = 0; i < channelCount; i += 1) {
                bufferIndexes.push(0);
                const xBuffer = new Float32Array(bufferLength);
                const yBuffer = new Float32Array(bufferLength);
                xBuffer.fill(0);
                yBuffer.fill(0);
                xBuffers.push(xBuffer);
                yBuffers.push(yBuffer);
            }
            // tslint:disable-next-line:deprecation
            scriptProcessorNode.onaudioprocess = (event) => {
                const inputBuffer = event.inputBuffer;
                const outputBuffer = event.outputBuffer;
                const numberOfChannels = inputBuffer.numberOfChannels;
                for (let i = 0; i < numberOfChannels; i += 1) {
                    const input = inputBuffer.getChannelData(i);
                    const output = outputBuffer.getChannelData(i);
                    bufferIndexes[i] = filterBuffer(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffers[i], yBuffers[i], bufferIndexes[i], bufferLength, input, output);
                }
            };
            const nyquist = nativeContext.sampleRate / 2;
            const nativeIIRFilterNodeFaker = {
                get bufferSize() {
                    return bufferSize;
                },
                get channelCount() {
                    return scriptProcessorNode.channelCount;
                },
                set channelCount(value) {
                    scriptProcessorNode.channelCount = value;
                },
                get channelCountMode() {
                    return scriptProcessorNode.channelCountMode;
                },
                set channelCountMode(value) {
                    scriptProcessorNode.channelCountMode = value;
                },
                get channelInterpretation() {
                    return scriptProcessorNode.channelInterpretation;
                },
                set channelInterpretation(value) {
                    scriptProcessorNode.channelInterpretation = value;
                },
                get context() {
                    return scriptProcessorNode.context;
                },
                get inputs() {
                    return [scriptProcessorNode];
                },
                get numberOfInputs() {
                    return scriptProcessorNode.numberOfInputs;
                },
                get numberOfOutputs() {
                    return scriptProcessorNode.numberOfOutputs;
                },
                addEventListener(...args) {
                    // @todo Dissallow adding an audioprocess listener.
                    return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);
                },
                dispatchEvent(...args) {
                    return scriptProcessorNode.dispatchEvent(args[0]);
                },
                getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
                    if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {
                        throw createInvalidAccessError();
                    }
                    const length = frequencyHz.length;
                    for (let i = 0; i < length; i += 1) {
                        const omega = -Math.PI * (frequencyHz[i] / nyquist);
                        const z = [Math.cos(omega), Math.sin(omega)];
                        const numerator = evaluatePolynomial(convertedFeedforward, z);
                        const denominator = evaluatePolynomial(convertedFeedback, z);
                        const response = divide(numerator, denominator);
                        magResponse[i] = Math.sqrt(response[0] * response[0] + response[1] * response[1]);
                        phaseResponse[i] = Math.atan2(response[1], response[0]);
                    }
                },
                removeEventListener(...args) {
                    return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);
                }
            };
            return interceptConnections(nativeIIRFilterNodeFaker, scriptProcessorNode);
        };
    };

    const createNativeMediaElementAudioSourceNode = (nativeAudioContext, options) => {
        return nativeAudioContext.createMediaElementSource(options.mediaElement);
    };

    const createNativeMediaStreamAudioDestinationNode = (nativeAudioContext, options) => {
        const nativeMediaStreamAudioDestinationNode = nativeAudioContext.createMediaStreamDestination();
        assignNativeAudioNodeOptions(nativeMediaStreamAudioDestinationNode, options);
        // Bug #174: Safari does expose a wrong numberOfOutputs.
        if (nativeMediaStreamAudioDestinationNode.numberOfOutputs === 1) {
            Object.defineProperty(nativeMediaStreamAudioDestinationNode, 'numberOfOutputs', { get: () => 0 });
        }
        return nativeMediaStreamAudioDestinationNode;
    };

    const createNativeMediaStreamAudioSourceNode = (nativeAudioContext, { mediaStream }) => {
        const audioStreamTracks = mediaStream.getAudioTracks();
        /*
         * Bug #151: Safari does not use the audio track as input anymore if it gets removed from the mediaStream after construction.
         * Bug #159: Safari picks the first audio track if the MediaStream has more than one audio track.
         */
        audioStreamTracks.sort((a, b) => (a.id < b.id ? -1 : a.id > b.id ? 1 : 0));
        const filteredAudioStreamTracks = audioStreamTracks.slice(0, 1);
        const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(new MediaStream(filteredAudioStreamTracks));
        /*
         * Bug #151 & #159: The given mediaStream gets reconstructed before it gets passed to the native node which is why the accessor needs
         * to be overwritten as it would otherwise expose the reconstructed version.
         */
        Object.defineProperty(nativeMediaStreamAudioSourceNode, 'mediaStream', { value: mediaStream });
        return nativeMediaStreamAudioSourceNode;
    };

    const createNativeMediaStreamTrackAudioSourceNodeFactory = (createInvalidStateError, isNativeOfflineAudioContext) => {
        return (nativeAudioContext, { mediaStreamTrack }) => {
            // Bug #121: Only Firefox does yet support the MediaStreamTrackAudioSourceNode.
            if (typeof nativeAudioContext.createMediaStreamTrackSource === 'function') {
                return nativeAudioContext.createMediaStreamTrackSource(mediaStreamTrack);
            }
            const mediaStream = new MediaStream([mediaStreamTrack]);
            const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(mediaStream);
            // Bug #120: Firefox does not throw an error if the mediaStream has no audio track.
            if (mediaStreamTrack.kind !== 'audio') {
                throw createInvalidStateError();
            }
            // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.
            if (isNativeOfflineAudioContext(nativeAudioContext)) {
                throw new TypeError();
            }
            return nativeMediaStreamAudioSourceNode;
        };
    };

    const createNativeOfflineAudioContextConstructor = (window) => {
        if (window === null) {
            return null;
        }
        if (window.hasOwnProperty('OfflineAudioContext')) {
            return window.OfflineAudioContext;
        }
        return window.hasOwnProperty('webkitOfflineAudioContext') ? window.webkitOfflineAudioContext : null;
    };

    const createNativeOscillatorNodeFactory = (addSilentConnection, cacheTestResult, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls) => {
        return (nativeContext, options) => {
            const nativeOscillatorNode = nativeContext.createOscillator();
            assignNativeAudioNodeOptions(nativeOscillatorNode, options);
            assignNativeAudioNodeAudioParamValue(nativeOscillatorNode, options, 'detune');
            assignNativeAudioNodeAudioParamValue(nativeOscillatorNode, options, 'frequency');
            if (options.periodicWave !== undefined) {
                nativeOscillatorNode.setPeriodicWave(options.periodicWave);
            }
            else {
                assignNativeAudioNodeOption(nativeOscillatorNode, options, 'type');
            }
            // Bug #44: Only Chrome, Edge & Opera throw a RangeError yet.
            if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {
                wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeOscillatorNode);
            }
            // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.
            if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, () => testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) {
                wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeOscillatorNode, nativeContext);
            }
            // Bug #44: Only Firefox does not throw a RangeError yet.
            if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {
                wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeOscillatorNode);
            }
            // Bug #175: Safari will not fire an ended event if the OscillatorNode is unconnected.
            addSilentConnection(nativeContext, nativeOscillatorNode);
            return nativeOscillatorNode;
        };
    };

    const createNativePannerNodeFactory = (createNativePannerNodeFaker) => {
        return (nativeContext, options) => {
            const nativePannerNode = nativeContext.createPanner();
            // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.
            if (nativePannerNode.orientationX === undefined) {
                return createNativePannerNodeFaker(nativeContext, options);
            }
            assignNativeAudioNodeOptions(nativePannerNode, options);
            assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'orientationX');
            assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'orientationY');
            assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'orientationZ');
            assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'positionX');
            assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'positionY');
            assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'positionZ');
            assignNativeAudioNodeOption(nativePannerNode, options, 'coneInnerAngle');
            assignNativeAudioNodeOption(nativePannerNode, options, 'coneOuterAngle');
            assignNativeAudioNodeOption(nativePannerNode, options, 'coneOuterGain');
            assignNativeAudioNodeOption(nativePannerNode, options, 'distanceModel');
            assignNativeAudioNodeOption(nativePannerNode, options, 'maxDistance');
            assignNativeAudioNodeOption(nativePannerNode, options, 'panningModel');
            assignNativeAudioNodeOption(nativePannerNode, options, 'refDistance');
            assignNativeAudioNodeOption(nativePannerNode, options, 'rolloffFactor');
            return nativePannerNode;
        };
    };

    const createNativePannerNodeFakerFactory = (connectNativeAudioNodeToNativeAudioNode, createInvalidStateError, createNativeChannelMergerNode, createNativeGainNode, createNativeScriptProcessorNode, createNativeWaveShaperNode, createNotSupportedError, disconnectNativeAudioNodeFromNativeAudioNode, monitorConnections) => {
        return (nativeContext, { coneInnerAngle, coneOuterAngle, coneOuterGain, distanceModel, maxDistance, orientationX, orientationY, orientationZ, panningModel, positionX, positionY, positionZ, refDistance, rolloffFactor, ...audioNodeOptions }) => {
            const pannerNode = nativeContext.createPanner();
            // Bug #125: Safari does not throw an error yet.
            if (audioNodeOptions.channelCount > 2) {
                throw createNotSupportedError();
            }
            // Bug #126: Safari does not throw an error yet.
            if (audioNodeOptions.channelCountMode === 'max') {
                throw createNotSupportedError();
            }
            assignNativeAudioNodeOptions(pannerNode, audioNodeOptions);
            const SINGLE_CHANNEL_OPTIONS = {
                channelCount: 1,
                channelCountMode: 'explicit',
                channelInterpretation: 'discrete'
            };
            const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
                ...SINGLE_CHANNEL_OPTIONS,
                channelInterpretation: 'speakers',
                numberOfInputs: 6
            });
            const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });
            const orientationXGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 1 });
            const orientationYGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });
            const orientationZGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });
            const positionXGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });
            const positionYGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });
            const positionZGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });
            const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 6, 1);
            const waveShaperNode = createNativeWaveShaperNode(nativeContext, {
                ...SINGLE_CHANNEL_OPTIONS,
                curve: new Float32Array([1, 1]),
                oversample: 'none'
            });
            let lastOrientation = [orientationX, orientationY, orientationZ];
            let lastPosition = [positionX, positionY, positionZ];
            // tslint:disable-next-line:deprecation
            scriptProcessorNode.onaudioprocess = ({ inputBuffer }) => {
                const orientation = [
                    inputBuffer.getChannelData(0)[0],
                    inputBuffer.getChannelData(1)[0],
                    inputBuffer.getChannelData(2)[0]
                ];
                if (orientation.some((value, index) => value !== lastOrientation[index])) {
                    pannerNode.setOrientation(...orientation); // tslint:disable-line:deprecation
                    lastOrientation = orientation;
                }
                const positon = [
                    inputBuffer.getChannelData(3)[0],
                    inputBuffer.getChannelData(4)[0],
                    inputBuffer.getChannelData(5)[0]
                ];
                if (positon.some((value, index) => value !== lastPosition[index])) {
                    pannerNode.setPosition(...positon); // tslint:disable-line:deprecation
                    lastPosition = positon;
                }
            };
            Object.defineProperty(orientationYGainNode.gain, 'defaultValue', { get: () => 0 });
            Object.defineProperty(orientationZGainNode.gain, 'defaultValue', { get: () => 0 });
            Object.defineProperty(positionXGainNode.gain, 'defaultValue', { get: () => 0 });
            Object.defineProperty(positionYGainNode.gain, 'defaultValue', { get: () => 0 });
            Object.defineProperty(positionZGainNode.gain, 'defaultValue', { get: () => 0 });
            const nativePannerNodeFaker = {
                get bufferSize() {
                    return undefined;
                },
                get channelCount() {
                    return pannerNode.channelCount;
                },
                set channelCount(value) {
                    // Bug #125: Safari does not throw an error yet.
                    if (value > 2) {
                        throw createNotSupportedError();
                    }
                    inputGainNode.channelCount = value;
                    pannerNode.channelCount = value;
                },
                get channelCountMode() {
                    return pannerNode.channelCountMode;
                },
                set channelCountMode(value) {
                    // Bug #126: Safari does not throw an error yet.
                    if (value === 'max') {
                        throw createNotSupportedError();
                    }
                    inputGainNode.channelCountMode = value;
                    pannerNode.channelCountMode = value;
                },
                get channelInterpretation() {
                    return pannerNode.channelInterpretation;
                },
                set channelInterpretation(value) {
                    inputGainNode.channelInterpretation = value;
                    pannerNode.channelInterpretation = value;
                },
                get coneInnerAngle() {
                    return pannerNode.coneInnerAngle;
                },
                set coneInnerAngle(value) {
                    pannerNode.coneInnerAngle = value;
                },
                get coneOuterAngle() {
                    return pannerNode.coneOuterAngle;
                },
                set coneOuterAngle(value) {
                    pannerNode.coneOuterAngle = value;
                },
                get coneOuterGain() {
                    return pannerNode.coneOuterGain;
                },
                set coneOuterGain(value) {
                    // Bug #127: Safari does not throw an InvalidStateError yet.
                    if (value < 0 || value > 1) {
                        throw createInvalidStateError();
                    }
                    pannerNode.coneOuterGain = value;
                },
                get context() {
                    return pannerNode.context;
                },
                get distanceModel() {
                    return pannerNode.distanceModel;
                },
                set distanceModel(value) {
                    pannerNode.distanceModel = value;
                },
                get inputs() {
                    return [inputGainNode];
                },
                get maxDistance() {
                    return pannerNode.maxDistance;
                },
                set maxDistance(value) {
                    // Bug #128: Safari does not throw an error yet.
                    if (value < 0) {
                        throw new RangeError();
                    }
                    pannerNode.maxDistance = value;
                },
                get numberOfInputs() {
                    return pannerNode.numberOfInputs;
                },
                get numberOfOutputs() {
                    return pannerNode.numberOfOutputs;
                },
                get orientationX() {
                    return orientationXGainNode.gain;
                },
                get orientationY() {
                    return orientationYGainNode.gain;
                },
                get orientationZ() {
                    return orientationZGainNode.gain;
                },
                get panningModel() {
                    return pannerNode.panningModel;
                },
                set panningModel(value) {
                    pannerNode.panningModel = value;
                },
                get positionX() {
                    return positionXGainNode.gain;
                },
                get positionY() {
                    return positionYGainNode.gain;
                },
                get positionZ() {
                    return positionZGainNode.gain;
                },
                get refDistance() {
                    return pannerNode.refDistance;
                },
                set refDistance(value) {
                    // Bug #129: Safari does not throw an error yet.
                    if (value < 0) {
                        throw new RangeError();
                    }
                    pannerNode.refDistance = value;
                },
                get rolloffFactor() {
                    return pannerNode.rolloffFactor;
                },
                set rolloffFactor(value) {
                    // Bug #130: Safari does not throw an error yet.
                    if (value < 0) {
                        throw new RangeError();
                    }
                    pannerNode.rolloffFactor = value;
                },
                addEventListener(...args) {
                    return inputGainNode.addEventListener(args[0], args[1], args[2]);
                },
                dispatchEvent(...args) {
                    return inputGainNode.dispatchEvent(args[0]);
                },
                removeEventListener(...args) {
                    return inputGainNode.removeEventListener(args[0], args[1], args[2]);
                }
            };
            if (coneInnerAngle !== nativePannerNodeFaker.coneInnerAngle) {
                nativePannerNodeFaker.coneInnerAngle = coneInnerAngle;
            }
            if (coneOuterAngle !== nativePannerNodeFaker.coneOuterAngle) {
                nativePannerNodeFaker.coneOuterAngle = coneOuterAngle;
            }
            if (coneOuterGain !== nativePannerNodeFaker.coneOuterGain) {
                nativePannerNodeFaker.coneOuterGain = coneOuterGain;
            }
            if (distanceModel !== nativePannerNodeFaker.distanceModel) {
                nativePannerNodeFaker.distanceModel = distanceModel;
            }
            if (maxDistance !== nativePannerNodeFaker.maxDistance) {
                nativePannerNodeFaker.maxDistance = maxDistance;
            }
            if (orientationX !== nativePannerNodeFaker.orientationX.value) {
                nativePannerNodeFaker.orientationX.value = orientationX;
            }
            if (orientationY !== nativePannerNodeFaker.orientationY.value) {
                nativePannerNodeFaker.orientationY.value = orientationY;
            }
            if (orientationZ !== nativePannerNodeFaker.orientationZ.value) {
                nativePannerNodeFaker.orientationZ.value = orientationZ;
            }
            if (panningModel !== nativePannerNodeFaker.panningModel) {
                nativePannerNodeFaker.panningModel = panningModel;
            }
            if (positionX !== nativePannerNodeFaker.positionX.value) {
                nativePannerNodeFaker.positionX.value = positionX;
            }
            if (positionY !== nativePannerNodeFaker.positionY.value) {
                nativePannerNodeFaker.positionY.value = positionY;
            }
            if (positionZ !== nativePannerNodeFaker.positionZ.value) {
                nativePannerNodeFaker.positionZ.value = positionZ;
            }
            if (refDistance !== nativePannerNodeFaker.refDistance) {
                nativePannerNodeFaker.refDistance = refDistance;
            }
            if (rolloffFactor !== nativePannerNodeFaker.rolloffFactor) {
                nativePannerNodeFaker.rolloffFactor = rolloffFactor;
            }
            if (lastOrientation[0] !== 1 || lastOrientation[1] !== 0 || lastOrientation[2] !== 0) {
                pannerNode.setOrientation(...lastOrientation); // tslint:disable-line:deprecation
            }
            if (lastPosition[0] !== 0 || lastPosition[1] !== 0 || lastPosition[2] !== 0) {
                pannerNode.setPosition(...lastPosition); // tslint:disable-line:deprecation
            }
            const whenConnected = () => {
                inputGainNode.connect(pannerNode);
                // Bug #119: Safari does not fully support the WaveShaperNode.
                connectNativeAudioNodeToNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);
                waveShaperNode.connect(orientationXGainNode).connect(channelMergerNode, 0, 0);
                waveShaperNode.connect(orientationYGainNode).connect(channelMergerNode, 0, 1);
                waveShaperNode.connect(orientationZGainNode).connect(channelMergerNode, 0, 2);
                waveShaperNode.connect(positionXGainNode).connect(channelMergerNode, 0, 3);
                waveShaperNode.connect(positionYGainNode).connect(channelMergerNode, 0, 4);
                waveShaperNode.connect(positionZGainNode).connect(channelMergerNode, 0, 5);
                channelMergerNode.connect(scriptProcessorNode).connect(nativeContext.destination);
            };
            const whenDisconnected = () => {
                inputGainNode.disconnect(pannerNode);
                // Bug #119: Safari does not fully support the WaveShaperNode.
                disconnectNativeAudioNodeFromNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);
                waveShaperNode.disconnect(orientationXGainNode);
                orientationXGainNode.disconnect(channelMergerNode);
                waveShaperNode.disconnect(orientationYGainNode);
                orientationYGainNode.disconnect(channelMergerNode);
                waveShaperNode.disconnect(orientationZGainNode);
                orientationZGainNode.disconnect(channelMergerNode);
                waveShaperNode.disconnect(positionXGainNode);
                positionXGainNode.disconnect(channelMergerNode);
                waveShaperNode.disconnect(positionYGainNode);
                positionYGainNode.disconnect(channelMergerNode);
                waveShaperNode.disconnect(positionZGainNode);
                positionZGainNode.disconnect(channelMergerNode);
                channelMergerNode.disconnect(scriptProcessorNode);
                scriptProcessorNode.disconnect(nativeContext.destination);
            };
            return monitorConnections(interceptConnections(nativePannerNodeFaker, pannerNode), whenConnected, whenDisconnected);
        };
    };

    const createNativePeriodicWaveFactory = (createIndexSizeError) => {
        return (nativeContext, { disableNormalization, imag, real }) => {
            // Bug #180: Safari does not allow to use ordinary arrays.
            const convertedImag = imag instanceof Float32Array ? imag : new Float32Array(imag);
            const convertedReal = real instanceof Float32Array ? real : new Float32Array(real);
            const nativePeriodicWave = nativeContext.createPeriodicWave(convertedReal, convertedImag, { disableNormalization });
            // Bug #181: Safari does not throw an IndexSizeError so far if the given arrays have less than two values.
            if (Array.from(imag).length < 2) {
                throw createIndexSizeError();
            }
            return nativePeriodicWave;
        };
    };

    const createNativeScriptProcessorNode = (nativeContext, bufferSize, numberOfInputChannels, numberOfOutputChannels) => {
        return nativeContext.createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels);
    };

    const createNativeStereoPannerNodeFactory = (createNativeStereoPannerNodeFaker, createNotSupportedError) => {
        return (nativeContext, options) => {
            const channelCountMode = options.channelCountMode;
            /*
             * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari
             * which supports it and therefore it can't be supported at all.
             */
            if (channelCountMode === 'clamped-max') {
                throw createNotSupportedError();
            }
            // Bug #105: Safari does not support the StereoPannerNode.
            if (nativeContext.createStereoPanner === undefined) {
                return createNativeStereoPannerNodeFaker(nativeContext, options);
            }
            const nativeStereoPannerNode = nativeContext.createStereoPanner();
            assignNativeAudioNodeOptions(nativeStereoPannerNode, options);
            assignNativeAudioNodeAudioParamValue(nativeStereoPannerNode, options, 'pan');
            /*
             * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari
             * which supports it and therefore it can't be supported at all.
             */
            Object.defineProperty(nativeStereoPannerNode, 'channelCountMode', {
                get: () => channelCountMode,
                set: (value) => {
                    if (value !== channelCountMode) {
                        throw createNotSupportedError();
                    }
                }
            });
            return nativeStereoPannerNode;
        };
    };

    const createNativeStereoPannerNodeFakerFactory = (createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeGainNode, createNativeWaveShaperNode, createNotSupportedError, monitorConnections) => {
        // The curve has a size of 14bit plus 1 value to have an exact representation for zero. This value has been determined experimentally.
        const CURVE_SIZE = 16385;
        const DC_CURVE = new Float32Array([1, 1]);
        const HALF_PI = Math.PI / 2;
        const SINGLE_CHANNEL_OPTIONS = { channelCount: 1, channelCountMode: 'explicit', channelInterpretation: 'discrete' };
        const SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS = { ...SINGLE_CHANNEL_OPTIONS, oversample: 'none' };
        const buildInternalGraphForMono = (nativeContext, inputGainNode, panGainNode, channelMergerNode) => {
            const leftWaveShaperCurve = new Float32Array(CURVE_SIZE);
            const rightWaveShaperCurve = new Float32Array(CURVE_SIZE);
            for (let i = 0; i < CURVE_SIZE; i += 1) {
                const x = (i / (CURVE_SIZE - 1)) * HALF_PI;
                leftWaveShaperCurve[i] = Math.cos(x);
                rightWaveShaperCurve[i] = Math.sin(x);
            }
            const leftGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });
            // Bug #119: Safari does not fully support the WaveShaperNode.
            const leftWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: leftWaveShaperCurve }));
            // Bug #119: Safari does not fully support the WaveShaperNode.
            const panWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: DC_CURVE }));
            const rightGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });
            // Bug #119: Safari does not fully support the WaveShaperNode.
            const rightWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: rightWaveShaperCurve }));
            return {
                connectGraph() {
                    inputGainNode.connect(leftGainNode);
                    inputGainNode.connect(panWaveShaperNode.inputs[0]);
                    inputGainNode.connect(rightGainNode);
                    panWaveShaperNode.connect(panGainNode);
                    panGainNode.connect(leftWaveShaperNode.inputs[0]);
                    panGainNode.connect(rightWaveShaperNode.inputs[0]);
                    leftWaveShaperNode.connect(leftGainNode.gain);
                    rightWaveShaperNode.connect(rightGainNode.gain);
                    leftGainNode.connect(channelMergerNode, 0, 0);
                    rightGainNode.connect(channelMergerNode, 0, 1);
                },
                disconnectGraph() {
                    inputGainNode.disconnect(leftGainNode);
                    inputGainNode.disconnect(panWaveShaperNode.inputs[0]);
                    inputGainNode.disconnect(rightGainNode);
                    panWaveShaperNode.disconnect(panGainNode);
                    panGainNode.disconnect(leftWaveShaperNode.inputs[0]);
                    panGainNode.disconnect(rightWaveShaperNode.inputs[0]);
                    leftWaveShaperNode.disconnect(leftGainNode.gain);
                    rightWaveShaperNode.disconnect(rightGainNode.gain);
                    leftGainNode.disconnect(channelMergerNode, 0, 0);
                    rightGainNode.disconnect(channelMergerNode, 0, 1);
                }
            };
        };
        const buildInternalGraphForStereo = (nativeContext, inputGainNode, panGainNode, channelMergerNode) => {
            const leftInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
            const leftInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
            const rightInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
            const rightInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
            const centerIndex = Math.floor(CURVE_SIZE / 2);
            for (let i = 0; i < CURVE_SIZE; i += 1) {
                if (i > centerIndex) {
                    const x = ((i - centerIndex) / (CURVE_SIZE - 1 - centerIndex)) * HALF_PI;
                    leftInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);
                    leftInputForRightOutputWaveShaperCurve[i] = Math.sin(x);
                    rightInputForLeftOutputWaveShaperCurve[i] = 0;
                    rightInputForRightOutputWaveShaperCurve[i] = 1;
                }
                else {
                    const x = (i / (CURVE_SIZE - 1 - centerIndex)) * HALF_PI;
                    leftInputForLeftOutputWaveShaperCurve[i] = 1;
                    leftInputForRightOutputWaveShaperCurve[i] = 0;
                    rightInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);
                    rightInputForRightOutputWaveShaperCurve[i] = Math.sin(x);
                }
            }
            const channelSplitterNode = createNativeChannelSplitterNode(nativeContext, {
                channelCount: 2,
                channelCountMode: 'explicit',
                channelInterpretation: 'discrete',
                numberOfOutputs: 2
            });
            const leftInputForLeftOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });
            // Bug #119: Safari does not fully support the WaveShaperNode.
            const leftInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
                ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
                curve: leftInputForLeftOutputWaveShaperCurve
            });
            const leftInputForRightOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });
            // Bug #119: Safari does not fully support the WaveShaperNode.
            const leftInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
                ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
                curve: leftInputForRightOutputWaveShaperCurve
            });
            // Bug #119: Safari does not fully support the WaveShaperNode.
            const panWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: DC_CURVE }));
            const rightInputForLeftOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });
            // Bug #119: Safari does not fully support the WaveShaperNode.
            const rightInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
                ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
                curve: rightInputForLeftOutputWaveShaperCurve
            });
            const rightInputForRightOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });
            // Bug #119: Safari does not fully support the WaveShaperNode.
            const rightInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
                ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
                curve: rightInputForRightOutputWaveShaperCurve
            });
            return {
                connectGraph() {
                    inputGainNode.connect(channelSplitterNode);
                    inputGainNode.connect(panWaveShaperNode.inputs[0]);
                    channelSplitterNode.connect(leftInputForLeftOutputGainNode, 0);
                    channelSplitterNode.connect(leftInputForRightOutputGainNode, 0);
                    channelSplitterNode.connect(rightInputForLeftOutputGainNode, 1);
                    channelSplitterNode.connect(rightInputForRightOutputGainNode, 1);
                    panWaveShaperNode.connect(panGainNode);
                    panGainNode.connect(leftInputForLeftOutputWaveShaperNode.inputs[0]);
                    panGainNode.connect(leftInputForRightOutputWaveShaperNode.inputs[0]);
                    panGainNode.connect(rightInputForLeftOutputWaveShaperNode.inputs[0]);
                    panGainNode.connect(rightInputForRightOutputWaveShaperNode.inputs[0]);
                    leftInputForLeftOutputWaveShaperNode.connect(leftInputForLeftOutputGainNode.gain);
                    leftInputForRightOutputWaveShaperNode.connect(leftInputForRightOutputGainNode.gain);
                    rightInputForLeftOutputWaveShaperNode.connect(rightInputForLeftOutputGainNode.gain);
                    rightInputForRightOutputWaveShaperNode.connect(rightInputForRightOutputGainNode.gain);
                    leftInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);
                    rightInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);
                    leftInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);
                    rightInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);
                },
                disconnectGraph() {
                    inputGainNode.disconnect(channelSplitterNode);
                    inputGainNode.disconnect(panWaveShaperNode.inputs[0]);
                    channelSplitterNode.disconnect(leftInputForLeftOutputGainNode, 0);
                    channelSplitterNode.disconnect(leftInputForRightOutputGainNode, 0);
                    channelSplitterNode.disconnect(rightInputForLeftOutputGainNode, 1);
                    channelSplitterNode.disconnect(rightInputForRightOutputGainNode, 1);
                    panWaveShaperNode.disconnect(panGainNode);
                    panGainNode.disconnect(leftInputForLeftOutputWaveShaperNode.inputs[0]);
                    panGainNode.disconnect(leftInputForRightOutputWaveShaperNode.inputs[0]);
                    panGainNode.disconnect(rightInputForLeftOutputWaveShaperNode.inputs[0]);
                    panGainNode.disconnect(rightInputForRightOutputWaveShaperNode.inputs[0]);
                    leftInputForLeftOutputWaveShaperNode.disconnect(leftInputForLeftOutputGainNode.gain);
                    leftInputForRightOutputWaveShaperNode.disconnect(leftInputForRightOutputGainNode.gain);
                    rightInputForLeftOutputWaveShaperNode.disconnect(rightInputForLeftOutputGainNode.gain);
                    rightInputForRightOutputWaveShaperNode.disconnect(rightInputForRightOutputGainNode.gain);
                    leftInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);
                    rightInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);
                    leftInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);
                    rightInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);
                }
            };
        };
        const buildInternalGraph = (nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode) => {
            if (channelCount === 1) {
                return buildInternalGraphForMono(nativeContext, inputGainNode, panGainNode, channelMergerNode);
            }
            if (channelCount === 2) {
                return buildInternalGraphForStereo(nativeContext, inputGainNode, panGainNode, channelMergerNode);
            }
            throw createNotSupportedError();
        };
        return (nativeContext, { channelCount, channelCountMode, pan, ...audioNodeOptions }) => {
            if (channelCountMode === 'max') {
                throw createNotSupportedError();
            }
            const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
                ...audioNodeOptions,
                channelCount: 1,
                channelCountMode,
                numberOfInputs: 2
            });
            const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, channelCount, channelCountMode, gain: 1 });
            const panGainNode = createNativeGainNode(nativeContext, {
                channelCount: 1,
                channelCountMode: 'explicit',
                channelInterpretation: 'discrete',
                gain: pan
            });
            let { connectGraph, disconnectGraph } = buildInternalGraph(nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode);
            Object.defineProperty(panGainNode.gain, 'defaultValue', { get: () => 0 });
            Object.defineProperty(panGainNode.gain, 'minValue', { get: () => -1 });
            const nativeStereoPannerNodeFakerFactory = {
                get bufferSize() {
                    return undefined;
                },
                get channelCount() {
                    return inputGainNode.channelCount;
                },
                set channelCount(value) {
                    if (inputGainNode.channelCount !== value) {
                        if (isConnected) {
                            disconnectGraph();
                        }
                        ({ connectGraph, disconnectGraph } = buildInternalGraph(nativeContext, value, inputGainNode, panGainNode, channelMergerNode));
                        if (isConnected) {
                            connectGraph();
                        }
                    }
                    inputGainNode.channelCount = value;
                },
                get channelCountMode() {
                    return inputGainNode.channelCountMode;
                },
                set channelCountMode(value) {
                    if (value === 'clamped-max' || value === 'max') {
                        throw createNotSupportedError();
                    }
                    inputGainNode.channelCountMode = value;
                },
                get channelInterpretation() {
                    return inputGainNode.channelInterpretation;
                },
                set channelInterpretation(value) {
                    inputGainNode.channelInterpretation = value;
                },
                get context() {
                    return inputGainNode.context;
                },
                get inputs() {
                    return [inputGainNode];
                },
                get numberOfInputs() {
                    return inputGainNode.numberOfInputs;
                },
                get numberOfOutputs() {
                    return inputGainNode.numberOfOutputs;
                },
                get pan() {
                    return panGainNode.gain;
                },
                addEventListener(...args) {
                    return inputGainNode.addEventListener(args[0], args[1], args[2]);
                },
                dispatchEvent(...args) {
                    return inputGainNode.dispatchEvent(args[0]);
                },
                removeEventListener(...args) {
                    return inputGainNode.removeEventListener(args[0], args[1], args[2]);
                }
            };
            let isConnected = false;
            const whenConnected = () => {
                connectGraph();
                isConnected = true;
            };
            const whenDisconnected = () => {
                disconnectGraph();
                isConnected = false;
            };
            return monitorConnections(interceptConnections(nativeStereoPannerNodeFakerFactory, channelMergerNode), whenConnected, whenDisconnected);
        };
    };

    const createNativeWaveShaperNodeFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeWaveShaperNodeFaker, isDCCurve, monitorConnections, nativeAudioContextConstructor, overwriteAccessors) => {
        return (nativeContext, options) => {
            const nativeWaveShaperNode = nativeContext.createWaveShaper();
            /*
             * Bug #119: Safari does not correctly map the values.
             * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of
             * the webkitAudioContext is used as a workaround here.
             */
            if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === 'webkitAudioContext') {
                return createNativeWaveShaperNodeFaker(nativeContext, options);
            }
            assignNativeAudioNodeOptions(nativeWaveShaperNode, options);
            const curve = options.curve === null || options.curve instanceof Float32Array ? options.curve : new Float32Array(options.curve);
            // Bug #104: Chrome, Edge and Opera will throw an InvalidAccessError when the curve has less than two samples.
            if (curve !== null && curve.length < 2) {
                throw createInvalidStateError();
            }
            // Only values of type Float32Array can be assigned to the curve property.
            assignNativeAudioNodeOption(nativeWaveShaperNode, { curve }, 'curve');
            assignNativeAudioNodeOption(nativeWaveShaperNode, options, 'oversample');
            let disconnectNativeAudioBufferSourceNode = null;
            let isConnected = false;
            overwriteAccessors(nativeWaveShaperNode, 'curve', (get) => () => get.call(nativeWaveShaperNode), (set) => (value) => {
                set.call(nativeWaveShaperNode, value);
                if (isConnected) {
                    if (isDCCurve(value) && disconnectNativeAudioBufferSourceNode === null) {
                        disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);
                    }
                    else if (!isDCCurve(value) && disconnectNativeAudioBufferSourceNode !== null) {
                        disconnectNativeAudioBufferSourceNode();
                        disconnectNativeAudioBufferSourceNode = null;
                    }
                }
                return value;
            });
            const whenConnected = () => {
                isConnected = true;
                if (isDCCurve(nativeWaveShaperNode.curve)) {
                    disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);
                }
            };
            const whenDisconnected = () => {
                isConnected = false;
                if (disconnectNativeAudioBufferSourceNode !== null) {
                    disconnectNativeAudioBufferSourceNode();
                    disconnectNativeAudioBufferSourceNode = null;
                }
            };
            return monitorConnections(nativeWaveShaperNode, whenConnected, whenDisconnected);
        };
    };

    const createNativeWaveShaperNodeFakerFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeGainNode, isDCCurve, monitorConnections) => {
        return (nativeContext, { curve, oversample, ...audioNodeOptions }) => {
            const negativeWaveShaperNode = nativeContext.createWaveShaper();
            const positiveWaveShaperNode = nativeContext.createWaveShaper();
            assignNativeAudioNodeOptions(negativeWaveShaperNode, audioNodeOptions);
            assignNativeAudioNodeOptions(positiveWaveShaperNode, audioNodeOptions);
            const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });
            const invertGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: -1 });
            const outputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });
            const revertGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: -1 });
            let disconnectNativeAudioBufferSourceNode = null;
            let isConnected = false;
            let unmodifiedCurve = null;
            const nativeWaveShaperNodeFaker = {
                get bufferSize() {
                    return undefined;
                },
                get channelCount() {
                    return negativeWaveShaperNode.channelCount;
                },
                set channelCount(value) {
                    inputGainNode.channelCount = value;
                    invertGainNode.channelCount = value;
                    negativeWaveShaperNode.channelCount = value;
                    outputGainNode.channelCount = value;
                    positiveWaveShaperNode.channelCount = value;
                    revertGainNode.channelCount = value;
                },
                get channelCountMode() {
                    return negativeWaveShaperNode.channelCountMode;
                },
                set channelCountMode(value) {
                    inputGainNode.channelCountMode = value;
                    invertGainNode.channelCountMode = value;
                    negativeWaveShaperNode.channelCountMode = value;
                    outputGainNode.channelCountMode = value;
                    positiveWaveShaperNode.channelCountMode = value;
                    revertGainNode.channelCountMode = value;
                },
                get channelInterpretation() {
                    return negativeWaveShaperNode.channelInterpretation;
                },
                set channelInterpretation(value) {
                    inputGainNode.channelInterpretation = value;
                    invertGainNode.channelInterpretation = value;
                    negativeWaveShaperNode.channelInterpretation = value;
                    outputGainNode.channelInterpretation = value;
                    positiveWaveShaperNode.channelInterpretation = value;
                    revertGainNode.channelInterpretation = value;
                },
                get context() {
                    return negativeWaveShaperNode.context;
                },
                get curve() {
                    return unmodifiedCurve;
                },
                set curve(value) {
                    // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.
                    if (value !== null && value.length < 2) {
                        throw createInvalidStateError();
                    }
                    if (value === null) {
                        negativeWaveShaperNode.curve = value;
                        positiveWaveShaperNode.curve = value;
                    }
                    else {
                        const curveLength = value.length;
                        const negativeCurve = new Float32Array(curveLength + 2 - (curveLength % 2));
                        const positiveCurve = new Float32Array(curveLength + 2 - (curveLength % 2));
                        negativeCurve[0] = value[0];
                        positiveCurve[0] = -value[curveLength - 1];
                        const length = Math.ceil((curveLength + 1) / 2);
                        const centerIndex = (curveLength + 1) / 2 - 1;
                        for (let i = 1; i < length; i += 1) {
                            const theoreticIndex = (i / length) * centerIndex;
                            const lowerIndex = Math.floor(theoreticIndex);
                            const upperIndex = Math.ceil(theoreticIndex);
                            negativeCurve[i] =
                                lowerIndex === upperIndex
                                    ? value[lowerIndex]
                                    : (1 - (theoreticIndex - lowerIndex)) * value[lowerIndex] +
                                        (1 - (upperIndex - theoreticIndex)) * value[upperIndex];
                            positiveCurve[i] =
                                lowerIndex === upperIndex
                                    ? -value[curveLength - 1 - lowerIndex]
                                    : -((1 - (theoreticIndex - lowerIndex)) * value[curveLength - 1 - lowerIndex]) -
                                        (1 - (upperIndex - theoreticIndex)) * value[curveLength - 1 - upperIndex];
                        }
                        negativeCurve[length] = curveLength % 2 === 1 ? value[length - 1] : (value[length - 2] + value[length - 1]) / 2;
                        negativeWaveShaperNode.curve = negativeCurve;
                        positiveWaveShaperNode.curve = positiveCurve;
                    }
                    unmodifiedCurve = value;
                    if (isConnected) {
                        if (isDCCurve(unmodifiedCurve) && disconnectNativeAudioBufferSourceNode === null) {
                            disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);
                        }
                        else if (disconnectNativeAudioBufferSourceNode !== null) {
                            disconnectNativeAudioBufferSourceNode();
                            disconnectNativeAudioBufferSourceNode = null;
                        }
                    }
                },
                get inputs() {
                    return [inputGainNode];
                },
                get numberOfInputs() {
                    return negativeWaveShaperNode.numberOfInputs;
                },
                get numberOfOutputs() {
                    return negativeWaveShaperNode.numberOfOutputs;
                },
                get oversample() {
                    return negativeWaveShaperNode.oversample;
                },
                set oversample(value) {
                    negativeWaveShaperNode.oversample = value;
                    positiveWaveShaperNode.oversample = value;
                },
                addEventListener(...args) {
                    return inputGainNode.addEventListener(args[0], args[1], args[2]);
                },
                dispatchEvent(...args) {
                    return inputGainNode.dispatchEvent(args[0]);
                },
                removeEventListener(...args) {
                    return inputGainNode.removeEventListener(args[0], args[1], args[2]);
                }
            };
            if (curve !== null) {
                // Only values of type Float32Array can be assigned to the curve property.
                nativeWaveShaperNodeFaker.curve = curve instanceof Float32Array ? curve : new Float32Array(curve);
            }
            if (oversample !== nativeWaveShaperNodeFaker.oversample) {
                nativeWaveShaperNodeFaker.oversample = oversample;
            }
            const whenConnected = () => {
                inputGainNode.connect(negativeWaveShaperNode).connect(outputGainNode);
                inputGainNode.connect(invertGainNode).connect(positiveWaveShaperNode).connect(revertGainNode).connect(outputGainNode);
                isConnected = true;
                if (isDCCurve(unmodifiedCurve)) {
                    disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);
                }
            };
            const whenDisconnected = () => {
                inputGainNode.disconnect(negativeWaveShaperNode);
                negativeWaveShaperNode.disconnect(outputGainNode);
                inputGainNode.disconnect(invertGainNode);
                invertGainNode.disconnect(positiveWaveShaperNode);
                positiveWaveShaperNode.disconnect(revertGainNode);
                revertGainNode.disconnect(outputGainNode);
                isConnected = false;
                if (disconnectNativeAudioBufferSourceNode !== null) {
                    disconnectNativeAudioBufferSourceNode();
                    disconnectNativeAudioBufferSourceNode = null;
                }
            };
            return monitorConnections(interceptConnections(nativeWaveShaperNodeFaker, outputGainNode), whenConnected, whenDisconnected);
        };
    };

    const createNotSupportedError = () => new DOMException('', 'NotSupportedError');

    const DEFAULT_OPTIONS$e = {
        numberOfChannels: 1
    };
    const createOfflineAudioContextConstructor = (baseAudioContextConstructor, cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, startRendering) => {
        return class OfflineAudioContext extends baseAudioContextConstructor {
            constructor(a, b, c) {
                let options;
                if (typeof a === 'number' && b !== undefined && c !== undefined) {
                    options = { length: b, numberOfChannels: a, sampleRate: c };
                }
                else if (typeof a === 'object') {
                    options = a;
                }
                else {
                    throw new Error('The given parameters are not valid.');
                }
                const { length, numberOfChannels, sampleRate } = { ...DEFAULT_OPTIONS$e, ...options };
                const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);
                // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.
                if (!cacheTestResult(testPromiseSupport, () => testPromiseSupport(nativeOfflineAudioContext))) {
                    nativeOfflineAudioContext.addEventListener('statechange', (() => {
                        let i = 0;
                        const delayStateChangeEvent = (event) => {
                            if (this._state === 'running') {
                                if (i > 0) {
                                    nativeOfflineAudioContext.removeEventListener('statechange', delayStateChangeEvent);
                                    event.stopImmediatePropagation();
                                    this._waitForThePromiseToSettle(event);
                                }
                                else {
                                    i += 1;
                                }
                            }
                        };
                        return delayStateChangeEvent;
                    })());
                }
                super(nativeOfflineAudioContext, numberOfChannels);
                this._length = length;
                this._nativeOfflineAudioContext = nativeOfflineAudioContext;
                this._state = null;
            }
            get length() {
                // Bug #17: Safari does not yet expose the length.
                if (this._nativeOfflineAudioContext.length === undefined) {
                    return this._length;
                }
                return this._nativeOfflineAudioContext.length;
            }
            get state() {
                return this._state === null ? this._nativeOfflineAudioContext.state : this._state;
            }
            startRendering() {
                /*
                 * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore
                 * the state of the nativeOfflineAudioContext might no transition to running immediately.
                 */
                if (this._state === 'running') {
                    return Promise.reject(createInvalidStateError());
                }
                this._state = 'running';
                return startRendering(this.destination, this._nativeOfflineAudioContext).finally(() => {
                    this._state = null;
                    deactivateAudioGraph(this);
                });
            }
            _waitForThePromiseToSettle(event) {
                if (this._state === null) {
                    this._nativeOfflineAudioContext.dispatchEvent(event);
                }
                else {
                    setTimeout(() => this._waitForThePromiseToSettle(event));
                }
            }
        };
    };

    const DEFAULT_OPTIONS$f = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        detune: 0,
        frequency: 440,
        periodicWave: undefined,
        type: 'sine'
    };
    const createOscillatorNodeConstructor = (audioNodeConstructor, createAudioParam, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {
        return class OscillatorNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$f, ...options };
                const nativeOscillatorNode = createNativeOscillatorNode(nativeContext, mergedOptions);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const oscillatorNodeRenderer = (isOffline ? createOscillatorNodeRenderer() : null);
                const nyquist = context.sampleRate / 2;
                super(context, false, nativeOscillatorNode, oscillatorNodeRenderer);
                // Bug #81: Firefox & Safari do not export the correct values for maxValue and minValue.
                this._detune = createAudioParam(this, isOffline, nativeOscillatorNode.detune, 153600, -153600);
                // Bug #76: Safari does not export the correct values for maxValue and minValue.
                this._frequency = createAudioParam(this, isOffline, nativeOscillatorNode.frequency, nyquist, -nyquist);
                this._nativeOscillatorNode = nativeOscillatorNode;
                this._onended = null;
                this._oscillatorNodeRenderer = oscillatorNodeRenderer;
                if (this._oscillatorNodeRenderer !== null && mergedOptions.periodicWave !== undefined) {
                    this._oscillatorNodeRenderer.periodicWave =
                        mergedOptions.periodicWave;
                }
            }
            get detune() {
                return this._detune;
            }
            get frequency() {
                return this._frequency;
            }
            get onended() {
                return this._onended;
            }
            set onended(value) {
                const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;
                this._nativeOscillatorNode.onended = wrappedListener;
                const nativeOnEnded = this._nativeOscillatorNode.onended;
                this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
            }
            get type() {
                return this._nativeOscillatorNode.type;
            }
            set type(value) {
                this._nativeOscillatorNode.type = value;
                if (this._oscillatorNodeRenderer !== null) {
                    this._oscillatorNodeRenderer.periodicWave = null;
                }
            }
            setPeriodicWave(periodicWave) {
                this._nativeOscillatorNode.setPeriodicWave(periodicWave);
                if (this._oscillatorNodeRenderer !== null) {
                    this._oscillatorNodeRenderer.periodicWave = periodicWave;
                }
            }
            start(when = 0) {
                this._nativeOscillatorNode.start(when);
                if (this._oscillatorNodeRenderer !== null) {
                    this._oscillatorNodeRenderer.start = when;
                }
                if (this.context.state !== 'closed') {
                    setInternalStateToActive(this);
                    const resetInternalStateToPassive = () => {
                        this._nativeOscillatorNode.removeEventListener('ended', resetInternalStateToPassive);
                        if (isActiveAudioNode(this)) {
                            setInternalStateToPassive(this);
                        }
                    };
                    this._nativeOscillatorNode.addEventListener('ended', resetInternalStateToPassive);
                }
            }
            stop(when = 0) {
                this._nativeOscillatorNode.stop(when);
                if (this._oscillatorNodeRenderer !== null) {
                    this._oscillatorNodeRenderer.stop = when;
                }
            }
        };
    };

    const createOscillatorNodeRendererFactory = (connectAudioParam, createNativeOscillatorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeOscillatorNodes = new WeakMap();
            let periodicWave = null;
            let start = null;
            let stop = null;
            const createOscillatorNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeOscillatorNode = getNativeAudioNode(proxy);
                // If the initially used nativeOscillatorNode was not constructed on the same OfflineAudioContext it needs to be created again.
                const nativeOscillatorNodeIsOwnedByContext = isOwnedByContext(nativeOscillatorNode, nativeOfflineAudioContext);
                if (!nativeOscillatorNodeIsOwnedByContext) {
                    const options = {
                        channelCount: nativeOscillatorNode.channelCount,
                        channelCountMode: nativeOscillatorNode.channelCountMode,
                        channelInterpretation: nativeOscillatorNode.channelInterpretation,
                        detune: nativeOscillatorNode.detune.value,
                        frequency: nativeOscillatorNode.frequency.value,
                        periodicWave: periodicWave === null ? undefined : periodicWave,
                        type: nativeOscillatorNode.type
                    };
                    nativeOscillatorNode = createNativeOscillatorNode(nativeOfflineAudioContext, options);
                    if (start !== null) {
                        nativeOscillatorNode.start(start);
                    }
                    if (stop !== null) {
                        nativeOscillatorNode.stop(stop);
                    }
                }
                renderedNativeOscillatorNodes.set(nativeOfflineAudioContext, nativeOscillatorNode);
                if (!nativeOscillatorNodeIsOwnedByContext) {
                    await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency, trace);
                }
                else {
                    await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency, trace);
                }
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeOscillatorNode, trace);
                return nativeOscillatorNode;
            };
            return {
                set periodicWave(value) {
                    periodicWave = value;
                },
                set start(value) {
                    start = value;
                },
                set stop(value) {
                    stop = value;
                },
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeOscillatorNode = renderedNativeOscillatorNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeOscillatorNode !== undefined) {
                        return Promise.resolve(renderedNativeOscillatorNode);
                    }
                    return createOscillatorNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const DEFAULT_OPTIONS$g = {
        channelCount: 2,
        channelCountMode: 'clamped-max',
        channelInterpretation: 'speakers',
        coneInnerAngle: 360,
        coneOuterAngle: 360,
        coneOuterGain: 0,
        distanceModel: 'inverse',
        maxDistance: 10000,
        orientationX: 1,
        orientationY: 0,
        orientationZ: 0,
        panningModel: 'equalpower',
        positionX: 0,
        positionY: 0,
        positionZ: 0,
        refDistance: 1,
        rolloffFactor: 1
    };
    const createPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {
        return class PannerNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$g, ...options };
                const nativePannerNode = createNativePannerNode(nativeContext, mergedOptions);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const pannerNodeRenderer = (isOffline ? createPannerNodeRenderer() : null);
                super(context, false, nativePannerNode, pannerNodeRenderer);
                this._nativePannerNode = nativePannerNode;
                // Bug #74: Safari does not export the correct values for maxValue and minValue.
                this._orientationX = createAudioParam(this, isOffline, nativePannerNode.orientationX, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);
                this._orientationY = createAudioParam(this, isOffline, nativePannerNode.orientationY, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);
                this._orientationZ = createAudioParam(this, isOffline, nativePannerNode.orientationZ, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);
                this._positionX = createAudioParam(this, isOffline, nativePannerNode.positionX, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);
                this._positionY = createAudioParam(this, isOffline, nativePannerNode.positionY, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);
                this._positionZ = createAudioParam(this, isOffline, nativePannerNode.positionZ, MOST_POSITIVE_SINGLE_FLOAT, MOST_NEGATIVE_SINGLE_FLOAT);
                // @todo Determine a meaningful tail-time instead of just using one second.
                setAudioNodeTailTime(this, 1);
            }
            get coneInnerAngle() {
                return this._nativePannerNode.coneInnerAngle;
            }
            set coneInnerAngle(value) {
                this._nativePannerNode.coneInnerAngle = value;
            }
            get coneOuterAngle() {
                return this._nativePannerNode.coneOuterAngle;
            }
            set coneOuterAngle(value) {
                this._nativePannerNode.coneOuterAngle = value;
            }
            get coneOuterGain() {
                return this._nativePannerNode.coneOuterGain;
            }
            set coneOuterGain(value) {
                this._nativePannerNode.coneOuterGain = value;
            }
            get distanceModel() {
                return this._nativePannerNode.distanceModel;
            }
            set distanceModel(value) {
                this._nativePannerNode.distanceModel = value;
            }
            get maxDistance() {
                return this._nativePannerNode.maxDistance;
            }
            set maxDistance(value) {
                this._nativePannerNode.maxDistance = value;
            }
            get orientationX() {
                return this._orientationX;
            }
            get orientationY() {
                return this._orientationY;
            }
            get orientationZ() {
                return this._orientationZ;
            }
            get panningModel() {
                return this._nativePannerNode.panningModel;
            }
            set panningModel(value) {
                this._nativePannerNode.panningModel = value;
            }
            get positionX() {
                return this._positionX;
            }
            get positionY() {
                return this._positionY;
            }
            get positionZ() {
                return this._positionZ;
            }
            get refDistance() {
                return this._nativePannerNode.refDistance;
            }
            set refDistance(value) {
                this._nativePannerNode.refDistance = value;
            }
            get rolloffFactor() {
                return this._nativePannerNode.rolloffFactor;
            }
            set rolloffFactor(value) {
                this._nativePannerNode.rolloffFactor = value;
            }
        };
    };

    const createPannerNodeRendererFactory = (connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeGainNode, createNativePannerNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {
        return () => {
            const renderedNativeAudioNodes = new WeakMap();
            let renderedBufferPromise = null;
            const createAudioNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeGainNode = null;
                let nativePannerNode = getNativeAudioNode(proxy);
                const commonAudioNodeOptions = {
                    channelCount: nativePannerNode.channelCount,
                    channelCountMode: nativePannerNode.channelCountMode,
                    channelInterpretation: nativePannerNode.channelInterpretation
                };
                const commonNativePannerNodeOptions = {
                    ...commonAudioNodeOptions,
                    coneInnerAngle: nativePannerNode.coneInnerAngle,
                    coneOuterAngle: nativePannerNode.coneOuterAngle,
                    coneOuterGain: nativePannerNode.coneOuterGain,
                    distanceModel: nativePannerNode.distanceModel,
                    maxDistance: nativePannerNode.maxDistance,
                    panningModel: nativePannerNode.panningModel,
                    refDistance: nativePannerNode.refDistance,
                    rolloffFactor: nativePannerNode.rolloffFactor
                };
                // If the initially used nativePannerNode was not constructed on the same OfflineAudioContext it needs to be created again.
                const nativePannerNodeIsOwnedByContext = isOwnedByContext(nativePannerNode, nativeOfflineAudioContext);
                // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.
                if ('bufferSize' in nativePannerNode) {
                    nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });
                }
                else if (!nativePannerNodeIsOwnedByContext) {
                    const options = {
                        ...commonNativePannerNodeOptions,
                        orientationX: nativePannerNode.orientationX.value,
                        orientationY: nativePannerNode.orientationY.value,
                        orientationZ: nativePannerNode.orientationZ.value,
                        positionX: nativePannerNode.positionX.value,
                        positionY: nativePannerNode.positionY.value,
                        positionZ: nativePannerNode.positionZ.value
                    };
                    nativePannerNode = createNativePannerNode(nativeOfflineAudioContext, options);
                }
                renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeGainNode === null ? nativePannerNode : nativeGainNode);
                if (nativeGainNode !== null) {
                    if (renderedBufferPromise === null) {
                        if (nativeOfflineAudioContextConstructor === null) {
                            throw new Error('Missing the native OfflineAudioContext constructor.');
                        }
                        const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(6, 
                        // Bug #17: Safari does not yet expose the length.
                        proxy.context.length, nativeOfflineAudioContext.sampleRate);
                        const nativeChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {
                            channelCount: 1,
                            channelCountMode: 'explicit',
                            channelInterpretation: 'speakers',
                            numberOfInputs: 6
                        });
                        nativeChannelMergerNode.connect(partialOfflineAudioContext.destination);
                        renderedBufferPromise = (async () => {
                            const nativeConstantSourceNodes = await Promise.all([
                                proxy.orientationX,
                                proxy.orientationY,
                                proxy.orientationZ,
                                proxy.positionX,
                                proxy.positionY,
                                proxy.positionZ
                            ].map(async (audioParam, index) => {
                                const nativeConstantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {
                                    channelCount: 1,
                                    channelCountMode: 'explicit',
                                    channelInterpretation: 'discrete',
                                    offset: index === 0 ? 1 : 0
                                });
                                await renderAutomation(partialOfflineAudioContext, audioParam, nativeConstantSourceNode.offset, trace);
                                return nativeConstantSourceNode;
                            }));
                            for (let i = 0; i < 6; i += 1) {
                                nativeConstantSourceNodes[i].connect(nativeChannelMergerNode, 0, i);
                                nativeConstantSourceNodes[i].start(0);
                            }
                            return renderNativeOfflineAudioContext(partialOfflineAudioContext);
                        })();
                    }
                    const renderedBuffer = await renderedBufferPromise;
                    const inputGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });
                    await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, inputGainNode, trace);
                    const channelDatas = [];
                    for (let i = 0; i < renderedBuffer.numberOfChannels; i += 1) {
                        channelDatas.push(renderedBuffer.getChannelData(i));
                    }
                    let lastOrientation = [channelDatas[0][0], channelDatas[1][0], channelDatas[2][0]];
                    let lastPosition = [channelDatas[3][0], channelDatas[4][0], channelDatas[5][0]];
                    let gateGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });
                    let partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {
                        ...commonNativePannerNodeOptions,
                        orientationX: lastOrientation[0],
                        orientationY: lastOrientation[1],
                        orientationZ: lastOrientation[2],
                        positionX: lastPosition[0],
                        positionY: lastPosition[1],
                        positionZ: lastPosition[2]
                    });
                    inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);
                    partialPannerNode.connect(nativeGainNode);
                    for (let i = 128; i < renderedBuffer.length; i += 128) {
                        const orientation = [channelDatas[0][i], channelDatas[1][i], channelDatas[2][i]];
                        const positon = [channelDatas[3][i], channelDatas[4][i], channelDatas[5][i]];
                        if (orientation.some((value, index) => value !== lastOrientation[index]) ||
                            positon.some((value, index) => value !== lastPosition[index])) {
                            lastOrientation = orientation;
                            lastPosition = positon;
                            const currentTime = i / nativeOfflineAudioContext.sampleRate;
                            gateGainNode.gain.setValueAtTime(0, currentTime);
                            gateGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 0 });
                            partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {
                                ...commonNativePannerNodeOptions,
                                orientationX: lastOrientation[0],
                                orientationY: lastOrientation[1],
                                orientationZ: lastOrientation[2],
                                positionX: lastPosition[0],
                                positionY: lastPosition[1],
                                positionZ: lastPosition[2]
                            });
                            gateGainNode.gain.setValueAtTime(1, currentTime);
                            inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);
                            partialPannerNode.connect(nativeGainNode);
                        }
                    }
                    return nativeGainNode;
                }
                if (!nativePannerNodeIsOwnedByContext) {
                    await renderAutomation(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY, trace);
                    await renderAutomation(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ, trace);
                }
                else {
                    await connectAudioParam(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY, trace);
                    await connectAudioParam(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ, trace);
                }
                if (isNativeAudioNodeFaker(nativePannerNode)) {
                    await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode.inputs[0], trace);
                }
                else {
                    await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode, trace);
                }
                return nativePannerNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeGainNodeOrNativePannerNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeGainNodeOrNativePannerNode !== undefined) {
                        return Promise.resolve(renderedNativeGainNodeOrNativePannerNode);
                    }
                    return createAudioNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const DEFAULT_OPTIONS$h = {
        disableNormalization: false
    };
    const createPeriodicWaveConstructor = (createNativePeriodicWave, getNativeContext, periodicWaveStore, sanitizePeriodicWaveOptions) => {
        return class PeriodicWave {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = sanitizePeriodicWaveOptions({ ...DEFAULT_OPTIONS$h, ...options });
                const periodicWave = createNativePeriodicWave(nativeContext, mergedOptions);
                periodicWaveStore.add(periodicWave);
                // This does violate all good pratices but it is used here to simplify the handling of periodic waves.
                return periodicWave;
            }
            static [Symbol.hasInstance](instance) {
                return ((instance !== null && typeof instance === 'object' && Object.getPrototypeOf(instance) === PeriodicWave.prototype) ||
                    periodicWaveStore.has(instance));
            }
        };
    };

    const createRenderAutomation = (getAudioParamRenderer, renderInputsOfAudioParam) => {
        return (nativeOfflineAudioContext, audioParam, nativeAudioParam, trace) => {
            const audioParamRenderer = getAudioParamRenderer(audioParam);
            audioParamRenderer.replay(nativeAudioParam);
            return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam, trace);
        };
    };

    const createRenderInputsOfAudioNode = (getAudioNodeConnections, getAudioNodeRenderer, isPartOfACycle) => {
        return async (audioNode, nativeOfflineAudioContext, nativeAudioNode, trace) => {
            const audioNodeConnections = getAudioNodeConnections(audioNode);
            const nextTrace = [...trace, audioNode];
            await Promise.all(audioNodeConnections.activeInputs
                .map((connections, input) => Array.from(connections)
                .filter(([source]) => !nextTrace.includes(source))
                .map(async ([source, output]) => {
                const audioNodeRenderer = getAudioNodeRenderer(source);
                const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext, nextTrace);
                const destination = audioNode.context.destination;
                if (!isPartOfACycle(source) && (audioNode !== destination || !isPartOfACycle(audioNode))) {
                    renderedNativeAudioNode.connect(nativeAudioNode, output, input);
                }
            }))
                .reduce((allRenderingPromises, renderingPromises) => [...allRenderingPromises, ...renderingPromises], []));
        };
    };

    const createRenderInputsOfAudioParam = (getAudioNodeRenderer, getAudioParamConnections, isPartOfACycle) => {
        return async (audioParam, nativeOfflineAudioContext, nativeAudioParam, trace) => {
            const audioParamConnections = getAudioParamConnections(audioParam);
            await Promise.all(Array.from(audioParamConnections.activeInputs).map(async ([source, output]) => {
                const audioNodeRenderer = getAudioNodeRenderer(source);
                const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext, trace);
                if (!isPartOfACycle(source)) {
                    renderedNativeAudioNode.connect(nativeAudioParam, output);
                }
            }));
        };
    };

    const createRenderNativeOfflineAudioContext = (cacheTestResult, createNativeGainNode, createNativeScriptProcessorNode, testOfflineAudioContextCurrentTimeSupport) => {
        return (nativeOfflineAudioContext) => {
            // Bug #21: Safari does not support promises yet.
            if (cacheTestResult(testPromiseSupport, () => testPromiseSupport(nativeOfflineAudioContext))) {
                // Bug #158: Chrome and Edge do not advance currentTime if it is not accessed while rendering the audio.
                return Promise.resolve(cacheTestResult(testOfflineAudioContextCurrentTimeSupport, testOfflineAudioContextCurrentTimeSupport)).then((isOfflineAudioContextCurrentTimeSupported) => {
                    if (!isOfflineAudioContextCurrentTimeSupported) {
                        const scriptProcessorNode = createNativeScriptProcessorNode(nativeOfflineAudioContext, 512, 0, 1);
                        nativeOfflineAudioContext.oncomplete = () => {
                            scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation
                            scriptProcessorNode.disconnect();
                        };
                        scriptProcessorNode.onaudioprocess = () => nativeOfflineAudioContext.currentTime; // tslint:disable-line:deprecation
                        scriptProcessorNode.connect(nativeOfflineAudioContext.destination);
                    }
                    return nativeOfflineAudioContext.startRendering();
                });
            }
            return new Promise((resolve) => {
                // Bug #48: Safari does not render an OfflineAudioContext without any connected node.
                const gainNode = createNativeGainNode(nativeOfflineAudioContext, {
                    channelCount: 1,
                    channelCountMode: 'explicit',
                    channelInterpretation: 'discrete',
                    gain: 0
                });
                nativeOfflineAudioContext.oncomplete = (event) => {
                    gainNode.disconnect();
                    resolve(event.renderedBuffer);
                };
                gainNode.connect(nativeOfflineAudioContext.destination);
                nativeOfflineAudioContext.startRendering();
            });
        };
    };

    const createSetActiveAudioWorkletNodeInputs = (activeAudioWorkletNodeInputsStore) => {
        return (nativeAudioWorkletNode, activeInputs) => {
            activeAudioWorkletNodeInputsStore.set(nativeAudioWorkletNode, activeInputs);
        };
    };

    const createSetAudioNodeTailTime = (audioNodeTailTimeStore) => {
        return (audioNode, tailTime) => audioNodeTailTimeStore.set(audioNode, tailTime);
    };

    const createStartRendering = (audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {
        const trace = [];
        return (destination, nativeOfflineAudioContext) => getAudioNodeRenderer(destination)
            .render(destination, nativeOfflineAudioContext, trace)
            /*
             * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to the
             * destination.
             */
            .then(() => Promise.all(Array.from(getUnrenderedAudioWorkletNodes(nativeOfflineAudioContext)).map((audioWorkletNode) => getAudioNodeRenderer(audioWorkletNode).render(audioWorkletNode, nativeOfflineAudioContext, trace))))
            .then(() => renderNativeOfflineAudioContext(nativeOfflineAudioContext))
            .then((audioBuffer) => {
            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
            // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
            if (typeof audioBuffer.copyFromChannel !== 'function') {
                wrapAudioBufferCopyChannelMethods(audioBuffer);
                wrapAudioBufferGetChannelDataMethod(audioBuffer);
                // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
            }
            else if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) {
                wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
            }
            audioBufferStore.add(audioBuffer);
            return audioBuffer;
        });
    };

    const DEFAULT_OPTIONS$i = {
        channelCount: 2,
        /*
         * Bug #105: The channelCountMode should be 'clamped-max' according to the spec but is set to 'explicit' to achieve consistent
         * behavior.
         */
        channelCountMode: 'explicit',
        channelInterpretation: 'speakers',
        pan: 0
    };
    const createStereoPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext) => {
        return class StereoPannerNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$i, ...options };
                const nativeStereoPannerNode = createNativeStereoPannerNode(nativeContext, mergedOptions);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const stereoPannerNodeRenderer = (isOffline ? createStereoPannerNodeRenderer() : null);
                super(context, false, nativeStereoPannerNode, stereoPannerNodeRenderer);
                this._pan = createAudioParam(this, isOffline, nativeStereoPannerNode.pan);
            }
            get pan() {
                return this._pan;
            }
        };
    };

    const createStereoPannerNodeRendererFactory = (connectAudioParam, createNativeStereoPannerNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeStereoPannerNodes = new WeakMap();
            const createStereoPannerNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeStereoPannerNode = getNativeAudioNode(proxy);
                /*
                 * If the initially used nativeStereoPannerNode was not constructed on the same OfflineAudioContext it needs to be created
                 * again.
                 */
                const nativeStereoPannerNodeIsOwnedByContext = isOwnedByContext(nativeStereoPannerNode, nativeOfflineAudioContext);
                if (!nativeStereoPannerNodeIsOwnedByContext) {
                    const options = {
                        channelCount: nativeStereoPannerNode.channelCount,
                        channelCountMode: nativeStereoPannerNode.channelCountMode,
                        channelInterpretation: nativeStereoPannerNode.channelInterpretation,
                        pan: nativeStereoPannerNode.pan.value
                    };
                    nativeStereoPannerNode = createNativeStereoPannerNode(nativeOfflineAudioContext, options);
                }
                renderedNativeStereoPannerNodes.set(nativeOfflineAudioContext, nativeStereoPannerNode);
                if (!nativeStereoPannerNodeIsOwnedByContext) {
                    await renderAutomation(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan, trace);
                }
                else {
                    await connectAudioParam(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan, trace);
                }
                if (isNativeAudioNodeFaker(nativeStereoPannerNode)) {
                    await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode.inputs[0], trace);
                }
                else {
                    await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode, trace);
                }
                return nativeStereoPannerNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeStereoPannerNode = renderedNativeStereoPannerNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeStereoPannerNode !== undefined) {
                        return Promise.resolve(renderedNativeStereoPannerNode);
                    }
                    return createStereoPannerNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    // Bug #33: Safari exposes an AudioBuffer but it can't be used as a constructor.
    const createTestAudioBufferConstructorSupport = (nativeAudioBufferConstructor) => {
        return () => {
            if (nativeAudioBufferConstructor === null) {
                return false;
            }
            try {
                new nativeAudioBufferConstructor({ length: 1, sampleRate: 44100 }); // tslint:disable-line:no-unused-expression
            }
            catch {
                return false;
            }
            return true;
        };
    };

    /*
     * Firefox up to version 67 didn't fully support the copyFromChannel() and copyToChannel() methods. Therefore testing one of those methods
     * is enough to know if the other one is supported as well.
     */
    const createTestAudioBufferCopyChannelMethodsSubarraySupport = (nativeOfflineAudioContextConstructor) => {
        return () => {
            if (nativeOfflineAudioContextConstructor === null) {
                return false;
            }
            const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            const nativeAudioBuffer = nativeOfflineAudioContext.createBuffer(1, 1, 44100);
            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
            if (nativeAudioBuffer.copyToChannel === undefined) {
                return true;
            }
            const source = new Float32Array(2);
            try {
                nativeAudioBuffer.copyFromChannel(source, 0, 0);
            }
            catch {
                return false;
            }
            return true;
        };
    };

    const createTestAudioContextCloseMethodSupport = (nativeAudioContextConstructor) => {
        return () => {
            if (nativeAudioContextConstructor === null) {
                return false;
            }
            // Try to check the prototype before constructing the AudioContext.
            if (nativeAudioContextConstructor.prototype !== undefined && nativeAudioContextConstructor.prototype.close !== undefined) {
                return true;
            }
            const audioContext = new nativeAudioContextConstructor();
            const isAudioContextClosable = audioContext.close !== undefined;
            try {
                audioContext.close();
            }
            catch {
                // Ignore errors.
            }
            return isAudioContextClosable;
        };
    };

    /**
     * Edge up to version 14, Firefox up to version 52, Safari up to version 9 and maybe other browsers
     * did not refuse to decode invalid parameters with a TypeError.
     */
    const createTestAudioContextDecodeAudioDataMethodTypeErrorSupport = (nativeOfflineAudioContextConstructor) => {
        return () => {
            if (nativeOfflineAudioContextConstructor === null) {
                return Promise.resolve(false);
            }
            const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            // Bug #21: Safari does not support promises yet.
            return new Promise((resolve) => {
                let isPending = true;
                const resolvePromise = (err) => {
                    if (isPending) {
                        isPending = false;
                        offlineAudioContext.startRendering();
                        resolve(err instanceof TypeError);
                    }
                };
                let promise;
                // Bug #26: Safari throws a synchronous error.
                try {
                    promise = offlineAudioContext
                        // Bug #1: Safari requires a successCallback.
                        .decodeAudioData(null, () => {
                        // Ignore the success callback.
                    }, resolvePromise);
                }
                catch (err) {
                    resolvePromise(err);
                }
                // Bug #21: Safari does not support promises yet.
                if (promise !== undefined) {
                    // Bug #6: Chrome, Edge, Firefox and Opera do not call the errorCallback.
                    promise.catch(resolvePromise);
                }
            });
        };
    };

    const createTestAudioContextOptionsSupport = (nativeAudioContextConstructor) => {
        return () => {
            if (nativeAudioContextConstructor === null) {
                return false;
            }
            let audioContext;
            try {
                audioContext = new nativeAudioContextConstructor({ latencyHint: 'balanced' });
            }
            catch {
                return false;
            }
            audioContext.close();
            return true;
        };
    };

    // Safari up to version 12.0 (but not v12.1) didn't return the destination in case it was an AudioNode.
    const createTestAudioNodeConnectMethodSupport = (nativeOfflineAudioContextConstructor) => {
        return () => {
            if (nativeOfflineAudioContextConstructor === null) {
                return false;
            }
            const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            const nativeGainNode = nativeOfflineAudioContext.createGain();
            const isSupported = nativeGainNode.connect(nativeGainNode) === nativeGainNode;
            nativeGainNode.disconnect(nativeGainNode);
            return isSupported;
        };
    };

    /**
     * Chrome version 66 and 67 did not call the process() function of an AudioWorkletProcessor if it had no outputs. AudioWorklet support was
     * enabled by default in version 66.
     */
    const createTestAudioWorkletProcessorNoOutputsSupport = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor) => {
        return async () => {
            // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.
            if (nativeAudioWorkletNodeConstructor === null) {
                return true;
            }
            if (nativeOfflineAudioContextConstructor === null) {
                return false;
            }
            const blob = new Blob(['class A extends AudioWorkletProcessor{process(){this.port.postMessage(0)}}registerProcessor("a",A)'], {
                type: 'application/javascript; charset=utf-8'
            });
            const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 8000);
            const url = URL.createObjectURL(blob);
            let isCallingProcess = false;
            try {
                await offlineAudioContext.audioWorklet.addModule(url);
                const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, 'a', { numberOfOutputs: 0 });
                const oscillator = offlineAudioContext.createOscillator();
                audioWorkletNode.port.onmessage = () => (isCallingProcess = true);
                oscillator.connect(audioWorkletNode);
                oscillator.start(0);
                await offlineAudioContext.startRendering();
                if (!isCallingProcess) {
                    await new Promise((resolve) => setTimeout(resolve, 5));
                }
            }
            catch {
                // Ignore errors.
            }
            finally {
                URL.revokeObjectURL(url);
            }
            return isCallingProcess;
        };
    };

    // Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.
    const createTestAudioWorkletProcessorPostMessageSupport = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor) => {
        return async () => {
            // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.
            if (nativeAudioWorkletNodeConstructor === null) {
                return true;
            }
            if (nativeOfflineAudioContextConstructor === null) {
                return false;
            }
            const blob = new Blob(['class A extends AudioWorkletProcessor{process(i){this.port.postMessage(i,[i[0][0].buffer])}}registerProcessor("a",A)'], {
                type: 'application/javascript; charset=utf-8'
            });
            const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 8000);
            const url = URL.createObjectURL(blob);
            let isEmittingMessageEvents = false;
            let isEmittingProcessorErrorEvents = false;
            try {
                await offlineAudioContext.audioWorklet.addModule(url);
                const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, 'a', { numberOfOutputs: 0 });
                const oscillator = offlineAudioContext.createOscillator();
                audioWorkletNode.port.onmessage = () => (isEmittingMessageEvents = true);
                audioWorkletNode.onprocessorerror = () => (isEmittingProcessorErrorEvents = true);
                oscillator.connect(audioWorkletNode);
                await offlineAudioContext.startRendering();
            }
            catch {
                // Ignore errors.
            }
            finally {
                URL.revokeObjectURL(url);
            }
            return isEmittingMessageEvents && !isEmittingProcessorErrorEvents;
        };
    };

    /**
     * Firefox up to version 69 did not throw an error when setting a different channelCount or channelCountMode.
     */
    const createTestChannelMergerNodeChannelCountSupport = (nativeOfflineAudioContextConstructor) => {
        return () => {
            if (nativeOfflineAudioContextConstructor === null) {
                return false;
            }
            const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            const nativeChannelMergerNode = offlineAudioContext.createChannelMerger();
            /**
             * Bug #15: Safari does not return the default properties. It still needs to be patched. This test is supposed to test the support
             * in other browsers.
             */
            if (nativeChannelMergerNode.channelCountMode === 'max') {
                return true;
            }
            try {
                nativeChannelMergerNode.channelCount = 2;
            }
            catch {
                return true;
            }
            return false;
        };
    };

    const createTestConstantSourceNodeAccurateSchedulingSupport = (nativeOfflineAudioContextConstructor) => {
        return () => {
            if (nativeOfflineAudioContextConstructor === null) {
                return false;
            }
            const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            // Bug #62: Safari does not support ConstantSourceNodes.
            if (nativeOfflineAudioContext.createConstantSource === undefined) {
                return true;
            }
            const nativeConstantSourceNode = nativeOfflineAudioContext.createConstantSource();
            /*
             * @todo This is using bug #75 to detect bug #70. That works because both bugs were unique to
             * the implementation of Firefox right now, but it could probably be done in a better way.
             */
            return nativeConstantSourceNode.offset.maxValue !== Number.POSITIVE_INFINITY;
        };
    };

    // Opera up to version 57 did not allow to reassign the buffer of a ConvolverNode.
    const createTestConvolverNodeBufferReassignabilitySupport = (nativeOfflineAudioContextConstructor) => {
        return () => {
            if (nativeOfflineAudioContextConstructor === null) {
                return false;
            }
            const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            const nativeConvolverNode = offlineAudioContext.createConvolver();
            nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);
            try {
                nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);
            }
            catch {
                return false;
            }
            return true;
        };
    };

    // Chrome up to version v80, Edge up to version v80 and Opera up to version v67 did not allow to set the channelCount property of a ConvolverNode to 1. They also did not allow to set the channelCountMode to 'explicit'.
    const createTestConvolverNodeChannelCountSupport = (nativeOfflineAudioContextConstructor) => {
        return () => {
            if (nativeOfflineAudioContextConstructor === null) {
                return false;
            }
            const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            const nativeConvolverNode = offlineAudioContext.createConvolver();
            try {
                nativeConvolverNode.channelCount = 1;
            }
            catch {
                return false;
            }
            return true;
        };
    };

    const createTestIsSecureContextSupport = (window) => {
        return () => window !== null && window.hasOwnProperty('isSecureContext');
    };

    // Firefox up to version 68 did not throw an error when creating a MediaStreamAudioSourceNode with a mediaStream that had no audio track.
    const createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport = (nativeAudioContextConstructor) => {
        return () => {
            if (nativeAudioContextConstructor === null) {
                return false;
            }
            const audioContext = new nativeAudioContextConstructor();
            try {
                audioContext.createMediaStreamSource(new MediaStream());
                return false;
            }
            catch (err) {
                return true;
            }
        };
    };

    const createTestOfflineAudioContextCurrentTimeSupport = (createNativeGainNode, nativeOfflineAudioContextConstructor) => {
        return () => {
            if (nativeOfflineAudioContextConstructor === null) {
                return Promise.resolve(false);
            }
            const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            // Bug #48: Safari does not render an OfflineAudioContext without any connected node.
            const gainNode = createNativeGainNode(nativeOfflineAudioContext, {
                channelCount: 1,
                channelCountMode: 'explicit',
                channelInterpretation: 'discrete',
                gain: 0
            });
            // Bug #21: Safari does not support promises yet.
            return new Promise((resolve) => {
                nativeOfflineAudioContext.oncomplete = () => {
                    gainNode.disconnect();
                    resolve(nativeOfflineAudioContext.currentTime !== 0);
                };
                nativeOfflineAudioContext.startRendering();
            });
        };
    };

    /**
     * Firefox up to version 62 did not kick off the processing of the StereoPannerNode if the value of pan was zero.
     */
    const createTestStereoPannerNodeDefaultValueSupport = (nativeOfflineAudioContextConstructor) => {
        return () => {
            if (nativeOfflineAudioContextConstructor === null) {
                return Promise.resolve(false);
            }
            const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            /*
             * Bug #105: Safari does not support the StereoPannerNode. Therefore the returned value should normally be false but the faker does
             * support the tested behaviour.
             */
            if (nativeOfflineAudioContext.createStereoPanner === undefined) {
                return Promise.resolve(true);
            }
            // Bug #62: Safari does not support ConstantSourceNodes.
            if (nativeOfflineAudioContext.createConstantSource === undefined) {
                return Promise.resolve(true);
            }
            const constantSourceNode = nativeOfflineAudioContext.createConstantSource();
            const stereoPanner = nativeOfflineAudioContext.createStereoPanner();
            constantSourceNode.channelCount = 1;
            constantSourceNode.offset.value = 1;
            stereoPanner.channelCount = 1;
            constantSourceNode.start();
            constantSourceNode.connect(stereoPanner).connect(nativeOfflineAudioContext.destination);
            return nativeOfflineAudioContext.startRendering().then((buffer) => buffer.getChannelData(0)[0] !== 1);
        };
    };

    const createUnknownError = () => new DOMException('', 'UnknownError');

    const DEFAULT_OPTIONS$j = {
        channelCount: 2,
        channelCountMode: 'max',
        channelInterpretation: 'speakers',
        curve: null,
        oversample: 'none'
    };
    const createWaveShaperNodeConstructor = (audioNodeConstructor, createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {
        return class WaveShaperNode extends audioNodeConstructor {
            constructor(context, options) {
                const nativeContext = getNativeContext(context);
                const mergedOptions = { ...DEFAULT_OPTIONS$j, ...options };
                const nativeWaveShaperNode = createNativeWaveShaperNode(nativeContext, mergedOptions);
                const isOffline = isNativeOfflineAudioContext(nativeContext);
                const waveShaperNodeRenderer = (isOffline ? createWaveShaperNodeRenderer() : null);
                // @todo Add a mechanism to only switch a WaveShaperNode to active while it is connected.
                super(context, true, nativeWaveShaperNode, waveShaperNodeRenderer);
                this._isCurveNullified = false;
                this._nativeWaveShaperNode = nativeWaveShaperNode;
                // @todo Determine a meaningful tail-time instead of just using one second.
                setAudioNodeTailTime(this, 1);
            }
            get curve() {
                if (this._isCurveNullified) {
                    return null;
                }
                return this._nativeWaveShaperNode.curve;
            }
            set curve(value) {
                // Bug #103: Safari does not allow to set the curve to null.
                if (value === null) {
                    this._isCurveNullified = true;
                    this._nativeWaveShaperNode.curve = new Float32Array([0, 0]);
                }
                else {
                    // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.
                    // Bug #104: Chrome, Edge and Opera will throw an InvalidAccessError when the curve has less than two samples.
                    if (value.length < 2) {
                        throw createInvalidStateError();
                    }
                    this._isCurveNullified = false;
                    this._nativeWaveShaperNode.curve = value;
                }
            }
            get oversample() {
                return this._nativeWaveShaperNode.oversample;
            }
            set oversample(value) {
                this._nativeWaveShaperNode.oversample = value;
            }
        };
    };

    const createWaveShaperNodeRendererFactory = (createNativeWaveShaperNode, getNativeAudioNode, renderInputsOfAudioNode) => {
        return () => {
            const renderedNativeWaveShaperNodes = new WeakMap();
            const createWaveShaperNode = async (proxy, nativeOfflineAudioContext, trace) => {
                let nativeWaveShaperNode = getNativeAudioNode(proxy);
                // If the initially used nativeWaveShaperNode was not constructed on the same OfflineAudioContext it needs to be created again.
                const nativeWaveShaperNodeIsOwnedByContext = isOwnedByContext(nativeWaveShaperNode, nativeOfflineAudioContext);
                if (!nativeWaveShaperNodeIsOwnedByContext) {
                    const options = {
                        channelCount: nativeWaveShaperNode.channelCount,
                        channelCountMode: nativeWaveShaperNode.channelCountMode,
                        channelInterpretation: nativeWaveShaperNode.channelInterpretation,
                        curve: nativeWaveShaperNode.curve,
                        oversample: nativeWaveShaperNode.oversample
                    };
                    nativeWaveShaperNode = createNativeWaveShaperNode(nativeOfflineAudioContext, options);
                }
                renderedNativeWaveShaperNodes.set(nativeOfflineAudioContext, nativeWaveShaperNode);
                if (isNativeAudioNodeFaker(nativeWaveShaperNode)) {
                    await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode.inputs[0], trace);
                }
                else {
                    await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode, trace);
                }
                return nativeWaveShaperNode;
            };
            return {
                render(proxy, nativeOfflineAudioContext, trace) {
                    const renderedNativeWaveShaperNode = renderedNativeWaveShaperNodes.get(nativeOfflineAudioContext);
                    if (renderedNativeWaveShaperNode !== undefined) {
                        return Promise.resolve(renderedNativeWaveShaperNode);
                    }
                    return createWaveShaperNode(proxy, nativeOfflineAudioContext, trace);
                }
            };
        };
    };

    const createWindow = () => (typeof window === 'undefined' ? null : window);

    const createWrapAudioBufferCopyChannelMethods = (convertNumberToUnsignedLong, createIndexSizeError) => {
        return (audioBuffer) => {
            audioBuffer.copyFromChannel = (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {
                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
                if (channelNumber >= audioBuffer.numberOfChannels) {
                    throw createIndexSizeError();
                }
                const audioBufferLength = audioBuffer.length;
                const channelData = audioBuffer.getChannelData(channelNumber);
                const destinationLength = destination.length;
                for (let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < destinationLength; i += 1) {
                    destination[i] = channelData[i + bufferOffset];
                }
            };
            audioBuffer.copyToChannel = (source, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {
                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
                if (channelNumber >= audioBuffer.numberOfChannels) {
                    throw createIndexSizeError();
                }
                const audioBufferLength = audioBuffer.length;
                const channelData = audioBuffer.getChannelData(channelNumber);
                const sourceLength = source.length;
                for (let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < sourceLength; i += 1) {
                    channelData[i + bufferOffset] = source[i];
                }
            };
        };
    };

    const createWrapAudioBufferCopyChannelMethodsOutOfBounds = (convertNumberToUnsignedLong) => {
        return (audioBuffer) => {
            audioBuffer.copyFromChannel = ((copyFromChannel) => {
                return (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {
                    const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
                    const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
                    if (bufferOffset < audioBuffer.length) {
                        return copyFromChannel.call(audioBuffer, destination, channelNumber, bufferOffset);
                    }
                };
            })(audioBuffer.copyFromChannel);
            audioBuffer.copyToChannel = ((copyToChannel) => {
                return (source, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {
                    const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
                    const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
                    if (bufferOffset < audioBuffer.length) {
                        return copyToChannel.call(audioBuffer, source, channelNumber, bufferOffset);
                    }
                };
            })(audioBuffer.copyToChannel);
        };
    };

    const createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer = (overwriteAccessors) => {
        return (nativeAudioBufferSourceNode, nativeContext) => {
            const nullifiedBuffer = nativeContext.createBuffer(1, 1, 44100);
            if (nativeAudioBufferSourceNode.buffer === null) {
                nativeAudioBufferSourceNode.buffer = nullifiedBuffer;
            }
            overwriteAccessors(nativeAudioBufferSourceNode, 'buffer', (get) => () => {
                const value = get.call(nativeAudioBufferSourceNode);
                return value === nullifiedBuffer ? null : value;
            }, (set) => (value) => {
                return set.call(nativeAudioBufferSourceNode, value === null ? nullifiedBuffer : value);
            });
        };
    };

    const createWrapChannelMergerNode = (createInvalidStateError, monitorConnections) => {
        return (nativeContext, channelMergerNode) => {
            // Bug #15: Safari does not return the default properties.
            channelMergerNode.channelCount = 1;
            channelMergerNode.channelCountMode = 'explicit';
            // Bug #16: Safari does not throw an error when setting a different channelCount or channelCountMode.
            Object.defineProperty(channelMergerNode, 'channelCount', {
                get: () => 1,
                set: () => {
                    throw createInvalidStateError();
                }
            });
            Object.defineProperty(channelMergerNode, 'channelCountMode', {
                get: () => 'explicit',
                set: () => {
                    throw createInvalidStateError();
                }
            });
            // Bug #20: Safari requires a connection of any kind to treat the input signal correctly.
            const audioBufferSourceNode = nativeContext.createBufferSource();
            const whenConnected = () => {
                const length = channelMergerNode.numberOfInputs;
                for (let i = 0; i < length; i += 1) {
                    audioBufferSourceNode.connect(channelMergerNode, 0, i);
                }
            };
            const whenDisconnected = () => audioBufferSourceNode.disconnect(channelMergerNode);
            monitorConnections(channelMergerNode, whenConnected, whenDisconnected);
        };
    };

    const isDCCurve = (curve) => {
        if (curve === null) {
            return false;
        }
        const length = curve.length;
        if (length % 2 !== 0) {
            return curve[Math.floor(length / 2)] !== 0;
        }
        return curve[length / 2 - 1] + curve[length / 2] !== 0;
    };

    const overwriteAccessors = (object, property, createGetter, createSetter) => {
        let prototype = Object.getPrototypeOf(object);
        while (!prototype.hasOwnProperty(property)) {
            prototype = Object.getPrototypeOf(prototype);
        }
        const { get, set } = Object.getOwnPropertyDescriptor(prototype, property);
        Object.defineProperty(object, property, { get: createGetter(get), set: createSetter(set) });
    };

    const sanitizeAudioWorkletNodeOptions = (options) => {
        return {
            ...options,
            outputChannelCount: options.outputChannelCount !== undefined
                ? options.outputChannelCount
                : options.numberOfInputs === 1 && options.numberOfOutputs === 1
                    ? /*
                       * Bug #61: This should be the computedNumberOfChannels, but unfortunately that is almost impossible to fake. That's why
                       * the channelCountMode is required to be 'explicit' as long as there is not a native implementation in every browser. That
                       * makes sure the computedNumberOfChannels is equivilant to the channelCount which makes it much easier to compute.
                       */
                        [options.channelCount]
                    : Array.from({ length: options.numberOfOutputs }, () => 1)
        };
    };

    const sanitizeChannelSplitterOptions = (options) => {
        return { ...options, channelCount: options.numberOfOutputs };
    };

    const sanitizePeriodicWaveOptions = (options) => {
        const { imag, real } = options;
        if (imag === undefined) {
            if (real === undefined) {
                return { ...options, imag: [0, 0], real: [0, 0] };
            }
            return { ...options, imag: Array.from(real, () => 0), real };
        }
        if (real === undefined) {
            return { ...options, imag, real: Array.from(imag, () => 0) };
        }
        return { ...options, imag, real };
    };

    const testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport = (nativeContext) => {
        const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
        nativeAudioBufferSourceNode.start();
        try {
            nativeAudioBufferSourceNode.start();
        }
        catch {
            return true;
        }
        return false;
    };

    const testAudioBufferSourceNodeStartMethodOffsetClampingSupport = (nativeContext) => {
        const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
        const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);
        nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
        try {
            nativeAudioBufferSourceNode.start(0, 1);
        }
        catch {
            return false;
        }
        return true;
    };

    const testAudioBufferSourceNodeStopMethodNullifiedBufferSupport = (nativeContext) => {
        const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
        nativeAudioBufferSourceNode.start();
        try {
            nativeAudioBufferSourceNode.stop();
        }
        catch {
            return false;
        }
        return true;
    };

    const testAudioScheduledSourceNodeStartMethodNegativeParametersSupport = (nativeContext) => {
        const nativeAudioBufferSourceNode = nativeContext.createOscillator();
        try {
            nativeAudioBufferSourceNode.start(-1);
        }
        catch (err) {
            return err instanceof RangeError;
        }
        return false;
    };

    const testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport = (nativeContext) => {
        const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);
        const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
        nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
        nativeAudioBufferSourceNode.start();
        nativeAudioBufferSourceNode.stop();
        try {
            nativeAudioBufferSourceNode.stop();
            return true;
        }
        catch {
            return false;
        }
    };

    const testAudioScheduledSourceNodeStopMethodNegativeParametersSupport = (nativeContext) => {
        const nativeAudioBufferSourceNode = nativeContext.createOscillator();
        try {
            nativeAudioBufferSourceNode.stop(-1);
        }
        catch (err) {
            return err instanceof RangeError;
        }
        return false;
    };

    /*
     * Bug #122: Edge up to version v18 did not allow to construct a DOMException'. It also had a couple more bugs but since this is easy to
     * test it's used here as a placeholder.
     *
     * Bug #27: Edge up to version v18 did reject an invalid arrayBuffer passed to decodeAudioData() with a DOMException.
     *
     * Bug #50: Edge up to version v18 did not allow to create AudioNodes on a closed context.
     *
     * Bug #57: Edge up to version v18 did not throw an error when assigning the type of an OscillatorNode to 'custom'.
     *
     * Bug #63: Edge up to version v18 did not expose the mediaElement property of a MediaElementAudioSourceNode.
     *
     * Bug #64: Edge up to version v18 did not support the MediaStreamAudioDestinationNode.
     *
     * Bug #71: Edge up to version v18 did not allow to set the buffer of an AudioBufferSourceNode to null.
     *
     * Bug #93: Edge up to version v18 did set the sampleRate of an AudioContext to zero when it was closed.
     *
     * Bug #101: Edge up to version v18 refused to execute decodeAudioData() on a closed context.
     *
     * Bug #106: Edge up to version v18 did not expose the maxValue and minValue properties of the pan AudioParam of a StereoPannerNode.
     *
     * Bug #110: Edge up to version v18 did not expose the maxValue and minValue properties of the attack, knee, ratio, release and threshold AudioParams of a DynamicsCompressorNode.
     *
     * Bug #123: Edge up to version v18 did not support HRTF as the panningModel for a PannerNode.
     *
     * Bug #145: Edge up to version v18 did throw an IndexSizeError when an OfflineAudioContext was created with a sampleRate of zero.
     *
     * Bug #161: Edge up to version v18 did not expose the maxValue and minValue properties of the delayTime AudioParam of a DelayNode.
     */
    const testDomExceptionConstructorSupport = () => {
        try {
            new DOMException(); // tslint:disable-line:no-unused-expression
        }
        catch {
            return false;
        }
        return true;
    };

    // Safari at version 11 did not support transferables.
    const testTransferablesSupport = () => new Promise((resolve) => {
        const arrayBuffer = new ArrayBuffer(0);
        const { port1, port2 } = new MessageChannel();
        port1.onmessage = ({ data }) => resolve(data !== null);
        port2.postMessage(arrayBuffer, [arrayBuffer]);
    });

    const wrapAudioBufferSourceNodeStartMethodOffsetClamping = (nativeAudioBufferSourceNode) => {
        nativeAudioBufferSourceNode.start = ((start) => {
            return (when = 0, offset = 0, duration) => {
                const buffer = nativeAudioBufferSourceNode.buffer;
                // Bug #154: Safari does not clamp the offset if it is equal to or greater than the duration of the buffer.
                const clampedOffset = buffer === null ? offset : Math.min(buffer.duration, offset);
                // Bug #155: Safari does not handle the offset correctly if it would cause the buffer to be not be played at all.
                if (buffer !== null && clampedOffset > buffer.duration - 0.5 / nativeAudioBufferSourceNode.context.sampleRate) {
                    start.call(nativeAudioBufferSourceNode, when, 0, 0);
                }
                else {
                    start.call(nativeAudioBufferSourceNode, when, clampedOffset, duration);
                }
            };
        })(nativeAudioBufferSourceNode.start);
    };

    const wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls = (nativeAudioScheduledSourceNode, nativeContext) => {
        const nativeGainNode = nativeContext.createGain();
        nativeAudioScheduledSourceNode.connect(nativeGainNode);
        const disconnectGainNode = ((disconnect) => {
            return () => {
                // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.
                disconnect.call(nativeAudioScheduledSourceNode, nativeGainNode);
                nativeAudioScheduledSourceNode.removeEventListener('ended', disconnectGainNode);
            };
        })(nativeAudioScheduledSourceNode.disconnect);
        nativeAudioScheduledSourceNode.addEventListener('ended', disconnectGainNode);
        interceptConnections(nativeAudioScheduledSourceNode, nativeGainNode);
        nativeAudioScheduledSourceNode.stop = ((stop) => {
            let isStopped = false;
            return (when = 0) => {
                if (isStopped) {
                    try {
                        stop.call(nativeAudioScheduledSourceNode, when);
                    }
                    catch {
                        nativeGainNode.gain.setValueAtTime(0, when);
                    }
                }
                else {
                    stop.call(nativeAudioScheduledSourceNode, when);
                    isStopped = true;
                }
            };
        })(nativeAudioScheduledSourceNode.stop);
    };

    const wrapEventListener = (target, eventListener) => {
        return (event) => {
            const descriptor = { value: target };
            Object.defineProperties(event, {
                currentTarget: descriptor,
                target: descriptor
            });
            if (typeof eventListener === 'function') {
                return eventListener.call(target, event);
            }
            return eventListener.handleEvent.call(target, event);
        };
    };

    const addActiveInputConnectionToAudioNode = createAddActiveInputConnectionToAudioNode(insertElementInSet);
    const addPassiveInputConnectionToAudioNode = createAddPassiveInputConnectionToAudioNode(insertElementInSet);
    const deleteActiveInputConnectionToAudioNode = createDeleteActiveInputConnectionToAudioNode(pickElementFromSet);
    const audioNodeTailTimeStore = new WeakMap();
    const getAudioNodeTailTime = createGetAudioNodeTailTime(audioNodeTailTimeStore);
    const cacheTestResult = createCacheTestResult(new Map(), new WeakMap());
    const window$1 = createWindow();
    const createNativeAnalyserNode = createNativeAnalyserNodeFactory(cacheTestResult, createIndexSizeError);
    const getAudioNodeRenderer = createGetAudioNodeRenderer(getAudioNodeConnections);
    const renderInputsOfAudioNode = createRenderInputsOfAudioNode(getAudioNodeConnections, getAudioNodeRenderer, isPartOfACycle);
    const createAnalyserNodeRenderer = createAnalyserNodeRendererFactory(createNativeAnalyserNode, getNativeAudioNode, renderInputsOfAudioNode);
    const getNativeContext = createGetNativeContext(CONTEXT_STORE);
    const nativeOfflineAudioContextConstructor = createNativeOfflineAudioContextConstructor(window$1);
    const isNativeOfflineAudioContext = createIsNativeOfflineAudioContext(nativeOfflineAudioContextConstructor);
    const audioParamAudioNodeStore = new WeakMap();
    const eventTargetConstructor = createEventTargetConstructor(wrapEventListener);
    const nativeAudioContextConstructor = createNativeAudioContextConstructor(window$1);
    const isNativeAudioContext = createIsNativeAudioContext(nativeAudioContextConstructor);
    const isNativeAudioNode$1 = createIsNativeAudioNode(window$1);
    const isNativeAudioParam = createIsNativeAudioParam(window$1);
    const audioNodeConstructor = createAudioNodeConstructor(createAddAudioNodeConnections(AUDIO_NODE_CONNECTIONS_STORE), createAddConnectionToAudioNode(addActiveInputConnectionToAudioNode, addPassiveInputConnectionToAudioNode, connectNativeAudioNodeToNativeAudioNode, deleteActiveInputConnectionToAudioNode, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getAudioNodeTailTime, getEventListenersOfAudioNode, getNativeAudioNode, insertElementInSet, isActiveAudioNode, isPartOfACycle, isPassiveAudioNode), cacheTestResult, createIncrementCycleCounterFactory(CYCLE_COUNTERS, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, isActiveAudioNode), createIndexSizeError, createInvalidAccessError, createNotSupportedError, createDecrementCycleCounter(connectNativeAudioNodeToNativeAudioNode, CYCLE_COUNTERS, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, getNativeContext, isActiveAudioNode, isNativeOfflineAudioContext), createDetectCycles(audioParamAudioNodeStore, getAudioNodeConnections, getValueForKey), eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode$1, isNativeAudioParam, isNativeOfflineAudioContext);
    const analyserNodeConstructor = createAnalyserNodeConstructor(audioNodeConstructor, createAnalyserNodeRenderer, createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext);
    const audioBufferStore = new WeakSet();
    const nativeAudioBufferConstructor = createNativeAudioBufferConstructor(window$1);
    const convertNumberToUnsignedLong = createConvertNumberToUnsignedLong(new Uint32Array(1));
    const wrapAudioBufferCopyChannelMethods = createWrapAudioBufferCopyChannelMethods(convertNumberToUnsignedLong, createIndexSizeError);
    const wrapAudioBufferCopyChannelMethodsOutOfBounds = createWrapAudioBufferCopyChannelMethodsOutOfBounds(convertNumberToUnsignedLong);
    const audioBufferConstructor = createAudioBufferConstructor(audioBufferStore, cacheTestResult, createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, createTestAudioBufferConstructorSupport(nativeAudioBufferConstructor), wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);
    const addSilentConnection = createAddSilentConnection(createNativeGainNode);
    const renderInputsOfAudioParam = createRenderInputsOfAudioParam(getAudioNodeRenderer, getAudioParamConnections, isPartOfACycle);
    const connectAudioParam = createConnectAudioParam(renderInputsOfAudioParam);
    const createNativeAudioBufferSourceNode = createNativeAudioBufferSourceNodeFactory(addSilentConnection, cacheTestResult, testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, testAudioBufferSourceNodeStartMethodOffsetClampingSupport, testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioBufferSourceNodeStartMethodOffsetClamping, createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer(overwriteAccessors), wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls);
    const renderAutomation = createRenderAutomation(createGetAudioParamRenderer(getAudioParamConnections), renderInputsOfAudioParam);
    const createAudioBufferSourceNodeRenderer = createAudioBufferSourceNodeRendererFactory(connectAudioParam, createNativeAudioBufferSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
    const createAudioParam = createAudioParamFactory(createAddAudioParamConnections(AUDIO_PARAM_CONNECTIONS_STORE), audioParamAudioNodeStore, AUDIO_PARAM_STORE, createAudioParamRenderer, bundle.createCancelAndHoldAutomationEvent, bundle.createCancelScheduledValuesAutomationEvent, bundle.createExponentialRampToValueAutomationEvent, bundle.createLinearRampToValueAutomationEvent, bundle.createSetTargetAutomationEvent, bundle.createSetValueAutomationEvent, bundle.createSetValueCurveAutomationEvent, nativeAudioContextConstructor);
    const audioBufferSourceNodeConstructor = createAudioBufferSourceNodeConstructor(audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener);
    const audioDestinationNodeConstructor = createAudioDestinationNodeConstructor(audioNodeConstructor, createAudioDestinationNodeRenderer, createIndexSizeError, createInvalidStateError, createNativeAudioDestinationNodeFactory(createNativeGainNode, overwriteAccessors), getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode);
    const createBiquadFilterNodeRenderer = createBiquadFilterNodeRendererFactory(connectAudioParam, createNativeBiquadFilterNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
    const setAudioNodeTailTime = createSetAudioNodeTailTime(audioNodeTailTimeStore);
    const biquadFilterNodeConstructor = createBiquadFilterNodeConstructor(audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, createInvalidAccessError, createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
    const monitorConnections = createMonitorConnections(insertElementInSet, isNativeAudioNode$1);
    const wrapChannelMergerNode = createWrapChannelMergerNode(createInvalidStateError, monitorConnections);
    const createNativeChannelMergerNode = createNativeChannelMergerNodeFactory(nativeAudioContextConstructor, wrapChannelMergerNode);
    const createChannelMergerNodeRenderer = createChannelMergerNodeRendererFactory(createNativeChannelMergerNode, getNativeAudioNode, renderInputsOfAudioNode);
    const channelMergerNodeConstructor = createChannelMergerNodeConstructor(audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext);
    const createChannelSplitterNodeRenderer = createChannelSplitterNodeRendererFactory(createNativeChannelSplitterNode, getNativeAudioNode, renderInputsOfAudioNode);
    const channelSplitterNodeConstructor = createChannelSplitterNodeConstructor(audioNodeConstructor, createChannelSplitterNodeRenderer, createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext, sanitizeChannelSplitterOptions);
    const createNativeConstantSourceNodeFaker = createNativeConstantSourceNodeFakerFactory(addSilentConnection, createNativeAudioBufferSourceNode, createNativeGainNode, monitorConnections);
    const createNativeConstantSourceNode = createNativeConstantSourceNodeFactory(addSilentConnection, cacheTestResult, createNativeConstantSourceNodeFaker, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport);
    const createConstantSourceNodeRenderer = createConstantSourceNodeRendererFactory(connectAudioParam, createNativeConstantSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
    const constantSourceNodeConstructor = createConstantSourceNodeConstructor(audioNodeConstructor, createAudioParam, createConstantSourceNodeRenderer, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener);
    const createNativeConvolverNode = createNativeConvolverNodeFactory(createNotSupportedError, overwriteAccessors);
    const createConvolverNodeRenderer = createConvolverNodeRendererFactory(createNativeConvolverNode, getNativeAudioNode, renderInputsOfAudioNode);
    const convolverNodeConstructor = createConvolverNodeConstructor(audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
    const createDelayNodeRenderer = createDelayNodeRendererFactory(connectAudioParam, createNativeDelayNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
    const delayNodeConstructor = createDelayNodeConstructor(audioNodeConstructor, createAudioParam, createDelayNodeRenderer, createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
    const createNativeDynamicsCompressorNode = createNativeDynamicsCompressorNodeFactory(createNotSupportedError);
    const createDynamicsCompressorNodeRenderer = createDynamicsCompressorNodeRendererFactory(connectAudioParam, createNativeDynamicsCompressorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
    const dynamicsCompressorNodeConstructor = createDynamicsCompressorNodeConstructor(audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, createNotSupportedError, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
    const createGainNodeRenderer = createGainNodeRendererFactory(connectAudioParam, createNativeGainNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
    const gainNodeConstructor = createGainNodeConstructor(audioNodeConstructor, createAudioParam, createGainNodeRenderer, createNativeGainNode, getNativeContext, isNativeOfflineAudioContext);
    const createNativeIIRFilterNodeFaker = createNativeIIRFilterNodeFakerFactory(createInvalidAccessError, createInvalidStateError, createNativeScriptProcessorNode, createNotSupportedError);
    const renderNativeOfflineAudioContext = createRenderNativeOfflineAudioContext(cacheTestResult, createNativeGainNode, createNativeScriptProcessorNode, createTestOfflineAudioContextCurrentTimeSupport(createNativeGainNode, nativeOfflineAudioContextConstructor));
    const createIIRFilterNodeRenderer = createIIRFilterNodeRendererFactory(createNativeAudioBufferSourceNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext);
    const createNativeIIRFilterNode = createNativeIIRFilterNodeFactory(createNativeIIRFilterNodeFaker);
    const iIRFilterNodeConstructor = createIIRFilterNodeConstructor(audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
    const createAudioListener = createAudioListenerFactory(createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeScriptProcessorNode, isNativeOfflineAudioContext);
    const unrenderedAudioWorkletNodeStore = new WeakMap();
    const minimalBaseAudioContextConstructor = createMinimalBaseAudioContextConstructor(audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, wrapEventListener);
    const createNativeOscillatorNode = createNativeOscillatorNodeFactory(addSilentConnection, cacheTestResult, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls);
    const createOscillatorNodeRenderer = createOscillatorNodeRendererFactory(connectAudioParam, createNativeOscillatorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
    const oscillatorNodeConstructor = createOscillatorNodeConstructor(audioNodeConstructor, createAudioParam, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, wrapEventListener);
    const createConnectedNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNodeFactory(createNativeAudioBufferSourceNode);
    const createNativeWaveShaperNodeFaker = createNativeWaveShaperNodeFakerFactory(createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeGainNode, isDCCurve, monitorConnections);
    const createNativeWaveShaperNode = createNativeWaveShaperNodeFactory(createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeWaveShaperNodeFaker, isDCCurve, monitorConnections, nativeAudioContextConstructor, overwriteAccessors);
    const createNativePannerNodeFaker = createNativePannerNodeFakerFactory(connectNativeAudioNodeToNativeAudioNode, createInvalidStateError, createNativeChannelMergerNode, createNativeGainNode, createNativeScriptProcessorNode, createNativeWaveShaperNode, createNotSupportedError, disconnectNativeAudioNodeFromNativeAudioNode, monitorConnections);
    const createNativePannerNode = createNativePannerNodeFactory(createNativePannerNodeFaker);
    const createPannerNodeRenderer = createPannerNodeRendererFactory(connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeGainNode, createNativePannerNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);
    const pannerNodeConstructor = createPannerNodeConstructor(audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
    const createNativePeriodicWave = createNativePeriodicWaveFactory(createIndexSizeError);
    const periodicWaveConstructor = createPeriodicWaveConstructor(createNativePeriodicWave, getNativeContext, new WeakSet(), sanitizePeriodicWaveOptions);
    const nativeStereoPannerNodeFakerFactory = createNativeStereoPannerNodeFakerFactory(createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeGainNode, createNativeWaveShaperNode, createNotSupportedError, monitorConnections);
    const createNativeStereoPannerNode = createNativeStereoPannerNodeFactory(nativeStereoPannerNodeFakerFactory, createNotSupportedError);
    const createStereoPannerNodeRenderer = createStereoPannerNodeRendererFactory(connectAudioParam, createNativeStereoPannerNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
    const stereoPannerNodeConstructor = createStereoPannerNodeConstructor(audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext);
    const createWaveShaperNodeRenderer = createWaveShaperNodeRendererFactory(createNativeWaveShaperNode, getNativeAudioNode, renderInputsOfAudioNode);
    const waveShaperNodeConstructor = createWaveShaperNodeConstructor(audioNodeConstructor, createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
    const isSecureContext = createIsSecureContext(window$1);
    const exposeCurrentFrameAndCurrentTime = createExposeCurrentFrameAndCurrentTime(window$1);
    const backupOfflineAudioContextStore = new WeakMap();
    const getOrCreateBackupOfflineAudioContext = createGetOrCreateBackupOfflineAudioContext(backupOfflineAudioContextStore, nativeOfflineAudioContextConstructor);
    const nativeAudioWorkletNodeConstructor = createNativeAudioWorkletNodeConstructor(window$1);
    // The addAudioWorkletModule() function is only available in a SecureContext.
    const addAudioWorkletModule = isSecureContext
        ? createAddAudioWorkletModule(cacheTestResult, createNotSupportedError, createEvaluateSource(window$1), exposeCurrentFrameAndCurrentTime, createFetchSource(createAbortError), getNativeContext, getOrCreateBackupOfflineAudioContext, isNativeOfflineAudioContext, new WeakMap(), new WeakMap(), createTestAudioWorkletProcessorPostMessageSupport(nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor), 
        // @todo window is guaranteed to be defined because isSecureContext checks that as well.
        window$1)
        : undefined;
    const isNativeContext = createIsNativeContext(isNativeAudioContext, isNativeOfflineAudioContext);
    const decodeAudioData = createDecodeAudioData(audioBufferStore, cacheTestResult, createDataCloneError, createEncodingError, new WeakSet(), getNativeContext, isNativeContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);
    const baseAudioContextConstructor = createBaseAudioContextConstructor(addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor);
    const mediaElementAudioSourceNodeConstructor = createMediaElementAudioSourceNodeConstructor(audioNodeConstructor, createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext);
    const mediaStreamAudioDestinationNodeConstructor = createMediaStreamAudioDestinationNodeConstructor(audioNodeConstructor, createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext);
    const mediaStreamAudioSourceNodeConstructor = createMediaStreamAudioSourceNodeConstructor(audioNodeConstructor, createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext);
    const createNativeMediaStreamTrackAudioSourceNode = createNativeMediaStreamTrackAudioSourceNodeFactory(createInvalidStateError, isNativeOfflineAudioContext);
    const mediaStreamTrackAudioSourceNodeConstructor = createMediaStreamTrackAudioSourceNodeConstructor(audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext);
    const audioContextConstructor = createAudioContextConstructor(baseAudioContextConstructor, createInvalidStateError, createNotSupportedError, createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor);
    const getUnrenderedAudioWorkletNodes = createGetUnrenderedAudioWorkletNodes(unrenderedAudioWorkletNodeStore);
    const addUnrenderedAudioWorkletNode = createAddUnrenderedAudioWorkletNode(getUnrenderedAudioWorkletNodes);
    const connectMultipleOutputs = createConnectMultipleOutputs(createIndexSizeError);
    const deleteUnrenderedAudioWorkletNode = createDeleteUnrenderedAudioWorkletNode(getUnrenderedAudioWorkletNodes);
    const disconnectMultipleOutputs = createDisconnectMultipleOutputs(createIndexSizeError);
    const activeAudioWorkletNodeInputsStore = new WeakMap();
    const getActiveAudioWorkletNodeInputs = createGetActiveAudioWorkletNodeInputs(activeAudioWorkletNodeInputsStore, getValueForKey);
    const createNativeAudioWorkletNodeFaker = createNativeAudioWorkletNodeFakerFactory(connectMultipleOutputs, createIndexSizeError, createInvalidStateError, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, createNativeScriptProcessorNode, createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getActiveAudioWorkletNodeInputs, monitorConnections);
    const createNativeAudioWorkletNode = createNativeAudioWorkletNodeFactory(createInvalidStateError, createNativeAudioWorkletNodeFaker, createNativeGainNode, createNotSupportedError, monitorConnections);
    const createAudioWorkletNodeRenderer = createAudioWorkletNodeRendererFactory(connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);
    const getBackupOfflineAudioContext = createGetBackupOfflineAudioContext(backupOfflineAudioContextStore);
    const setActiveAudioWorkletNodeInputs = createSetActiveAudioWorkletNodeInputs(activeAudioWorkletNodeInputsStore);
    // The AudioWorkletNode constructor is only available in a SecureContext.
    const audioWorkletNodeConstructor = isSecureContext
        ? createAudioWorkletNodeConstructor(addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, getAudioNodeConnections, getBackupOfflineAudioContext, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, sanitizeAudioWorkletNodeOptions, setActiveAudioWorkletNodeInputs, wrapEventListener)
        : undefined;
    const createNativeOfflineAudioContext = createCreateNativeOfflineAudioContext(createNotSupportedError, nativeOfflineAudioContextConstructor);
    const startRendering = createStartRendering(audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);
    const offlineAudioContextConstructor = createOfflineAudioContextConstructor(baseAudioContextConstructor, cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, startRendering);
    const isAnyAudioContext = createIsAnyAudioContext(CONTEXT_STORE, isNativeAudioContext);
    const isAnyAudioNode = createIsAnyAudioNode(AUDIO_NODE_STORE, isNativeAudioNode$1);
    const isAnyAudioParam = createIsAnyAudioParam(AUDIO_PARAM_STORE, isNativeAudioParam);
    const isAnyOfflineAudioContext = createIsAnyOfflineAudioContext(CONTEXT_STORE, isNativeOfflineAudioContext);
    const isSupported = () => createIsSupportedPromise(cacheTestResult, createTestAudioBufferCopyChannelMethodsSubarraySupport(nativeOfflineAudioContextConstructor), createTestAudioContextCloseMethodSupport(nativeAudioContextConstructor), createTestAudioContextDecodeAudioDataMethodTypeErrorSupport(nativeOfflineAudioContextConstructor), createTestAudioContextOptionsSupport(nativeAudioContextConstructor), createTestAudioNodeConnectMethodSupport(nativeOfflineAudioContextConstructor), createTestAudioWorkletProcessorNoOutputsSupport(nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor), createTestChannelMergerNodeChannelCountSupport(nativeOfflineAudioContextConstructor), createTestConstantSourceNodeAccurateSchedulingSupport(nativeOfflineAudioContextConstructor), createTestConvolverNodeBufferReassignabilitySupport(nativeOfflineAudioContextConstructor), createTestConvolverNodeChannelCountSupport(nativeOfflineAudioContextConstructor), testDomExceptionConstructorSupport, createTestIsSecureContextSupport(window$1), createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport(nativeAudioContextConstructor), createTestStereoPannerNodeDefaultValueSupport(nativeOfflineAudioContextConstructor), testTransferablesSupport);

    /**
     * Assert that the statement is true, otherwise invoke the error.
     * @param statement
     * @param error The message which is passed into an Error
     */
    function assert(statement, error) {
        if (!statement) {
            throw new Error(error);
        }
    }
    /**
     * Make sure that the given value is within the range
     */
    function assertRange(value, gte, lte = Infinity) {
        if (!(gte <= value && value <= lte)) {
            throw new RangeError(`Value must be within [${gte}, ${lte}], got: ${value}`);
        }
    }
    /**
     * Make sure that the given value is within the range
     */
    function assertContextRunning(context) {
        // add a warning if the context is not started
        if (!context.isOffline && context.state !== "running") {
            warn("The AudioContext is \"suspended\". Invoke Tone.start() from a user action to start the audio.");
        }
    }
    /**
     * The default logger is the console
     */
    let defaultLogger = console;
    /**
     * Set the logging interface
     */
    function setLogger(logger) {
        defaultLogger = logger;
    }
    /**
     * Log anything
     */
    function log(...args) {
        defaultLogger.log(...args);
    }
    /**
     * Warn anything
     */
    function warn(...args) {
        defaultLogger.warn(...args);
    }

    var Debug = /*#__PURE__*/Object.freeze({
        __proto__: null,
        assert: assert,
        assertRange: assertRange,
        assertContextRunning: assertContextRunning,
        setLogger: setLogger,
        log: log,
        warn: warn
    });

    /**
     * Test if the arg is undefined
     */
    function isUndef(arg) {
        return typeof arg === "undefined";
    }
    /**
     * Test if the arg is not undefined
     */
    function isDefined(arg) {
        return !isUndef(arg);
    }
    /**
     * Test if the arg is a function
     */
    function isFunction(arg) {
        return typeof arg === "function";
    }
    /**
     * Test if the argument is a number.
     */
    function isNumber(arg) {
        return (typeof arg === "number");
    }
    /**
     * Test if the given argument is an object literal (i.e. `{}`);
     */
    function isObject(arg) {
        return (Object.prototype.toString.call(arg) === "[object Object]" && arg.constructor === Object);
    }
    /**
     * Test if the argument is a boolean.
     */
    function isBoolean(arg) {
        return (typeof arg === "boolean");
    }
    /**
     * Test if the argument is an Array
     */
    function isArray(arg) {
        return (Array.isArray(arg));
    }
    /**
     * Test if the argument is a string.
     */
    function isString(arg) {
        return (typeof arg === "string");
    }
    /**
     * Test if the argument is in the form of a note in scientific pitch notation.
     * e.g. "C4"
     */
    function isNote(arg) {
        return isString(arg) && /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i.test(arg);
    }

    /**
     * Create a new AudioContext
     */
    function createAudioContext(options) {
        return new audioContextConstructor(options);
    }
    /**
     * Create a new OfflineAudioContext
     */
    function createOfflineAudioContext(channels, length, sampleRate) {
        return new offlineAudioContextConstructor(channels, length, sampleRate);
    }
    /**
     * A reference to the window object
     * @hidden
     */
    const theWindow = typeof self === "object" ? self : null;
    /**
     * If the browser has a window object which has an AudioContext
     * @hidden
     */
    const hasAudioContext = theWindow &&
        (theWindow.hasOwnProperty("AudioContext") || theWindow.hasOwnProperty("webkitAudioContext"));
    function createAudioWorkletNode(context, name, options) {
        assert(isDefined(audioWorkletNodeConstructor), "This node only works in a secure context (https or localhost)");
        // @ts-ignore
        return new audioWorkletNodeConstructor(context, name, options);
    }

    /*! *****************************************************************************
    Copyright (c) Microsoft Corporation.

    Permission to use, copy, modify, and/or distribute this software for any
    purpose with or without fee is hereby granted.

    THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
    REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
    AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
    INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
    LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
    OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
    PERFORMANCE OF THIS SOFTWARE.
    ***************************************************************************** */

    function __decorate(decorators, target, key, desc) {
        var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
        if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
        else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
        return c > 3 && r && Object.defineProperty(target, key, r), r;
    }

    function __awaiter(thisArg, _arguments, P, generator) {
        function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
        return new (P || (P = Promise))(function (resolve, reject) {
            function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
            function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
            function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
            step((generator = generator.apply(thisArg, _arguments || [])).next());
        });
    }

    /**
     * A class which provides a reliable callback using either
     * a Web Worker, or if that isn't supported, falls back to setTimeout.
     */
    class Ticker {
        constructor(callback, type, updateInterval) {
            this._callback = callback;
            this._type = type;
            this._updateInterval = updateInterval;
            // create the clock source for the first time
            this._createClock();
        }
        /**
         * Generate a web worker
         */
        _createWorker() {
            const blob = new Blob([
                /* javascript */ `
			// the initial timeout time
			let timeoutTime =  ${(this._updateInterval * 1000).toFixed(1)};
			// onmessage callback
			self.onmessage = function(msg){
				timeoutTime = parseInt(msg.data);
			};
			// the tick function which posts a message
			// and schedules a new tick
			function tick(){
				setTimeout(tick, timeoutTime);
				self.postMessage('tick');
			}
			// call tick initially
			tick();
			`
            ], { type: "text/javascript" });
            const blobUrl = URL.createObjectURL(blob);
            const worker = new Worker(blobUrl);
            worker.onmessage = this._callback.bind(this);
            this._worker = worker;
        }
        /**
         * Create a timeout loop
         */
        _createTimeout() {
            this._timeout = setTimeout(() => {
                this._createTimeout();
                this._callback();
            }, this._updateInterval * 1000);
        }
        /**
         * Create the clock source.
         */
        _createClock() {
            if (this._type === "worker") {
                try {
                    this._createWorker();
                }
                catch (e) {
                    // workers not supported, fallback to timeout
                    this._type = "timeout";
                    this._createClock();
                }
            }
            else if (this._type === "timeout") {
                this._createTimeout();
            }
        }
        /**
         * Clean up the current clock source
         */
        _disposeClock() {
            if (this._timeout) {
                clearTimeout(this._timeout);
                this._timeout = 0;
            }
            if (this._worker) {
                this._worker.terminate();
                this._worker.onmessage = null;
            }
        }
        /**
         * The rate in seconds the ticker will update
         */
        get updateInterval() {
            return this._updateInterval;
        }
        set updateInterval(interval) {
            this._updateInterval = Math.max(interval, 128 / 44100);
            if (this._type === "worker") {
                this._worker.postMessage(Math.max(interval * 1000, 1));
            }
        }
        /**
         * The type of the ticker, either a worker or a timeout
         */
        get type() {
            return this._type;
        }
        set type(type) {
            this._disposeClock();
            this._type = type;
            this._createClock();
        }
        /**
         * Clean up
         */
        dispose() {
            this._disposeClock();
        }
    }

    /**
     * Test if the given value is an instanceof AudioParam
     */
    function isAudioParam(arg) {
        return isAnyAudioParam(arg);
    }
    /**
     * Test if the given value is an instanceof AudioNode
     */
    function isAudioNode$1(arg) {
        return isAnyAudioNode(arg);
    }
    /**
     * Test if the arg is instanceof an OfflineAudioContext
     */
    function isOfflineAudioContext(arg) {
        return isAnyOfflineAudioContext(arg);
    }
    /**
     * Test if the arg is an instanceof AudioContext
     */
    function isAudioContext(arg) {
        return isAnyAudioContext(arg);
    }
    /**
     * Test if the arg is instanceof an AudioBuffer
     */
    function isAudioBuffer(arg) {
        return arg instanceof AudioBuffer;
    }

    /**
     * Some objects should not be merged
     */
    function noCopy(key, arg) {
        return key === "value" || isAudioParam(arg) || isAudioNode$1(arg) || isAudioBuffer(arg);
    }
    function deepMerge(target, ...sources) {
        if (!sources.length) {
            return target;
        }
        const source = sources.shift();
        if (isObject(target) && isObject(source)) {
            for (const key in source) {
                if (noCopy(key, source[key])) {
                    target[key] = source[key];
                }
                else if (isObject(source[key])) {
                    if (!target[key]) {
                        Object.assign(target, { [key]: {} });
                    }
                    deepMerge(target[key], source[key]);
                }
                else {
                    Object.assign(target, { [key]: source[key] });
                }
            }
        }
        // @ts-ignore
        return deepMerge(target, ...sources);
    }
    /**
     * Returns true if the two arrays have the same value for each of the elements
     */
    function deepEquals(arrayA, arrayB) {
        return arrayA.length === arrayB.length && arrayA.every((element, index) => arrayB[index] === element);
    }
    /**
     * Convert an args array into an object.
     */
    function optionsFromArguments(defaults, argsArray, keys = [], objKey) {
        const opts = {};
        const args = Array.from(argsArray);
        // if the first argument is an object and has an object key
        if (isObject(args[0]) && objKey && !Reflect.has(args[0], objKey)) {
            // if it's not part of the defaults
            const partOfDefaults = Object.keys(args[0]).some(key => Reflect.has(defaults, key));
            if (!partOfDefaults) {
                // merge that key
                deepMerge(opts, { [objKey]: args[0] });
                // remove the obj key from the keys
                keys.splice(keys.indexOf(objKey), 1);
                // shift the first argument off
                args.shift();
            }
        }
        if (args.length === 1 && isObject(args[0])) {
            deepMerge(opts, args[0]);
        }
        else {
            for (let i = 0; i < keys.length; i++) {
                if (isDefined(args[i])) {
                    opts[keys[i]] = args[i];
                }
            }
        }
        return deepMerge(defaults, opts);
    }
    /**
     * Return this instances default values by calling Constructor.getDefaults()
     */
    function getDefaultsFromInstance(instance) {
        return instance.constructor.getDefaults();
    }
    /**
     * Returns the fallback if the given object is undefined.
     * Take an array of arguments and return a formatted options object.
     */
    function defaultArg(given, fallback) {
        if (isUndef(given)) {
            return fallback;
        }
        else {
            return given;
        }
    }
    /**
     * Remove all of the properties belonging to omit from obj.
     */
    function omitFromObject(obj, omit) {
        omit.forEach(prop => {
            if (Reflect.has(obj, prop)) {
                delete obj[prop];
            }
        });
        return obj;
    }

    /**
     * Tone.js
     * @author Yotam Mann
     * @license http://opensource.org/licenses/MIT MIT License
     * @copyright 2014-2019 Yotam Mann
     */
    /**
     * @class  Tone is the base class of all other classes.
     * @category Core
     * @constructor
     */
    class Tone {
        constructor() {
            //-------------------------------------
            // 	DEBUGGING
            //-------------------------------------
            /**
             * Set this debug flag to log all events that happen in this class.
             */
            this.debug = false;
            //-------------------------------------
            // 	DISPOSING
            //-------------------------------------
            /**
             * Indicates if the instance was disposed
             */
            this._wasDisposed = false;
        }
        /**
         * Returns all of the default options belonging to the class.
         */
        static getDefaults() {
            return {};
        }
        /**
         * Prints the outputs to the console log for debugging purposes.
         * Prints the contents only if either the object has a property
         * called `debug` set to true, or a variable called TONE_DEBUG_CLASS
         * is set to the name of the class.
         * @example
         * const osc = new Tone.Oscillator();
         * // prints all logs originating from this oscillator
         * osc.debug = true;
         * // calls to start/stop will print in the console
         * osc.start();
         */
        log(...args) {
            // if the object is either set to debug = true
            // or if there is a string on the Tone.global.with the class name
            if (this.debug || (theWindow && this.toString() === theWindow.TONE_DEBUG_CLASS)) {
                log(this, ...args);
            }
        }
        /**
         * disconnect and dispose.
         */
        dispose() {
            this._wasDisposed = true;
            return this;
        }
        /**
         * Indicates if the instance was disposed. 'Disposing' an
         * instance means that all of the Web Audio nodes that were
         * created for the instance are disconnected and freed for garbage collection.
         */
        get disposed() {
            return this._wasDisposed;
        }
        /**
         * Convert the class to a string
         * @example
         * const osc = new Tone.Oscillator();
         * console.log(osc.toString());
         */
        toString() {
            return this.name;
        }
    }
    /**
     * The version number semver
     */
    Tone.version = version;

    /**
     * The threshold for correctness for operators. Less than one sample even
     * at very high sampling rates (e.g. `1e-6 < 1 / 192000`).
     */
    const EPSILON = 1e-6;
    /**
     * Test if A is greater than B
     */
    function GT(a, b) {
        return a > b + EPSILON;
    }
    /**
     * Test if A is greater than or equal to B
     */
    function GTE(a, b) {
        return GT(a, b) || EQ(a, b);
    }
    /**
     * Test if A is less than B
     */
    function LT(a, b) {
        return a + EPSILON < b;
    }
    /**
     * Test if A is less than B
     */
    function EQ(a, b) {
        return Math.abs(a - b) < EPSILON;
    }
    /**
     * Clamp the value within the given range
     */
    function clamp(value, min, max) {
        return Math.max(Math.min(value, max), min);
    }

    /**
     * A Timeline class for scheduling and maintaining state
     * along a timeline. All events must have a "time" property.
     * Internally, events are stored in time order for fast
     * retrieval.
     */
    class Timeline extends Tone {
        constructor() {
            super();
            this.name = "Timeline";
            /**
             * The array of scheduled timeline events
             */
            this._timeline = [];
            const options = optionsFromArguments(Timeline.getDefaults(), arguments, ["memory"]);
            this.memory = options.memory;
            this.increasing = options.increasing;
        }
        static getDefaults() {
            return {
                memory: Infinity,
                increasing: false,
            };
        }
        /**
         * The number of items in the timeline.
         */
        get length() {
            return this._timeline.length;
        }
        /**
         * Insert an event object onto the timeline. Events must have a "time" attribute.
         * @param event  The event object to insert into the timeline.
         */
        add(event) {
            // the event needs to have a time attribute
            assert(Reflect.has(event, "time"), "Timeline: events must have a time attribute");
            event.time = event.time.valueOf();
            if (this.increasing && this.length) {
                const lastValue = this._timeline[this.length - 1];
                assert(GTE(event.time, lastValue.time), "The time must be greater than or equal to the last scheduled time");
                this._timeline.push(event);
            }
            else {
                const index = this._search(event.time);
                this._timeline.splice(index + 1, 0, event);
            }
            // if the length is more than the memory, remove the previous ones
            if (this.length > this.memory) {
                const diff = this.length - this.memory;
                this._timeline.splice(0, diff);
            }
            return this;
        }
        /**
         * Remove an event from the timeline.
         * @param  {Object}  event  The event object to remove from the list.
         * @returns {Timeline} this
         */
        remove(event) {
            const index = this._timeline.indexOf(event);
            if (index !== -1) {
                this._timeline.splice(index, 1);
            }
            return this;
        }
        /**
         * Get the nearest event whose time is less than or equal to the given time.
         * @param  time  The time to query.
         */
        get(time, param = "time") {
            const index = this._search(time, param);
            if (index !== -1) {
                return this._timeline[index];
            }
            else {
                return null;
            }
        }
        /**
         * Return the first event in the timeline without removing it
         * @returns {Object} The first event object
         */
        peek() {
            return this._timeline[0];
        }
        /**
         * Return the first event in the timeline and remove it
         */
        shift() {
            return this._timeline.shift();
        }
        /**
         * Get the event which is scheduled after the given time.
         * @param  time  The time to query.
         */
        getAfter(time, param = "time") {
            const index = this._search(time, param);
            if (index + 1 < this._timeline.length) {
                return this._timeline[index + 1];
            }
            else {
                return null;
            }
        }
        /**
         * Get the event before the event at the given time.
         * @param  time  The time to query.
         */
        getBefore(time) {
            const len = this._timeline.length;
            // if it's after the last item, return the last item
            if (len > 0 && this._timeline[len - 1].time < time) {
                return this._timeline[len - 1];
            }
            const index = this._search(time);
            if (index - 1 >= 0) {
                return this._timeline[index - 1];
            }
            else {
                return null;
            }
        }
        /**
         * Cancel events at and after the given time
         * @param  after  The time to query.
         */
        cancel(after) {
            if (this._timeline.length > 1) {
                let index = this._search(after);
                if (index >= 0) {
                    if (EQ(this._timeline[index].time, after)) {
                        // get the first item with that time
                        for (let i = index; i >= 0; i--) {
                            if (EQ(this._timeline[i].time, after)) {
                                index = i;
                            }
                            else {
                                break;
                            }
                        }
                        this._timeline = this._timeline.slice(0, index);
                    }
                    else {
                        this._timeline = this._timeline.slice(0, index + 1);
                    }
                }
                else {
                    this._timeline = [];
                }
            }
            else if (this._timeline.length === 1) {
                // the first item's time
                if (GTE(this._timeline[0].time, after)) {
                    this._timeline = [];
                }
            }
            return this;
        }
        /**
         * Cancel events before or equal to the given time.
         * @param  time  The time to cancel before.
         */
        cancelBefore(time) {
            const index = this._search(time);
            if (index >= 0) {
                this._timeline = this._timeline.slice(index + 1);
            }
            return this;
        }
        /**
         * Returns the previous event if there is one. null otherwise
         * @param  event The event to find the previous one of
         * @return The event right before the given event
         */
        previousEvent(event) {
            const index = this._timeline.indexOf(event);
            if (index > 0) {
                return this._timeline[index - 1];
            }
            else {
                return null;
            }
        }
        /**
         * Does a binary search on the timeline array and returns the
         * nearest event index whose time is after or equal to the given time.
         * If a time is searched before the first index in the timeline, -1 is returned.
         * If the time is after the end, the index of the last item is returned.
         */
        _search(time, param = "time") {
            if (this._timeline.length === 0) {
                return -1;
            }
            let beginning = 0;
            const len = this._timeline.length;
            let end = len;
            if (len > 0 && this._timeline[len - 1][param] <= time) {
                return len - 1;
            }
            while (beginning < end) {
                // calculate the midpoint for roughly equal partition
                let midPoint = Math.floor(beginning + (end - beginning) / 2);
                const event = this._timeline[midPoint];
                const nextEvent = this._timeline[midPoint + 1];
                if (EQ(event[param], time)) {
                    // choose the last one that has the same time
                    for (let i = midPoint; i < this._timeline.length; i++) {
                        const testEvent = this._timeline[i];
                        if (EQ(testEvent[param], time)) {
                            midPoint = i;
                        }
                        else {
                            break;
                        }
                    }
                    return midPoint;
                }
                else if (LT(event[param], time) && GT(nextEvent[param], time)) {
                    return midPoint;
                }
                else if (GT(event[param], time)) {
                    // search lower
                    end = midPoint;
                }
                else {
                    // search upper
                    beginning = midPoint + 1;
                }
            }
            return -1;
        }
        /**
         * Internal iterator. Applies extra safety checks for
         * removing items from the array.
         */
        _iterate(callback, lowerBound = 0, upperBound = this._timeline.length - 1) {
            this._timeline.slice(lowerBound, upperBound + 1).forEach(callback);
        }
        /**
         * Iterate over everything in the array
         * @param  callback The callback to invoke with every item
         */
        forEach(callback) {
            this._iterate(callback);
            return this;
        }
        /**
         * Iterate over everything in the array at or before the given time.
         * @param  time The time to check if items are before
         * @param  callback The callback to invoke with every item
         */
        forEachBefore(time, callback) {
            // iterate over the items in reverse so that removing an item doesn't break things
            const upperBound = this._search(time);
            if (upperBound !== -1) {
                this._iterate(callback, 0, upperBound);
            }
            return this;
        }
        /**
         * Iterate over everything in the array after the given time.
         * @param  time The time to check if items are before
         * @param  callback The callback to invoke with every item
         */
        forEachAfter(time, callback) {
            // iterate over the items in reverse so that removing an item doesn't break things
            const lowerBound = this._search(time);
            this._iterate(callback, lowerBound + 1);
            return this;
        }
        /**
         * Iterate over everything in the array between the startTime and endTime.
         * The timerange is inclusive of the startTime, but exclusive of the endTime.
         * range = [startTime, endTime).
         * @param  startTime The time to check if items are before
         * @param  endTime The end of the test interval.
         * @param  callback The callback to invoke with every item
         */
        forEachBetween(startTime, endTime, callback) {
            let lowerBound = this._search(startTime);
            let upperBound = this._search(endTime);
            if (lowerBound !== -1 && upperBound !== -1) {
                if (this._timeline[lowerBound].time !== startTime) {
                    lowerBound += 1;
                }
                // exclusive of the end time
                if (this._timeline[upperBound].time === endTime) {
                    upperBound -= 1;
                }
                this._iterate(callback, lowerBound, upperBound);
            }
            else if (lowerBound === -1) {
                this._iterate(callback, 0, upperBound);
            }
            return this;
        }
        /**
         * Iterate over everything in the array at or after the given time. Similar to
         * forEachAfter, but includes the item(s) at the given time.
         * @param  time The time to check if items are before
         * @param  callback The callback to invoke with every item
         */
        forEachFrom(time, callback) {
            // iterate over the items in reverse so that removing an item doesn't break things
            let lowerBound = this._search(time);
            // work backwards until the event time is less than time
            while (lowerBound >= 0 && this._timeline[lowerBound].time >= time) {
                lowerBound--;
            }
            this._iterate(callback, lowerBound + 1);
            return this;
        }
        /**
         * Iterate over everything in the array at the given time
         * @param  time The time to check if items are before
         * @param  callback The callback to invoke with every item
         */
        forEachAtTime(time, callback) {
            // iterate over the items in reverse so that removing an item doesn't break things
            const upperBound = this._search(time);
            if (upperBound !== -1 && EQ(this._timeline[upperBound].time, time)) {
                let lowerBound = upperBound;
                for (let i = upperBound; i >= 0; i--) {
                    if (EQ(this._timeline[i].time, time)) {
                        lowerBound = i;
                    }
                    else {
                        break;
                    }
                }
                this._iterate(event => {
                    callback(event);
                }, lowerBound, upperBound);
            }
            return this;
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this._timeline = [];
            return this;
        }
    }

    //-------------------------------------
    // INITIALIZING NEW CONTEXT
    //-------------------------------------
    /**
     * Array of callbacks to invoke when a new context is created
     */
    const notifyNewContext = [];
    /**
     * Used internally to setup a new Context
     */
    function onContextInit(cb) {
        notifyNewContext.push(cb);
    }
    /**
     * Invoke any classes which need to also be initialized when a new context is created.
     */
    function initializeContext(ctx) {
        // add any additional modules
        notifyNewContext.forEach(cb => cb(ctx));
    }
    /**
     * Array of callbacks to invoke when a new context is created
     */
    const notifyCloseContext = [];
    /**
     * Used internally to tear down a Context
     */
    function onContextClose(cb) {
        notifyCloseContext.push(cb);
    }
    function closeContext(ctx) {
        // add any additional modules
        notifyCloseContext.forEach(cb => cb(ctx));
    }

    /**
     * Emitter gives classes which extend it
     * the ability to listen for and emit events.
     * Inspiration and reference from Jerome Etienne's [MicroEvent](https://github.com/jeromeetienne/microevent.js).
     * MIT (c) 2011 Jerome Etienne.
     * @category Core
     */
    class Emitter extends Tone {
        constructor() {
            super(...arguments);
            this.name = "Emitter";
        }
        /**
         * Bind a callback to a specific event.
         * @param  event     The name of the event to listen for.
         * @param  callback  The callback to invoke when the event is emitted
         */
        on(event, callback) {
            // split the event
            const events = event.split(/\W+/);
            events.forEach(eventName => {
                if (isUndef(this._events)) {
                    this._events = {};
                }
                if (!this._events.hasOwnProperty(eventName)) {
                    this._events[eventName] = [];
                }
                this._events[eventName].push(callback);
            });
            return this;
        }
        /**
         * Bind a callback which is only invoked once
         * @param  event     The name of the event to listen for.
         * @param  callback  The callback to invoke when the event is emitted
         */
        once(event, callback) {
            const boundCallback = (...args) => {
                // invoke the callback
                callback(...args);
                // remove the event
                this.off(event, boundCallback);
            };
            this.on(event, boundCallback);
            return this;
        }
        /**
         * Remove the event listener.
         * @param  event     The event to stop listening to.
         * @param  callback  The callback which was bound to the event with Emitter.on.
         *                   If no callback is given, all callbacks events are removed.
         */
        off(event, callback) {
            const events = event.split(/\W+/);
            events.forEach(eventName => {
                if (isUndef(this._events)) {
                    this._events = {};
                }
                if (this._events.hasOwnProperty(event)) {
                    if (isUndef(callback)) {
                        this._events[event] = [];
                    }
                    else {
                        const eventList = this._events[event];
                        for (let i = eventList.length - 1; i >= 0; i--) {
                            if (eventList[i] === callback) {
                                eventList.splice(i, 1);
                            }
                        }
                    }
                }
            });
            return this;
        }
        /**
         * Invoke all of the callbacks bound to the event
         * with any arguments passed in.
         * @param  event  The name of the event.
         * @param args The arguments to pass to the functions listening.
         */
        emit(event, ...args) {
            if (this._events) {
                if (this._events.hasOwnProperty(event)) {
                    const eventList = this._events[event].slice(0);
                    for (let i = 0, len = eventList.length; i < len; i++) {
                        eventList[i].apply(this, args);
                    }
                }
            }
            return this;
        }
        /**
         * Add Emitter functions (on/off/emit) to the object
         */
        static mixin(constr) {
            // instance._events = {};
            ["on", "once", "off", "emit"].forEach(name => {
                const property = Object.getOwnPropertyDescriptor(Emitter.prototype, name);
                Object.defineProperty(constr.prototype, name, property);
            });
        }
        /**
         * Clean up
         */
        dispose() {
            super.dispose();
            this._events = undefined;
            return this;
        }
    }

    class BaseContext extends Emitter {
        constructor() {
            super(...arguments);
            this.isOffline = false;
        }
    }

    /**
     * Wrapper around the native AudioContext.
     * @category Core
     */
    class Context extends BaseContext {
        constructor() {
            super();
            this.name = "Context";
            /**
             * An object containing all of the constants AudioBufferSourceNodes
             */
            this._constants = new Map();
            /**
             * All of the setTimeout events.
             */
            this._timeouts = new Timeline();
            /**
             * The timeout id counter
             */
            this._timeoutIds = 0;
            /**
             * Private indicator if the context has been initialized
             */
            this._initialized = false;
            /**
             * Indicates if the context is an OfflineAudioContext or an AudioContext
             */
            this.isOffline = false;
            //--------------------------------------------
            // AUDIO WORKLET
            //--------------------------------------------
            /**
             * Maps a module name to promise of the addModule method
             */
            this._workletModules = new Map();
            const options = optionsFromArguments(Context.getDefaults(), arguments, ["context"]);
            if (options.context) {
                this._context = options.context;
            }
            else {
                this._context = createAudioContext({
                    latencyHint: options.latencyHint,
                });
            }
            this._ticker = new Ticker(this.emit.bind(this, "tick"), options.clockSource, options.updateInterval);
            this.on("tick", this._timeoutLoop.bind(this));
            // fwd events from the context
            this._context.onstatechange = () => {
                this.emit("statechange", this.state);
            };
            this._setLatencyHint(options.latencyHint);
            this.lookAhead = options.lookAhead;
        }
        static getDefaults() {
            return {
                clockSource: "worker",
                latencyHint: "interactive",
                lookAhead: 0.1,
                updateInterval: 0.05,
            };
        }
        /**
         * Finish setting up the context. **You usually do not need to do this manually.**
         */
        initialize() {
            if (!this._initialized) {
                // add any additional modules
                initializeContext(this);
                this._initialized = true;
            }
            return this;
        }
        //---------------------------
        // BASE AUDIO CONTEXT METHODS
        //---------------------------
        createAnalyser() {
            return this._context.createAnalyser();
        }
        createOscillator() {
            return this._context.createOscillator();
        }
        createBufferSource() {
            return this._context.createBufferSource();
        }
        createBiquadFilter() {
            return this._context.createBiquadFilter();
        }
        createBuffer(numberOfChannels, length, sampleRate) {
            return this._context.createBuffer(numberOfChannels, length, sampleRate);
        }
        createChannelMerger(numberOfInputs) {
            return this._context.createChannelMerger(numberOfInputs);
        }
        createChannelSplitter(numberOfOutputs) {
            return this._context.createChannelSplitter(numberOfOutputs);
        }
        createConstantSource() {
            return this._context.createConstantSource();
        }
        createConvolver() {
            return this._context.createConvolver();
        }
        createDelay(maxDelayTime) {
            return this._context.createDelay(maxDelayTime);
        }
        createDynamicsCompressor() {
            return this._context.createDynamicsCompressor();
        }
        createGain() {
            return this._context.createGain();
        }
        createIIRFilter(feedForward, feedback) {
            // @ts-ignore
            return this._context.createIIRFilter(feedForward, feedback);
        }
        createPanner() {
            return this._context.createPanner();
        }
        createPeriodicWave(real, imag, constraints) {
            return this._context.createPeriodicWave(real, imag, constraints);
        }
        createStereoPanner() {
            return this._context.createStereoPanner();
        }
        createWaveShaper() {
            return this._context.createWaveShaper();
        }
        createMediaStreamSource(stream) {
            assert(isAudioContext(this._context), "Not available if OfflineAudioContext");
            const context = this._context;
            return context.createMediaStreamSource(stream);
        }
        createMediaStreamDestination() {
            assert(isAudioContext(this._context), "Not available if OfflineAudioContext");
            const context = this._context;
            return context.createMediaStreamDestination();
        }
        decodeAudioData(audioData) {
            return this._context.decodeAudioData(audioData);
        }
        /**
         * The current time in seconds of the AudioContext.
         */
        get currentTime() {
            return this._context.currentTime;
        }
        /**
         * The current time in seconds of the AudioContext.
         */
        get state() {
            return this._context.state;
        }
        /**
         * The current time in seconds of the AudioContext.
         */
        get sampleRate() {
            return this._context.sampleRate;
        }
        /**
         * The listener
         */
        get listener() {
            this.initialize();
            return this._listener;
        }
        set listener(l) {
            assert(!this._initialized, "The listener cannot be set after initialization.");
            this._listener = l;
        }
        /**
         * There is only one Transport per Context. It is created on initialization.
         */
        get transport() {
            this.initialize();
            return this._transport;
        }
        set transport(t) {
            assert(!this._initialized, "The transport cannot be set after initialization.");
            this._transport = t;
        }
        /**
         * This is the Draw object for the context which is useful for synchronizing the draw frame with the Tone.js clock.
         */
        get draw() {
            this.initialize();
            return this._draw;
        }
        set draw(d) {
            assert(!this._initialized, "Draw cannot be set after initialization.");
            this._draw = d;
        }
        /**
         * A reference to the Context's destination node.
         */
        get destination() {
            this.initialize();
            return this._destination;
        }
        set destination(d) {
            assert(!this._initialized, "The destination cannot be set after initialization.");
            this._destination = d;
        }
        /**
         * Create an audio worklet node from a name and options. The module
         * must first be loaded using [[addAudioWorkletModule]].
         */
        createAudioWorkletNode(name, options) {
            return createAudioWorkletNode(this.rawContext, name, options);
        }
        /**
         * Add an AudioWorkletProcessor module
         * @param url The url of the module
         * @param name The name of the module
         */
        addAudioWorkletModule(url, name) {
            return __awaiter(this, void 0, void 0, function* () {
                assert(isDefined(this.rawContext.audioWorklet), "AudioWorkletNode is only available in a secure context (https or localhost)");
                if (!this._workletModules.has(name)) {
                    this._workletModules.set(name, this.rawContext.audioWorklet.addModule(url));
                }
                yield this._workletModules.get(name);
            });
        }
        /**
         * Returns a promise which resolves when all of the worklets have been loaded on this context
         */
        workletsAreReady() {
            return __awaiter(this, void 0, void 0, function* () {
                const promises = [];
                this._workletModules.forEach(promise => promises.push(promise));
                yield Promise.all(promises);
            });
        }
        //---------------------------
        // TICKER
        //---------------------------
        /**
         * How often the interval callback is invoked.
         * This number corresponds to how responsive the scheduling
         * can be. context.updateInterval + context.lookAhead gives you the
         * total latency between scheduling an event and hearing it.
         */
        get updateInterval() {
            return this._ticker.updateInterval;
        }
        set updateInterval(interval) {
            this._ticker.updateInterval = interval;
        }
        /**
         * What the source of the clock is, either "worker" (default),
         * "timeout", or "offline" (none).
         */
        get clockSource() {
            return this._ticker.type;
        }
        set clockSource(type) {
            this._ticker.type = type;
        }
        /**
         * The type of playback, which affects tradeoffs between audio
         * output latency and responsiveness.
         * In addition to setting the value in seconds, the latencyHint also
         * accepts the strings "interactive" (prioritizes low latency),
         * "playback" (prioritizes sustained playback), "balanced" (balances
         * latency and performance).
         * @example
         * // prioritize sustained playback
         * const context = new Tone.Context({ latencyHint: "playback" });
         * // set this context as the global Context
         * Tone.setContext(context);
         * // the global context is gettable with Tone.getContext()
         * console.log(Tone.getContext().latencyHint);
         */
        get latencyHint() {
            return this._latencyHint;
        }
        /**
         * Update the lookAhead and updateInterval based on the latencyHint
         */
        _setLatencyHint(hint) {
            let lookAheadValue = 0;
            this._latencyHint = hint;
            if (isString(hint)) {
                switch (hint) {
                    case "interactive":
                        lookAheadValue = 0.1;
                        break;
                    case "playback":
                        lookAheadValue = 0.5;
                        break;
                    case "balanced":
                        lookAheadValue = 0.25;
                        break;
                }
            }
            this.lookAhead = lookAheadValue;
            this.updateInterval = lookAheadValue / 2;
        }
        /**
         * The unwrapped AudioContext or OfflineAudioContext
         */
        get rawContext() {
            return this._context;
        }
        /**
         * The current audio context time plus a short [[lookAhead]].
         */
        now() {
            return this._context.currentTime + this.lookAhead;
        }
        /**
         * The current audio context time without the [[lookAhead]].
         * In most cases it is better to use [[now]] instead of [[immediate]] since
         * with [[now]] the [[lookAhead]] is applied equally to _all_ components including internal components,
         * to making sure that everything is scheduled in sync. Mixing [[now]] and [[immediate]]
         * can cause some timing issues. If no lookAhead is desired, you can set the [[lookAhead]] to `0`.
         */
        immediate() {
            return this._context.currentTime;
        }
        /**
         * Starts the audio context from a suspended state. This is required
         * to initially start the AudioContext. See [[Tone.start]]
         */
        resume() {
            if (this._context.state === "suspended" && isAudioContext(this._context)) {
                return this._context.resume();
            }
            else {
                return Promise.resolve();
            }
        }
        /**
         * Close the context. Once closed, the context can no longer be used and
         * any AudioNodes created from the context will be silent.
         */
        close() {
            return __awaiter(this, void 0, void 0, function* () {
                if (isAudioContext(this._context)) {
                    yield this._context.close();
                }
                if (this._initialized) {
                    closeContext(this);
                }
            });
        }
        /**
         * **Internal** Generate a looped buffer at some constant value.
         */
        getConstant(val) {
            if (this._constants.has(val)) {
                return this._constants.get(val);
            }
            else {
                const buffer = this._context.createBuffer(1, 128, this._context.sampleRate);
                const arr = buffer.getChannelData(0);
                for (let i = 0; i < arr.length; i++) {
                    arr[i] = val;
                }
                const constant = this._context.createBufferSource();
                constant.channelCount = 1;
                constant.channelCountMode = "explicit";
                constant.buffer = buffer;
                constant.loop = true;
                constant.start(0);
                this._constants.set(val, constant);
                return constant;
            }
        }
        /**
         * Clean up. Also closes the audio context.
         */
        dispose() {
            super.dispose();
            this._ticker.dispose();
            this._timeouts.dispose();
            Object.keys(this._constants).map(val => this._constants[val].disconnect());
            return this;
        }
        //---------------------------
        // TIMEOUTS
        //---------------------------
        /**
         * The private loop which keeps track of the context scheduled timeouts
         * Is invoked from the clock source
         */
        _timeoutLoop() {
            const now = this.now();
            let firstEvent = this._timeouts.peek();
            while (this._timeouts.length && firstEvent && firstEvent.time <= now) {
                // invoke the callback
                firstEvent.callback();
                // shift the first event off
                this._timeouts.shift();
                // get the next one
                firstEvent = this._timeouts.peek();
            }
        }
        /**
         * A setTimeout which is guaranteed by the clock source.
         * Also runs in the offline context.
         * @param  fn       The callback to invoke
         * @param  timeout  The timeout in seconds
         * @returns ID to use when invoking Context.clearTimeout
         */
        setTimeout(fn, timeout) {
            this._timeoutIds++;
            const now = this.now();
            this._timeouts.add({
                callback: fn,
                id: this._timeoutIds,
                time: now + timeout,
            });
            return this._timeoutIds;
        }
        /**
         * Clears a previously scheduled timeout with Tone.context.setTimeout
         * @param  id  The ID returned from setTimeout
         */
        clearTimeout(id) {
            this._timeouts.forEach(event => {
                if (event.id === id) {
                    this._timeouts.remove(event);
                }
            });
            return this;
        }
        /**
         * Clear the function scheduled by [[setInterval]]
         */
        clearInterval(id) {
            return this.clearTimeout(id);
        }
        /**
         * Adds a repeating event to the context's callback clock
         */
        setInterval(fn, interval) {
            const id = ++this._timeoutIds;
            const intervalFn = () => {
                const now = this.now();
                this._timeouts.add({
                    callback: () => {
                        // invoke the callback
                        fn();
                        // invoke the event to repeat it
                        intervalFn();
                    },
                    id,
                    time: now + interval,
                });
            };
            // kick it off
            intervalFn();
            return id;
        }
    }

    class DummyContext extends BaseContext {
        constructor() {
            super(...arguments);
            this.lookAhead = 0;
            this.latencyHint = 0;
            this.isOffline = false;
        }
        //---------------------------
        // BASE AUDIO CONTEXT METHODS
        //---------------------------
        createAnalyser() {
            return {};
        }
        createOscillator() {
            return {};
        }
        createBufferSource() {
            return {};
        }
        createBiquadFilter() {
            return {};
        }
        createBuffer(_numberOfChannels, _length, _sampleRate) {
            return {};
        }
        createChannelMerger(_numberOfInputs) {
            return {};
        }
        createChannelSplitter(_numberOfOutputs) {
            return {};
        }
        createConstantSource() {
            return {};
        }
        createConvolver() {
            return {};
        }
        createDelay(_maxDelayTime) {
            return {};
        }
        createDynamicsCompressor() {
            return {};
        }
        createGain() {
            return {};
        }
        createIIRFilter(_feedForward, _feedback) {
            return {};
        }
        createPanner() {
            return {};
        }
        createPeriodicWave(_real, _imag, _constraints) {
            return {};
        }
        createStereoPanner() {
            return {};
        }
        createWaveShaper() {
            return {};
        }
        createMediaStreamSource(_stream) {
            return {};
        }
        createMediaStreamDestination() {
            return {};
        }
        decodeAudioData(_audioData) {
            return Promise.resolve({});
        }
        //---------------------------
        // TONE AUDIO CONTEXT METHODS
        //---------------------------
        createAudioWorkletNode(_name, _options) {
            return {};
        }
        get rawContext() {
            return {};
        }
        addAudioWorkletModule(_url, _name) {
            return __awaiter(this, void 0, void 0, function* () {
                return Promise.resolve();
            });
        }
        resume() {
            return Promise.resolve();
        }
        setTimeout(_fn, _timeout) {
            return 0;
        }
        clearTimeout(_id) {
            return this;
        }
        setInterval(_fn, _interval) {
            return 0;
        }
        clearInterval(_id) {
            return this;
        }
        getConstant(_val) {
            return {};
        }
        get currentTime() {
            return 0;
        }
        get state() {
            return {};
        }
        get sampleRate() {
            return 0;
        }
        get listener() {
            return {};
        }
        get transport() {
            return {};
        }
        get draw() {
            return {};
        }
        set draw(_d) { }
        get destination() {
            return {};
        }
        set destination(_d) { }
        now() {
            return 0;
        }
        immediate() {
            return 0;
        }
    }

    /**
     * Make the property not writable using `defineProperty`. Internal use only.
     */
    function readOnly(target, property) {
        if (isArray(property)) {
            property.forEach(str => readOnly(target, str));
        }
        else {
            Object.defineProperty(target, property, {
                enumerable: true,
                writable: false,
            });
        }
    }
    /**
     * Make an attribute writeable. Internal use only.
     */
    function writable(target, property) {
        if (isArray(property)) {
            property.forEach(str => writable(target, str));
        }
        else {
            Object.defineProperty(target, property, {
                writable: true,
            });
        }
    }
    const noOp = () => {
        // no operation here!
    };

    /**
     * AudioBuffer loading and storage. ToneAudioBuffer is used internally by all
     * classes that make requests for audio files such as Tone.Player,
     * Tone.Sampler and Tone.Convolver.
     * Aside from load callbacks from individual buffers, ToneAudioBuffer
     * provides events which keep track of the loading progress
     * of _all_ of the buffers. These are ToneAudioBuffer.on("load" / "progress" / "error")
     * @example
     * const buffer = new Tone.ToneAudioBuffer("https://tonejs.github.io/audio/casio/A1.mp3", () => {
     * 	console.log("loaded");
     * });
     * @category Core
     */
    class ToneAudioBuffer extends Tone {
        constructor() {
            super();
            this.name = "ToneAudioBuffer";
            /**
             * Callback when the buffer is loaded.
             */
            this.onload = noOp;
            const options = optionsFromArguments(ToneAudioBuffer.getDefaults(), arguments, ["url", "onload", "onerror"]);
            this.reverse = options.reverse;
            this.onload = options.onload;
            if (options.url && isAudioBuffer(options.url) || options.url instanceof ToneAudioBuffer) {
                this.set(options.url);
            }
            else if (isString(options.url)) {
                // initiate the download
                this.load(options.url).catch(options.onerror);
            }
        }
        static getDefaults() {
            return {
                onerror: noOp,
                onload: noOp,
                reverse: false,
            };
        }
        /**
         * The sample rate of the AudioBuffer
         */
        get sampleRate() {
            if (this._buffer) {
                return this._buffer.sampleRate;
            }
            else {
                return getContext().sampleRate;
            }
        }
        /**
         * Pass in an AudioBuffer or ToneAudioBuffer to set the value of this buffer.
         */
        set(buffer) {
            if (buffer instanceof ToneAudioBuffer) {
                // if it's loaded, set it
                if (buffer.loaded) {
                    this._buffer = buffer.get();
                }
                else {
                    // otherwise when it's loaded, invoke it's callback
                    buffer.onload = () => {
                        this.set(buffer);
                        this.onload(this);
                    };
                }
            }
            else {
                this._buffer = buffer;
            }
            // reverse it initially
            if (this._reversed) {
                this._reverse();
            }
            return this;
        }
        /**
         * The audio buffer stored in the object.
         */
        get() {
            return this._buffer;
        }
        /**
         * Makes an fetch request for the selected url then decodes the file as an audio buffer.
         * Invokes the callback once the audio buffer loads.
         * @param url The url of the buffer to load. filetype support depends on the browser.
         * @returns A Promise which resolves with this ToneAudioBuffer
         */
        load(url) {
            return __awaiter(this, void 0, void 0, function* () {
                const doneLoading = ToneAudioBuffer.load(url).then(audioBuffer => {
                    this.set(audioBuffer);
                    // invoke the onload method
                    this.onload(this);
                });
                ToneAudioBuffer.downloads.push(doneLoading);
                try {
                    yield doneLoading;
                }
                finally {
                    // remove the downloaded file
                    const index = ToneAudioBuffer.downloads.indexOf(doneLoading);
                    ToneAudioBuffer.downloads.splice(index, 1);
                }
                return this;
            });
        }
        /**
         * clean up
         */
        dispose() {
            super.dispose();
            this._buffer = undefined;
            return this;
        }
        /**
         * Set the audio buffer from the array.
         * To create a multichannel AudioBuffer, pass in a multidimensional array.
         * @param array The array to fill the audio buffer
         */
        fromArray(array) {
            const isMultidimensional = isArray(array) && array[0].length > 0;
            const channels = isMultidimensional ? array.length : 1;
            const len = isMultidimensional ? array[0].length : array.length;
            const context = getContext();
            const buffer = context.createBuffer(channels, len, context.sampleRate);
            const multiChannelArray = !isMultidimensional && channels === 1 ?
                [array] : array;
            for (let c = 0; c < channels; c++) {
                buffer.copyToChannel(multiChannelArray[c], c);
            }
            this._buffer = buffer;
            return this;
        }
        /**
         * Sums multiple channels into 1 channel
         * @param chanNum Optionally only copy a single channel from the array.
         */
        toMono(chanNum) {
            if (isNumber(chanNum)) {
                this.fromArray(this.toArray(chanNum));
            }
            else {
                let outputArray = new Float32Array(this.length);
                const numChannels = this.numberOfChannels;
                for (let channel = 0; channel < numChannels; channel++) {
                    const channelArray = this.toArray(channel);
                    for (let i = 0; i < channelArray.length; i++) {
                        outputArray[i] += channelArray[i];
                    }
                }
                // divide by the number of channels
                outputArray = outputArray.map(sample => sample / numChannels);
                this.fromArray(outputArray);
            }
            return this;
        }
        /**
         * Get the buffer as an array. Single channel buffers will return a 1-dimensional
         * Float32Array, and multichannel buffers will return multidimensional arrays.
         * @param channel Optionally only copy a single channel from the array.
         */
        toArray(channel) {
            if (isNumber(channel)) {
                return this.getChannelData(channel);
            }
            else if (this.numberOfChannels === 1) {
                return this.toArray(0);
            }
            else {
                const ret = [];
                for (let c = 0; c < this.numberOfChannels; c++) {
                    ret[c] = this.getChannelData(c);
                }
                return ret;
            }
        }
        /**
         * Returns the Float32Array representing the PCM audio data for the specific channel.
         * @param  channel  The channel number to return
         * @return The audio as a TypedArray
         */
        getChannelData(channel) {
            if (this._buffer) {
                return this._buffer.getChannelData(channel);
            }
            else {
                return new Float32Array(0);
            }
        }
        /**
         * Cut a subsection of the array and return a buffer of the
         * subsection. Does not modify the original buffer
         * @param start The time to start the slice
         * @param end The end time to slice. If none is given will default to the end of the buffer
         */
        slice(start, end = this.duration) {
            const startSamples = Math.floor(start * this.sampleRate);
            const endSamples = Math.floor(end * this.sampleRate);
            assert(startSamples < endSamples, "The start time must be less than the end time");
            const length = endSamples - startSamples;
            const retBuffer = getContext().createBuffer(this.numberOfChannels, length, this.sampleRate);
            for (let channel = 0; channel < this.numberOfChannels; channel++) {
                retBuffer.copyToChannel(this.getChannelData(channel).subarray(startSamples, endSamples), channel);
            }
            return new ToneAudioBuffer(retBuffer);
        }
        /**
         * Reverse the buffer.
         */
        _reverse() {
            if (this.loaded) {
                for (let i = 0; i < this.numberOfChannels; i++) {
                    this.getChannelData(i).reverse();
                }
            }
            return this;
        }
        /**
         * If the buffer is loaded or not
         */
        get loaded() {
            return this.length > 0;
        }
        /**
         * The duration of the buffer in seconds.
         */
        get duration() {
            if (this._buffer) {
                return this._buffer.duration;
            }
            else {
                return 0;
            }
        }
        /**
         * The length of the buffer in samples
         */
        get length() {
            if (this._buffer) {
                return this._buffer.length;
            }
            else {
                return 0;
            }
        }
        /**
         * The number of discrete audio channels. Returns 0 if no buffer is loaded.
         */
        get numberOfChannels() {
            if (this._buffer) {
                return this._buffer.numberOfChannels;
            }
            else {
                return 0;
            }
        }
        /**
         * Reverse the buffer.
         */
        get reverse() {
            return this._reversed;
        }
        set reverse(rev) {
            if (this._reversed !== rev) {
                this._reversed = rev;
                this._reverse();
            }
        }
        /**
         * Create a ToneAudioBuffer from the array. To create a multichannel AudioBuffer,
         * pass in a multidimensional array.
         * @param array The array to fill the audio buffer
         * @return A ToneAudioBuffer created from the array
         */
        static fromArray(array) {
            return (new ToneAudioBuffer()).fromArray(array);
        }
        /**
         * Creates a ToneAudioBuffer from a URL, returns a promise which resolves to a ToneAudioBuffer
         * @param  url The url to load.
         * @return A promise which resolves to a ToneAudioBuffer
         */
        static fromUrl(url) {
            return __awaiter(this, void 0, void 0, function* () {
                const buffer = new ToneAudioBuffer();
                return yield buffer.load(url);
            });
        }
        /**
         * Loads a url using fetch and returns the AudioBuffer.
         */
        static load(url) {
            return __awaiter(this, void 0, void 0, function* () {
                // test if the url contains multiple extensions
                const matches = url.match(/\[(.+\|?)+\]$/);
                if (matches) {
                    const extensions = matches[1].split("|");
                    let extension = extensions[0];
                    for (const ext of extensions) {
                        if (ToneAudioBuffer.supportsType(ext)) {
                            extension = ext;
                            break;
                        }
                    }
                    url = url.replace(matches[0], extension);
                }
                // make sure there is a slash between the baseUrl and the url
                const baseUrl = ToneAudioBuffer.baseUrl === "" || ToneAudioBuffer.baseUrl.endsWith("/") ? ToneAudioBuffer.baseUrl : ToneAudioBuffer.baseUrl + "/";
                const response = yield fetch(baseUrl + url);
                if (!response.ok) {
                    throw new Error(`could not load url: ${url}`);
                }
                const arrayBuffer = yield response.arrayBuffer();
                const audioBuffer = yield getContext().decodeAudioData(arrayBuffer);
                return audioBuffer;
            });
        }
        /**
         * Checks a url's extension to see if the current browser can play that file type.
         * @param url The url/extension to test
         * @return If the file extension can be played
         * @static
         * @example
         * Tone.ToneAudioBuffer.supportsType("wav"); // returns true
         * Tone.ToneAudioBuffer.supportsType("path/to/file.wav"); // returns true
         */
        static supportsType(url) {
            const extensions = url.split(".");
            const extension = extensions[extensions.length - 1];
            const response = document.createElement("audio").canPlayType("audio/" + extension);
            return response !== "";
        }
        /**
         * Returns a Promise which resolves when all of the buffers have loaded
         */
        static loaded() {
            return __awaiter(this, void 0, void 0, function* () {
                // this makes sure that the function is always async
                yield Promise.resolve();
                while (ToneAudioBuffer.downloads.length) {
                    yield ToneAudioBuffer.downloads[0];
                }
            });
        }
    }
    //-------------------------------------
    // STATIC METHODS
    //-------------------------------------
    /**
     * A path which is prefixed before every url.
     */
    ToneAudioBuffer.baseUrl = "";
    /**
     * All of the downloads
     */
    ToneAudioBuffer.downloads = [];

    /**
     * Wrapper around the OfflineAudioContext
     * @category Core
     * @example
     * // generate a single channel, 0.5 second buffer
     * const context = new Tone.OfflineContext(1, 0.5, 44100);
     * const osc = new Tone.Oscillator({ context });
     * context.render().then(buffer => {
     * 	console.log(buffer.numberOfChannels, buffer.duration);
     * });
     */
    class OfflineContext extends Context {
        constructor() {
            super({
                clockSource: "offline",
                context: isOfflineAudioContext(arguments[0]) ?
                    arguments[0] : createOfflineAudioContext(arguments[0], arguments[1] * arguments[2], arguments[2]),
                lookAhead: 0,
                updateInterval: isOfflineAudioContext(arguments[0]) ?
                    128 / arguments[0].sampleRate : 128 / arguments[2],
            });
            this.name = "OfflineContext";
            /**
             * An artificial clock source
             */
            this._currentTime = 0;
            this.isOffline = true;
            this._duration = isOfflineAudioContext(arguments[0]) ?
                arguments[0].length / arguments[0].sampleRate : arguments[1];
        }
        /**
         * Override the now method to point to the internal clock time
         */
        now() {
            return this._currentTime;
        }
        /**
         * Same as this.now()
         */
        get currentTime() {
            return this._currentTime;
        }
        /**
         * Render just the clock portion of the audio context.
         */
        _renderClock(asynchronous) {
            return __awaiter(this, void 0, void 0, function* () {
                let index = 0;
                while (this._duration - this._currentTime >= 0) {
                    // invoke all the callbacks on that time
                    this.emit("tick");
                    // increment the clock in block-sized chunks
                    this._currentTime += 128 / this.sampleRate;
                    // yield once a second of audio
                    index++;
                    const yieldEvery = Math.floor(this.sampleRate / 128);
                    if (asynchronous && index % yieldEvery === 0) {
                        yield new Promise(done => setTimeout(done, 1));
                    }
                }
            });
        }
        /**
         * Render the output of the OfflineContext
         * @param asynchronous If the clock should be rendered asynchronously, which will not block the main thread, but be slightly slower.
         */
        render(asynchronous = true) {
            return __awaiter(this, void 0, void 0, function* () {
                yield this.workletsAreReady();
                yield this._renderClock(asynchronous);
                const buffer = yield this._context.startRendering();
                return new ToneAudioBuffer(buffer);
            });
        }
        /**
         * Close the context
         */
        close() {
            return Promise.resolve();
        }
    }

    /**
     * This dummy context is used to avoid throwing immediate errors when importing in Node.js
     */
    const dummyContext = new DummyContext();
    /**
     * The global audio context which is getable and assignable through
     * getContext and setContext
     */
    let globalContext = dummyContext;
    /**
     * Returns the default system-wide [[Context]]
     * @category Core
     */
    function getContext() {
        if (globalContext === dummyContext && hasAudioContext) {
            setContext(new Context());
        }
        return globalContext;
    }
    /**
     * Set the default audio context
     * @category Core
     */
    function setContext(context) {
        if (isAudioContext(context)) {
            globalContext = new Context(context);
        }
        else if (isOfflineAudioContext(context)) {
            globalContext = new OfflineContext(context);
        }
        else {
            globalContext = context;
        }
    }
    /**
     * Most browsers will not play _any_ audio until a user
     * clicks something (like a play button). Invoke this method
     * on a click or keypress event handler to start the audio context.
     * More about the Autoplay policy
     * [here](https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio)
     * @example
     * document.querySelector("button").addEventListener("click", async () => {
     * 	await Tone.start();
     * 	console.log("context started");
     * });
     * @category Core
     */
    function start() {
        return globalContext.resume();
    }
    /**
     * Log Tone.js + version in the console.
     */
    if (theWindow && !theWindow.TONE_SILENCE_LOGGING) {
        let prefix = "v";
        const printString = ` * Tone.js ${prefix}${version} * `;
        // eslint-disable-next-line no-console
        console.log(`%c${printString}`, "background: #000; color: #fff");
    }

    /**
     * Equal power gain scale. Good for cross-fading.
     * @param  percent (0-1)
     */
    /**
     * Convert decibels into gain.
     */
    function dbToGain(db) {
        return Math.pow(10, db / 20);
    }
    /**
     * Convert gain to decibels.
     */
    function gainToDb(gain) {
        return 20 * (Math.log(gain) / Math.LN10);
    }
    /**
     * Convert an interval (in semitones) to a frequency ratio.
     * @param interval the number of semitones above the base note
     * @example
     * Tone.intervalToFrequencyRatio(0); // 1
     * Tone.intervalToFrequencyRatio(12); // 2
     * Tone.intervalToFrequencyRatio(-12); // 0.5
     */
    function intervalToFrequencyRatio(interval) {
        return Math.pow(2, (interval / 12));
    }
    /**
     * The Global [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used
     * to generate all the other pitch values from notes. A4's values in Hertz.
     */
    let A4 = 440;
    function getA4() {
        return A4;
    }
    function setA4(freq) {
        A4 = freq;
    }
    /**
     * Convert a frequency value to a MIDI note.
     * @param frequency The value to frequency value to convert.
     * @example
     * Tone.ftom(440); // returns 69
     */
    function ftom(frequency) {
        return Math.round(ftomf(frequency));
    }
    /**
     * Convert a frequency to a floating point midi value
     */
    function ftomf(frequency) {
        return 69 + 12 * Math.log2(frequency / A4);
    }
    /**
     * Convert a MIDI note to frequency value.
     * @param  midi The midi number to convert.
     * @return The corresponding frequency value
     * @example
     * Tone.mtof(69); // 440
     */
    function mtof(midi) {
        return A4 * Math.pow(2, (midi - 69) / 12);
    }

    /**
     * TimeBase is a flexible encoding of time which can be evaluated to and from a string.
     */
    class TimeBaseClass extends Tone {
        /**
         * @param context The context associated with the time value. Used to compute
         * Transport and context-relative timing.
         * @param  value  The time value as a number, string or object
         * @param  units  Unit values
         */
        constructor(context, value, units) {
            super();
            /**
             * The default units
             */
            this.defaultUnits = "s";
            this._val = value;
            this._units = units;
            this.context = context;
            this._expressions = this._getExpressions();
        }
        /**
         * All of the time encoding expressions
         */
        _getExpressions() {
            return {
                hz: {
                    method: (value) => {
                        return this._frequencyToUnits(parseFloat(value));
                    },
                    regexp: /^(\d+(?:\.\d+)?)hz$/i,
                },
                i: {
                    method: (value) => {
                        return this._ticksToUnits(parseInt(value, 10));
                    },
                    regexp: /^(\d+)i$/i,
                },
                m: {
                    method: (value) => {
                        return this._beatsToUnits(parseInt(value, 10) * this._getTimeSignature());
                    },
                    regexp: /^(\d+)m$/i,
                },
                n: {
                    method: (value, dot) => {
                        const numericValue = parseInt(value, 10);
                        const scalar = dot === "." ? 1.5 : 1;
                        if (numericValue === 1) {
                            return this._beatsToUnits(this._getTimeSignature()) * scalar;
                        }
                        else {
                            return this._beatsToUnits(4 / numericValue) * scalar;
                        }
                    },
                    regexp: /^(\d+)n(\.?)$/i,
                },
                number: {
                    method: (value) => {
                        return this._expressions[this.defaultUnits].method.call(this, value);
                    },
                    regexp: /^(\d+(?:\.\d+)?)$/,
                },
                s: {
                    method: (value) => {
                        return this._secondsToUnits(parseFloat(value));
                    },
                    regexp: /^(\d+(?:\.\d+)?)s$/,
                },
                samples: {
                    method: (value) => {
                        return parseInt(value, 10) / this.context.sampleRate;
                    },
                    regexp: /^(\d+)samples$/,
                },
                t: {
                    method: (value) => {
                        const numericValue = parseInt(value, 10);
                        return this._beatsToUnits(8 / (Math.floor(numericValue) * 3));
                    },
                    regexp: /^(\d+)t$/i,
                },
                tr: {
                    method: (m, q, s) => {
                        let total = 0;
                        if (m && m !== "0") {
                            total += this._beatsToUnits(this._getTimeSignature() * parseFloat(m));
                        }
                        if (q && q !== "0") {
                            total += this._beatsToUnits(parseFloat(q));
                        }
                        if (s && s !== "0") {
                            total += this._beatsToUnits(parseFloat(s) / 4);
                        }
                        return total;
                    },
                    regexp: /^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?$/,
                },
            };
        }
        //-------------------------------------
        // 	VALUE OF
        //-------------------------------------
        /**
         * Evaluate the time value. Returns the time in seconds.
         */
        valueOf() {
            if (this._val instanceof TimeBaseClass) {
                this.fromType(this._val);
            }
            if (isUndef(this._val)) {
                return this._noArg();
            }
            else if (isString(this._val) && isUndef(this._units)) {
                for (const units in this._expressions) {
                    if (this._expressions[units].regexp.test(this._val.trim())) {
                        this._units = units;
                        break;
                    }
                }
            }
            else if (isObject(this._val)) {
                let total = 0;
                for (const typeName in this._val) {
                    if (isDefined(this._val[typeName])) {
                        const quantity = this._val[typeName];
                        // @ts-ignore
                        const time = (new this.constructor(this.context, typeName)).valueOf() * quantity;
                        total += time;
                    }
                }
                return total;
            }
            if (isDefined(this._units)) {
                const expr = this._expressions[this._units];
                const matching = this._val.toString().trim().match(expr.regexp);
                if (matching) {
                    return expr.method.apply(this, matching.slice(1));
                }
                else {
                    return expr.method.call(this, this._val);
                }
            }
            else if (isString(this._val)) {
                return parseFloat(this._val);
            }
            else {
                return this._val;
            }
        }
        //-------------------------------------
        // 	UNIT CONVERSIONS
        //-------------------------------------
        /**
         * Returns the value of a frequency in the current units
         */
        _frequencyToUnits(freq) {
            return 1 / freq;
        }
        /**
         * Return the value of the beats in the current units
         */
        _beatsToUnits(beats) {
            return (60 / this._getBpm()) * beats;
        }
        /**
         * Returns the value of a second in the current units
         */
        _secondsToUnits(seconds) {
            return seconds;
        }
        /**
         * Returns the value of a tick in the current time units
         */
        _ticksToUnits(ticks) {
            return (ticks * (this._beatsToUnits(1)) / this._getPPQ());
        }
        /**
         * With no arguments, return 'now'
         */
        _noArg() {
            return this._now();
        }
        //-------------------------------------
        // 	TEMPO CONVERSIONS
        //-------------------------------------
        /**
         * Return the bpm
         */
        _getBpm() {
            return this.context.transport.bpm.value;
        }
        /**
         * Return the timeSignature
         */
        _getTimeSignature() {
            return this.context.transport.timeSignature;
        }
        /**
         * Return the PPQ or 192 if Transport is not available
         */
        _getPPQ() {
            return this.context.transport.PPQ;
        }
        //-------------------------------------
        // 	CONVERSION INTERFACE
        //-------------------------------------
        /**
         * Coerce a time type into this units type.
         * @param type Any time type units
         */
        fromType(type) {
            this._units = undefined;
            switch (this.defaultUnits) {
                case "s":
                    this._val = type.toSeconds();
                    break;
                case "i":
                    this._val = type.toTicks();
                    break;
                case "hz":
                    this._val = type.toFrequency();
                    break;
                case "midi":
                    this._val = type.toMidi();
                    break;
            }
            return this;
        }
        /**
         * Return the value in hertz
         */
        toFrequency() {
            return 1 / this.toSeconds();
        }
        /**
         * Return the time in samples
         */
        toSamples() {
            return this.toSeconds() * this.context.sampleRate;
        }
        /**
         * Return the time in milliseconds.
         */
        toMilliseconds() {
            return this.toSeconds() * 1000;
        }
    }

    /**
     * TimeClass is a primitive type for encoding and decoding Time values.
     * TimeClass can be passed into the parameter of any method which takes time as an argument.
     * @param  val    The time value.
     * @param  units  The units of the value.
     * @example
     * const time = Tone.Time("4n"); // a quarter note
     * @category Unit
     */
    class TimeClass extends TimeBaseClass {
        constructor() {
            super(...arguments);
            this.name = "TimeClass";
        }
        _getExpressions() {
            return Object.assign(super._getExpressions(), {
                now: {
                    method: (capture) => {
                        return this._now() + new this.constructor(this.context, capture).valueOf();
                    },
                    regexp: /^\+(.+)/,
                },
                quantize: {
                    method: (capture) => {
                        const quantTo = new TimeClass(this.context, capture).valueOf();
                        return this._secondsToUnits(this.context.transport.nextSubdivision(quantTo));
                    },
                    regexp: /^@(.+)/,
                },
            });
        }
        /**
         * Quantize the time by the given subdivision. Optionally add a
         * percentage which will move the time value towards the ideal
         * quantized value by that percentage.
         * @param  subdiv    The subdivision to quantize to
         * @param  percent  Move the time value towards the quantized value by a percentage.
         * @example
         * Tone.Time(21).quantize(2); // returns 22
         * Tone.Time(0.6).quantize("4n", 0.5); // returns 0.55
         */
        quantize(subdiv, percent = 1) {
            const subdivision = new this.constructor(this.context, subdiv).valueOf();
            const value = this.valueOf();
            const multiple = Math.round(value / subdivision);
            const ideal = multiple * subdivision;
            const diff = ideal - value;
            return value + diff * percent;
        }
        //-------------------------------------
        // CONVERSIONS
        //-------------------------------------
        /**
         * Convert a Time to Notation. The notation values are will be the
         * closest representation between 1m to 128th note.
         * @return {Notation}
         * @example
         * // if the Transport is at 120bpm:
         * Tone.Time(2).toNotation(); // returns "1m"
         */
        toNotation() {
            const time = this.toSeconds();
            const testNotations = ["1m"];
            for (let power = 1; power < 9; power++) {
                const subdiv = Math.pow(2, power);
                testNotations.push(subdiv + "n.");
                testNotations.push(subdiv + "n");
                testNotations.push(subdiv + "t");
            }
            testNotations.push("0");
            // find the closets notation representation
            let closest = testNotations[0];
            let closestSeconds = new TimeClass(this.context, testNotations[0]).toSeconds();
            testNotations.forEach(notation => {
                const notationSeconds = new TimeClass(this.context, notation).toSeconds();
                if (Math.abs(notationSeconds - time) < Math.abs(closestSeconds - time)) {
                    closest = notation;
                    closestSeconds = notationSeconds;
                }
            });
            return closest;
        }
        /**
         * Return the time encoded as Bars:Beats:Sixteenths.
         */
        toBarsBeatsSixteenths() {
            const quarterTime = this._beatsToUnits(1);
            let quarters = this.valueOf() / quarterTime;
            quarters = parseFloat(quarters.toFixed(4));
            const measures = Math.floor(quarters / this._getTimeSignature());
            let sixteenths = (quarters % 1) * 4;
            quarters = Math.floor(quarters) % this._getTimeSignature();
            const sixteenthString = sixteenths.toString();
            if (sixteenthString.length > 3) {
                // the additional parseFloat removes insignificant trailing zeroes
                sixteenths = parseFloat(parseFloat(sixteenthString).toFixed(3));
            }
            const progress = [measures, quarters, sixteenths];
            return progress.join(":");
        }
        /**
         * Return the time in ticks.
         */
        toTicks() {
            const quarterTime = this._beatsToUnits(1);
            const quarters = this.valueOf() / quarterTime;
            return Math.round(quarters * this._getPPQ());
        }
        /**
         * Return the time in seconds.
         */
        toSeconds() {
            return this.valueOf();
        }
        /**
         * Return the value as a midi note.
         */
        toMidi() {
            return ftom(this.toFrequency());
        }
        _now() {
            return this.context.now();
        }
    }
    /**
     * Create a TimeClass from a time string or number. The time is computed against the
     * global Tone.Context. To use a specific context, use [[TimeClass]]
     * @param value A value which represents time
     * @param units The value's units if they can't be inferred by the value.
     * @category Unit
     * @example
     * const time = Tone.Time("4n").toSeconds();
     * console.log(time);
     * @example
     * const note = Tone.Time(1).toNotation();
     * console.log(note);
     * @example
     * const freq = Tone.Time(0.5).toFrequency();
     * console.log(freq);
     */
    function Time(value, units) {
        return new TimeClass(getContext(), value, units);
    }

    /**
     * Frequency is a primitive type for encoding Frequency values.
     * Eventually all time values are evaluated to hertz using the `valueOf` method.
     * @example
     * Tone.Frequency("C3"); // 261
     * Tone.Frequency(38, "midi");
     * Tone.Frequency("C3").transpose(4);
     * @category Unit
     */
    class FrequencyClass extends TimeClass {
        constructor() {
            super(...arguments);
            this.name = "Frequency";
            this.defaultUnits = "hz";
        }
        /**
         * The [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used
         * to generate all the other pitch values from notes. A4's values in Hertz.
         */
        static get A4() {
            return getA4();
        }
        static set A4(freq) {
            setA4(freq);
        }
        //-------------------------------------
        // 	AUGMENT BASE EXPRESSIONS
        //-------------------------------------
        _getExpressions() {
            return Object.assign({}, super._getExpressions(), {
                midi: {
                    regexp: /^(\d+(?:\.\d+)?midi)/,
                    method(value) {
                        if (this.defaultUnits === "midi") {
                            return value;
                        }
                        else {
                            return FrequencyClass.mtof(value);
                        }
                    },
                },
                note: {
                    regexp: /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i,
                    method(pitch, octave) {
                        const index = noteToScaleIndex[pitch.toLowerCase()];
                        const noteNumber = index + (parseInt(octave, 10) + 1) * 12;
                        if (this.defaultUnits === "midi") {
                            return noteNumber;
                        }
                        else {
                            return FrequencyClass.mtof(noteNumber);
                        }
                    },
                },
                tr: {
                    regexp: /^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?/,
                    method(m, q, s) {
                        let total = 1;
                        if (m && m !== "0") {
                            total *= this._beatsToUnits(this._getTimeSignature() * parseFloat(m));
                        }
                        if (q && q !== "0") {
                            total *= this._beatsToUnits(parseFloat(q));
                        }
                        if (s && s !== "0") {
                            total *= this._beatsToUnits(parseFloat(s) / 4);
                        }
                        return total;
                    },
                },
            });
        }
        //-------------------------------------
        // 	EXPRESSIONS
        //-------------------------------------
        /**
         * Transposes the frequency by the given number of semitones.
         * @return  A new transposed frequency
         * @example
         * Tone.Frequency("A4").transpose(3); // "C5"
         */
        transpose(interval) {
            return new FrequencyClass(this.context, this.valueOf() * intervalToFrequencyRatio(interval));
        }
        /**
         * Takes an array of semitone intervals and returns
         * an array of frequencies transposed by those intervals.
         * @return  Returns an array of Frequencies
         * @example
         * Tone.Frequency("A4").harmonize([0, 3, 7]); // ["A4", "C5", "E5"]
         */
        harmonize(intervals) {
            return intervals.map(interval => {
                return this.transpose(interval);
            });
        }
        //-------------------------------------
        // 	UNIT CONVERSIONS
        //-------------------------------------
        /**
         * Return the value of the frequency as a MIDI note
         * @example
         * Tone.Frequency("C4").toMidi(); // 60
         */
        toMidi() {
            return ftom(this.valueOf());
        }
        /**
         * Return the value of the frequency in Scientific Pitch Notation
         * @example
         * Tone.Frequency(69, "midi").toNote(); // "A4"
         */
        toNote() {
            const freq = this.toFrequency();
            const log = Math.log2(freq / FrequencyClass.A4);
            let noteNumber = Math.round(12 * log) + 57;
            const octave = Math.floor(noteNumber / 12);
            if (octave < 0) {
                noteNumber += -12 * octave;
            }
            const noteName = scaleIndexToNote[noteNumber % 12];
            return noteName + octave.toString();
        }
        /**
         * Return the duration of one cycle in seconds.
         */
        toSeconds() {
            return 1 / super.toSeconds();
        }
        /**
         * Return the duration of one cycle in ticks
         */
        toTicks() {
            const quarterTime = this._beatsToUnits(1);
            const quarters = this.valueOf() / quarterTime;
            return Math.floor(quarters * this._getPPQ());
        }
        //-------------------------------------
        // 	UNIT CONVERSIONS HELPERS
        //-------------------------------------
        /**
         * With no arguments, return 0
         */
        _noArg() {
            return 0;
        }
        /**
         * Returns the value of a frequency in the current units
         */
        _frequencyToUnits(freq) {
            return freq;
        }
        /**
         * Returns the value of a tick in the current time units
         */
        _ticksToUnits(ticks) {
            return 1 / ((ticks * 60) / (this._getBpm() * this._getPPQ()));
        }
        /**
         * Return the value of the beats in the current units
         */
        _beatsToUnits(beats) {
            return 1 / super._beatsToUnits(beats);
        }
        /**
         * Returns the value of a second in the current units
         */
        _secondsToUnits(seconds) {
            return 1 / seconds;
        }
        /**
         * Convert a MIDI note to frequency value.
         * @param  midi The midi number to convert.
         * @return The corresponding frequency value
         */
        static mtof(midi) {
            return mtof(midi);
        }
        /**
         * Convert a frequency value to a MIDI note.
         * @param frequency The value to frequency value to convert.
         */
        static ftom(frequency) {
            return ftom(frequency);
        }
    }
    //-------------------------------------
    // 	FREQUENCY CONVERSIONS
    //-------------------------------------
    /**
     * Note to scale index.
     * @hidden
     */
    const noteToScaleIndex = {
        cbb: -2, cb: -1, c: 0, "c#": 1, cx: 2,
        dbb: 0, db: 1, d: 2, "d#": 3, dx: 4,
        ebb: 2, eb: 3, e: 4, "e#": 5, ex: 6,
        fbb: 3, fb: 4, f: 5, "f#": 6, fx: 7,
        gbb: 5, gb: 6, g: 7, "g#": 8, gx: 9,
        abb: 7, ab: 8, a: 9, "a#": 10, ax: 11,
        bbb: 9, bb: 10, b: 11, "b#": 12, bx: 13,
    };
    /**
     * scale index to note (sharps)
     * @hidden
     */
    const scaleIndexToNote = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];
    /**
     * Convert a value into a FrequencyClass object.
     * @category Unit
     * @example
     * const midi = Tone.Frequency("C3").toMidi();
     * console.log(midi);
     * @example
     * const hertz = Tone.Frequency(38, "midi").toFrequency();
     * console.log(hertz);
     */
    function Frequency(value, units) {
        return new FrequencyClass(getContext(), value, units);
    }

    /**
     * TransportTime is a the time along the Transport's
     * timeline. It is similar to Tone.Time, but instead of evaluating
     * against the AudioContext's clock, it is evaluated against
     * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).
     * @category Unit
     */
    class TransportTimeClass extends TimeClass {
        constructor() {
            super(...arguments);
            this.name = "TransportTime";
        }
        /**
         * Return the current time in whichever context is relevant
         */
        _now() {
            return this.context.transport.seconds;
        }
    }
    /**
     * TransportTime is a the time along the Transport's
     * timeline. It is similar to [[Time]], but instead of evaluating
     * against the AudioContext's clock, it is evaluated against
     * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).
     * @category Unit
     */
    function TransportTime(value, units) {
        return new TransportTimeClass(getContext(), value, units);
    }

    /**
     * The Base class for all nodes that have an AudioContext.
     */
    class ToneWithContext extends Tone {
        constructor() {
            super();
            const options = optionsFromArguments(ToneWithContext.getDefaults(), arguments, ["context"]);
            if (this.defaultContext) {
                this.context = this.defaultContext;
            }
            else {
                this.context = options.context;
            }
        }
        static getDefaults() {
            return {
                context: getContext(),
            };
        }
        /**
         * Return the current time of the Context clock plus the lookAhead.
         * @example
         * setInterval(() => {
         * 	console.log(Tone.now());
         * }, 100);
         */
        now() {
            return this.context.currentTime + this.context.lookAhead;
        }
        /**
         * Return the current time of the Context clock without any lookAhead.
         * @example
         * setInterval(() => {
         * 	console.log(Tone.immediate());
         * }, 100);
         */
        immediate() {
            return this.context.currentTime;
        }
        /**
         * The duration in seconds of one sample.
         * @example
         * console.log(Tone.Transport.sampleTime);
         */
        get sampleTime() {
            return 1 / this.context.sampleRate;
        }
        /**
         * The number of seconds of 1 processing block (128 samples)
         * @example
         * console.log(Tone.Destination.blockTime);
         */
        get blockTime() {
            return 128 / this.context.sampleRate;
        }
        /**
         * Convert the incoming time to seconds.
         * This is calculated against the current [[Tone.Transport]] bpm
         * @example
         * const gain = new Tone.Gain();
         * setInterval(() => console.log(gain.toSeconds("4n")), 100);
         * // ramp the tempo to 60 bpm over 30 seconds
         * Tone.getTransport().bpm.rampTo(60, 30);
         */
        toSeconds(time) {
            return new TimeClass(this.context, time).toSeconds();
        }
        /**
         * Convert the input to a frequency number
         * @example
         * const gain = new Tone.Gain();
         * console.log(gain.toFrequency("4n"));
         */
        toFrequency(freq) {
            return new FrequencyClass(this.context, freq).toFrequency();
        }
        /**
         * Convert the input time into ticks
         * @example
         * const gain = new Tone.Gain();
         * console.log(gain.toTicks("4n"));
         */
        toTicks(time) {
            return new TransportTimeClass(this.context, time).toTicks();
        }
        //-------------------------------------
        // 	GET/SET
        //-------------------------------------
        /**
         * Get a subset of the properties which are in the partial props
         */
        _getPartialProperties(props) {
            const options = this.get();
            // remove attributes from the prop that are not in the partial
            Object.keys(options).forEach(name => {
                if (isUndef(props[name])) {
                    delete options[name];
                }
            });
            return options;
        }
        /**
         * Get the object's attributes.
         * @example
         * const osc = new Tone.Oscillator();
         * console.log(osc.get());
         */
        get() {
            const defaults = getDefaultsFromInstance(this);
            Object.keys(defaults).forEach(attribute => {
                if (Reflect.has(this, attribute)) {
                    const member = this[attribute];
                    if (isDefined(member) && isDefined(member.value) && isDefined(member.setValueAtTime)) {
                        defaults[attribute] = member.value;
                    }
                    else if (member instanceof ToneWithContext) {
                        defaults[attribute] = member._getPartialProperties(defaults[attribute]);
                        // otherwise make sure it's a serializable type
                    }
                    else if (isArray(member) || isNumber(member) || isString(member) || isBoolean(member)) {
                        defaults[attribute] = member;
                    }
                    else {
                        // remove all undefined and unserializable attributes
                        delete defaults[attribute];
                    }
                }
            });
            return defaults;
        }
        /**
         * Set multiple properties at once with an object.
         * @example
         * const filter = new Tone.Filter().toDestination();
         * // set values using an object
         * filter.set({
         * 	frequency: "C6",
         * 	type: "highpass"
         * });
         * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/Analogsynth_octaves_highmid.mp3").connect(filter);
         * player.autostart = true;
         */
        set(props) {
            Object.keys(props).forEach(attribute => {
                if (Reflect.has(this, attribute) && isDefined(this[attribute])) {
                    if (this[attribute] && isDefined(this[attribute].value) && isDefined(this[attribute].setValueAtTime)) {
                        // small optimization
                        if (this[attribute].value !== props[attribute]) {
                            this[attribute].value = props[attribute];
                        }
                    }
                    else if (this[attribute] instanceof ToneWithContext) {
                        this[attribute].set(props[attribute]);
                    }
                    else {
                        this[attribute] = props[attribute];
                    }
                }
            });
            return this;
        }
    }

    /**
     * A Timeline State. Provides the methods: `setStateAtTime("state", time)` and `getValueAtTime(time)`
     * @param initial The initial state of the StateTimeline.  Defaults to `undefined`
     */
    class StateTimeline extends Timeline {
        constructor(initial = "stopped") {
            super();
            this.name = "StateTimeline";
            this._initial = initial;
            this.setStateAtTime(this._initial, 0);
        }
        /**
         * Returns the scheduled state scheduled before or at
         * the given time.
         * @param  time  The time to query.
         * @return  The name of the state input in setStateAtTime.
         */
        getValueAtTime(time) {
            const event = this.get(time);
            if (event !== null) {
                return event.state;
            }
            else {
                return this._initial;
            }
        }
        /**
         * Add a state to the timeline.
         * @param  state The name of the state to set.
         * @param  time  The time to query.
         * @param options Any additional options that are needed in the timeline.
         */
        setStateAtTime(state, time, options) {
            assertRange(time, 0);
            this.add(Object.assign({}, options, {
                state,
                time,
            }));
            return this;
        }
        /**
         * Return the event before the time with the given state
         * @param  state The state to look for
         * @param  time  When to check before
         * @return  The event with the given state before the time
         */
        getLastState(state, time) {
            // time = this.toSeconds(time);
            const index = this._search(time);
            for (let i = index; i >= 0; i--) {
                const event = this._timeline[i];
                if (event.state === state) {
                    return event;
                }
            }
        }
        /**
         * Return the event after the time with the given state
         * @param  state The state to look for
         * @param  time  When to check from
         * @return  The event with the given state after the time
         */
        getNextState(state, time) {
            // time = this.toSeconds(time);
            const index = this._search(time);
            if (index !== -1) {
                for (let i = index; i < this._timeline.length; i++) {
                    const event = this._timeline[i];
                    if (event.state === state) {
                        return event;
                    }
                }
            }
        }
    }

    /**
     * Param wraps the native Web Audio's AudioParam to provide
     * additional unit conversion functionality. It also
     * serves as a base-class for classes which have a single,
     * automatable parameter.
     * @category Core
     */
    class Param extends ToneWithContext {
        constructor() {
            super(optionsFromArguments(Param.getDefaults(), arguments, ["param", "units", "convert"]));
            this.name = "Param";
            this.overridden = false;
            /**
             * The minimum output value
             */
            this._minOutput = 1e-7;
            const options = optionsFromArguments(Param.getDefaults(), arguments, ["param", "units", "convert"]);
            assert(isDefined(options.param) &&
                (isAudioParam(options.param) || options.param instanceof Param), "param must be an AudioParam");
            while (!isAudioParam(options.param)) {
                options.param = options.param._param;
            }
            this._swappable = isDefined(options.swappable) ? options.swappable : false;
            if (this._swappable) {
                this.input = this.context.createGain();
                // initialize
                this._param = options.param;
                this.input.connect(this._param);
            }
            else {
                this._param = this.input = options.param;
            }
            this._events = new Timeline(1000);
            this._initialValue = this._param.defaultValue;
            this.units = options.units;
            this.convert = options.convert;
            this._minValue = options.minValue;
            this._maxValue = options.maxValue;
            // if the value is defined, set it immediately
            if (isDefined(options.value) && options.value !== this._toType(this._initialValue)) {
                this.setValueAtTime(options.value, 0);
            }
        }
        static getDefaults() {
            return Object.assign(ToneWithContext.getDefaults(), {
                convert: true,
                units: "number",
            });
        }
        get value() {
            const now = this.now();
            return this.getValueAtTime(now);
        }
        set value(value) {
            this.cancelScheduledValues(this.now());
            this.setValueAtTime(value, this.now());
        }
        get minValue() {
            // if it's not the default minValue, return it
            if (isDefined(this._minValue)) {
                return this._minValue;
            }
            else if (this.units === "time" || this.units === "frequency" ||
                this.units === "normalRange" || this.units === "positive" ||
                this.units === "transportTime" || this.units === "ticks" ||
                this.units === "bpm" || this.units === "hertz" || this.units === "samples") {
                return 0;
            }
            else if (this.units === "audioRange") {
                return -1;
            }
            else if (this.units === "decibels") {
                return -Infinity;
            }
            else {
                return this._param.minValue;
            }
        }
        get maxValue() {
            if (isDefined(this._maxValue)) {
                return this._maxValue;
            }
            else if (this.units === "normalRange" ||
                this.units === "audioRange") {
                return 1;
            }
            else {
                return this._param.maxValue;
            }
        }
        /**
         * Type guard based on the unit name
         */
        _is(arg, type) {
            return this.units === type;
        }
        /**
         * Make sure the value is always in the defined range
         */
        _assertRange(value) {
            if (isDefined(this.maxValue) && isDefined(this.minValue)) {
                assertRange(value, this._fromType(this.minValue), this._fromType(this.maxValue));
            }
            return value;
        }
        /**
         * Convert the given value from the type specified by Param.units
         * into the destination value (such as Gain or Frequency).
         */
        _fromType(val) {
            if (this.convert && !this.overridden) {
                if (this._is(val, "time")) {
                    return this.toSeconds(val);
                }
                else if (this._is(val, "decibels")) {
                    return dbToGain(val);
                }
                else if (this._is(val, "frequency")) {
                    return this.toFrequency(val);
                }
                else {
                    return val;
                }
            }
            else if (this.overridden) {
                // if it's overridden, should only schedule 0s
                return 0;
            }
            else {
                return val;
            }
        }
        /**
         * Convert the parameters value into the units specified by Param.units.
         */
        _toType(val) {
            if (this.convert && this.units === "decibels") {
                return gainToDb(val);
            }
            else {
                return val;
            }
        }
        //-------------------------------------
        // ABSTRACT PARAM INTERFACE
        // all docs are generated from ParamInterface.ts
        //-------------------------------------
        setValueAtTime(value, time) {
            const computedTime = this.toSeconds(time);
            const numericValue = this._fromType(value);
            assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(time)}`);
            this._assertRange(numericValue);
            this.log(this.units, "setValueAtTime", value, computedTime);
            this._events.add({
                time: computedTime,
                type: "setValueAtTime",
                value: numericValue,
            });
            this._param.setValueAtTime(numericValue, computedTime);
            return this;
        }
        getValueAtTime(time) {
            const computedTime = Math.max(this.toSeconds(time), 0);
            const after = this._events.getAfter(computedTime);
            const before = this._events.get(computedTime);
            let value = this._initialValue;
            // if it was set by
            if (before === null) {
                value = this._initialValue;
            }
            else if (before.type === "setTargetAtTime" && (after === null || after.type === "setValueAtTime")) {
                const previous = this._events.getBefore(before.time);
                let previousVal;
                if (previous === null) {
                    previousVal = this._initialValue;
                }
                else {
                    previousVal = previous.value;
                }
                if (before.type === "setTargetAtTime") {
                    value = this._exponentialApproach(before.time, previousVal, before.value, before.constant, computedTime);
                }
            }
            else if (after === null) {
                value = before.value;
            }
            else if (after.type === "linearRampToValueAtTime" || after.type === "exponentialRampToValueAtTime") {
                let beforeValue = before.value;
                if (before.type === "setTargetAtTime") {
                    const previous = this._events.getBefore(before.time);
                    if (previous === null) {
                        beforeValue = this._initialValue;
                    }
                    else {
                        beforeValue = previous.value;
                    }
                }
                if (after.type === "linearRampToValueAtTime") {
                    value = this._linearInterpolate(before.time, beforeValue, after.time, after.value, computedTime);
                }
                else {
                    value = this._exponentialInterpolate(before.time, beforeValue, after.time, after.value, computedTime);
                }
            }
            else {
                value = before.value;
            }
            return this._toType(value);
        }
        setRampPoint(time) {
            time = this.toSeconds(time);
            let currentVal = this.getValueAtTime(time);
            this.cancelAndHoldAtTime(time);
            if (this._fromType(currentVal) === 0) {
                currentVal = this._toType(this._minOutput);
            }
            this.setValueAtTime(currentVal, time);
            return this;
        }
        linearRampToValueAtTime(value, endTime) {
            const numericValue = this._fromType(value);
            const computedTime = this.toSeconds(endTime);
            assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to linearRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);
            this._assertRange(numericValue);
            this._events.add({
                time: computedTime,
                type: "linearRampToValueAtTime",
                value: numericValue,
            });
            this.log(this.units, "linearRampToValueAtTime", value, computedTime);
            this._param.linearRampToValueAtTime(numericValue, computedTime);
            return this;
        }
        exponentialRampToValueAtTime(value, endTime) {
            let numericValue = this._fromType(value);
            numericValue = Math.max(this._minOutput, numericValue);
            this._assertRange(numericValue);
            const computedTime = this.toSeconds(endTime);
            assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to exponentialRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);
            // store the event
            this._events.add({
                time: computedTime,
                type: "exponentialRampToValueAtTime",
                value: numericValue,
            });
            this.log(this.units, "exponentialRampToValueAtTime", value, computedTime);
            this._param.exponentialRampToValueAtTime(numericValue, computedTime);
            return this;
        }
        exponentialRampTo(value, rampTime, startTime) {
            startTime = this.toSeconds(startTime);
            this.setRampPoint(startTime);
            this.exponentialRampToValueAtTime(value, startTime + this.toSeconds(rampTime));
            return this;
        }
        linearRampTo(value, rampTime, startTime) {
            startTime = this.toSeconds(startTime);
            this.setRampPoint(startTime);
            this.linearRampToValueAtTime(value, startTime + this.toSeconds(rampTime));
            return this;
        }
        targetRampTo(value, rampTime, startTime) {
            startTime = this.toSeconds(startTime);
            this.setRampPoint(startTime);
            this.exponentialApproachValueAtTime(value, startTime, rampTime);
            return this;
        }
        exponentialApproachValueAtTime(value, time, rampTime) {
            time = this.toSeconds(time);
            rampTime = this.toSeconds(rampTime);
            const timeConstant = Math.log(rampTime + 1) / Math.log(200);
            this.setTargetAtTime(value, time, timeConstant);
            // at 90% start a linear ramp to the final value
            this.cancelAndHoldAtTime(time + rampTime * 0.9);
            this.linearRampToValueAtTime(value, time + rampTime);
            return this;
        }
        setTargetAtTime(value, startTime, timeConstant) {
            const numericValue = this._fromType(value);
            // The value will never be able to approach without timeConstant > 0.
            assert(isFinite(timeConstant) && timeConstant > 0, "timeConstant must be a number greater than 0");
            const computedTime = this.toSeconds(startTime);
            this._assertRange(numericValue);
            assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setTargetAtTime: ${JSON.stringify(value)}, ${JSON.stringify(startTime)}`);
            this._events.add({
                constant: timeConstant,
                time: computedTime,
                type: "setTargetAtTime",
                value: numericValue,
            });
            this.log(this.units, "setTargetAtTime", value, computedTime, timeConstant);
            this._param.setTargetAtTime(numericValue, computedTime, timeConstant);
            return this;
        }
        setValueCurveAtTime(values, startTime, duration, scaling = 1) {
            duration = this.toSeconds(duration);
            startTime = this.toSeconds(startTime);
            const startingValue = this._fromType(values[0]) * scaling;
            this.setValueAtTime(this._toType(startingValue), startTime);
            const segTime = duration / (values.length - 1);
            for (let i = 1; i < values.length; i++) {
                const numericValue = this._fromType(values[i]) * scaling;
                this.linearRampToValueAtTime(this._toType(numericValue), startTime + i * segTime);
            }
            return this;
        }
        cancelScheduledValues(time) {
            const computedTime = this.toSeconds(time);
            assert(isFinite(computedTime), `Invalid argument to cancelScheduledValues: ${JSON.stringify(time)}`);
            this._events.cancel(computedTime);
            this._param.cancelScheduledValues(computedTime);
            this.log(this.units, "cancelScheduledValues", computedTime);
            return this;
        }
        cancelAndHoldAtTime(time) {
            const computedTime = this.toSeconds(time);
            const valueAtTime = this._fromType(this.getValueAtTime(computedTime));
            // remove the schedule events
            assert(isFinite(computedTime), `Invalid argument to cancelAndHoldAtTime: ${JSON.stringify(time)}`);
            this.log(this.units, "cancelAndHoldAtTime", computedTime, "value=" + valueAtTime);
            // if there is an event at the given computedTime
            // and that even is not a "set"
            const before = this._events.get(computedTime);
            const after = this._events.getAfter(computedTime);
            if (before && EQ(before.time, computedTime)) {
                // remove everything after
                if (after) {
                    this._param.cancelScheduledValues(after.time);
                    this._events.cancel(after.time);
                }
                else {
                    this._param.cancelAndHoldAtTime(computedTime);
                    this._events.cancel(computedTime + this.sampleTime);
                }
            }
            else if (after) {
                this._param.cancelScheduledValues(after.time);
                // cancel the next event(s)
                this._events.cancel(after.time);
                if (after.type === "linearRampToValueAtTime") {
                    this.linearRampToValueAtTime(this._toType(valueAtTime), computedTime);
                }
                else if (after.type === "exponentialRampToValueAtTime") {
                    this.exponentialRampToValueAtTime(this._toType(valueAtTime), computedTime);
                }
            }
            // set the value at the given time
            this._events.add({
                time: computedTime,
                type: "setValueAtTime",
                value: valueAtTime,
            });
            this._param.setValueAtTime(valueAtTime, computedTime);
            return this;
        }
        rampTo(value, rampTime = 0.1, startTime) {
            if (this.units === "frequency" || this.units === "bpm" || this.units === "decibels") {
                this.exponentialRampTo(value, rampTime, startTime);
            }
            else {
                this.linearRampTo(value, rampTime, startTime);
            }
            return this;
        }
        /**
         * Apply all of the previously scheduled events to the passed in Param or AudioParam.
         * The applied values will start at the context's current time and schedule
         * all of the events which are scheduled on this Param onto the passed in param.
         */
        apply(param) {
            const now = this.context.currentTime;
            // set the param's value at the current time and schedule everything else
            param.setValueAtTime(this.getValueAtTime(now), now);
            // if the previous event was a curve, then set the rest of it
            const previousEvent = this._events.get(now);
            if (previousEvent && previousEvent.type === "setTargetAtTime") {
                // approx it until the next event with linear ramps
                const nextEvent = this._events.getAfter(previousEvent.time);
                // or for 2 seconds if there is no event
                const endTime = nextEvent ? nextEvent.time : now + 2;
                const subdivisions = (endTime - now) / 10;
                for (let i = now; i < endTime; i += subdivisions) {
                    param.linearRampToValueAtTime(this.getValueAtTime(i), i);
                }
            }
            this._events.forEachAfter(this.context.currentTime, event => {
                if (event.type === "cancelScheduledValues") {
                    param.cancelScheduledValues(event.time);
                }
                else if (event.type === "setTargetAtTime") {
                    param.setTargetAtTime(event.value, event.time, event.constant);
                }
                else {
                    param[event.type](event.value, event.time);
                }
            });
            return this;
        }
        /**
         * Replace the Param's internal AudioParam. Will apply scheduled curves
         * onto the parameter and replace the connections.
         */
        setParam(param) {
            assert(this._swappable, "The Param must be assigned as 'swappable' in the constructor");
            const input = this.input;
            input.disconnect(this._param);
            this.apply(param);
            this._param = param;
            input.connect(this._param);
            return this;
        }
        dispose() {
            super.dispose();
            this._events.dispose();
            return this;
        }
        get defaultValue() {
            return this._toType(this._param.defaultValue);
        }
        //-------------------------------------
        // 	AUTOMATION CURVE CALCULATIONS
        // 	MIT License, copyright (c) 2014 Jordan Santell
        //-------------------------------------
        // Calculates the the value along the curve produced by setTargetAtTime
        _exponentialApproach(t0, v0, v1, timeConstant, t) {
            return v1 + (v0 - v1) * Math.exp(-(t - t0) / timeConstant);
        }
        // Calculates the the value along the curve produced by linearRampToValueAtTime
        _linearInterpolate(t0, v0, t1, v1, t) {
            return v0 + (v1 - v0) * ((t - t0) / (t1 - t0));
        }
        // Calculates the the value along the curve produced by exponentialRampToValueAtTime
        _exponentialInterpolate(t0, v0, t1, v1, t) {
            return v0 * Math.pow(v1 / v0, (t - t0) / (t1 - t0));
        }
    }

    /**
     * ToneAudioNode is the base class for classes which process audio.
     */
    class ToneAudioNode extends ToneWithContext {
        constructor() {
            super(...arguments);
            /**
             * The name of the class
             */
            this.name = "ToneAudioNode";
            /**
             * List all of the node that must be set to match the ChannelProperties
             */
            this._internalChannels = [];
        }
        /**
         * The number of inputs feeding into the AudioNode.
         * For source nodes, this will be 0.
         * @example
         * const node = new Tone.Gain();
         * console.log(node.numberOfInputs);
         */
        get numberOfInputs() {
            if (isDefined(this.input)) {
                if (isAudioParam(this.input) || this.input instanceof Param) {
                    return 1;
                }
                else {
                    return this.input.numberOfInputs;
                }
            }
            else {
                return 0;
            }
        }
        /**
         * The number of outputs of the AudioNode.
         * @example
         * const node = new Tone.Gain();
         * console.log(node.numberOfOutputs);
         */
        get numberOfOutputs() {
            if (isDefined(this.output)) {
                return this.output.numberOfOutputs;
            }
            else {
                return 0;
            }
        }
        //-------------------------------------
        // AUDIO PROPERTIES
        //-------------------------------------
        /**
         * Used to decide which nodes to get/set properties on
         */
        _isAudioNode(node) {
            return isDefined(node) && (node instanceof ToneAudioNode || isAudioNode$1(node));
        }
        /**
         * Get all of the audio nodes (either internal or input/output) which together
         * make up how the class node responds to channel input/output
         */
        _getInternalNodes() {
            const nodeList = this._internalChannels.slice(0);
            if (this._isAudioNode(this.input)) {
                nodeList.push(this.input);
            }
            if (this._isAudioNode(this.output)) {
                if (this.input !== this.output) {
                    nodeList.push(this.output);
                }
            }
            return nodeList;
        }
        /**
         * Set the audio options for this node such as channelInterpretation
         * channelCount, etc.
         * @param options
         */
        _setChannelProperties(options) {
            const nodeList = this._getInternalNodes();
            nodeList.forEach(node => {
                node.channelCount = options.channelCount;
                node.channelCountMode = options.channelCountMode;
                node.channelInterpretation = options.channelInterpretation;
            });
        }
        /**
         * Get the current audio options for this node such as channelInterpretation
         * channelCount, etc.
         */
        _getChannelProperties() {
            const nodeList = this._getInternalNodes();
            assert(nodeList.length > 0, "ToneAudioNode does not have any internal nodes");
            // use the first node to get properties
            // they should all be the same
            const node = nodeList[0];
            return {
                channelCount: node.channelCount,
                channelCountMode: node.channelCountMode,
                channelInterpretation: node.channelInterpretation,
            };
        }
        /**
         * channelCount is the number of channels used when up-mixing and down-mixing
         * connections to any inputs to the node. The default value is 2 except for
         * specific nodes where its value is specially determined.
         */
        get channelCount() {
            return this._getChannelProperties().channelCount;
        }
        set channelCount(channelCount) {
            const props = this._getChannelProperties();
            // merge it with the other properties
            this._setChannelProperties(Object.assign(props, { channelCount }));
        }
        /**
         * channelCountMode determines how channels will be counted when up-mixing and
         * down-mixing connections to any inputs to the node.
         * The default value is "max". This attribute has no effect for nodes with no inputs.
         * * "max" - computedNumberOfChannels is the maximum of the number of channels of all connections to an input. In this mode channelCount is ignored.
         * * "clamped-max" - computedNumberOfChannels is determined as for "max" and then clamped to a maximum value of the given channelCount.
         * * "explicit" - computedNumberOfChannels is the exact value as specified by the channelCount.
         */
        get channelCountMode() {
            return this._getChannelProperties().channelCountMode;
        }
        set channelCountMode(channelCountMode) {
            const props = this._getChannelProperties();
            // merge it with the other properties
            this._setChannelProperties(Object.assign(props, { channelCountMode }));
        }
        /**
         * channelInterpretation determines how individual channels will be treated
         * when up-mixing and down-mixing connections to any inputs to the node.
         * The default value is "speakers".
         */
        get channelInterpretation() {
            return this._getChannelProperties().channelInterpretation;
        }
        set channelInterpretation(channelInterpretation) {
            const props = this._getChannelProperties();
            // merge it with the other properties
            this._setChannelProperties(Object.assign(props, { channelInterpretation }));
        }
        //-------------------------------------
        // CONNECTIONS
        //-------------------------------------
        /**
         * connect the output of a ToneAudioNode to an AudioParam, AudioNode, or ToneAudioNode
         * @param destination The output to connect to
         * @param outputNum The output to connect from
         * @param inputNum The input to connect to
         */
        connect(destination, outputNum = 0, inputNum = 0) {
            connect(this, destination, outputNum, inputNum);
            return this;
        }
        /**
         * Connect the output to the context's destination node.
         * @example
         * const osc = new Tone.Oscillator("C2").start();
         * osc.toDestination();
         */
        toDestination() {
            this.connect(this.context.destination);
            return this;
        }
        /**
         * Connect the output to the context's destination node.
         * See [[toDestination]]
         * @deprecated
         */
        toMaster() {
            warn("toMaster() has been renamed toDestination()");
            return this.toDestination();
        }
        /**
         * disconnect the output
         */
        disconnect(destination, outputNum = 0, inputNum = 0) {
            disconnect(this, destination, outputNum, inputNum);
            return this;
        }
        /**
         * Connect the output of this node to the rest of the nodes in series.
         * @example
         * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/handdrum-loop.mp3");
         * player.autostart = true;
         * const filter = new Tone.AutoFilter(4).start();
         * const distortion = new Tone.Distortion(0.5);
         * // connect the player to the filter, distortion and then to the master output
         * player.chain(filter, distortion, Tone.Destination);
         */
        chain(...nodes) {
            connectSeries(this, ...nodes);
            return this;
        }
        /**
         * connect the output of this node to the rest of the nodes in parallel.
         * @example
         * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3");
         * player.autostart = true;
         * const pitchShift = new Tone.PitchShift(4).toDestination();
         * const filter = new Tone.Filter("G5").toDestination();
         * // connect a node to the pitch shift and filter in parallel
         * player.fan(pitchShift, filter);
         */
        fan(...nodes) {
            nodes.forEach(node => this.connect(node));
            return this;
        }
        /**
         * Dispose and disconnect
         */
        dispose() {
            super.dispose();
            if (isDefined(this.input)) {
                if (this.input instanceof ToneAudioNode) {
                    this.input.dispose();
                }
                else if (isAudioNode$1(this.input)) {
                    this.input.disconnect();
                }
            }
            if (isDefined(this.output)) {
                if (this.output instanceof ToneAudioNode) {
                    this.output.dispose();
                }
                else if (isAudioNode$1(this.output)) {
                    this.output.disconnect();
                }
            }
            this._internalChannels = [];
            return this;
        }
    }
    //-------------------------------------
    // CONNECTIONS
    //-------------------------------------
    /**
     * connect together all of the arguments in series
     * @param nodes
     */
    function connectSeries(...nodes) {
        const first = nodes.shift();
        nodes.reduce((prev, current) => {
            if (prev instanceof ToneAudioNode) {
                prev.connect(current);
            }
            else if (isAudioNode$1(prev)) {
                connect(prev, current);
            }
            return current;
        }, first);
    }
    /**
     * Connect two nodes together so that signal flows from the
     * first node to the second. Optionally specify the input and output channels.
     * @param srcNode The source node
     * @param dstNode The destination node
     * @param outputNumber The output channel of the srcNode
     * @param inputNumber The input channel of the dstNode
     */
    function connect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {
        assert(isDefined(srcNode), "Cannot connect from undefined node");
        assert(isDefined(dstNode), "Cannot connect to undefined node");
        if (dstNode instanceof ToneAudioNode || isAudioNode$1(dstNode)) {
            assert(dstNode.numberOfInputs > 0, "Cannot connect to node with no inputs");
        }
        assert(srcNode.numberOfOutputs > 0, "Cannot connect from node with no outputs");
        // resolve the input of the dstNode
        while ((dstNode instanceof ToneAudioNode || dstNode instanceof Param)) {
            if (isDefined(dstNode.input)) {
                dstNode = dstNode.input;
            }
        }
        while (srcNode instanceof ToneAudioNode) {
            if (isDefined(srcNode.output)) {
                srcNode = srcNode.output;
            }
        }
        // make the connection
        if (isAudioParam(dstNode)) {
            srcNode.connect(dstNode, outputNumber);
        }
        else {
            srcNode.connect(dstNode, outputNumber, inputNumber);
        }
    }
    /**
     * Disconnect a node from all nodes or optionally include a destination node and input/output channels.
     * @param srcNode The source node
     * @param dstNode The destination node
     * @param outputNumber The output channel of the srcNode
     * @param inputNumber The input channel of the dstNode
     */
    function disconnect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {
        // resolve the destination node
        if (isDefined(dstNode)) {
            while (dstNode instanceof ToneAudioNode) {
                dstNode = dstNode.input;
            }
        }
        // resolve the src node
        while (!(isAudioNode$1(srcNode))) {
            if (isDefined(srcNode.output)) {
                srcNode = srcNode.output;
            }
        }
        if (isAudioParam(dstNode)) {
            srcNode.disconnect(dstNode, outputNumber);
        }
        else if (isAudioNode$1(dstNode)) {
            srcNode.disconnect(dstNode, outputNumber, inputNumber);
        }
        else {
            srcNode.disconnect();
        }
    }

    /**
     * A thin wrapper around the Native Web Audio GainNode.
     * The GainNode is a basic building block of the Web Audio
     * API and is useful for routing audio and adjusting gains.
     * @category Core
     * @example
     * return Tone.Offline(() => {
     * 	const gainNode = new Tone.Gain(0).toDestination();
     * 	const osc = new Tone.Oscillator(30).connect(gainNode).start();
     * 	gainNode.gain.rampTo(1, 0.1);
     * 	gainNode.gain.rampTo(0, 0.4, 0.2);
     * }, 0.7, 1);
     */
    class Gain extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Gain.getDefaults(), arguments, ["gain", "units"]));
            this.name = "Gain";
            /**
             * The wrapped GainNode.
             */
            this._gainNode = this.context.createGain();
            // input = output
            this.input = this._gainNode;
            this.output = this._gainNode;
            const options = optionsFromArguments(Gain.getDefaults(), arguments, ["gain", "units"]);
            this.gain = new Param({
                context: this.context,
                convert: options.convert,
                param: this._gainNode.gain,
                units: options.units,
                value: options.gain,
                minValue: options.minValue,
                maxValue: options.maxValue,
            });
            readOnly(this, "gain");
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                convert: true,
                gain: 1,
                units: "gain",
            });
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this._gainNode.disconnect();
            this.gain.dispose();
            return this;
        }
    }

    /**
     * Base class for fire-and-forget nodes
     */
    class OneShotSource extends ToneAudioNode {
        constructor(options) {
            super(options);
            /**
             * The callback to invoke after the
             * source is done playing.
             */
            this.onended = noOp;
            /**
             * The start time
             */
            this._startTime = -1;
            /**
             * The stop time
             */
            this._stopTime = -1;
            /**
             * The id of the timeout
             */
            this._timeout = -1;
            /**
             * The public output node
             */
            this.output = new Gain({
                context: this.context,
                gain: 0,
            });
            /**
             * The output gain node.
             */
            this._gainNode = this.output;
            /**
             * Get the playback state at the given time
             */
            this.getStateAtTime = function (time) {
                const computedTime = this.toSeconds(time);
                if (this._startTime !== -1 &&
                    computedTime >= this._startTime &&
                    (this._stopTime === -1 || computedTime <= this._stopTime)) {
                    return "started";
                }
                else {
                    return "stopped";
                }
            };
            this._fadeIn = options.fadeIn;
            this._fadeOut = options.fadeOut;
            this._curve = options.curve;
            this.onended = options.onended;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                curve: "linear",
                fadeIn: 0,
                fadeOut: 0,
                onended: noOp,
            });
        }
        /**
         * Start the source at the given time
         * @param  time When to start the source
         */
        _startGain(time, gain = 1) {
            assert(this._startTime === -1, "Source cannot be started more than once");
            // apply a fade in envelope
            const fadeInTime = this.toSeconds(this._fadeIn);
            // record the start time
            this._startTime = time + fadeInTime;
            this._startTime = Math.max(this._startTime, this.context.currentTime);
            // schedule the envelope
            if (fadeInTime > 0) {
                this._gainNode.gain.setValueAtTime(0, time);
                if (this._curve === "linear") {
                    this._gainNode.gain.linearRampToValueAtTime(gain, time + fadeInTime);
                }
                else {
                    this._gainNode.gain.exponentialApproachValueAtTime(gain, time, fadeInTime);
                }
            }
            else {
                this._gainNode.gain.setValueAtTime(gain, time);
            }
            return this;
        }
        /**
         * Stop the source node at the given time.
         * @param time When to stop the source
         */
        stop(time) {
            this.log("stop", time);
            this._stopGain(this.toSeconds(time));
            return this;
        }
        /**
         * Stop the source at the given time
         * @param  time When to stop the source
         */
        _stopGain(time) {
            assert(this._startTime !== -1, "'start' must be called before 'stop'");
            // cancel the previous stop
            this.cancelStop();
            // the fadeOut time
            const fadeOutTime = this.toSeconds(this._fadeOut);
            // schedule the stop callback
            this._stopTime = this.toSeconds(time) + fadeOutTime;
            this._stopTime = Math.max(this._stopTime, this.context.currentTime);
            if (fadeOutTime > 0) {
                // start the fade out curve at the given time
                if (this._curve === "linear") {
                    this._gainNode.gain.linearRampTo(0, fadeOutTime, time);
                }
                else {
                    this._gainNode.gain.targetRampTo(0, fadeOutTime, time);
                }
            }
            else {
                // stop any ongoing ramps, and set the value to 0
                this._gainNode.gain.cancelAndHoldAtTime(time);
                this._gainNode.gain.setValueAtTime(0, time);
            }
            this.context.clearTimeout(this._timeout);
            this._timeout = this.context.setTimeout(() => {
                // allow additional time for the exponential curve to fully decay
                const additionalTail = this._curve === "exponential" ? fadeOutTime * 2 : 0;
                this._stopSource(this.now() + additionalTail);
                this._onended();
            }, this._stopTime - this.context.currentTime);
            return this;
        }
        /**
         * Invoke the onended callback
         */
        _onended() {
            if (this.onended !== noOp) {
                this.onended(this);
                // overwrite onended to make sure it only is called once
                this.onended = noOp;
                // dispose when it's ended to free up for garbage collection only in the online context
                if (!this.context.isOffline) {
                    const disposeCallback = () => this.dispose();
                    // @ts-ignore
                    if (typeof window.requestIdleCallback !== "undefined") {
                        // @ts-ignore
                        window.requestIdleCallback(disposeCallback);
                    }
                    else {
                        setTimeout(disposeCallback, 1000);
                    }
                }
            }
        }
        /**
         * Get the playback state at the current time
         */
        get state() {
            return this.getStateAtTime(this.now());
        }
        /**
         * Cancel a scheduled stop event
         */
        cancelStop() {
            this.log("cancelStop");
            assert(this._startTime !== -1, "Source is not started");
            // cancel the stop envelope
            this._gainNode.gain.cancelScheduledValues(this._startTime + this.sampleTime);
            this.context.clearTimeout(this._timeout);
            this._stopTime = -1;
            return this;
        }
        dispose() {
            super.dispose();
            this._gainNode.disconnect();
            return this;
        }
    }

    /**
     * Wrapper around the native fire-and-forget ConstantSource.
     * Adds the ability to reschedule the stop method.
     * @category Signal
     */
    class ToneConstantSource extends OneShotSource {
        constructor() {
            super(optionsFromArguments(ToneConstantSource.getDefaults(), arguments, ["offset"]));
            this.name = "ToneConstantSource";
            /**
             * The signal generator
             */
            this._source = this.context.createConstantSource();
            const options = optionsFromArguments(ToneConstantSource.getDefaults(), arguments, ["offset"]);
            connect(this._source, this._gainNode);
            this.offset = new Param({
                context: this.context,
                convert: options.convert,
                param: this._source.offset,
                units: options.units,
                value: options.offset,
                minValue: options.minValue,
                maxValue: options.maxValue,
            });
        }
        static getDefaults() {
            return Object.assign(OneShotSource.getDefaults(), {
                convert: true,
                offset: 1,
                units: "number",
            });
        }
        /**
         * Start the source node at the given time
         * @param  time When to start the source
         */
        start(time) {
            const computedTime = this.toSeconds(time);
            this.log("start", computedTime);
            this._startGain(computedTime);
            this._source.start(computedTime);
            return this;
        }
        _stopSource(time) {
            this._source.stop(time);
        }
        dispose() {
            super.dispose();
            if (this.state === "started") {
                this.stop();
            }
            this._source.disconnect();
            this.offset.dispose();
            return this;
        }
    }

    /**
     * A signal is an audio-rate value. Tone.Signal is a core component of the library.
     * Unlike a number, Signals can be scheduled with sample-level accuracy. Tone.Signal
     * has all of the methods available to native Web Audio
     * [AudioParam](http://webaudio.github.io/web-audio-api/#the-audioparam-interface)
     * as well as additional conveniences. Read more about working with signals
     * [here](https://github.com/Tonejs/Tone.js/wiki/Signals).
     *
     * @example
     * const osc = new Tone.Oscillator().toDestination().start();
     * // a scheduleable signal which can be connected to control an AudioParam or another Signal
     * const signal = new Tone.Signal({
     * 	value: "C4",
     * 	units: "frequency"
     * }).connect(osc.frequency);
     * // the scheduled ramp controls the connected signal
     * signal.rampTo("C2", 4, "+0.5");
     * @category Signal
     */
    class Signal extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Signal.getDefaults(), arguments, ["value", "units"]));
            this.name = "Signal";
            /**
             * Indicates if the value should be overridden on connection.
             */
            this.override = true;
            const options = optionsFromArguments(Signal.getDefaults(), arguments, ["value", "units"]);
            this.output = this._constantSource = new ToneConstantSource({
                context: this.context,
                convert: options.convert,
                offset: options.value,
                units: options.units,
                minValue: options.minValue,
                maxValue: options.maxValue,
            });
            this._constantSource.start(0);
            this.input = this._param = this._constantSource.offset;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                convert: true,
                units: "number",
                value: 0,
            });
        }
        connect(destination, outputNum = 0, inputNum = 0) {
            // start it only when connected to something
            connectSignal(this, destination, outputNum, inputNum);
            return this;
        }
        dispose() {
            super.dispose();
            this._param.dispose();
            this._constantSource.dispose();
            return this;
        }
        //-------------------------------------
        // ABSTRACT PARAM INTERFACE
        // just a proxy for the ConstantSourceNode's offset AudioParam
        // all docs are generated from AbstractParam.ts
        //-------------------------------------
        setValueAtTime(value, time) {
            this._param.setValueAtTime(value, time);
            return this;
        }
        getValueAtTime(time) {
            return this._param.getValueAtTime(time);
        }
        setRampPoint(time) {
            this._param.setRampPoint(time);
            return this;
        }
        linearRampToValueAtTime(value, time) {
            this._param.linearRampToValueAtTime(value, time);
            return this;
        }
        exponentialRampToValueAtTime(value, time) {
            this._param.exponentialRampToValueAtTime(value, time);
            return this;
        }
        exponentialRampTo(value, rampTime, startTime) {
            this._param.exponentialRampTo(value, rampTime, startTime);
            return this;
        }
        linearRampTo(value, rampTime, startTime) {
            this._param.linearRampTo(value, rampTime, startTime);
            return this;
        }
        targetRampTo(value, rampTime, startTime) {
            this._param.targetRampTo(value, rampTime, startTime);
            return this;
        }
        exponentialApproachValueAtTime(value, time, rampTime) {
            this._param.exponentialApproachValueAtTime(value, time, rampTime);
            return this;
        }
        setTargetAtTime(value, startTime, timeConstant) {
            this._param.setTargetAtTime(value, startTime, timeConstant);
            return this;
        }
        setValueCurveAtTime(values, startTime, duration, scaling) {
            this._param.setValueCurveAtTime(values, startTime, duration, scaling);
            return this;
        }
        cancelScheduledValues(time) {
            this._param.cancelScheduledValues(time);
            return this;
        }
        cancelAndHoldAtTime(time) {
            this._param.cancelAndHoldAtTime(time);
            return this;
        }
        rampTo(value, rampTime, startTime) {
            this._param.rampTo(value, rampTime, startTime);
            return this;
        }
        get value() {
            return this._param.value;
        }
        set value(value) {
            this._param.value = value;
        }
        get convert() {
            return this._param.convert;
        }
        set convert(convert) {
            this._param.convert = convert;
        }
        get units() {
            return this._param.units;
        }
        get overridden() {
            return this._param.overridden;
        }
        set overridden(overridden) {
            this._param.overridden = overridden;
        }
        get maxValue() {
            return this._param.maxValue;
        }
        get minValue() {
            return this._param.minValue;
        }
        /**
         * See [[Param.apply]].
         */
        apply(param) {
            this._param.apply(param);
            return this;
        }
    }
    /**
     * When connecting from a signal, it's necessary to zero out the node destination
     * node if that node is also a signal. If the destination is not 0, then the values
     * will be summed. This method insures that the output of the destination signal will
     * be the same as the source signal, making the destination signal a pass through node.
     * @param signal The output signal to connect from
     * @param destination the destination to connect to
     * @param outputNum the optional output number
     * @param inputNum the input number
     */
    function connectSignal(signal, destination, outputNum, inputNum) {
        if (destination instanceof Param || isAudioParam(destination) ||
            (destination instanceof Signal && destination.override)) {
            // cancel changes
            destination.cancelScheduledValues(0);
            // reset the value
            destination.setValueAtTime(0, 0);
            // mark the value as overridden
            if (destination instanceof Signal) {
                destination.overridden = true;
            }
        }
        connect(signal, destination, outputNum, inputNum);
    }

    /**
     * A Param class just for computing ticks. Similar to the [[Param]] class,
     * but offers conversion to BPM values as well as ability to compute tick
     * duration and elapsed ticks
     */
    class TickParam extends Param {
        constructor() {
            super(optionsFromArguments(TickParam.getDefaults(), arguments, ["value"]));
            this.name = "TickParam";
            /**
             * The timeline which tracks all of the automations.
             */
            this._events = new Timeline(Infinity);
            /**
             * The internal holder for the multiplier value
             */
            this._multiplier = 1;
            const options = optionsFromArguments(TickParam.getDefaults(), arguments, ["value"]);
            // set the multiplier
            this._multiplier = options.multiplier;
            // clear the ticks from the beginning
            this._events.cancel(0);
            // set an initial event
            this._events.add({
                ticks: 0,
                time: 0,
                type: "setValueAtTime",
                value: this._fromType(options.value),
            });
            this.setValueAtTime(options.value, 0);
        }
        static getDefaults() {
            return Object.assign(Param.getDefaults(), {
                multiplier: 1,
                units: "hertz",
                value: 1,
            });
        }
        setTargetAtTime(value, time, constant) {
            // approximate it with multiple linear ramps
            time = this.toSeconds(time);
            this.setRampPoint(time);
            const computedValue = this._fromType(value);
            // start from previously scheduled value
            const prevEvent = this._events.get(time);
            const segments = Math.round(Math.max(1 / constant, 1));
            for (let i = 0; i <= segments; i++) {
                const segTime = constant * i + time;
                const rampVal = this._exponentialApproach(prevEvent.time, prevEvent.value, computedValue, constant, segTime);
                this.linearRampToValueAtTime(this._toType(rampVal), segTime);
            }
            return this;
        }
        setValueAtTime(value, time) {
            const computedTime = this.toSeconds(time);
            super.setValueAtTime(value, time);
            const event = this._events.get(computedTime);
            const previousEvent = this._events.previousEvent(event);
            const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);
            event.ticks = Math.max(ticksUntilTime, 0);
            return this;
        }
        linearRampToValueAtTime(value, time) {
            const computedTime = this.toSeconds(time);
            super.linearRampToValueAtTime(value, time);
            const event = this._events.get(computedTime);
            const previousEvent = this._events.previousEvent(event);
            const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);
            event.ticks = Math.max(ticksUntilTime, 0);
            return this;
        }
        exponentialRampToValueAtTime(value, time) {
            // aproximate it with multiple linear ramps
            time = this.toSeconds(time);
            const computedVal = this._fromType(value);
            // start from previously scheduled value
            const prevEvent = this._events.get(time);
            // approx 10 segments per second
            const segments = Math.round(Math.max((time - prevEvent.time) * 10, 1));
            const segmentDur = ((time - prevEvent.time) / segments);
            for (let i = 0; i <= segments; i++) {
                const segTime = segmentDur * i + prevEvent.time;
                const rampVal = this._exponentialInterpolate(prevEvent.time, prevEvent.value, time, computedVal, segTime);
                this.linearRampToValueAtTime(this._toType(rampVal), segTime);
            }
            return this;
        }
        /**
         * Returns the tick value at the time. Takes into account
         * any automation curves scheduled on the signal.
         * @param  event The time to get the tick count at
         * @return The number of ticks which have elapsed at the time given any automations.
         */
        _getTicksUntilEvent(event, time) {
            if (event === null) {
                event = {
                    ticks: 0,
                    time: 0,
                    type: "setValueAtTime",
                    value: 0,
                };
            }
            else if (isUndef(event.ticks)) {
                const previousEvent = this._events.previousEvent(event);
                event.ticks = this._getTicksUntilEvent(previousEvent, event.time);
            }
            const val0 = this._fromType(this.getValueAtTime(event.time));
            let val1 = this._fromType(this.getValueAtTime(time));
            // if it's right on the line, take the previous value
            const onTheLineEvent = this._events.get(time);
            if (onTheLineEvent && onTheLineEvent.time === time && onTheLineEvent.type === "setValueAtTime") {
                val1 = this._fromType(this.getValueAtTime(time - this.sampleTime));
            }
            return 0.5 * (time - event.time) * (val0 + val1) + event.ticks;
        }
        /**
         * Returns the tick value at the time. Takes into account
         * any automation curves scheduled on the signal.
         * @param  time The time to get the tick count at
         * @return The number of ticks which have elapsed at the time given any automations.
         */
        getTicksAtTime(time) {
            const computedTime = this.toSeconds(time);
            const event = this._events.get(computedTime);
            return Math.max(this._getTicksUntilEvent(event, computedTime), 0);
        }
        /**
         * Return the elapsed time of the number of ticks from the given time
         * @param ticks The number of ticks to calculate
         * @param  time The time to get the next tick from
         * @return The duration of the number of ticks from the given time in seconds
         */
        getDurationOfTicks(ticks, time) {
            const computedTime = this.toSeconds(time);
            const currentTick = this.getTicksAtTime(time);
            return this.getTimeOfTick(currentTick + ticks) - computedTime;
        }
        /**
         * Given a tick, returns the time that tick occurs at.
         * @return The time that the tick occurs.
         */
        getTimeOfTick(tick) {
            const before = this._events.get(tick, "ticks");
            const after = this._events.getAfter(tick, "ticks");
            if (before && before.ticks === tick) {
                return before.time;
            }
            else if (before && after &&
                after.type === "linearRampToValueAtTime" &&
                before.value !== after.value) {
                const val0 = this._fromType(this.getValueAtTime(before.time));
                const val1 = this._fromType(this.getValueAtTime(after.time));
                const delta = (val1 - val0) / (after.time - before.time);
                const k = Math.sqrt(Math.pow(val0, 2) - 2 * delta * (before.ticks - tick));
                const sol1 = (-val0 + k) / delta;
                const sol2 = (-val0 - k) / delta;
                return (sol1 > 0 ? sol1 : sol2) + before.time;
            }
            else if (before) {
                if (before.value === 0) {
                    return Infinity;
                }
                else {
                    return before.time + (tick - before.ticks) / before.value;
                }
            }
            else {
                return tick / this._initialValue;
            }
        }
        /**
         * Convert some number of ticks their the duration in seconds accounting
         * for any automation curves starting at the given time.
         * @param  ticks The number of ticks to convert to seconds.
         * @param  when  When along the automation timeline to convert the ticks.
         * @return The duration in seconds of the ticks.
         */
        ticksToTime(ticks, when) {
            return this.getDurationOfTicks(ticks, when);
        }
        /**
         * The inverse of [[ticksToTime]]. Convert a duration in
         * seconds to the corresponding number of ticks accounting for any
         * automation curves starting at the given time.
         * @param  duration The time interval to convert to ticks.
         * @param  when When along the automation timeline to convert the ticks.
         * @return The duration in ticks.
         */
        timeToTicks(duration, when) {
            const computedTime = this.toSeconds(when);
            const computedDuration = this.toSeconds(duration);
            const startTicks = this.getTicksAtTime(computedTime);
            const endTicks = this.getTicksAtTime(computedTime + computedDuration);
            return endTicks - startTicks;
        }
        /**
         * Convert from the type when the unit value is BPM
         */
        _fromType(val) {
            if (this.units === "bpm" && this.multiplier) {
                return 1 / (60 / val / this.multiplier);
            }
            else {
                return super._fromType(val);
            }
        }
        /**
         * Special case of type conversion where the units === "bpm"
         */
        _toType(val) {
            if (this.units === "bpm" && this.multiplier) {
                return (val / this.multiplier) * 60;
            }
            else {
                return super._toType(val);
            }
        }
        /**
         * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.
         */
        get multiplier() {
            return this._multiplier;
        }
        set multiplier(m) {
            // get and reset the current value with the new multiplier
            // might be necessary to clear all the previous values
            const currentVal = this.value;
            this._multiplier = m;
            this.cancelScheduledValues(0);
            this.setValueAtTime(currentVal, 0);
        }
    }

    /**
     * TickSignal extends Tone.Signal, but adds the capability
     * to calculate the number of elapsed ticks. exponential and target curves
     * are approximated with multiple linear ramps.
     *
     * Thank you Bruno Dias, H. Sofia Pinto, and David M. Matos,
     * for your [WAC paper](https://smartech.gatech.edu/bitstream/handle/1853/54588/WAC2016-49.pdf)
     * describing integrating timing functions for tempo calculations.
     */
    class TickSignal extends Signal {
        constructor() {
            super(optionsFromArguments(TickSignal.getDefaults(), arguments, ["value"]));
            this.name = "TickSignal";
            const options = optionsFromArguments(TickSignal.getDefaults(), arguments, ["value"]);
            this.input = this._param = new TickParam({
                context: this.context,
                convert: options.convert,
                multiplier: options.multiplier,
                param: this._constantSource.offset,
                units: options.units,
                value: options.value,
            });
        }
        static getDefaults() {
            return Object.assign(Signal.getDefaults(), {
                multiplier: 1,
                units: "hertz",
                value: 1,
            });
        }
        ticksToTime(ticks, when) {
            return this._param.ticksToTime(ticks, when);
        }
        timeToTicks(duration, when) {
            return this._param.timeToTicks(duration, when);
        }
        getTimeOfTick(tick) {
            return this._param.getTimeOfTick(tick);
        }
        getDurationOfTicks(ticks, time) {
            return this._param.getDurationOfTicks(ticks, time);
        }
        getTicksAtTime(time) {
            return this._param.getTicksAtTime(time);
        }
        /**
         * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.
         */
        get multiplier() {
            return this._param.multiplier;
        }
        set multiplier(m) {
            this._param.multiplier = m;
        }
        dispose() {
            super.dispose();
            this._param.dispose();
            return this;
        }
    }

    /**
     * Uses [TickSignal](TickSignal) to track elapsed ticks with complex automation curves.
     */
    class TickSource extends ToneWithContext {
        constructor() {
            super(optionsFromArguments(TickSource.getDefaults(), arguments, ["frequency"]));
            this.name = "TickSource";
            /**
             * The state timeline
             */
            this._state = new StateTimeline();
            /**
             * The offset values of the ticks
             */
            this._tickOffset = new Timeline();
            const options = optionsFromArguments(TickSource.getDefaults(), arguments, ["frequency"]);
            this.frequency = new TickSignal({
                context: this.context,
                units: options.units,
                value: options.frequency,
            });
            readOnly(this, "frequency");
            // set the initial state
            this._state.setStateAtTime("stopped", 0);
            // add the first event
            this.setTicksAtTime(0, 0);
        }
        static getDefaults() {
            return Object.assign({
                frequency: 1,
                units: "hertz",
            }, ToneWithContext.getDefaults());
        }
        /**
         * Returns the playback state of the source, either "started", "stopped" or "paused".
         */
        get state() {
            return this.getStateAtTime(this.now());
        }
        /**
         * Start the clock at the given time. Optionally pass in an offset
         * of where to start the tick counter from.
         * @param  time    The time the clock should start
         * @param offset The number of ticks to start the source at
         */
        start(time, offset) {
            const computedTime = this.toSeconds(time);
            if (this._state.getValueAtTime(computedTime) !== "started") {
                this._state.setStateAtTime("started", computedTime);
                if (isDefined(offset)) {
                    this.setTicksAtTime(offset, computedTime);
                }
            }
            return this;
        }
        /**
         * Stop the clock. Stopping the clock resets the tick counter to 0.
         * @param time The time when the clock should stop.
         */
        stop(time) {
            const computedTime = this.toSeconds(time);
            // cancel the previous stop
            if (this._state.getValueAtTime(computedTime) === "stopped") {
                const event = this._state.get(computedTime);
                if (event && event.time > 0) {
                    this._tickOffset.cancel(event.time);
                    this._state.cancel(event.time);
                }
            }
            this._state.cancel(computedTime);
            this._state.setStateAtTime("stopped", computedTime);
            this.setTicksAtTime(0, computedTime);
            return this;
        }
        /**
         * Pause the clock. Pausing does not reset the tick counter.
         * @param time The time when the clock should stop.
         */
        pause(time) {
            const computedTime = this.toSeconds(time);
            if (this._state.getValueAtTime(computedTime) === "started") {
                this._state.setStateAtTime("paused", computedTime);
            }
            return this;
        }
        /**
         * Cancel start/stop/pause and setTickAtTime events scheduled after the given time.
         * @param time When to clear the events after
         */
        cancel(time) {
            time = this.toSeconds(time);
            this._state.cancel(time);
            this._tickOffset.cancel(time);
            return this;
        }
        /**
         * Get the elapsed ticks at the given time
         * @param  time  When to get the tick value
         * @return The number of ticks
         */
        getTicksAtTime(time) {
            const computedTime = this.toSeconds(time);
            const stopEvent = this._state.getLastState("stopped", computedTime);
            // this event allows forEachBetween to iterate until the current time
            const tmpEvent = { state: "paused", time: computedTime };
            this._state.add(tmpEvent);
            // keep track of the previous offset event
            let lastState = stopEvent;
            let elapsedTicks = 0;
            // iterate through all the events since the last stop
            this._state.forEachBetween(stopEvent.time, computedTime + this.sampleTime, e => {
                let periodStartTime = lastState.time;
                // if there is an offset event in this period use that
                const offsetEvent = this._tickOffset.get(e.time);
                if (offsetEvent && offsetEvent.time >= lastState.time) {
                    elapsedTicks = offsetEvent.ticks;
                    periodStartTime = offsetEvent.time;
                }
                if (lastState.state === "started" && e.state !== "started") {
                    elapsedTicks += this.frequency.getTicksAtTime(e.time) - this.frequency.getTicksAtTime(periodStartTime);
                }
                lastState = e;
            });
            // remove the temporary event
            this._state.remove(tmpEvent);
            // return the ticks
            return elapsedTicks;
        }
        /**
         * The number of times the callback was invoked. Starts counting at 0
         * and increments after the callback was invoked. Returns -1 when stopped.
         */
        get ticks() {
            return this.getTicksAtTime(this.now());
        }
        set ticks(t) {
            this.setTicksAtTime(t, this.now());
        }
        /**
         * The time since ticks=0 that the TickSource has been running. Accounts
         * for tempo curves
         */
        get seconds() {
            return this.getSecondsAtTime(this.now());
        }
        set seconds(s) {
            const now = this.now();
            const ticks = this.frequency.timeToTicks(s, now);
            this.setTicksAtTime(ticks, now);
        }
        /**
         * Return the elapsed seconds at the given time.
         * @param  time  When to get the elapsed seconds
         * @return  The number of elapsed seconds
         */
        getSecondsAtTime(time) {
            time = this.toSeconds(time);
            const stopEvent = this._state.getLastState("stopped", time);
            // this event allows forEachBetween to iterate until the current time
            const tmpEvent = { state: "paused", time };
            this._state.add(tmpEvent);
            // keep track of the previous offset event
            let lastState = stopEvent;
            let elapsedSeconds = 0;
            // iterate through all the events since the last stop
            this._state.forEachBetween(stopEvent.time, time + this.sampleTime, e => {
                let periodStartTime = lastState.time;
                // if there is an offset event in this period use that
                const offsetEvent = this._tickOffset.get(e.time);
                if (offsetEvent && offsetEvent.time >= lastState.time) {
                    elapsedSeconds = offsetEvent.seconds;
                    periodStartTime = offsetEvent.time;
                }
                if (lastState.state === "started" && e.state !== "started") {
                    elapsedSeconds += e.time - periodStartTime;
                }
                lastState = e;
            });
            // remove the temporary event
            this._state.remove(tmpEvent);
            // return the ticks
            return elapsedSeconds;
        }
        /**
         * Set the clock's ticks at the given time.
         * @param  ticks The tick value to set
         * @param  time  When to set the tick value
         */
        setTicksAtTime(ticks, time) {
            time = this.toSeconds(time);
            this._tickOffset.cancel(time);
            this._tickOffset.add({
                seconds: this.frequency.getDurationOfTicks(ticks, time),
                ticks,
                time,
            });
            return this;
        }
        /**
         * Returns the scheduled state at the given time.
         * @param  time  The time to query.
         */
        getStateAtTime(time) {
            time = this.toSeconds(time);
            return this._state.getValueAtTime(time);
        }
        /**
         * Get the time of the given tick. The second argument
         * is when to test before. Since ticks can be set (with setTicksAtTime)
         * there may be multiple times for a given tick value.
         * @param  tick The tick number.
         * @param  before When to measure the tick value from.
         * @return The time of the tick
         */
        getTimeOfTick(tick, before = this.now()) {
            const offset = this._tickOffset.get(before);
            const event = this._state.get(before);
            const startTime = Math.max(offset.time, event.time);
            const absoluteTicks = this.frequency.getTicksAtTime(startTime) + tick - offset.ticks;
            return this.frequency.getTimeOfTick(absoluteTicks);
        }
        /**
         * Invoke the callback event at all scheduled ticks between the
         * start time and the end time
         * @param  startTime  The beginning of the search range
         * @param  endTime    The end of the search range
         * @param  callback   The callback to invoke with each tick
         */
        forEachTickBetween(startTime, endTime, callback) {
            // only iterate through the sections where it is "started"
            let lastStateEvent = this._state.get(startTime);
            this._state.forEachBetween(startTime, endTime, event => {
                if (lastStateEvent && lastStateEvent.state === "started" && event.state !== "started") {
                    this.forEachTickBetween(Math.max(lastStateEvent.time, startTime), event.time - this.sampleTime, callback);
                }
                lastStateEvent = event;
            });
            let error = null;
            if (lastStateEvent && lastStateEvent.state === "started") {
                const maxStartTime = Math.max(lastStateEvent.time, startTime);
                // figure out the difference between the frequency ticks and the
                const startTicks = this.frequency.getTicksAtTime(maxStartTime);
                const ticksAtStart = this.frequency.getTicksAtTime(lastStateEvent.time);
                const diff = startTicks - ticksAtStart;
                let offset = Math.ceil(diff) - diff;
                // guard against floating point issues
                offset = EQ(offset, 1) ? 0 : offset;
                let nextTickTime = this.frequency.getTimeOfTick(startTicks + offset);
                while (nextTickTime < endTime) {
                    try {
                        callback(nextTickTime, Math.round(this.getTicksAtTime(nextTickTime)));
                    }
                    catch (e) {
                        error = e;
                        break;
                    }
                    nextTickTime += this.frequency.getDurationOfTicks(1, nextTickTime);
                }
            }
            if (error) {
                throw error;
            }
            return this;
        }
        /**
         * Clean up
         */
        dispose() {
            super.dispose();
            this._state.dispose();
            this._tickOffset.dispose();
            this.frequency.dispose();
            return this;
        }
    }

    /**
     * A sample accurate clock which provides a callback at the given rate.
     * While the callback is not sample-accurate (it is still susceptible to
     * loose JS timing), the time passed in as the argument to the callback
     * is precise. For most applications, it is better to use Tone.Transport
     * instead of the Clock by itself since you can synchronize multiple callbacks.
     * @example
     * // the callback will be invoked approximately once a second
     * // and will print the time exactly once a second apart.
     * const clock = new Tone.Clock(time => {
     * 	console.log(time);
     * }, 1);
     * clock.start();
     * @category Core
     */
    class Clock extends ToneWithContext {
        constructor() {
            super(optionsFromArguments(Clock.getDefaults(), arguments, ["callback", "frequency"]));
            this.name = "Clock";
            /**
             * The callback function to invoke at the scheduled tick.
             */
            this.callback = noOp;
            /**
             * The last time the loop callback was invoked
             */
            this._lastUpdate = 0;
            /**
             * Keep track of the playback state
             */
            this._state = new StateTimeline("stopped");
            /**
             * Context bound reference to the _loop method
             * This is necessary to remove the event in the end.
             */
            this._boundLoop = this._loop.bind(this);
            const options = optionsFromArguments(Clock.getDefaults(), arguments, ["callback", "frequency"]);
            this.callback = options.callback;
            this._tickSource = new TickSource({
                context: this.context,
                frequency: options.frequency,
                units: options.units,
            });
            this._lastUpdate = 0;
            this.frequency = this._tickSource.frequency;
            readOnly(this, "frequency");
            // add an initial state
            this._state.setStateAtTime("stopped", 0);
            // bind a callback to the worker thread
            this.context.on("tick", this._boundLoop);
        }
        static getDefaults() {
            return Object.assign(ToneWithContext.getDefaults(), {
                callback: noOp,
                frequency: 1,
                units: "hertz",
            });
        }
        /**
         * Returns the playback state of the source, either "started", "stopped" or "paused".
         */
        get state() {
            return this._state.getValueAtTime(this.now());
        }
        /**
         * Start the clock at the given time. Optionally pass in an offset
         * of where to start the tick counter from.
         * @param  time    The time the clock should start
         * @param offset  Where the tick counter starts counting from.
         */
        start(time, offset) {
            // make sure the context is running
            assertContextRunning(this.context);
            // start the loop
            const computedTime = this.toSeconds(time);
            this.log("start", computedTime);
            if (this._state.getValueAtTime(computedTime) !== "started") {
                this._state.setStateAtTime("started", computedTime);
                this._tickSource.start(computedTime, offset);
                if (computedTime < this._lastUpdate) {
                    this.emit("start", computedTime, offset);
                }
            }
            return this;
        }
        /**
         * Stop the clock. Stopping the clock resets the tick counter to 0.
         * @param time The time when the clock should stop.
         * @example
         * const clock = new Tone.Clock(time => {
         * 	console.log(time);
         * }, 1);
         * clock.start();
         * // stop the clock after 10 seconds
         * clock.stop("+10");
         */
        stop(time) {
            const computedTime = this.toSeconds(time);
            this.log("stop", computedTime);
            this._state.cancel(computedTime);
            this._state.setStateAtTime("stopped", computedTime);
            this._tickSource.stop(computedTime);
            if (computedTime < this._lastUpdate) {
                this.emit("stop", computedTime);
            }
            return this;
        }
        /**
         * Pause the clock. Pausing does not reset the tick counter.
         * @param time The time when the clock should stop.
         */
        pause(time) {
            const computedTime = this.toSeconds(time);
            if (this._state.getValueAtTime(computedTime) === "started") {
                this._state.setStateAtTime("paused", computedTime);
                this._tickSource.pause(computedTime);
                if (computedTime < this._lastUpdate) {
                    this.emit("pause", computedTime);
                }
            }
            return this;
        }
        /**
         * The number of times the callback was invoked. Starts counting at 0
         * and increments after the callback was invoked.
         */
        get ticks() {
            return Math.ceil(this.getTicksAtTime(this.now()));
        }
        set ticks(t) {
            this._tickSource.ticks = t;
        }
        /**
         * The time since ticks=0 that the Clock has been running. Accounts for tempo curves
         */
        get seconds() {
            return this._tickSource.seconds;
        }
        set seconds(s) {
            this._tickSource.seconds = s;
        }
        /**
         * Return the elapsed seconds at the given time.
         * @param  time  When to get the elapsed seconds
         * @return  The number of elapsed seconds
         */
        getSecondsAtTime(time) {
            return this._tickSource.getSecondsAtTime(time);
        }
        /**
         * Set the clock's ticks at the given time.
         * @param  ticks The tick value to set
         * @param  time  When to set the tick value
         */
        setTicksAtTime(ticks, time) {
            this._tickSource.setTicksAtTime(ticks, time);
            return this;
        }
        /**
         * Get the time of the given tick. The second argument
         * is when to test before. Since ticks can be set (with setTicksAtTime)
         * there may be multiple times for a given tick value.
         * @param  tick The tick number.
         * @param  before When to measure the tick value from.
         * @return The time of the tick
         */
        getTimeOfTick(tick, before = this.now()) {
            return this._tickSource.getTimeOfTick(tick, before);
        }
        /**
         * Get the clock's ticks at the given time.
         * @param  time  When to get the tick value
         * @return The tick value at the given time.
         */
        getTicksAtTime(time) {
            return this._tickSource.getTicksAtTime(time);
        }
        /**
         * Get the time of the next tick
         * @param  offset The tick number.
         */
        nextTickTime(offset, when) {
            const computedTime = this.toSeconds(when);
            const currentTick = this.getTicksAtTime(computedTime);
            return this._tickSource.getTimeOfTick(currentTick + offset, computedTime);
        }
        /**
         * The scheduling loop.
         */
        _loop() {
            const startTime = this._lastUpdate;
            const endTime = this.now();
            this._lastUpdate = endTime;
            this.log("loop", startTime, endTime);
            if (startTime !== endTime) {
                // the state change events
                this._state.forEachBetween(startTime, endTime, e => {
                    switch (e.state) {
                        case "started":
                            const offset = this._tickSource.getTicksAtTime(e.time);
                            this.emit("start", e.time, offset);
                            break;
                        case "stopped":
                            if (e.time !== 0) {
                                this.emit("stop", e.time);
                            }
                            break;
                        case "paused":
                            this.emit("pause", e.time);
                            break;
                    }
                });
                // the tick callbacks
                this._tickSource.forEachTickBetween(startTime, endTime, (time, ticks) => {
                    this.callback(time, ticks);
                });
            }
        }
        /**
         * Returns the scheduled state at the given time.
         * @param  time  The time to query.
         * @return  The name of the state input in setStateAtTime.
         * @example
         * const clock = new Tone.Clock();
         * clock.start("+0.1");
         * clock.getStateAtTime("+0.1"); // returns "started"
         */
        getStateAtTime(time) {
            const computedTime = this.toSeconds(time);
            return this._state.getValueAtTime(computedTime);
        }
        /**
         * Clean up
         */
        dispose() {
            super.dispose();
            this.context.off("tick", this._boundLoop);
            this._tickSource.dispose();
            this._state.dispose();
            return this;
        }
    }
    Emitter.mixin(Clock);

    /**
     * Wrapper around Web Audio's native [DelayNode](http://webaudio.github.io/web-audio-api/#the-delaynode-interface).
     * @category Core
     * @example
     * return Tone.Offline(() => {
     * 	const delay = new Tone.Delay(0.1).toDestination();
     * 	// connect the signal to both the delay and the destination
     * 	const pulse = new Tone.PulseOscillator().connect(delay).toDestination();
     * 	// start and stop the pulse
     * 	pulse.start(0).stop(0.01);
     * }, 0.5, 1);
     */
    class Delay extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Delay.getDefaults(), arguments, ["delayTime", "maxDelay"]));
            this.name = "Delay";
            const options = optionsFromArguments(Delay.getDefaults(), arguments, ["delayTime", "maxDelay"]);
            const maxDelayInSeconds = this.toSeconds(options.maxDelay);
            this._maxDelay = Math.max(maxDelayInSeconds, this.toSeconds(options.delayTime));
            this._delayNode = this.input = this.output = this.context.createDelay(maxDelayInSeconds);
            this.delayTime = new Param({
                context: this.context,
                param: this._delayNode.delayTime,
                units: "time",
                value: options.delayTime,
                minValue: 0,
                maxValue: this.maxDelay,
            });
            readOnly(this, "delayTime");
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                delayTime: 0,
                maxDelay: 1,
            });
        }
        /**
         * The maximum delay time. This cannot be changed after
         * the value is passed into the constructor.
         */
        get maxDelay() {
            return this._maxDelay;
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this._delayNode.disconnect();
            this.delayTime.dispose();
            return this;
        }
    }

    /**
     * Generate a buffer by rendering all of the Tone.js code within the callback using the OfflineAudioContext.
     * The OfflineAudioContext is capable of rendering much faster than real time in many cases.
     * The callback function also passes in an offline instance of [[Context]] which can be used
     * to schedule events along the Transport.
     * @param  callback  All Tone.js nodes which are created and scheduled within this callback are recorded into the output Buffer.
     * @param  duration     the amount of time to record for.
     * @return  The promise which is invoked with the ToneAudioBuffer of the recorded output.
     * @example
     * // render 2 seconds of the oscillator
     * Tone.Offline(() => {
     * 	// only nodes created in this callback will be recorded
     * 	const oscillator = new Tone.Oscillator().toDestination().start(0);
     * }, 2).then((buffer) => {
     * 	// do something with the output buffer
     * 	console.log(buffer);
     * });
     * @example
     * // can also schedule events along the Transport
     * // using the passed in Offline Transport
     * Tone.Offline(({ transport }) => {
     * 	const osc = new Tone.Oscillator().toDestination();
     * 	transport.schedule(time => {
     * 		osc.start(time).stop(time + 0.1);
     * 	}, 1);
     * 	// make sure to start the transport
     * 	transport.start(0.2);
     * }, 4).then((buffer) => {
     * 	// do something with the output buffer
     * 	console.log(buffer);
     * });
     * @category Core
     */
    function Offline(callback, duration, channels = 2, sampleRate = getContext().sampleRate) {
        return __awaiter(this, void 0, void 0, function* () {
            // set the OfflineAudioContext based on the current context
            const originalContext = getContext();
            const context = new OfflineContext(channels, duration, sampleRate);
            setContext(context);
            // invoke the callback/scheduling
            yield callback(context);
            // then render the audio
            const bufferPromise = context.render();
            // return the original AudioContext
            setContext(originalContext);
            // await the rendering
            const buffer = yield bufferPromise;
            // return the audio
            return new ToneAudioBuffer(buffer);
        });
    }

    /**
     * A data structure for holding multiple buffers in a Map-like datastructure.
     *
     * @example
     * const pianoSamples = new Tone.ToneAudioBuffers({
     * 	A1: "https://tonejs.github.io/audio/casio/A1.mp3",
     * 	A2: "https://tonejs.github.io/audio/casio/A2.mp3",
     * }, () => {
     * 	const player = new Tone.Player().toDestination();
     * 	// play one of the samples when they all load
     * 	player.buffer = pianoSamples.get("A2");
     * 	player.start();
     * });
     * @example
     * // To pass in additional parameters in the second parameter
     * const buffers = new Tone.ToneAudioBuffers({
     * 	 urls: {
     * 		 A1: "A1.mp3",
     * 		 A2: "A2.mp3",
     * 	 },
     * 	 onload: () => console.log("loaded"),
     * 	 baseUrl: "https://tonejs.github.io/audio/casio/"
     * });
     * @category Core
     */
    class ToneAudioBuffers extends Tone {
        constructor() {
            super();
            this.name = "ToneAudioBuffers";
            /**
             * All of the buffers
             */
            this._buffers = new Map();
            /**
             * Keep track of the number of loaded buffers
             */
            this._loadingCount = 0;
            const options = optionsFromArguments(ToneAudioBuffers.getDefaults(), arguments, ["urls", "onload", "baseUrl"], "urls");
            this.baseUrl = options.baseUrl;
            // add each one
            Object.keys(options.urls).forEach(name => {
                this._loadingCount++;
                const url = options.urls[name];
                this.add(name, url, this._bufferLoaded.bind(this, options.onload), options.onerror);
            });
        }
        static getDefaults() {
            return {
                baseUrl: "",
                onerror: noOp,
                onload: noOp,
                urls: {},
            };
        }
        /**
         * True if the buffers object has a buffer by that name.
         * @param  name  The key or index of the buffer.
         */
        has(name) {
            return this._buffers.has(name.toString());
        }
        /**
         * Get a buffer by name. If an array was loaded,
         * then use the array index.
         * @param  name  The key or index of the buffer.
         */
        get(name) {
            assert(this.has(name), `ToneAudioBuffers has no buffer named: ${name}`);
            return this._buffers.get(name.toString());
        }
        /**
         * A buffer was loaded. decrement the counter.
         */
        _bufferLoaded(callback) {
            this._loadingCount--;
            if (this._loadingCount === 0 && callback) {
                callback();
            }
        }
        /**
         * If the buffers are loaded or not
         */
        get loaded() {
            return Array.from(this._buffers).every(([_, buffer]) => buffer.loaded);
        }
        /**
         * Add a buffer by name and url to the Buffers
         * @param  name      A unique name to give the buffer
         * @param  url  Either the url of the bufer, or a buffer which will be added with the given name.
         * @param  callback  The callback to invoke when the url is loaded.
         * @param  onerror  Invoked if the buffer can't be loaded
         */
        add(name, url, callback = noOp, onerror = noOp) {
            if (isString(url)) {
                this._buffers.set(name.toString(), new ToneAudioBuffer(this.baseUrl + url, callback, onerror));
            }
            else {
                this._buffers.set(name.toString(), new ToneAudioBuffer(url, callback, onerror));
            }
            return this;
        }
        dispose() {
            super.dispose();
            this._buffers.forEach(buffer => buffer.dispose());
            this._buffers.clear();
            return this;
        }
    }

    /**
     * Midi is a primitive type for encoding Time values.
     * Midi can be constructed with or without the `new` keyword. Midi can be passed
     * into the parameter of any method which takes time as an argument.
     * @category Unit
     */
    class MidiClass extends FrequencyClass {
        constructor() {
            super(...arguments);
            this.name = "MidiClass";
            this.defaultUnits = "midi";
        }
        /**
         * Returns the value of a frequency in the current units
         */
        _frequencyToUnits(freq) {
            return ftom(super._frequencyToUnits(freq));
        }
        /**
         * Returns the value of a tick in the current time units
         */
        _ticksToUnits(ticks) {
            return ftom(super._ticksToUnits(ticks));
        }
        /**
         * Return the value of the beats in the current units
         */
        _beatsToUnits(beats) {
            return ftom(super._beatsToUnits(beats));
        }
        /**
         * Returns the value of a second in the current units
         */
        _secondsToUnits(seconds) {
            return ftom(super._secondsToUnits(seconds));
        }
        /**
         * Return the value of the frequency as a MIDI note
         * @example
         * Tone.Midi(60).toMidi(); // 60
         */
        toMidi() {
            return this.valueOf();
        }
        /**
         * Return the value of the frequency as a MIDI note
         * @example
         * Tone.Midi(60).toFrequency(); // 261.6255653005986
         */
        toFrequency() {
            return mtof(this.toMidi());
        }
        /**
         * Transposes the frequency by the given number of semitones.
         * @return A new transposed MidiClass
         * @example
         * Tone.Midi("A4").transpose(3); // "C5"
         */
        transpose(interval) {
            return new MidiClass(this.context, this.toMidi() + interval);
        }
    }
    /**
     * Convert a value into a FrequencyClass object.
     * @category Unit
     */
    function Midi(value, units) {
        return new MidiClass(getContext(), value, units);
    }

    /**
     * Ticks is a primitive type for encoding Time values.
     * Ticks can be constructed with or without the `new` keyword. Ticks can be passed
     * into the parameter of any method which takes time as an argument.
     * @example
     * const t = Tone.Ticks("4n"); // a quarter note as ticks
     * @category Unit
     */
    class TicksClass extends TransportTimeClass {
        constructor() {
            super(...arguments);
            this.name = "Ticks";
            this.defaultUnits = "i";
        }
        /**
         * Get the current time in the given units
         */
        _now() {
            return this.context.transport.ticks;
        }
        /**
         * Return the value of the beats in the current units
         */
        _beatsToUnits(beats) {
            return this._getPPQ() * beats;
        }
        /**
         * Returns the value of a second in the current units
         */
        _secondsToUnits(seconds) {
            return Math.floor(seconds / (60 / this._getBpm()) * this._getPPQ());
        }
        /**
         * Returns the value of a tick in the current time units
         */
        _ticksToUnits(ticks) {
            return ticks;
        }
        /**
         * Return the time in ticks
         */
        toTicks() {
            return this.valueOf();
        }
        /**
         * Return the time in seconds
         */
        toSeconds() {
            return (this.valueOf() / this._getPPQ()) * (60 / this._getBpm());
        }
    }
    /**
     * Convert a time representation to ticks
     * @category Unit
     */
    function Ticks(value, units) {
        return new TicksClass(getContext(), value, units);
    }

    /**
     * Draw is useful for synchronizing visuals and audio events.
     * Callbacks from Tone.Transport or any of the Tone.Event classes
     * always happen _before_ the scheduled time and are not synchronized
     * to the animation frame so they are not good for triggering tightly
     * synchronized visuals and sound. Draw makes it easy to schedule
     * callbacks using the AudioContext time and uses requestAnimationFrame.
     * @example
     * Tone.Transport.schedule((time) => {
     * 	// use the time argument to schedule a callback with Draw
     * 	Tone.Draw.schedule(() => {
     * 		// do drawing or DOM manipulation here
     * 		console.log(time);
     * 	}, time);
     * }, "+0.5");
     * Tone.Transport.start();
     * @category Core
     */
    class Draw extends ToneWithContext {
        constructor() {
            super(...arguments);
            this.name = "Draw";
            /**
             * The duration after which events are not invoked.
             */
            this.expiration = 0.25;
            /**
             * The amount of time before the scheduled time
             * that the callback can be invoked. Default is
             * half the time of an animation frame (0.008 seconds).
             */
            this.anticipation = 0.008;
            /**
             * All of the events.
             */
            this._events = new Timeline();
            /**
             * The draw loop
             */
            this._boundDrawLoop = this._drawLoop.bind(this);
            /**
             * The animation frame id
             */
            this._animationFrame = -1;
        }
        /**
         * Schedule a function at the given time to be invoked
         * on the nearest animation frame.
         * @param  callback  Callback is invoked at the given time.
         * @param  time      The time relative to the AudioContext time to invoke the callback.
         * @example
         * Tone.Transport.scheduleRepeat(time => {
         * 	Tone.Draw.schedule(() => console.log(time), time);
         * }, 1);
         * Tone.Transport.start();
         */
        schedule(callback, time) {
            this._events.add({
                callback,
                time: this.toSeconds(time),
            });
            // start the draw loop on the first event
            if (this._events.length === 1) {
                this._animationFrame = requestAnimationFrame(this._boundDrawLoop);
            }
            return this;
        }
        /**
         * Cancel events scheduled after the given time
         * @param  after  Time after which scheduled events will be removed from the scheduling timeline.
         */
        cancel(after) {
            this._events.cancel(this.toSeconds(after));
            return this;
        }
        /**
         * The draw loop
         */
        _drawLoop() {
            const now = this.context.currentTime;
            while (this._events.length && this._events.peek().time - this.anticipation <= now) {
                const event = this._events.shift();
                if (event && now - event.time <= this.expiration) {
                    event.callback();
                }
            }
            if (this._events.length > 0) {
                this._animationFrame = requestAnimationFrame(this._boundDrawLoop);
            }
        }
        dispose() {
            super.dispose();
            this._events.dispose();
            cancelAnimationFrame(this._animationFrame);
            return this;
        }
    }
    //-------------------------------------
    // 	INITIALIZATION
    //-------------------------------------
    onContextInit(context => {
        context.draw = new Draw({ context });
    });
    onContextClose(context => {
        context.draw.dispose();
    });

    /**
     * Similar to Tone.Timeline, but all events represent
     * intervals with both "time" and "duration" times. The
     * events are placed in a tree structure optimized
     * for querying an intersection point with the timeline
     * events. Internally uses an [Interval Tree](https://en.wikipedia.org/wiki/Interval_tree)
     * to represent the data.
     */
    class IntervalTimeline extends Tone {
        constructor() {
            super(...arguments);
            this.name = "IntervalTimeline";
            /**
             * The root node of the inteval tree
             */
            this._root = null;
            /**
             * Keep track of the length of the timeline.
             */
            this._length = 0;
        }
        /**
         * The event to add to the timeline. All events must
         * have a time and duration value
         * @param  event  The event to add to the timeline
         */
        add(event) {
            assert(isDefined(event.time), "Events must have a time property");
            assert(isDefined(event.duration), "Events must have a duration parameter");
            event.time = event.time.valueOf();
            let node = new IntervalNode(event.time, event.time + event.duration, event);
            if (this._root === null) {
                this._root = node;
            }
            else {
                this._root.insert(node);
            }
            this._length++;
            // Restructure tree to be balanced
            while (node !== null) {
                node.updateHeight();
                node.updateMax();
                this._rebalance(node);
                node = node.parent;
            }
            return this;
        }
        /**
         * Remove an event from the timeline.
         * @param  event  The event to remove from the timeline
         */
        remove(event) {
            if (this._root !== null) {
                const results = [];
                this._root.search(event.time, results);
                for (const node of results) {
                    if (node.event === event) {
                        this._removeNode(node);
                        this._length--;
                        break;
                    }
                }
            }
            return this;
        }
        /**
         * The number of items in the timeline.
         * @readOnly
         */
        get length() {
            return this._length;
        }
        /**
         * Remove events whose time time is after the given time
         * @param  after  The time to query.
         */
        cancel(after) {
            this.forEachFrom(after, event => this.remove(event));
            return this;
        }
        /**
         * Set the root node as the given node
         */
        _setRoot(node) {
            this._root = node;
            if (this._root !== null) {
                this._root.parent = null;
            }
        }
        /**
         * Replace the references to the node in the node's parent
         * with the replacement node.
         */
        _replaceNodeInParent(node, replacement) {
            if (node.parent !== null) {
                if (node.isLeftChild()) {
                    node.parent.left = replacement;
                }
                else {
                    node.parent.right = replacement;
                }
                this._rebalance(node.parent);
            }
            else {
                this._setRoot(replacement);
            }
        }
        /**
         * Remove the node from the tree and replace it with
         * a successor which follows the schema.
         */
        _removeNode(node) {
            if (node.left === null && node.right === null) {
                this._replaceNodeInParent(node, null);
            }
            else if (node.right === null) {
                this._replaceNodeInParent(node, node.left);
            }
            else if (node.left === null) {
                this._replaceNodeInParent(node, node.right);
            }
            else {
                const balance = node.getBalance();
                let replacement;
                let temp = null;
                if (balance > 0) {
                    if (node.left.right === null) {
                        replacement = node.left;
                        replacement.right = node.right;
                        temp = replacement;
                    }
                    else {
                        replacement = node.left.right;
                        while (replacement.right !== null) {
                            replacement = replacement.right;
                        }
                        if (replacement.parent) {
                            replacement.parent.right = replacement.left;
                            temp = replacement.parent;
                            replacement.left = node.left;
                            replacement.right = node.right;
                        }
                    }
                }
                else if (node.right.left === null) {
                    replacement = node.right;
                    replacement.left = node.left;
                    temp = replacement;
                }
                else {
                    replacement = node.right.left;
                    while (replacement.left !== null) {
                        replacement = replacement.left;
                    }
                    if (replacement.parent) {
                        replacement.parent.left = replacement.right;
                        temp = replacement.parent;
                        replacement.left = node.left;
                        replacement.right = node.right;
                    }
                }
                if (node.parent !== null) {
                    if (node.isLeftChild()) {
                        node.parent.left = replacement;
                    }
                    else {
                        node.parent.right = replacement;
                    }
                }
                else {
                    this._setRoot(replacement);
                }
                if (temp) {
                    this._rebalance(temp);
                }
            }
            node.dispose();
        }
        /**
         * Rotate the tree to the left
         */
        _rotateLeft(node) {
            const parent = node.parent;
            const isLeftChild = node.isLeftChild();
            // Make node.right the new root of this sub tree (instead of node)
            const pivotNode = node.right;
            if (pivotNode) {
                node.right = pivotNode.left;
                pivotNode.left = node;
            }
            if (parent !== null) {
                if (isLeftChild) {
                    parent.left = pivotNode;
                }
                else {
                    parent.right = pivotNode;
                }
            }
            else {
                this._setRoot(pivotNode);
            }
        }
        /**
         * Rotate the tree to the right
         */
        _rotateRight(node) {
            const parent = node.parent;
            const isLeftChild = node.isLeftChild();
            // Make node.left the new root of this sub tree (instead of node)
            const pivotNode = node.left;
            if (pivotNode) {
                node.left = pivotNode.right;
                pivotNode.right = node;
            }
            if (parent !== null) {
                if (isLeftChild) {
                    parent.left = pivotNode;
                }
                else {
                    parent.right = pivotNode;
                }
            }
            else {
                this._setRoot(pivotNode);
            }
        }
        /**
         * Balance the BST
         */
        _rebalance(node) {
            const balance = node.getBalance();
            if (balance > 1 && node.left) {
                if (node.left.getBalance() < 0) {
                    this._rotateLeft(node.left);
                }
                else {
                    this._rotateRight(node);
                }
            }
            else if (balance < -1 && node.right) {
                if (node.right.getBalance() > 0) {
                    this._rotateRight(node.right);
                }
                else {
                    this._rotateLeft(node);
                }
            }
        }
        /**
         * Get an event whose time and duration span the give time. Will
         * return the match whose "time" value is closest to the given time.
         * @return  The event which spans the desired time
         */
        get(time) {
            if (this._root !== null) {
                const results = [];
                this._root.search(time, results);
                if (results.length > 0) {
                    let max = results[0];
                    for (let i = 1; i < results.length; i++) {
                        if (results[i].low > max.low) {
                            max = results[i];
                        }
                    }
                    return max.event;
                }
            }
            return null;
        }
        /**
         * Iterate over everything in the timeline.
         * @param  callback The callback to invoke with every item
         */
        forEach(callback) {
            if (this._root !== null) {
                const allNodes = [];
                this._root.traverse(node => allNodes.push(node));
                allNodes.forEach(node => {
                    if (node.event) {
                        callback(node.event);
                    }
                });
            }
            return this;
        }
        /**
         * Iterate over everything in the array in which the given time
         * overlaps with the time and duration time of the event.
         * @param  time The time to check if items are overlapping
         * @param  callback The callback to invoke with every item
         */
        forEachAtTime(time, callback) {
            if (this._root !== null) {
                const results = [];
                this._root.search(time, results);
                results.forEach(node => {
                    if (node.event) {
                        callback(node.event);
                    }
                });
            }
            return this;
        }
        /**
         * Iterate over everything in the array in which the time is greater
         * than or equal to the given time.
         * @param  time The time to check if items are before
         * @param  callback The callback to invoke with every item
         */
        forEachFrom(time, callback) {
            if (this._root !== null) {
                const results = [];
                this._root.searchAfter(time, results);
                results.forEach(node => {
                    if (node.event) {
                        callback(node.event);
                    }
                });
            }
            return this;
        }
        /**
         * Clean up
         */
        dispose() {
            super.dispose();
            if (this._root !== null) {
                this._root.traverse(node => node.dispose());
            }
            this._root = null;
            return this;
        }
    }
    //-------------------------------------
    // 	INTERVAL NODE HELPER
    //-------------------------------------
    /**
     * Represents a node in the binary search tree, with the addition
     * of a "high" value which keeps track of the highest value of
     * its children.
     * References:
     * https://brooknovak.wordpress.com/2013/12/07/augmented-interval-tree-in-c/
     * http://www.mif.vu.lt/~valdas/ALGORITMAI/LITERATURA/Cormen/Cormen.pdf
     * @param low
     * @param high
     */
    class IntervalNode {
        constructor(low, high, event) {
            // the nodes to the left
            this._left = null;
            // the nodes to the right
            this._right = null;
            // the parent node
            this.parent = null;
            // the number of child nodes
            this.height = 0;
            this.event = event;
            // the low value
            this.low = low;
            // the high value
            this.high = high;
            // the high value for this and all child nodes
            this.max = this.high;
        }
        /**
         * Insert a node into the correct spot in the tree
         */
        insert(node) {
            if (node.low <= this.low) {
                if (this.left === null) {
                    this.left = node;
                }
                else {
                    this.left.insert(node);
                }
            }
            else if (this.right === null) {
                this.right = node;
            }
            else {
                this.right.insert(node);
            }
        }
        /**
         * Search the tree for nodes which overlap
         * with the given point
         * @param  point  The point to query
         * @param  results  The array to put the results
         */
        search(point, results) {
            // If p is to the right of the rightmost point of any interval
            // in this node and all children, there won't be any matches.
            if (point > this.max) {
                return;
            }
            // Search left children
            if (this.left !== null) {
                this.left.search(point, results);
            }
            // Check this node
            if (this.low <= point && this.high > point) {
                results.push(this);
            }
            // If p is to the left of the time of this interval,
            // then it can't be in any child to the right.
            if (this.low > point) {
                return;
            }
            // Search right children
            if (this.right !== null) {
                this.right.search(point, results);
            }
        }
        /**
         * Search the tree for nodes which are less
         * than the given point
         * @param  point  The point to query
         * @param  results  The array to put the results
         */
        searchAfter(point, results) {
            // Check this node
            if (this.low >= point) {
                results.push(this);
                if (this.left !== null) {
                    this.left.searchAfter(point, results);
                }
            }
            // search the right side
            if (this.right !== null) {
                this.right.searchAfter(point, results);
            }
        }
        /**
         * Invoke the callback on this element and both it's branches
         * @param  {Function}  callback
         */
        traverse(callback) {
            callback(this);
            if (this.left !== null) {
                this.left.traverse(callback);
            }
            if (this.right !== null) {
                this.right.traverse(callback);
            }
        }
        /**
         * Update the height of the node
         */
        updateHeight() {
            if (this.left !== null && this.right !== null) {
                this.height = Math.max(this.left.height, this.right.height) + 1;
            }
            else if (this.right !== null) {
                this.height = this.right.height + 1;
            }
            else if (this.left !== null) {
                this.height = this.left.height + 1;
            }
            else {
                this.height = 0;
            }
        }
        /**
         * Update the height of the node
         */
        updateMax() {
            this.max = this.high;
            if (this.left !== null) {
                this.max = Math.max(this.max, this.left.max);
            }
            if (this.right !== null) {
                this.max = Math.max(this.max, this.right.max);
            }
        }
        /**
         * The balance is how the leafs are distributed on the node
         * @return  Negative numbers are balanced to the right
         */
        getBalance() {
            let balance = 0;
            if (this.left !== null && this.right !== null) {
                balance = this.left.height - this.right.height;
            }
            else if (this.left !== null) {
                balance = this.left.height + 1;
            }
            else if (this.right !== null) {
                balance = -(this.right.height + 1);
            }
            return balance;
        }
        /**
         * @returns true if this node is the left child of its parent
         */
        isLeftChild() {
            return this.parent !== null && this.parent.left === this;
        }
        /**
         * get/set the left node
         */
        get left() {
            return this._left;
        }
        set left(node) {
            this._left = node;
            if (node !== null) {
                node.parent = this;
            }
            this.updateHeight();
            this.updateMax();
        }
        /**
         * get/set the right node
         */
        get right() {
            return this._right;
        }
        set right(node) {
            this._right = node;
            if (node !== null) {
                node.parent = this;
            }
            this.updateHeight();
            this.updateMax();
        }
        /**
         * null out references.
         */
        dispose() {
            this.parent = null;
            this._left = null;
            this._right = null;
            this.event = null;
        }
    }

    var Units = /*#__PURE__*/Object.freeze({
        __proto__: null
    });

    /**
     * Volume is a simple volume node, useful for creating a volume fader.
     *
     * @example
     * const vol = new Tone.Volume(-12).toDestination();
     * const osc = new Tone.Oscillator().connect(vol).start();
     * @category Component
     */
    class Volume extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Volume.getDefaults(), arguments, ["volume"]));
            this.name = "Volume";
            const options = optionsFromArguments(Volume.getDefaults(), arguments, ["volume"]);
            this.input = this.output = new Gain({
                context: this.context,
                gain: options.volume,
                units: "decibels",
            });
            this.volume = this.output.gain;
            readOnly(this, "volume");
            this._unmutedVolume = options.volume;
            // set the mute initially
            this.mute = options.mute;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                mute: false,
                volume: 0,
            });
        }
        /**
         * Mute the output.
         * @example
         * const vol = new Tone.Volume(-12).toDestination();
         * const osc = new Tone.Oscillator().connect(vol).start();
         * // mute the output
         * vol.mute = true;
         */
        get mute() {
            return this.volume.value === -Infinity;
        }
        set mute(mute) {
            if (!this.mute && mute) {
                this._unmutedVolume = this.volume.value;
                // maybe it should ramp here?
                this.volume.value = -Infinity;
            }
            else if (this.mute && !mute) {
                this.volume.value = this._unmutedVolume;
            }
        }
        /**
         * clean up
         */
        dispose() {
            super.dispose();
            this.input.dispose();
            this.volume.dispose();
            return this;
        }
    }

    /**
     * A single master output which is connected to the
     * AudioDestinationNode (aka your speakers).
     * It provides useful conveniences such as the ability
     * to set the volume and mute the entire application.
     * It also gives you the ability to apply master effects to your application.
     *
     * @example
     * const oscillator = new Tone.Oscillator().start();
     * // the audio will go from the oscillator to the speakers
     * oscillator.connect(Tone.Destination);
     * // a convenience for connecting to the master output is also provided:
     * oscillator.toDestination();
     * @category Core
     */
    class Destination extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Destination.getDefaults(), arguments));
            this.name = "Destination";
            this.input = new Volume({ context: this.context });
            this.output = new Gain({ context: this.context });
            /**
             * The volume of the master output.
             */
            this.volume = this.input.volume;
            const options = optionsFromArguments(Destination.getDefaults(), arguments);
            connectSeries(this.input, this.output, this.context.rawContext.destination);
            this.mute = options.mute;
            this._internalChannels = [this.input, this.context.rawContext.destination, this.output];
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                mute: false,
                volume: 0,
            });
        }
        /**
         * Mute the output.
         * @example
         * const oscillator = new Tone.Oscillator().start().toDestination();
         * setTimeout(() => {
         * 	// mute the output
         * 	Tone.Destination.mute = true;
         * }, 1000);
         */
        get mute() {
            return this.input.mute;
        }
        set mute(mute) {
            this.input.mute = mute;
        }
        /**
         * Add a master effects chain. NOTE: this will disconnect any nodes which were previously
         * chained in the master effects chain.
         * @param args All arguments will be connected in a row and the Master will be routed through it.
         * @example
         * // route all audio through a filter and compressor
         * const lowpass = new Tone.Filter(800, "lowpass");
         * const compressor = new Tone.Compressor(-18);
         * Tone.Destination.chain(lowpass, compressor);
         */
        chain(...args) {
            this.input.disconnect();
            args.unshift(this.input);
            args.push(this.output);
            connectSeries(...args);
            return this;
        }
        /**
         * The maximum number of channels the system can output
         * @example
         * console.log(Tone.Destination.maxChannelCount);
         */
        get maxChannelCount() {
            return this.context.rawContext.destination.maxChannelCount;
        }
        /**
         * Clean up
         */
        dispose() {
            super.dispose();
            this.volume.dispose();
            return this;
        }
    }
    //-------------------------------------
    // 	INITIALIZATION
    //-------------------------------------
    onContextInit(context => {
        context.destination = new Destination({ context });
    });
    onContextClose(context => {
        context.destination.dispose();
    });

    /**
     * Represents a single value which is gettable and settable in a timed way
     */
    class TimelineValue extends Tone {
        /**
         * @param initialValue The value to return if there is no scheduled values
         */
        constructor(initialValue) {
            super();
            this.name = "TimelineValue";
            /**
             * The timeline which stores the values
             */
            this._timeline = new Timeline({ memory: 10 });
            this._initialValue = initialValue;
        }
        /**
         * Set the value at the given time
         */
        set(value, time) {
            this._timeline.add({
                value, time
            });
            return this;
        }
        /**
         * Get the value at the given time
         */
        get(time) {
            const event = this._timeline.get(time);
            if (event) {
                return event.value;
            }
            else {
                return this._initialValue;
            }
        }
    }

    /**
     * TransportEvent is an internal class used by [[Transport]]
     * to schedule events. Do no invoke this class directly, it is
     * handled from within Tone.Transport.
     */
    class TransportEvent {
        /**
         * @param transport The transport object which the event belongs to
         */
        constructor(transport, opts) {
            /**
             * The unique id of the event
             */
            this.id = TransportEvent._eventId++;
            const options = Object.assign(TransportEvent.getDefaults(), opts);
            this.transport = transport;
            this.callback = options.callback;
            this._once = options.once;
            this.time = options.time;
        }
        static getDefaults() {
            return {
                callback: noOp,
                once: false,
                time: 0,
            };
        }
        /**
         * Invoke the event callback.
         * @param  time  The AudioContext time in seconds of the event
         */
        invoke(time) {
            if (this.callback) {
                this.callback(time);
                if (this._once) {
                    this.transport.clear(this.id);
                }
            }
        }
        /**
         * Clean up
         */
        dispose() {
            this.callback = undefined;
            return this;
        }
    }
    /**
     * Current ID counter
     */
    TransportEvent._eventId = 0;

    /**
     * TransportRepeatEvent is an internal class used by Tone.Transport
     * to schedule repeat events. This class should not be instantiated directly.
     */
    class TransportRepeatEvent extends TransportEvent {
        /**
         * @param transport The transport object which the event belongs to
         */
        constructor(transport, opts) {
            super(transport, opts);
            /**
             * The ID of the current timeline event
             */
            this._currentId = -1;
            /**
             * The ID of the next timeline event
             */
            this._nextId = -1;
            /**
             * The time of the next event
             */
            this._nextTick = this.time;
            /**
             * a reference to the bound start method
             */
            this._boundRestart = this._restart.bind(this);
            const options = Object.assign(TransportRepeatEvent.getDefaults(), opts);
            this.duration = new TicksClass(transport.context, options.duration).valueOf();
            this._interval = new TicksClass(transport.context, options.interval).valueOf();
            this._nextTick = options.time;
            this.transport.on("start", this._boundRestart);
            this.transport.on("loopStart", this._boundRestart);
            this.context = this.transport.context;
            this._restart();
        }
        static getDefaults() {
            return Object.assign({}, TransportEvent.getDefaults(), {
                duration: Infinity,
                interval: 1,
                once: false,
            });
        }
        /**
         * Invoke the callback. Returns the tick time which
         * the next event should be scheduled at.
         * @param  time  The AudioContext time in seconds of the event
         */
        invoke(time) {
            // create more events if necessary
            this._createEvents(time);
            // call the super class
            super.invoke(time);
        }
        /**
         * Push more events onto the timeline to keep up with the position of the timeline
         */
        _createEvents(time) {
            // schedule the next event
            const ticks = this.transport.getTicksAtTime(time);
            if (ticks >= this.time && ticks >= this._nextTick && this._nextTick + this._interval < this.time + this.duration) {
                this._nextTick += this._interval;
                this._currentId = this._nextId;
                this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new TicksClass(this.context, this._nextTick).toSeconds());
            }
        }
        /**
         * Push more events onto the timeline to keep up with the position of the timeline
         */
        _restart(time) {
            this.transport.clear(this._currentId);
            this.transport.clear(this._nextId);
            this._nextTick = this.time;
            const ticks = this.transport.getTicksAtTime(time);
            if (ticks > this.time) {
                this._nextTick = this.time + Math.ceil((ticks - this.time) / this._interval) * this._interval;
            }
            this._currentId = this.transport.scheduleOnce(this.invoke.bind(this), new TicksClass(this.context, this._nextTick).toSeconds());
            this._nextTick += this._interval;
            this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new TicksClass(this.context, this._nextTick).toSeconds());
        }
        /**
         * Clean up
         */
        dispose() {
            super.dispose();
            this.transport.clear(this._currentId);
            this.transport.clear(this._nextId);
            this.transport.off("start", this._boundRestart);
            this.transport.off("loopStart", this._boundRestart);
            return this;
        }
    }

    /**
     * Transport for timing musical events.
     * Supports tempo curves and time changes. Unlike browser-based timing (setInterval, requestAnimationFrame)
     * Transport timing events pass in the exact time of the scheduled event
     * in the argument of the callback function. Pass that time value to the object
     * you're scheduling. <br><br>
     * A single transport is created for you when the library is initialized.
     * <br><br>
     * The transport emits the events: "start", "stop", "pause", and "loop" which are
     * called with the time of that event as the argument.
     *
     * @example
     * const osc = new Tone.Oscillator().toDestination();
     * // repeated event every 8th note
     * Tone.Transport.scheduleRepeat((time) => {
     * 	// use the callback time to schedule events
     * 	osc.start(time).stop(time + 0.1);
     * }, "8n");
     * // transport must be started before it starts invoking events
     * Tone.Transport.start();
     * @category Core
     */
    class Transport extends ToneWithContext {
        constructor() {
            super(optionsFromArguments(Transport.getDefaults(), arguments));
            this.name = "Transport";
            //-------------------------------------
            // 	LOOPING
            //-------------------------------------
            /**
             * If the transport loops or not.
             */
            this._loop = new TimelineValue(false);
            /**
             * The loop start position in ticks
             */
            this._loopStart = 0;
            /**
             * The loop end position in ticks
             */
            this._loopEnd = 0;
            //-------------------------------------
            // 	TIMELINE EVENTS
            //-------------------------------------
            /**
             * All the events in an object to keep track by ID
             */
            this._scheduledEvents = {};
            /**
             * The scheduled events.
             */
            this._timeline = new Timeline();
            /**
             * Repeated events
             */
            this._repeatedEvents = new IntervalTimeline();
            /**
             * All of the synced Signals
             */
            this._syncedSignals = [];
            /**
             * The swing amount
             */
            this._swingAmount = 0;
            const options = optionsFromArguments(Transport.getDefaults(), arguments);
            // CLOCK/TEMPO
            this._ppq = options.ppq;
            this._clock = new Clock({
                callback: this._processTick.bind(this),
                context: this.context,
                frequency: 0,
                units: "bpm",
            });
            this._bindClockEvents();
            this.bpm = this._clock.frequency;
            this._clock.frequency.multiplier = options.ppq;
            this.bpm.setValueAtTime(options.bpm, 0);
            readOnly(this, "bpm");
            this._timeSignature = options.timeSignature;
            // SWING
            this._swingTicks = options.ppq / 2; // 8n
        }
        static getDefaults() {
            return Object.assign(ToneWithContext.getDefaults(), {
                bpm: 120,
                loopEnd: "4m",
                loopStart: 0,
                ppq: 192,
                swing: 0,
                swingSubdivision: "8n",
                timeSignature: 4,
            });
        }
        //-------------------------------------
        // 	TICKS
        //-------------------------------------
        /**
         * called on every tick
         * @param  tickTime clock relative tick time
         */
        _processTick(tickTime, ticks) {
            // handle swing
            if (this._swingAmount > 0 &&
                ticks % this._ppq !== 0 && // not on a downbeat
                ticks % (this._swingTicks * 2) !== 0) {
                // add some swing
                const progress = (ticks % (this._swingTicks * 2)) / (this._swingTicks * 2);
                const amount = Math.sin((progress) * Math.PI) * this._swingAmount;
                tickTime += new TicksClass(this.context, this._swingTicks * 2 / 3).toSeconds() * amount;
            }
            // do the loop test
            if (this._loop.get(tickTime)) {
                if (ticks >= this._loopEnd) {
                    this.emit("loopEnd", tickTime);
                    this._clock.setTicksAtTime(this._loopStart, tickTime);
                    ticks = this._loopStart;
                    this.emit("loopStart", tickTime, this._clock.getSecondsAtTime(tickTime));
                    this.emit("loop", tickTime);
                }
            }
            // invoke the timeline events scheduled on this tick
            this._timeline.forEachAtTime(ticks, event => event.invoke(tickTime));
        }
        //-------------------------------------
        // 	SCHEDULABLE EVENTS
        //-------------------------------------
        /**
         * Schedule an event along the timeline.
         * @param callback The callback to be invoked at the time.
         * @param time The time to invoke the callback at.
         * @return The id of the event which can be used for canceling the event.
         * @example
         * // schedule an event on the 16th measure
         * Tone.Transport.schedule((time) => {
         * 	// invoked on measure 16
         * 	console.log("measure 16!");
         * }, "16:0:0");
         */
        schedule(callback, time) {
            const event = new TransportEvent(this, {
                callback,
                time: new TransportTimeClass(this.context, time).toTicks(),
            });
            return this._addEvent(event, this._timeline);
        }
        /**
         * Schedule a repeated event along the timeline. The event will fire
         * at the `interval` starting at the `startTime` and for the specified
         * `duration`.
         * @param  callback   The callback to invoke.
         * @param  interval   The duration between successive callbacks. Must be a positive number.
         * @param  startTime  When along the timeline the events should start being invoked.
         * @param  duration How long the event should repeat.
         * @return  The ID of the scheduled event. Use this to cancel the event.
         * @example
         * const osc = new Tone.Oscillator().toDestination().start();
         * // a callback invoked every eighth note after the first measure
         * Tone.Transport.scheduleRepeat((time) => {
         * 	osc.start(time).stop(time + 0.1);
         * }, "8n", "1m");
         */
        scheduleRepeat(callback, interval, startTime, duration = Infinity) {
            const event = new TransportRepeatEvent(this, {
                callback,
                duration: new TimeClass(this.context, duration).toTicks(),
                interval: new TimeClass(this.context, interval).toTicks(),
                time: new TransportTimeClass(this.context, startTime).toTicks(),
            });
            // kick it off if the Transport is started
            // @ts-ignore
            return this._addEvent(event, this._repeatedEvents);
        }
        /**
         * Schedule an event that will be removed after it is invoked.
         * @param callback The callback to invoke once.
         * @param time The time the callback should be invoked.
         * @returns The ID of the scheduled event.
         */
        scheduleOnce(callback, time) {
            const event = new TransportEvent(this, {
                callback,
                once: true,
                time: new TransportTimeClass(this.context, time).toTicks(),
            });
            return this._addEvent(event, this._timeline);
        }
        /**
         * Clear the passed in event id from the timeline
         * @param eventId The id of the event.
         */
        clear(eventId) {
            if (this._scheduledEvents.hasOwnProperty(eventId)) {
                const item = this._scheduledEvents[eventId.toString()];
                item.timeline.remove(item.event);
                item.event.dispose();
                delete this._scheduledEvents[eventId.toString()];
            }
            return this;
        }
        /**
         * Add an event to the correct timeline. Keep track of the
         * timeline it was added to.
         * @returns the event id which was just added
         */
        _addEvent(event, timeline) {
            this._scheduledEvents[event.id.toString()] = {
                event,
                timeline,
            };
            timeline.add(event);
            return event.id;
        }
        /**
         * Remove scheduled events from the timeline after
         * the given time. Repeated events will be removed
         * if their startTime is after the given time
         * @param after Clear all events after this time.
         */
        cancel(after = 0) {
            const computedAfter = this.toTicks(after);
            this._timeline.forEachFrom(computedAfter, event => this.clear(event.id));
            this._repeatedEvents.forEachFrom(computedAfter, event => this.clear(event.id));
            return this;
        }
        //-------------------------------------
        // 	START/STOP/PAUSE
        //-------------------------------------
        /**
         * Bind start/stop/pause events from the clock and emit them.
         */
        _bindClockEvents() {
            this._clock.on("start", (time, offset) => {
                offset = new TicksClass(this.context, offset).toSeconds();
                this.emit("start", time, offset);
            });
            this._clock.on("stop", (time) => {
                this.emit("stop", time);
            });
            this._clock.on("pause", (time) => {
                this.emit("pause", time);
            });
        }
        /**
         * Returns the playback state of the source, either "started", "stopped", or "paused"
         */
        get state() {
            return this._clock.getStateAtTime(this.now());
        }
        /**
         * Start the transport and all sources synced to the transport.
         * @param  time The time when the transport should start.
         * @param  offset The timeline offset to start the transport.
         * @example
         * // start the transport in one second starting at beginning of the 5th measure.
         * Tone.Transport.start("+1", "4:0:0");
         */
        start(time, offset) {
            let offsetTicks;
            if (isDefined(offset)) {
                offsetTicks = this.toTicks(offset);
            }
            // start the clock
            this._clock.start(time, offsetTicks);
            return this;
        }
        /**
         * Stop the transport and all sources synced to the transport.
         * @param time The time when the transport should stop.
         * @example
         * Tone.Transport.stop();
         */
        stop(time) {
            this._clock.stop(time);
            return this;
        }
        /**
         * Pause the transport and all sources synced to the transport.
         */
        pause(time) {
            this._clock.pause(time);
            return this;
        }
        /**
         * Toggle the current state of the transport. If it is
         * started, it will stop it, otherwise it will start the Transport.
         * @param  time The time of the event
         */
        toggle(time) {
            time = this.toSeconds(time);
            if (this._clock.getStateAtTime(time) !== "started") {
                this.start(time);
            }
            else {
                this.stop(time);
            }
            return this;
        }
        //-------------------------------------
        // 	SETTERS/GETTERS
        //-------------------------------------
        /**
         * The time signature as just the numerator over 4.
         * For example 4/4 would be just 4 and 6/8 would be 3.
         * @example
         * // common time
         * Tone.Transport.timeSignature = 4;
         * // 7/8
         * Tone.Transport.timeSignature = [7, 8];
         * // this will be reduced to a single number
         * Tone.Transport.timeSignature; // returns 3.5
         */
        get timeSignature() {
            return this._timeSignature;
        }
        set timeSignature(timeSig) {
            if (isArray(timeSig)) {
                timeSig = (timeSig[0] / timeSig[1]) * 4;
            }
            this._timeSignature = timeSig;
        }
        /**
         * When the Transport.loop = true, this is the starting position of the loop.
         */
        get loopStart() {
            return new TimeClass(this.context, this._loopStart, "i").toSeconds();
        }
        set loopStart(startPosition) {
            this._loopStart = this.toTicks(startPosition);
        }
        /**
         * When the Transport.loop = true, this is the ending position of the loop.
         */
        get loopEnd() {
            return new TimeClass(this.context, this._loopEnd, "i").toSeconds();
        }
        set loopEnd(endPosition) {
            this._loopEnd = this.toTicks(endPosition);
        }
        /**
         * If the transport loops or not.
         */
        get loop() {
            return this._loop.get(this.now());
        }
        set loop(loop) {
            this._loop.set(loop, this.now());
        }
        /**
         * Set the loop start and stop at the same time.
         * @example
         * // loop over the first measure
         * Tone.Transport.setLoopPoints(0, "1m");
         * Tone.Transport.loop = true;
         */
        setLoopPoints(startPosition, endPosition) {
            this.loopStart = startPosition;
            this.loopEnd = endPosition;
            return this;
        }
        /**
         * The swing value. Between 0-1 where 1 equal to the note + half the subdivision.
         */
        get swing() {
            return this._swingAmount;
        }
        set swing(amount) {
            // scale the values to a normal range
            this._swingAmount = amount;
        }
        /**
         * Set the subdivision which the swing will be applied to.
         * The default value is an 8th note. Value must be less
         * than a quarter note.
         */
        get swingSubdivision() {
            return new TicksClass(this.context, this._swingTicks).toNotation();
        }
        set swingSubdivision(subdivision) {
            this._swingTicks = this.toTicks(subdivision);
        }
        /**
         * The Transport's position in Bars:Beats:Sixteenths.
         * Setting the value will jump to that position right away.
         */
        get position() {
            const now = this.now();
            const ticks = this._clock.getTicksAtTime(now);
            return new TicksClass(this.context, ticks).toBarsBeatsSixteenths();
        }
        set position(progress) {
            const ticks = this.toTicks(progress);
            this.ticks = ticks;
        }
        /**
         * The Transport's position in seconds
         * Setting the value will jump to that position right away.
         */
        get seconds() {
            return this._clock.seconds;
        }
        set seconds(s) {
            const now = this.now();
            const ticks = this._clock.frequency.timeToTicks(s, now);
            this.ticks = ticks;
        }
        /**
         * The Transport's loop position as a normalized value. Always
         * returns 0 if the transport if loop is not true.
         */
        get progress() {
            if (this.loop) {
                const now = this.now();
                const ticks = this._clock.getTicksAtTime(now);
                return (ticks - this._loopStart) / (this._loopEnd - this._loopStart);
            }
            else {
                return 0;
            }
        }
        /**
         * The transports current tick position.
         */
        get ticks() {
            return this._clock.ticks;
        }
        set ticks(t) {
            if (this._clock.ticks !== t) {
                const now = this.now();
                // stop everything synced to the transport
                if (this.state === "started") {
                    const ticks = this._clock.getTicksAtTime(now);
                    // schedule to start on the next tick, #573
                    const time = this._clock.getTimeOfTick(Math.ceil(ticks));
                    this.emit("stop", time);
                    this._clock.setTicksAtTime(t, time);
                    // restart it with the new time
                    this.emit("start", time, this._clock.getSecondsAtTime(time));
                }
                else {
                    this._clock.setTicksAtTime(t, now);
                }
            }
        }
        /**
         * Get the clock's ticks at the given time.
         * @param  time  When to get the tick value
         * @return The tick value at the given time.
         */
        getTicksAtTime(time) {
            return Math.round(this._clock.getTicksAtTime(time));
        }
        /**
         * Return the elapsed seconds at the given time.
         * @param  time  When to get the elapsed seconds
         * @return  The number of elapsed seconds
         */
        getSecondsAtTime(time) {
            return this._clock.getSecondsAtTime(time);
        }
        /**
         * Pulses Per Quarter note. This is the smallest resolution
         * the Transport timing supports. This should be set once
         * on initialization and not set again. Changing this value
         * after other objects have been created can cause problems.
         */
        get PPQ() {
            return this._clock.frequency.multiplier;
        }
        set PPQ(ppq) {
            this._clock.frequency.multiplier = ppq;
        }
        //-------------------------------------
        // 	SYNCING
        //-------------------------------------
        /**
         * Returns the time aligned to the next subdivision
         * of the Transport. If the Transport is not started,
         * it will return 0.
         * Note: this will not work precisely during tempo ramps.
         * @param  subdivision  The subdivision to quantize to
         * @return  The context time of the next subdivision.
         * @example
         * // the transport must be started, otherwise returns 0
         * Tone.Transport.start();
         * Tone.Transport.nextSubdivision("4n");
         */
        nextSubdivision(subdivision) {
            subdivision = this.toTicks(subdivision);
            if (this.state !== "started") {
                // if the transport's not started, return 0
                return 0;
            }
            else {
                const now = this.now();
                // the remainder of the current ticks and the subdivision
                const transportPos = this.getTicksAtTime(now);
                const remainingTicks = subdivision - transportPos % subdivision;
                return this._clock.nextTickTime(remainingTicks, now);
            }
        }
        /**
         * Attaches the signal to the tempo control signal so that
         * any changes in the tempo will change the signal in the same
         * ratio.
         *
         * @param signal
         * @param ratio Optionally pass in the ratio between the two signals.
         * 			Otherwise it will be computed based on their current values.
         */
        syncSignal(signal, ratio) {
            if (!ratio) {
                // get the sync ratio
                const now = this.now();
                if (signal.getValueAtTime(now) !== 0) {
                    const bpm = this.bpm.getValueAtTime(now);
                    const computedFreq = 1 / (60 / bpm / this.PPQ);
                    ratio = signal.getValueAtTime(now) / computedFreq;
                }
                else {
                    ratio = 0;
                }
            }
            const ratioSignal = new Gain(ratio);
            // @ts-ignore
            this.bpm.connect(ratioSignal);
            // @ts-ignore
            ratioSignal.connect(signal._param);
            this._syncedSignals.push({
                initial: signal.value,
                ratio: ratioSignal,
                signal,
            });
            signal.value = 0;
            return this;
        }
        /**
         * Unsyncs a previously synced signal from the transport's control.
         * See Transport.syncSignal.
         */
        unsyncSignal(signal) {
            for (let i = this._syncedSignals.length - 1; i >= 0; i--) {
                const syncedSignal = this._syncedSignals[i];
                if (syncedSignal.signal === signal) {
                    syncedSignal.ratio.dispose();
                    syncedSignal.signal.value = syncedSignal.initial;
                    this._syncedSignals.splice(i, 1);
                }
            }
            return this;
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this._clock.dispose();
            writable(this, "bpm");
            this._timeline.dispose();
            this._repeatedEvents.dispose();
            return this;
        }
    }
    Emitter.mixin(Transport);
    //-------------------------------------
    // 	INITIALIZATION
    //-------------------------------------
    onContextInit(context => {
        context.transport = new Transport({ context });
    });
    onContextClose(context => {
        context.transport.dispose();
    });

    /**
     * Base class for sources.
     * start/stop of this.context.transport.
     *
     * ```
     * // Multiple state change events can be chained together,
     * // but must be set in the correct order and with ascending times
     * // OK
     * state.start().stop("+0.2");
     * // OK
     * state.start().stop("+0.2").start("+0.4").stop("+0.7")
     * // BAD
     * state.stop("+0.2").start();
     * // BAD
     * state.start("+0.3").stop("+0.2");
     * ```
     */
    class Source extends ToneAudioNode {
        constructor(options) {
            super(options);
            /**
             * Sources have no inputs
             */
            this.input = undefined;
            /**
             * Keep track of the scheduled state.
             */
            this._state = new StateTimeline("stopped");
            /**
             * The synced `start` callback function from the transport
             */
            this._synced = false;
            /**
             * Keep track of all of the scheduled event ids
             */
            this._scheduled = [];
            /**
             * Placeholder functions for syncing/unsyncing to transport
             */
            this._syncedStart = noOp;
            this._syncedStop = noOp;
            this._state.memory = 100;
            this._state.increasing = true;
            this._volume = this.output = new Volume({
                context: this.context,
                mute: options.mute,
                volume: options.volume,
            });
            this.volume = this._volume.volume;
            readOnly(this, "volume");
            this.onstop = options.onstop;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                mute: false,
                onstop: noOp,
                volume: 0,
            });
        }
        /**
         * Returns the playback state of the source, either "started" or "stopped".
         * @example
         * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/ahntone_c3.mp3", () => {
         * 	player.start();
         * 	console.log(player.state);
         * }).toDestination();
         */
        get state() {
            if (this._synced) {
                if (this.context.transport.state === "started") {
                    return this._state.getValueAtTime(this.context.transport.seconds);
                }
                else {
                    return "stopped";
                }
            }
            else {
                return this._state.getValueAtTime(this.now());
            }
        }
        /**
         * Mute the output.
         * @example
         * const osc = new Tone.Oscillator().toDestination().start();
         * // mute the output
         * osc.mute = true;
         */
        get mute() {
            return this._volume.mute;
        }
        set mute(mute) {
            this._volume.mute = mute;
        }
        /**
         * Ensure that the scheduled time is not before the current time.
         * Should only be used when scheduled unsynced.
         */
        _clampToCurrentTime(time) {
            if (this._synced) {
                return time;
            }
            else {
                return Math.max(time, this.context.currentTime);
            }
        }
        /**
         * Start the source at the specified time. If no time is given,
         * start the source now.
         * @param  time When the source should be started.
         * @example
         * const source = new Tone.Oscillator().toDestination();
         * source.start("+0.5"); // starts the source 0.5 seconds from now
         */
        start(time, offset, duration) {
            let computedTime = isUndef(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);
            computedTime = this._clampToCurrentTime(computedTime);
            // if it's started, stop it and restart it
            if (!this._synced && this._state.getValueAtTime(computedTime) === "started") {
                // time should be strictly greater than the previous start time
                assert(GT(computedTime, this._state.get(computedTime).time), "Start time must be strictly greater than previous start time");
                this._state.cancel(computedTime);
                this._state.setStateAtTime("started", computedTime);
                this.log("restart", computedTime);
                this.restart(computedTime, offset, duration);
            }
            else {
                this.log("start", computedTime);
                this._state.setStateAtTime("started", computedTime);
                if (this._synced) {
                    // add the offset time to the event
                    const event = this._state.get(computedTime);
                    if (event) {
                        event.offset = this.toSeconds(defaultArg(offset, 0));
                        event.duration = duration ? this.toSeconds(duration) : undefined;
                    }
                    const sched = this.context.transport.schedule(t => {
                        this._start(t, offset, duration);
                    }, computedTime);
                    this._scheduled.push(sched);
                    // if the transport is already started
                    // and the time is greater than where the transport is
                    if (this.context.transport.state === "started" &&
                        this.context.transport.getSecondsAtTime(this.immediate()) > computedTime) {
                        this._syncedStart(this.now(), this.context.transport.seconds);
                    }
                }
                else {
                    assertContextRunning(this.context);
                    this._start(computedTime, offset, duration);
                }
            }
            return this;
        }
        /**
         * Stop the source at the specified time. If no time is given,
         * stop the source now.
         * @param  time When the source should be stopped.
         * @example
         * const source = new Tone.Oscillator().toDestination();
         * source.start();
         * source.stop("+0.5"); // stops the source 0.5 seconds from now
         */
        stop(time) {
            let computedTime = isUndef(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);
            computedTime = this._clampToCurrentTime(computedTime);
            if (this._state.getValueAtTime(computedTime) === "started" || isDefined(this._state.getNextState("started", computedTime))) {
                this.log("stop", computedTime);
                if (!this._synced) {
                    this._stop(computedTime);
                }
                else {
                    const sched = this.context.transport.schedule(this._stop.bind(this), computedTime);
                    this._scheduled.push(sched);
                }
                this._state.cancel(computedTime);
                this._state.setStateAtTime("stopped", computedTime);
            }
            return this;
        }
        /**
         * Restart the source.
         */
        restart(time, offset, duration) {
            time = this.toSeconds(time);
            if (this._state.getValueAtTime(time) === "started") {
                this._state.cancel(time);
                this._restart(time, offset, duration);
            }
            return this;
        }
        /**
         * Sync the source to the Transport so that all subsequent
         * calls to `start` and `stop` are synced to the TransportTime
         * instead of the AudioContext time.
         *
         * @example
         * const osc = new Tone.Oscillator().toDestination();
         * // sync the source so that it plays between 0 and 0.3 on the Transport's timeline
         * osc.sync().start(0).stop(0.3);
         * // start the transport.
         * Tone.Transport.start();
         * // set it to loop once a second
         * Tone.Transport.loop = true;
         * Tone.Transport.loopEnd = 1;
         */
        sync() {
            if (!this._synced) {
                this._synced = true;
                this._syncedStart = (time, offset) => {
                    if (offset > 0) {
                        // get the playback state at that time
                        const stateEvent = this._state.get(offset);
                        // listen for start events which may occur in the middle of the sync'ed time
                        if (stateEvent && stateEvent.state === "started" && stateEvent.time !== offset) {
                            // get the offset
                            const startOffset = offset - this.toSeconds(stateEvent.time);
                            let duration;
                            if (stateEvent.duration) {
                                duration = this.toSeconds(stateEvent.duration) - startOffset;
                            }
                            this._start(time, this.toSeconds(stateEvent.offset) + startOffset, duration);
                        }
                    }
                };
                this._syncedStop = time => {
                    const seconds = this.context.transport.getSecondsAtTime(Math.max(time - this.sampleTime, 0));
                    if (this._state.getValueAtTime(seconds) === "started") {
                        this._stop(time);
                    }
                };
                this.context.transport.on("start", this._syncedStart);
                this.context.transport.on("loopStart", this._syncedStart);
                this.context.transport.on("stop", this._syncedStop);
                this.context.transport.on("pause", this._syncedStop);
                this.context.transport.on("loopEnd", this._syncedStop);
            }
            return this;
        }
        /**
         * Unsync the source to the Transport. See Source.sync
         */
        unsync() {
            if (this._synced) {
                this.context.transport.off("stop", this._syncedStop);
                this.context.transport.off("pause", this._syncedStop);
                this.context.transport.off("loopEnd", this._syncedStop);
                this.context.transport.off("start", this._syncedStart);
                this.context.transport.off("loopStart", this._syncedStart);
            }
            this._synced = false;
            // clear all of the scheduled ids
            this._scheduled.forEach(id => this.context.transport.clear(id));
            this._scheduled = [];
            this._state.cancel(0);
            // stop it also
            this._stop(0);
            return this;
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this.onstop = noOp;
            this.unsync();
            this._volume.dispose();
            this._state.dispose();
            return this;
        }
    }

    /**
     * Wrapper around the native BufferSourceNode.
     * @category Source
     */
    class ToneBufferSource extends OneShotSource {
        constructor() {
            super(optionsFromArguments(ToneBufferSource.getDefaults(), arguments, ["url", "onload"]));
            this.name = "ToneBufferSource";
            /**
             * The oscillator
             */
            this._source = this.context.createBufferSource();
            this._internalChannels = [this._source];
            /**
             * indicators if the source has started/stopped
             */
            this._sourceStarted = false;
            this._sourceStopped = false;
            const options = optionsFromArguments(ToneBufferSource.getDefaults(), arguments, ["url", "onload"]);
            connect(this._source, this._gainNode);
            this._source.onended = () => this._stopSource();
            /**
             * The playbackRate of the buffer
             */
            this.playbackRate = new Param({
                context: this.context,
                param: this._source.playbackRate,
                units: "positive",
                value: options.playbackRate,
            });
            // set some values initially
            this.loop = options.loop;
            this.loopStart = options.loopStart;
            this.loopEnd = options.loopEnd;
            this._buffer = new ToneAudioBuffer(options.url, options.onload, options.onerror);
            this._internalChannels.push(this._source);
        }
        static getDefaults() {
            return Object.assign(OneShotSource.getDefaults(), {
                url: new ToneAudioBuffer(),
                loop: false,
                loopEnd: 0,
                loopStart: 0,
                onload: noOp,
                onerror: noOp,
                playbackRate: 1,
            });
        }
        /**
         * The fadeIn time of the amplitude envelope.
         */
        get fadeIn() {
            return this._fadeIn;
        }
        set fadeIn(t) {
            this._fadeIn = t;
        }
        /**
         * The fadeOut time of the amplitude envelope.
         */
        get fadeOut() {
            return this._fadeOut;
        }
        set fadeOut(t) {
            this._fadeOut = t;
        }
        /**
         * The curve applied to the fades, either "linear" or "exponential"
         */
        get curve() {
            return this._curve;
        }
        set curve(t) {
            this._curve = t;
        }
        /**
         * Start the buffer
         * @param  time When the player should start.
         * @param  offset The offset from the beginning of the sample to start at.
         * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)
         * @param  gain  The gain to play the buffer back at.
         */
        start(time, offset, duration, gain = 1) {
            assert(this.buffer.loaded, "buffer is either not set or not loaded");
            const computedTime = this.toSeconds(time);
            // apply the gain envelope
            this._startGain(computedTime, gain);
            // if it's a loop the default offset is the loopstart point
            if (this.loop) {
                offset = defaultArg(offset, this.loopStart);
            }
            else {
                // otherwise the default offset is 0
                offset = defaultArg(offset, 0);
            }
            // make sure the offset is not less than 0
            let computedOffset = Math.max(this.toSeconds(offset), 0);
            // start the buffer source
            if (this.loop) {
                // modify the offset if it's greater than the loop time
                const loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;
                const loopStart = this.toSeconds(this.loopStart);
                const loopDuration = loopEnd - loopStart;
                // move the offset back
                if (GTE(computedOffset, loopEnd)) {
                    computedOffset = ((computedOffset - loopStart) % loopDuration) + loopStart;
                }
                // when the offset is very close to the duration, set it to 0
                if (EQ(computedOffset, this.buffer.duration)) {
                    computedOffset = 0;
                }
            }
            // this.buffer.loaded would have return false if the AudioBuffer was undefined
            this._source.buffer = this.buffer.get();
            this._source.loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;
            if (LT(computedOffset, this.buffer.duration)) {
                this._sourceStarted = true;
                this._source.start(computedTime, computedOffset);
            }
            // if a duration is given, schedule a stop
            if (isDefined(duration)) {
                let computedDur = this.toSeconds(duration);
                // make sure it's never negative
                computedDur = Math.max(computedDur, 0);
                this.stop(computedTime + computedDur);
            }
            return this;
        }
        _stopSource(time) {
            if (!this._sourceStopped && this._sourceStarted) {
                this._sourceStopped = true;
                this._source.stop(this.toSeconds(time));
                this._onended();
            }
        }
        /**
         * If loop is true, the loop will start at this position.
         */
        get loopStart() {
            return this._source.loopStart;
        }
        set loopStart(loopStart) {
            this._source.loopStart = this.toSeconds(loopStart);
        }
        /**
         * If loop is true, the loop will end at this position.
         */
        get loopEnd() {
            return this._source.loopEnd;
        }
        set loopEnd(loopEnd) {
            this._source.loopEnd = this.toSeconds(loopEnd);
        }
        /**
         * The audio buffer belonging to the player.
         */
        get buffer() {
            return this._buffer;
        }
        set buffer(buffer) {
            this._buffer.set(buffer);
        }
        /**
         * If the buffer should loop once it's over.
         */
        get loop() {
            return this._source.loop;
        }
        set loop(loop) {
            this._source.loop = loop;
            if (this._sourceStarted) {
                this.cancelStop();
            }
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this._source.onended = null;
            this._source.disconnect();
            this._buffer.dispose();
            this.playbackRate.dispose();
            return this;
        }
    }

    /**
     * Noise is a noise generator. It uses looped noise buffers to save on performance.
     * Noise supports the noise types: "pink", "white", and "brown". Read more about
     * colors of noise on [Wikipedia](https://en.wikipedia.org/wiki/Colors_of_noise).
     *
     * @example
     * // initialize the noise and start
     * const noise = new Tone.Noise("pink").start();
     * // make an autofilter to shape the noise
     * const autoFilter = new Tone.AutoFilter({
     * 	frequency: "8n",
     * 	baseFrequency: 200,
     * 	octaves: 8
     * }).toDestination().start();
     * // connect the noise
     * noise.connect(autoFilter);
     * // start the autofilter LFO
     * autoFilter.start();
     * @category Source
     */
    class Noise extends Source {
        constructor() {
            super(optionsFromArguments(Noise.getDefaults(), arguments, ["type"]));
            this.name = "Noise";
            /**
             * Private reference to the source
             */
            this._source = null;
            const options = optionsFromArguments(Noise.getDefaults(), arguments, ["type"]);
            this._playbackRate = options.playbackRate;
            this.type = options.type;
            this._fadeIn = options.fadeIn;
            this._fadeOut = options.fadeOut;
        }
        static getDefaults() {
            return Object.assign(Source.getDefaults(), {
                fadeIn: 0,
                fadeOut: 0,
                playbackRate: 1,
                type: "white",
            });
        }
        /**
         * The type of the noise. Can be "white", "brown", or "pink".
         * @example
         * const noise = new Tone.Noise().toDestination().start();
         * noise.type = "brown";
         */
        get type() {
            return this._type;
        }
        set type(type) {
            assert(type in _noiseBuffers, "Noise: invalid type: " + type);
            if (this._type !== type) {
                this._type = type;
                // if it's playing, stop and restart it
                if (this.state === "started") {
                    const now = this.now();
                    this._stop(now);
                    this._start(now);
                }
            }
        }
        /**
         * The playback rate of the noise. Affects
         * the "frequency" of the noise.
         */
        get playbackRate() {
            return this._playbackRate;
        }
        set playbackRate(rate) {
            this._playbackRate = rate;
            if (this._source) {
                this._source.playbackRate.value = rate;
            }
        }
        /**
         * internal start method
         */
        _start(time) {
            const buffer = _noiseBuffers[this._type];
            this._source = new ToneBufferSource({
                url: buffer,
                context: this.context,
                fadeIn: this._fadeIn,
                fadeOut: this._fadeOut,
                loop: true,
                onended: () => this.onstop(this),
                playbackRate: this._playbackRate,
            }).connect(this.output);
            this._source.start(this.toSeconds(time), Math.random() * (buffer.duration - 0.001));
        }
        /**
         * internal stop method
         */
        _stop(time) {
            if (this._source) {
                this._source.stop(this.toSeconds(time));
                this._source = null;
            }
        }
        /**
         * The fadeIn time of the amplitude envelope.
         */
        get fadeIn() {
            return this._fadeIn;
        }
        set fadeIn(time) {
            this._fadeIn = time;
            if (this._source) {
                this._source.fadeIn = this._fadeIn;
            }
        }
        /**
         * The fadeOut time of the amplitude envelope.
         */
        get fadeOut() {
            return this._fadeOut;
        }
        set fadeOut(time) {
            this._fadeOut = time;
            if (this._source) {
                this._source.fadeOut = this._fadeOut;
            }
        }
        _restart(time) {
            // TODO could be optimized by cancelling the buffer source 'stop'
            this._stop(time);
            this._start(time);
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            if (this._source) {
                this._source.disconnect();
            }
            return this;
        }
    }
    //--------------------
    // THE NOISE BUFFERS
    //--------------------
    // Noise buffer stats
    const BUFFER_LENGTH = 44100 * 5;
    const NUM_CHANNELS = 2;
    /**
     * Cache the noise buffers
     */
    const _noiseCache = {
        brown: null,
        pink: null,
        white: null,
    };
    /**
     * The noise arrays. Generated on initialization.
     * borrowed heavily from https://github.com/zacharydenton/noise.js
     * (c) 2013 Zach Denton (MIT)
     */
    const _noiseBuffers = {
        get brown() {
            if (!_noiseCache.brown) {
                const buffer = [];
                for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {
                    const channel = new Float32Array(BUFFER_LENGTH);
                    buffer[channelNum] = channel;
                    let lastOut = 0.0;
                    for (let i = 0; i < BUFFER_LENGTH; i++) {
                        const white = Math.random() * 2 - 1;
                        channel[i] = (lastOut + (0.02 * white)) / 1.02;
                        lastOut = channel[i];
                        channel[i] *= 3.5; // (roughly) compensate for gain
                    }
                }
                _noiseCache.brown = new ToneAudioBuffer().fromArray(buffer);
            }
            return _noiseCache.brown;
        },
        get pink() {
            if (!_noiseCache.pink) {
                const buffer = [];
                for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {
                    const channel = new Float32Array(BUFFER_LENGTH);
                    buffer[channelNum] = channel;
                    let b0, b1, b2, b3, b4, b5, b6;
                    b0 = b1 = b2 = b3 = b4 = b5 = b6 = 0.0;
                    for (let i = 0; i < BUFFER_LENGTH; i++) {
                        const white = Math.random() * 2 - 1;
                        b0 = 0.99886 * b0 + white * 0.0555179;
                        b1 = 0.99332 * b1 + white * 0.0750759;
                        b2 = 0.96900 * b2 + white * 0.1538520;
                        b3 = 0.86650 * b3 + white * 0.3104856;
                        b4 = 0.55000 * b4 + white * 0.5329522;
                        b5 = -0.7616 * b5 - white * 0.0168980;
                        channel[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;
                        channel[i] *= 0.11; // (roughly) compensate for gain
                        b6 = white * 0.115926;
                    }
                }
                _noiseCache.pink = new ToneAudioBuffer().fromArray(buffer);
            }
            return _noiseCache.pink;
        },
        get white() {
            if (!_noiseCache.white) {
                const buffer = [];
                for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {
                    const channel = new Float32Array(BUFFER_LENGTH);
                    buffer[channelNum] = channel;
                    for (let i = 0; i < BUFFER_LENGTH; i++) {
                        channel[i] = Math.random() * 2 - 1;
                    }
                }
                _noiseCache.white = new ToneAudioBuffer().fromArray(buffer);
            }
            return _noiseCache.white;
        },
    };

    /**
     * UserMedia uses MediaDevices.getUserMedia to open up and external microphone or audio input.
     * Check [MediaDevices API Support](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)
     * to see which browsers are supported. Access to an external input
     * is limited to secure (HTTPS) connections.
     * @example
     * const meter = new Tone.Meter();
     * const mic = new Tone.UserMedia().connect(meter);
     * mic.open().then(() => {
     * 	// promise resolves when input is available
     * 	console.log("mic open");
     * 	// print the incoming mic levels in decibels
     * 	setInterval(() => console.log(meter.getValue()), 100);
     * }).catch(e => {
     * 	// promise is rejected when the user doesn't have or allow mic access
     * 	console.log("mic not open");
     * });
     * @category Source
     */
    class UserMedia extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(UserMedia.getDefaults(), arguments, ["volume"]));
            this.name = "UserMedia";
            const options = optionsFromArguments(UserMedia.getDefaults(), arguments, ["volume"]);
            this._volume = this.output = new Volume({
                context: this.context,
                volume: options.volume,
            });
            this.volume = this._volume.volume;
            readOnly(this, "volume");
            this.mute = options.mute;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                mute: false,
                volume: 0
            });
        }
        /**
         * Open the media stream. If a string is passed in, it is assumed
         * to be the label or id of the stream, if a number is passed in,
         * it is the input number of the stream.
         * @param  labelOrId The label or id of the audio input media device.
         *                   With no argument, the default stream is opened.
         * @return The promise is resolved when the stream is open.
         */
        open(labelOrId) {
            return __awaiter(this, void 0, void 0, function* () {
                assert(UserMedia.supported, "UserMedia is not supported");
                // close the previous stream
                if (this.state === "started") {
                    this.close();
                }
                const devices = yield UserMedia.enumerateDevices();
                if (isNumber(labelOrId)) {
                    this._device = devices[labelOrId];
                }
                else {
                    this._device = devices.find((device) => {
                        return device.label === labelOrId || device.deviceId === labelOrId;
                    });
                    // didn't find a matching device
                    if (!this._device && devices.length > 0) {
                        this._device = devices[0];
                    }
                    assert(isDefined(this._device), `No matching device ${labelOrId}`);
                }
                // do getUserMedia
                const constraints = {
                    audio: {
                        echoCancellation: false,
                        sampleRate: this.context.sampleRate,
                        noiseSuppression: false,
                        mozNoiseSuppression: false,
                    }
                };
                if (this._device) {
                    // @ts-ignore
                    constraints.audio.deviceId = this._device.deviceId;
                }
                const stream = yield navigator.mediaDevices.getUserMedia(constraints);
                // start a new source only if the previous one is closed
                if (!this._stream) {
                    this._stream = stream;
                    // Wrap a MediaStreamSourceNode around the live input stream.
                    const mediaStreamNode = this.context.createMediaStreamSource(stream);
                    // Connect the MediaStreamSourceNode to a gate gain node
                    connect(mediaStreamNode, this.output);
                    this._mediaStream = mediaStreamNode;
                }
                return this;
            });
        }
        /**
         * Close the media stream
         */
        close() {
            if (this._stream && this._mediaStream) {
                this._stream.getAudioTracks().forEach((track) => {
                    track.stop();
                });
                this._stream = undefined;
                // remove the old media stream
                this._mediaStream.disconnect();
                this._mediaStream = undefined;
            }
            this._device = undefined;
            return this;
        }
        /**
         * Returns a promise which resolves with the list of audio input devices available.
         * @return The promise that is resolved with the devices
         * @example
         * Tone.UserMedia.enumerateDevices().then((devices) => {
         * 	// print the device labels
         * 	console.log(devices.map(device => device.label));
         * });
         */
        static enumerateDevices() {
            return __awaiter(this, void 0, void 0, function* () {
                const allDevices = yield navigator.mediaDevices.enumerateDevices();
                return allDevices.filter(device => {
                    return device.kind === "audioinput";
                });
            });
        }
        /**
         * Returns the playback state of the source, "started" when the microphone is open
         * and "stopped" when the mic is closed.
         */
        get state() {
            return this._stream && this._stream.active ? "started" : "stopped";
        }
        /**
         * Returns an identifier for the represented device that is
         * persisted across sessions. It is un-guessable by other applications and
         * unique to the origin of the calling application. It is reset when the
         * user clears cookies (for Private Browsing, a different identifier is
         * used that is not persisted across sessions). Returns undefined when the
         * device is not open.
         */
        get deviceId() {
            if (this._device) {
                return this._device.deviceId;
            }
            else {
                return undefined;
            }
        }
        /**
         * Returns a group identifier. Two devices have the
         * same group identifier if they belong to the same physical device.
         * Returns null  when the device is not open.
         */
        get groupId() {
            if (this._device) {
                return this._device.groupId;
            }
            else {
                return undefined;
            }
        }
        /**
         * Returns a label describing this device (for example "Built-in Microphone").
         * Returns undefined when the device is not open or label is not available
         * because of permissions.
         */
        get label() {
            if (this._device) {
                return this._device.label;
            }
            else {
                return undefined;
            }
        }
        /**
         * Mute the output.
         * @example
         * const mic = new Tone.UserMedia();
         * mic.open().then(() => {
         * 	// promise resolves when input is available
         * });
         * // mute the output
         * mic.mute = true;
         */
        get mute() {
            return this._volume.mute;
        }
        set mute(mute) {
            this._volume.mute = mute;
        }
        dispose() {
            super.dispose();
            this.close();
            this._volume.dispose();
            this.volume.dispose();
            return this;
        }
        /**
         * If getUserMedia is supported by the browser.
         */
        static get supported() {
            return isDefined(navigator.mediaDevices) &&
                isDefined(navigator.mediaDevices.getUserMedia);
        }
    }

    /**
     * Render a segment of the oscillator to an offline context and return the results as an array
     */
    function generateWaveform(instance, length) {
        return __awaiter(this, void 0, void 0, function* () {
            const duration = length / instance.context.sampleRate;
            const context = new OfflineContext(1, duration, instance.context.sampleRate);
            const clone = new instance.constructor(Object.assign(instance.get(), {
                // should do 2 iterations
                frequency: 2 / duration,
                // zero out the detune
                detune: 0,
                context
            })).toDestination();
            clone.start(0);
            const buffer = yield context.render();
            return buffer.getChannelData(0);
        });
    }

    /**
     * Wrapper around the native fire-and-forget OscillatorNode.
     * Adds the ability to reschedule the stop method.
     * ***[[Oscillator]] is better for most use-cases***
     * @category Source
     */
    class ToneOscillatorNode extends OneShotSource {
        constructor() {
            super(optionsFromArguments(ToneOscillatorNode.getDefaults(), arguments, ["frequency", "type"]));
            this.name = "ToneOscillatorNode";
            /**
             * The oscillator
             */
            this._oscillator = this.context.createOscillator();
            this._internalChannels = [this._oscillator];
            const options = optionsFromArguments(ToneOscillatorNode.getDefaults(), arguments, ["frequency", "type"]);
            connect(this._oscillator, this._gainNode);
            this.type = options.type;
            this.frequency = new Param({
                context: this.context,
                param: this._oscillator.frequency,
                units: "frequency",
                value: options.frequency,
            });
            this.detune = new Param({
                context: this.context,
                param: this._oscillator.detune,
                units: "cents",
                value: options.detune,
            });
            readOnly(this, ["frequency", "detune"]);
        }
        static getDefaults() {
            return Object.assign(OneShotSource.getDefaults(), {
                detune: 0,
                frequency: 440,
                type: "sine",
            });
        }
        /**
         * Start the oscillator node at the given time
         * @param  time When to start the oscillator
         */
        start(time) {
            const computedTime = this.toSeconds(time);
            this.log("start", computedTime);
            this._startGain(computedTime);
            this._oscillator.start(computedTime);
            return this;
        }
        _stopSource(time) {
            this._oscillator.stop(time);
        }
        /**
         * Sets an arbitrary custom periodic waveform given a PeriodicWave.
         * @param  periodicWave PeriodicWave should be created with context.createPeriodicWave
         */
        setPeriodicWave(periodicWave) {
            this._oscillator.setPeriodicWave(periodicWave);
            return this;
        }
        /**
         * The oscillator type. Either 'sine', 'sawtooth', 'square', or 'triangle'
         */
        get type() {
            return this._oscillator.type;
        }
        set type(type) {
            this._oscillator.type = type;
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            if (this.state === "started") {
                this.stop();
            }
            this._oscillator.disconnect();
            this.frequency.dispose();
            this.detune.dispose();
            return this;
        }
    }

    /**
     * Oscillator supports a number of features including
     * phase rotation, multiple oscillator types (see Oscillator.type),
     * and Transport syncing (see Oscillator.syncFrequency).
     *
     * @example
     * // make and start a 440hz sine tone
     * const osc = new Tone.Oscillator(440, "sine").toDestination().start();
     * @category Source
     */
    class Oscillator extends Source {
        constructor() {
            super(optionsFromArguments(Oscillator.getDefaults(), arguments, ["frequency", "type"]));
            this.name = "Oscillator";
            /**
             * the main oscillator
             */
            this._oscillator = null;
            const options = optionsFromArguments(Oscillator.getDefaults(), arguments, ["frequency", "type"]);
            this.frequency = new Signal({
                context: this.context,
                units: "frequency",
                value: options.frequency,
            });
            readOnly(this, "frequency");
            this.detune = new Signal({
                context: this.context,
                units: "cents",
                value: options.detune,
            });
            readOnly(this, "detune");
            this._partials = options.partials;
            this._partialCount = options.partialCount;
            this._type = options.type;
            if (options.partialCount && options.type !== "custom") {
                this._type = this.baseType + options.partialCount.toString();
            }
            this.phase = options.phase;
        }
        static getDefaults() {
            return Object.assign(Source.getDefaults(), {
                detune: 0,
                frequency: 440,
                partialCount: 0,
                partials: [],
                phase: 0,
                type: "sine",
            });
        }
        /**
         * start the oscillator
         */
        _start(time) {
            const computedTime = this.toSeconds(time);
            // new oscillator with previous values
            const oscillator = new ToneOscillatorNode({
                context: this.context,
                onended: () => this.onstop(this),
            });
            this._oscillator = oscillator;
            if (this._wave) {
                this._oscillator.setPeriodicWave(this._wave);
            }
            else {
                this._oscillator.type = this._type;
            }
            // connect the control signal to the oscillator frequency & detune
            this._oscillator.connect(this.output);
            this.frequency.connect(this._oscillator.frequency);
            this.detune.connect(this._oscillator.detune);
            // start the oscillator
            this._oscillator.start(computedTime);
        }
        /**
         * stop the oscillator
         */
        _stop(time) {
            const computedTime = this.toSeconds(time);
            if (this._oscillator) {
                this._oscillator.stop(computedTime);
            }
        }
        /**
         * Restart the oscillator. Does not stop the oscillator, but instead
         * just cancels any scheduled 'stop' from being invoked.
         */
        _restart(time) {
            const computedTime = this.toSeconds(time);
            this.log("restart", computedTime);
            if (this._oscillator) {
                this._oscillator.cancelStop();
            }
            this._state.cancel(computedTime);
            return this;
        }
        /**
         * Sync the signal to the Transport's bpm. Any changes to the transports bpm,
         * will also affect the oscillators frequency.
         * @example
         * const osc = new Tone.Oscillator().toDestination().start();
         * osc.frequency.value = 440;
         * // the ratio between the bpm and the frequency will be maintained
         * osc.syncFrequency();
         * // double the tempo
         * Tone.Transport.bpm.value *= 2;
         * // the frequency of the oscillator is doubled to 880
         */
        syncFrequency() {
            this.context.transport.syncSignal(this.frequency);
            return this;
        }
        /**
         * Unsync the oscillator's frequency from the Transport.
         * See Oscillator.syncFrequency
         */
        unsyncFrequency() {
            this.context.transport.unsyncSignal(this.frequency);
            return this;
        }
        /**
         * Get a cached periodic wave. Avoids having to recompute
         * the oscillator values when they have already been computed
         * with the same values.
         */
        _getCachedPeriodicWave() {
            if (this._type === "custom") {
                const oscProps = Oscillator._periodicWaveCache.find(description => {
                    return description.phase === this._phase &&
                        deepEquals(description.partials, this._partials);
                });
                return oscProps;
            }
            else {
                const oscProps = Oscillator._periodicWaveCache.find(description => {
                    return description.type === this._type &&
                        description.phase === this._phase;
                });
                this._partialCount = oscProps ? oscProps.partialCount : this._partialCount;
                return oscProps;
            }
        }
        get type() {
            return this._type;
        }
        set type(type) {
            this._type = type;
            const isBasicType = ["sine", "square", "sawtooth", "triangle"].indexOf(type) !== -1;
            if (this._phase === 0 && isBasicType) {
                this._wave = undefined;
                this._partialCount = 0;
                // just go with the basic approach
                if (this._oscillator !== null) {
                    // already tested that it's a basic type
                    this._oscillator.type = type;
                }
            }
            else {
                // first check if the value is cached
                const cache = this._getCachedPeriodicWave();
                if (isDefined(cache)) {
                    const { partials, wave } = cache;
                    this._wave = wave;
                    this._partials = partials;
                    if (this._oscillator !== null) {
                        this._oscillator.setPeriodicWave(this._wave);
                    }
                }
                else {
                    const [real, imag] = this._getRealImaginary(type, this._phase);
                    const periodicWave = this.context.createPeriodicWave(real, imag);
                    this._wave = periodicWave;
                    if (this._oscillator !== null) {
                        this._oscillator.setPeriodicWave(this._wave);
                    }
                    // set the cache
                    Oscillator._periodicWaveCache.push({
                        imag,
                        partialCount: this._partialCount,
                        partials: this._partials,
                        phase: this._phase,
                        real,
                        type: this._type,
                        wave: this._wave,
                    });
                    if (Oscillator._periodicWaveCache.length > 100) {
                        Oscillator._periodicWaveCache.shift();
                    }
                }
            }
        }
        get baseType() {
            return this._type.replace(this.partialCount.toString(), "");
        }
        set baseType(baseType) {
            if (this.partialCount && this._type !== "custom" && baseType !== "custom") {
                this.type = baseType + this.partialCount;
            }
            else {
                this.type = baseType;
            }
        }
        get partialCount() {
            return this._partialCount;
        }
        set partialCount(p) {
            assertRange(p, 0);
            let type = this._type;
            const partial = /^(sine|triangle|square|sawtooth)(\d+)$/.exec(this._type);
            if (partial) {
                type = partial[1];
            }
            if (this._type !== "custom") {
                if (p === 0) {
                    this.type = type;
                }
                else {
                    this.type = type + p.toString();
                }
            }
            else {
                // extend or shorten the partials array
                const fullPartials = new Float32Array(p);
                // copy over the partials array
                this._partials.forEach((v, i) => fullPartials[i] = v);
                this._partials = Array.from(fullPartials);
                this.type = this._type;
            }
        }
        /**
         * Returns the real and imaginary components based
         * on the oscillator type.
         * @returns [real: Float32Array, imaginary: Float32Array]
         */
        _getRealImaginary(type, phase) {
            const fftSize = 4096;
            let periodicWaveSize = fftSize / 2;
            const real = new Float32Array(periodicWaveSize);
            const imag = new Float32Array(periodicWaveSize);
            let partialCount = 1;
            if (type === "custom") {
                partialCount = this._partials.length + 1;
                this._partialCount = this._partials.length;
                periodicWaveSize = partialCount;
                // if the partial count is 0, don't bother doing any computation
                if (this._partials.length === 0) {
                    return [real, imag];
                }
            }
            else {
                const partial = /^(sine|triangle|square|sawtooth)(\d+)$/.exec(type);
                if (partial) {
                    partialCount = parseInt(partial[2], 10) + 1;
                    this._partialCount = parseInt(partial[2], 10);
                    type = partial[1];
                    partialCount = Math.max(partialCount, 2);
                    periodicWaveSize = partialCount;
                }
                else {
                    this._partialCount = 0;
                }
                this._partials = [];
            }
            for (let n = 1; n < periodicWaveSize; ++n) {
                const piFactor = 2 / (n * Math.PI);
                let b;
                switch (type) {
                    case "sine":
                        b = (n <= partialCount) ? 1 : 0;
                        this._partials[n - 1] = b;
                        break;
                    case "square":
                        b = (n & 1) ? 2 * piFactor : 0;
                        this._partials[n - 1] = b;
                        break;
                    case "sawtooth":
                        b = piFactor * ((n & 1) ? 1 : -1);
                        this._partials[n - 1] = b;
                        break;
                    case "triangle":
                        if (n & 1) {
                            b = 2 * (piFactor * piFactor) * ((((n - 1) >> 1) & 1) ? -1 : 1);
                        }
                        else {
                            b = 0;
                        }
                        this._partials[n - 1] = b;
                        break;
                    case "custom":
                        b = this._partials[n - 1];
                        break;
                    default:
                        throw new TypeError("Oscillator: invalid type: " + type);
                }
                if (b !== 0) {
                    real[n] = -b * Math.sin(phase * n);
                    imag[n] = b * Math.cos(phase * n);
                }
                else {
                    real[n] = 0;
                    imag[n] = 0;
                }
            }
            return [real, imag];
        }
        /**
         * Compute the inverse FFT for a given phase.
         */
        _inverseFFT(real, imag, phase) {
            let sum = 0;
            const len = real.length;
            for (let i = 0; i < len; i++) {
                sum += real[i] * Math.cos(i * phase) + imag[i] * Math.sin(i * phase);
            }
            return sum;
        }
        /**
         * Returns the initial value of the oscillator when stopped.
         * E.g. a "sine" oscillator with phase = 90 would return an initial value of -1.
         */
        getInitialValue() {
            const [real, imag] = this._getRealImaginary(this._type, 0);
            let maxValue = 0;
            const twoPi = Math.PI * 2;
            const testPositions = 32;
            // check for peaks in 16 places
            for (let i = 0; i < testPositions; i++) {
                maxValue = Math.max(this._inverseFFT(real, imag, (i / testPositions) * twoPi), maxValue);
            }
            return clamp(-this._inverseFFT(real, imag, this._phase) / maxValue, -1, 1);
        }
        get partials() {
            return this._partials.slice(0, this.partialCount);
        }
        set partials(partials) {
            this._partials = partials;
            this._partialCount = this._partials.length;
            if (partials.length) {
                this.type = "custom";
            }
        }
        get phase() {
            return this._phase * (180 / Math.PI);
        }
        set phase(phase) {
            this._phase = phase * Math.PI / 180;
            // reset the type
            this.type = this._type;
        }
        asArray(length = 1024) {
            return __awaiter(this, void 0, void 0, function* () {
                return generateWaveform(this, length);
            });
        }
        dispose() {
            super.dispose();
            if (this._oscillator !== null) {
                this._oscillator.dispose();
            }
            this._wave = undefined;
            this.frequency.dispose();
            this.detune.dispose();
            return this;
        }
    }
    /**
     * Cache the periodic waves to avoid having to redo computations
     */
    Oscillator._periodicWaveCache = [];

    /**
     * A signal operator has an input and output and modifies the signal.
     */
    class SignalOperator extends ToneAudioNode {
        constructor() {
            super(Object.assign(optionsFromArguments(SignalOperator.getDefaults(), arguments, ["context"])));
        }
        connect(destination, outputNum = 0, inputNum = 0) {
            connectSignal(this, destination, outputNum, inputNum);
            return this;
        }
    }

    /**
     * Wraps the native Web Audio API
     * [WaveShaperNode](http://webaudio.github.io/web-audio-api/#the-waveshapernode-interface).
     *
     * @example
     * const osc = new Tone.Oscillator().toDestination().start();
     * // multiply the output of the signal by 2 using the waveshaper's function
     * const timesTwo = new Tone.WaveShaper((val) => val * 2, 2048).connect(osc.frequency);
     * const signal = new Tone.Signal(440).connect(timesTwo);
     * @category Signal
     */
    class WaveShaper extends SignalOperator {
        constructor() {
            super(Object.assign(optionsFromArguments(WaveShaper.getDefaults(), arguments, ["mapping", "length"])));
            this.name = "WaveShaper";
            /**
             * the waveshaper node
             */
            this._shaper = this.context.createWaveShaper();
            /**
             * The input to the waveshaper node.
             */
            this.input = this._shaper;
            /**
             * The output from the waveshaper node
             */
            this.output = this._shaper;
            const options = optionsFromArguments(WaveShaper.getDefaults(), arguments, ["mapping", "length"]);
            if (isArray(options.mapping) || options.mapping instanceof Float32Array) {
                this.curve = Float32Array.from(options.mapping);
            }
            else if (isFunction(options.mapping)) {
                this.setMap(options.mapping, options.length);
            }
        }
        static getDefaults() {
            return Object.assign(Signal.getDefaults(), {
                length: 1024,
            });
        }
        /**
         * Uses a mapping function to set the value of the curve.
         * @param mapping The function used to define the values.
         *                The mapping function take two arguments:
         *                the first is the value at the current position
         *                which goes from -1 to 1 over the number of elements
         *                in the curve array. The second argument is the array position.
         * @example
         * const shaper = new Tone.WaveShaper();
         * // map the input signal from [-1, 1] to [0, 10]
         * shaper.setMap((val, index) => (val + 1) * 5);
         */
        setMap(mapping, length = 1024) {
            const array = new Float32Array(length);
            for (let i = 0, len = length; i < len; i++) {
                const normalized = (i / (len - 1)) * 2 - 1;
                array[i] = mapping(normalized, i);
            }
            this.curve = array;
            return this;
        }
        /**
         * The array to set as the waveshaper curve. For linear curves
         * array length does not make much difference, but for complex curves
         * longer arrays will provide smoother interpolation.
         */
        get curve() {
            return this._shaper.curve;
        }
        set curve(mapping) {
            this._shaper.curve = mapping;
        }
        /**
         * Specifies what type of oversampling (if any) should be used when
         * applying the shaping curve. Can either be "none", "2x" or "4x".
         */
        get oversample() {
            return this._shaper.oversample;
        }
        set oversample(oversampling) {
            const isOverSampleType = ["none", "2x", "4x"].some(str => str.includes(oversampling));
            assert(isOverSampleType, "oversampling must be either 'none', '2x', or '4x'");
            this._shaper.oversample = oversampling;
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this._shaper.disconnect();
            return this;
        }
    }

    /**
     * AudioToGain converts an input in AudioRange [-1,1] to NormalRange [0,1].
     * See [[GainToAudio]].
     * @category Signal
     */
    class AudioToGain extends SignalOperator {
        constructor() {
            super(...arguments);
            this.name = "AudioToGain";
            /**
             * The node which converts the audio ranges
             */
            this._norm = new WaveShaper({
                context: this.context,
                mapping: x => (x + 1) / 2,
            });
            /**
             * The AudioRange input [-1, 1]
             */
            this.input = this._norm;
            /**
             * The GainRange output [0, 1]
             */
            this.output = this._norm;
        }
        /**
         * clean up
         */
        dispose() {
            super.dispose();
            this._norm.dispose();
            return this;
        }
    }

    /**
     * Multiply two incoming signals. Or, if a number is given in the constructor,
     * multiplies the incoming signal by that value.
     *
     * @example
     * // multiply two signals
     * const mult = new Tone.Multiply();
     * const sigA = new Tone.Signal(3);
     * const sigB = new Tone.Signal(4);
     * sigA.connect(mult);
     * sigB.connect(mult.factor);
     * // output of mult is 12.
     * @example
     * // multiply a signal and a number
     * const mult = new Tone.Multiply(10);
     * const sig = new Tone.Signal(2).connect(mult);
     * // the output of mult is 20.
     * @category Signal
     */
    class Multiply extends Signal {
        constructor() {
            super(Object.assign(optionsFromArguments(Multiply.getDefaults(), arguments, ["value"])));
            this.name = "Multiply";
            /**
             * Indicates if the value should be overridden on connection
             */
            this.override = false;
            const options = optionsFromArguments(Multiply.getDefaults(), arguments, ["value"]);
            this._mult = this.input = this.output = new Gain({
                context: this.context,
                minValue: options.minValue,
                maxValue: options.maxValue,
            });
            this.factor = this._param = this._mult.gain;
            this.factor.setValueAtTime(options.value, 0);
        }
        static getDefaults() {
            return Object.assign(Signal.getDefaults(), {
                value: 0,
            });
        }
        dispose() {
            super.dispose();
            this._mult.dispose();
            return this;
        }
    }

    /**
     * An amplitude modulated oscillator node. It is implemented with
     * two oscillators, one which modulators the other's amplitude
     * through a gain node.
     * ```
     *    +-------------+       +----------+
     *    | Carrier Osc +>------> GainNode |
     *    +-------------+       |          +--->Output
     *                      +---> gain     |
     * +---------------+    |   +----------+
     * | Modulator Osc +>---+
     * +---------------+
     * ```
     * @example
     * return Tone.Offline(() => {
     * 	const amOsc = new Tone.AMOscillator(30, "sine", "square").toDestination().start();
     * }, 0.2, 1);
     * @category Source
     */
    class AMOscillator extends Source {
        constructor() {
            super(optionsFromArguments(AMOscillator.getDefaults(), arguments, ["frequency", "type", "modulationType"]));
            this.name = "AMOscillator";
            /**
             * convert the -1,1 output to 0,1
             */
            this._modulationScale = new AudioToGain({ context: this.context });
            /**
             * the node where the modulation happens
             */
            this._modulationNode = new Gain({
                context: this.context,
            });
            const options = optionsFromArguments(AMOscillator.getDefaults(), arguments, ["frequency", "type", "modulationType"]);
            this._carrier = new Oscillator({
                context: this.context,
                detune: options.detune,
                frequency: options.frequency,
                onstop: () => this.onstop(this),
                phase: options.phase,
                type: options.type,
            });
            this.frequency = this._carrier.frequency,
                this.detune = this._carrier.detune;
            this._modulator = new Oscillator({
                context: this.context,
                phase: options.phase,
                type: options.modulationType,
            });
            this.harmonicity = new Multiply({
                context: this.context,
                units: "positive",
                value: options.harmonicity,
            });
            // connections
            this.frequency.chain(this.harmonicity, this._modulator.frequency);
            this._modulator.chain(this._modulationScale, this._modulationNode.gain);
            this._carrier.chain(this._modulationNode, this.output);
            readOnly(this, ["frequency", "detune", "harmonicity"]);
        }
        static getDefaults() {
            return Object.assign(Oscillator.getDefaults(), {
                harmonicity: 1,
                modulationType: "square",
            });
        }
        /**
         * start the oscillator
         */
        _start(time) {
            this._modulator.start(time);
            this._carrier.start(time);
        }
        /**
         * stop the oscillator
         */
        _stop(time) {
            this._modulator.stop(time);
            this._carrier.stop(time);
        }
        _restart(time) {
            this._modulator.restart(time);
            this._carrier.restart(time);
        }
        /**
         * The type of the carrier oscillator
         */
        get type() {
            return this._carrier.type;
        }
        set type(type) {
            this._carrier.type = type;
        }
        get baseType() {
            return this._carrier.baseType;
        }
        set baseType(baseType) {
            this._carrier.baseType = baseType;
        }
        get partialCount() {
            return this._carrier.partialCount;
        }
        set partialCount(partialCount) {
            this._carrier.partialCount = partialCount;
        }
        /**
         * The type of the modulator oscillator
         */
        get modulationType() {
            return this._modulator.type;
        }
        set modulationType(type) {
            this._modulator.type = type;
        }
        get phase() {
            return this._carrier.phase;
        }
        set phase(phase) {
            this._carrier.phase = phase;
            this._modulator.phase = phase;
        }
        get partials() {
            return this._carrier.partials;
        }
        set partials(partials) {
            this._carrier.partials = partials;
        }
        asArray(length = 1024) {
            return __awaiter(this, void 0, void 0, function* () {
                return generateWaveform(this, length);
            });
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this.frequency.dispose();
            this.detune.dispose();
            this.harmonicity.dispose();
            this._carrier.dispose();
            this._modulator.dispose();
            this._modulationNode.dispose();
            this._modulationScale.dispose();
            return this;
        }
    }

    /**
     * FMOscillator implements a frequency modulation synthesis
     * ```
     *                                              +-------------+
     * +---------------+        +-------------+     | Carrier Osc |
     * | Modulator Osc +>-------> GainNode    |     |             +--->Output
     * +---------------+        |             +>----> frequency   |
     *                       +--> gain        |     +-------------+
     *                       |  +-------------+
     * +-----------------+   |
     * | modulationIndex +>--+
     * +-----------------+
     * ```
     *
     * @example
     * return Tone.Offline(() => {
     * 	const fmOsc = new Tone.FMOscillator({
     * 		frequency: 200,
     * 		type: "square",
     * 		modulationType: "triangle",
     * 		harmonicity: 0.2,
     * 		modulationIndex: 3
     * 	}).toDestination().start();
     * }, 0.1, 1);
     * @category Source
     */
    class FMOscillator extends Source {
        constructor() {
            super(optionsFromArguments(FMOscillator.getDefaults(), arguments, ["frequency", "type", "modulationType"]));
            this.name = "FMOscillator";
            /**
             * the node where the modulation happens
             */
            this._modulationNode = new Gain({
                context: this.context,
                gain: 0,
            });
            const options = optionsFromArguments(FMOscillator.getDefaults(), arguments, ["frequency", "type", "modulationType"]);
            this._carrier = new Oscillator({
                context: this.context,
                detune: options.detune,
                frequency: 0,
                onstop: () => this.onstop(this),
                phase: options.phase,
                type: options.type,
            });
            this.detune = this._carrier.detune;
            this.frequency = new Signal({
                context: this.context,
                units: "frequency",
                value: options.frequency,
            });
            this._modulator = new Oscillator({
                context: this.context,
                phase: options.phase,
                type: options.modulationType,
            });
            this.harmonicity = new Multiply({
                context: this.context,
                units: "positive",
                value: options.harmonicity,
            });
            this.modulationIndex = new Multiply({
                context: this.context,
                units: "positive",
                value: options.modulationIndex,
            });
            // connections
            this.frequency.connect(this._carrier.frequency);
            this.frequency.chain(this.harmonicity, this._modulator.frequency);
            this.frequency.chain(this.modulationIndex, this._modulationNode);
            this._modulator.connect(this._modulationNode.gain);
            this._modulationNode.connect(this._carrier.frequency);
            this._carrier.connect(this.output);
            this.detune.connect(this._modulator.detune);
            readOnly(this, ["modulationIndex", "frequency", "detune", "harmonicity"]);
        }
        static getDefaults() {
            return Object.assign(Oscillator.getDefaults(), {
                harmonicity: 1,
                modulationIndex: 2,
                modulationType: "square",
            });
        }
        /**
         * start the oscillator
         */
        _start(time) {
            this._modulator.start(time);
            this._carrier.start(time);
        }
        /**
         * stop the oscillator
         */
        _stop(time) {
            this._modulator.stop(time);
            this._carrier.stop(time);
        }
        _restart(time) {
            this._modulator.restart(time);
            this._carrier.restart(time);
            return this;
        }
        get type() {
            return this._carrier.type;
        }
        set type(type) {
            this._carrier.type = type;
        }
        get baseType() {
            return this._carrier.baseType;
        }
        set baseType(baseType) {
            this._carrier.baseType = baseType;
        }
        get partialCount() {
            return this._carrier.partialCount;
        }
        set partialCount(partialCount) {
            this._carrier.partialCount = partialCount;
        }
        /**
         * The type of the modulator oscillator
         */
        get modulationType() {
            return this._modulator.type;
        }
        set modulationType(type) {
            this._modulator.type = type;
        }
        get phase() {
            return this._carrier.phase;
        }
        set phase(phase) {
            this._carrier.phase = phase;
            this._modulator.phase = phase;
        }
        get partials() {
            return this._carrier.partials;
        }
        set partials(partials) {
            this._carrier.partials = partials;
        }
        asArray(length = 1024) {
            return __awaiter(this, void 0, void 0, function* () {
                return generateWaveform(this, length);
            });
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this.frequency.dispose();
            this.harmonicity.dispose();
            this._carrier.dispose();
            this._modulator.dispose();
            this._modulationNode.dispose();
            this.modulationIndex.dispose();
            return this;
        }
    }

    /**
     * PulseOscillator is an oscillator with control over pulse width,
     * also known as the duty cycle. At 50% duty cycle (width = 0) the wave is
     * a square wave.
     * [Read more](https://wigglewave.wordpress.com/2014/08/16/pulse-waveforms-and-harmonics/).
     * ```
     *    width = -0.25        width = 0.0          width = 0.25
     *
     *   +-----+            +-------+       +    +-------+     +-+
     *   |     |            |       |       |            |     |
     *   |     |            |       |       |            |     |
     * +-+     +-------+    +       +-------+            +-----+
     *
     *
     *    width = -0.5                              width = 0.5
     *
     *     +---+                                 +-------+   +---+
     *     |   |                                         |   |
     *     |   |                                         |   |
     * +---+   +-------+                                 +---+
     *
     *
     *    width = -0.75                             width = 0.75
     *
     *       +-+                                 +-------+ +-----+
     *       | |                                         | |
     *       | |                                         | |
     * +-----+ +-------+                                 +-+
     * ```
     * @example
     * return Tone.Offline(() => {
     * 	const pulse = new Tone.PulseOscillator(50, 0.4).toDestination().start();
     * }, 0.1, 1);
     * @category Source
     */
    class PulseOscillator extends Source {
        constructor() {
            super(optionsFromArguments(PulseOscillator.getDefaults(), arguments, ["frequency", "width"]));
            this.name = "PulseOscillator";
            /**
             * gate the width amount
             */
            this._widthGate = new Gain({
                context: this.context,
                gain: 0,
            });
            /**
             * Threshold the signal to turn it into a square
             */
            this._thresh = new WaveShaper({
                context: this.context,
                mapping: val => val <= 0 ? -1 : 1,
            });
            const options = optionsFromArguments(PulseOscillator.getDefaults(), arguments, ["frequency", "width"]);
            this.width = new Signal({
                context: this.context,
                units: "audioRange",
                value: options.width,
            });
            this._triangle = new Oscillator({
                context: this.context,
                detune: options.detune,
                frequency: options.frequency,
                onstop: () => this.onstop(this),
                phase: options.phase,
                type: "triangle",
            });
            this.frequency = this._triangle.frequency;
            this.detune = this._triangle.detune;
            // connections
            this._triangle.chain(this._thresh, this.output);
            this.width.chain(this._widthGate, this._thresh);
            readOnly(this, ["width", "frequency", "detune"]);
        }
        static getDefaults() {
            return Object.assign(Source.getDefaults(), {
                detune: 0,
                frequency: 440,
                phase: 0,
                type: "pulse",
                width: 0.2,
            });
        }
        /**
         * start the oscillator
         */
        _start(time) {
            time = this.toSeconds(time);
            this._triangle.start(time);
            this._widthGate.gain.setValueAtTime(1, time);
        }
        /**
         * stop the oscillator
         */
        _stop(time) {
            time = this.toSeconds(time);
            this._triangle.stop(time);
            // the width is still connected to the output.
            // that needs to be stopped also
            this._widthGate.gain.cancelScheduledValues(time);
            this._widthGate.gain.setValueAtTime(0, time);
        }
        _restart(time) {
            this._triangle.restart(time);
            this._widthGate.gain.cancelScheduledValues(time);
            this._widthGate.gain.setValueAtTime(1, time);
        }
        /**
         * The phase of the oscillator in degrees.
         */
        get phase() {
            return this._triangle.phase;
        }
        set phase(phase) {
            this._triangle.phase = phase;
        }
        /**
         * The type of the oscillator. Always returns "pulse".
         */
        get type() {
            return "pulse";
        }
        /**
         * The baseType of the oscillator. Always returns "pulse".
         */
        get baseType() {
            return "pulse";
        }
        /**
         * The partials of the waveform. Cannot set partials for this waveform type
         */
        get partials() {
            return [];
        }
        /**
         * No partials for this waveform type.
         */
        get partialCount() {
            return 0;
        }
        /**
         * *Internal use* The carrier oscillator type is fed through the
         * waveshaper node to create the pulse. Using different carrier oscillators
         * changes oscillator's behavior.
         */
        set carrierType(type) {
            this._triangle.type = type;
        }
        asArray(length = 1024) {
            return __awaiter(this, void 0, void 0, function* () {
                return generateWaveform(this, length);
            });
        }
        /**
         * Clean up method.
         */
        dispose() {
            super.dispose();
            this._triangle.dispose();
            this.width.dispose();
            this._widthGate.dispose();
            this._thresh.dispose();
            return this;
        }
    }

    /**
     * FatOscillator is an array of oscillators with detune spread between the oscillators
     * @example
     * const fatOsc = new Tone.FatOscillator("Ab3", "sawtooth", 40).toDestination().start();
     * @category Source
     */
    class FatOscillator extends Source {
        constructor() {
            super(optionsFromArguments(FatOscillator.getDefaults(), arguments, ["frequency", "type", "spread"]));
            this.name = "FatOscillator";
            /**
             * The array of oscillators
             */
            this._oscillators = [];
            const options = optionsFromArguments(FatOscillator.getDefaults(), arguments, ["frequency", "type", "spread"]);
            this.frequency = new Signal({
                context: this.context,
                units: "frequency",
                value: options.frequency,
            });
            this.detune = new Signal({
                context: this.context,
                units: "cents",
                value: options.detune,
            });
            this._spread = options.spread;
            this._type = options.type;
            this._phase = options.phase;
            this._partials = options.partials;
            this._partialCount = options.partialCount;
            // set the count initially
            this.count = options.count;
            readOnly(this, ["frequency", "detune"]);
        }
        static getDefaults() {
            return Object.assign(Oscillator.getDefaults(), {
                count: 3,
                spread: 20,
                type: "sawtooth",
            });
        }
        /**
         * start the oscillator
         */
        _start(time) {
            time = this.toSeconds(time);
            this._forEach(osc => osc.start(time));
        }
        /**
         * stop the oscillator
         */
        _stop(time) {
            time = this.toSeconds(time);
            this._forEach(osc => osc.stop(time));
        }
        _restart(time) {
            this._forEach(osc => osc.restart(time));
        }
        /**
         * Iterate over all of the oscillators
         */
        _forEach(iterator) {
            for (let i = 0; i < this._oscillators.length; i++) {
                iterator(this._oscillators[i], i);
            }
        }
        /**
         * The type of the oscillator
         */
        get type() {
            return this._type;
        }
        set type(type) {
            this._type = type;
            this._forEach(osc => osc.type = type);
        }
        /**
         * The detune spread between the oscillators. If "count" is
         * set to 3 oscillators and the "spread" is set to 40,
         * the three oscillators would be detuned like this: [-20, 0, 20]
         * for a total detune spread of 40 cents.
         * @example
         * const fatOsc = new Tone.FatOscillator().toDestination().start();
         * fatOsc.spread = 70;
         */
        get spread() {
            return this._spread;
        }
        set spread(spread) {
            this._spread = spread;
            if (this._oscillators.length > 1) {
                const start = -spread / 2;
                const step = spread / (this._oscillators.length - 1);
                this._forEach((osc, i) => osc.detune.value = start + step * i);
            }
        }
        /**
         * The number of detuned oscillators. Must be an integer greater than 1.
         * @example
         * const fatOsc = new Tone.FatOscillator("C#3", "sawtooth").toDestination().start();
         * // use 4 sawtooth oscillators
         * fatOsc.count = 4;
         */
        get count() {
            return this._oscillators.length;
        }
        set count(count) {
            assertRange(count, 1);
            if (this._oscillators.length !== count) {
                // dispose the previous oscillators
                this._forEach(osc => osc.dispose());
                this._oscillators = [];
                for (let i = 0; i < count; i++) {
                    const osc = new Oscillator({
                        context: this.context,
                        volume: -6 - count * 1.1,
                        type: this._type,
                        phase: this._phase + (i / count) * 360,
                        partialCount: this._partialCount,
                        onstop: i === 0 ? () => this.onstop(this) : noOp,
                    });
                    if (this.type === "custom") {
                        osc.partials = this._partials;
                    }
                    this.frequency.connect(osc.frequency);
                    this.detune.connect(osc.detune);
                    osc.detune.overridden = false;
                    osc.connect(this.output);
                    this._oscillators[i] = osc;
                }
                // set the spread
                this.spread = this._spread;
                if (this.state === "started") {
                    this._forEach(osc => osc.start());
                }
            }
        }
        get phase() {
            return this._phase;
        }
        set phase(phase) {
            this._phase = phase;
            this._forEach((osc, i) => osc.phase = this._phase + (i / this.count) * 360);
        }
        get baseType() {
            return this._oscillators[0].baseType;
        }
        set baseType(baseType) {
            this._forEach(osc => osc.baseType = baseType);
            this._type = this._oscillators[0].type;
        }
        get partials() {
            return this._oscillators[0].partials;
        }
        set partials(partials) {
            this._partials = partials;
            this._partialCount = this._partials.length;
            if (partials.length) {
                this._type = "custom";
                this._forEach(osc => osc.partials = partials);
            }
        }
        get partialCount() {
            return this._oscillators[0].partialCount;
        }
        set partialCount(partialCount) {
            this._partialCount = partialCount;
            this._forEach(osc => osc.partialCount = partialCount);
            this._type = this._oscillators[0].type;
        }
        asArray(length = 1024) {
            return __awaiter(this, void 0, void 0, function* () {
                return generateWaveform(this, length);
            });
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this.frequency.dispose();
            this.detune.dispose();
            this._forEach(osc => osc.dispose());
            return this;
        }
    }

    /**
     * PWMOscillator modulates the width of a Tone.PulseOscillator
     * at the modulationFrequency. This has the effect of continuously
     * changing the timbre of the oscillator by altering the harmonics
     * generated.
     * @example
     * return Tone.Offline(() => {
     * 	const pwm = new Tone.PWMOscillator(60, 0.3).toDestination().start();
     * }, 0.1, 1);
     * @category Source
     */
    class PWMOscillator extends Source {
        constructor() {
            super(optionsFromArguments(PWMOscillator.getDefaults(), arguments, ["frequency", "modulationFrequency"]));
            this.name = "PWMOscillator";
            this.sourceType = "pwm";
            /**
             * Scale the oscillator so it doesn't go silent
             * at the extreme values.
             */
            this._scale = new Multiply({
                context: this.context,
                value: 2,
            });
            const options = optionsFromArguments(PWMOscillator.getDefaults(), arguments, ["frequency", "modulationFrequency"]);
            this._pulse = new PulseOscillator({
                context: this.context,
                frequency: options.modulationFrequency,
            });
            // change the pulse oscillator type
            this._pulse.carrierType = "sine";
            this.modulationFrequency = this._pulse.frequency;
            this._modulator = new Oscillator({
                context: this.context,
                detune: options.detune,
                frequency: options.frequency,
                onstop: () => this.onstop(this),
                phase: options.phase,
            });
            this.frequency = this._modulator.frequency;
            this.detune = this._modulator.detune;
            // connections
            this._modulator.chain(this._scale, this._pulse.width);
            this._pulse.connect(this.output);
            readOnly(this, ["modulationFrequency", "frequency", "detune"]);
        }
        static getDefaults() {
            return Object.assign(Source.getDefaults(), {
                detune: 0,
                frequency: 440,
                modulationFrequency: 0.4,
                phase: 0,
                type: "pwm",
            });
        }
        /**
         * start the oscillator
         */
        _start(time) {
            time = this.toSeconds(time);
            this._modulator.start(time);
            this._pulse.start(time);
        }
        /**
         * stop the oscillator
         */
        _stop(time) {
            time = this.toSeconds(time);
            this._modulator.stop(time);
            this._pulse.stop(time);
        }
        /**
         * restart the oscillator
         */
        _restart(time) {
            this._modulator.restart(time);
            this._pulse.restart(time);
        }
        /**
         * The type of the oscillator. Always returns "pwm".
         */
        get type() {
            return "pwm";
        }
        /**
         * The baseType of the oscillator. Always returns "pwm".
         */
        get baseType() {
            return "pwm";
        }
        /**
         * The partials of the waveform. Cannot set partials for this waveform type
         */
        get partials() {
            return [];
        }
        /**
         * No partials for this waveform type.
         */
        get partialCount() {
            return 0;
        }
        /**
         * The phase of the oscillator in degrees.
         */
        get phase() {
            return this._modulator.phase;
        }
        set phase(phase) {
            this._modulator.phase = phase;
        }
        asArray(length = 1024) {
            return __awaiter(this, void 0, void 0, function* () {
                return generateWaveform(this, length);
            });
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this._pulse.dispose();
            this._scale.dispose();
            this._modulator.dispose();
            return this;
        }
    }

    const OmniOscillatorSourceMap = {
        am: AMOscillator,
        fat: FatOscillator,
        fm: FMOscillator,
        oscillator: Oscillator,
        pulse: PulseOscillator,
        pwm: PWMOscillator,
    };
    /**
     * OmniOscillator aggregates all of the oscillator types into one.
     * @example
     * return Tone.Offline(() => {
     * 	const omniOsc = new Tone.OmniOscillator("C#4", "pwm").toDestination().start();
     * }, 0.1, 1);
     * @category Source
     */
    class OmniOscillator extends Source {
        constructor() {
            super(optionsFromArguments(OmniOscillator.getDefaults(), arguments, ["frequency", "type"]));
            this.name = "OmniOscillator";
            const options = optionsFromArguments(OmniOscillator.getDefaults(), arguments, ["frequency", "type"]);
            this.frequency = new Signal({
                context: this.context,
                units: "frequency",
                value: options.frequency,
            });
            this.detune = new Signal({
                context: this.context,
                units: "cents",
                value: options.detune,
            });
            readOnly(this, ["frequency", "detune"]);
            // set the options
            this.set(options);
        }
        static getDefaults() {
            return Object.assign(Oscillator.getDefaults(), FMOscillator.getDefaults(), AMOscillator.getDefaults(), FatOscillator.getDefaults(), PulseOscillator.getDefaults(), PWMOscillator.getDefaults());
        }
        /**
         * start the oscillator
         */
        _start(time) {
            this._oscillator.start(time);
        }
        /**
         * start the oscillator
         */
        _stop(time) {
            this._oscillator.stop(time);
        }
        _restart(time) {
            this._oscillator.restart(time);
            return this;
        }
        /**
         * The type of the oscillator. Can be any of the basic types: sine, square, triangle, sawtooth. Or
         * prefix the basic types with "fm", "am", or "fat" to use the FMOscillator, AMOscillator or FatOscillator
         * types. The oscillator could also be set to "pwm" or "pulse". All of the parameters of the
         * oscillator's class are accessible when the oscillator is set to that type, but throws an error
         * when it's not.
         * @example
         * const omniOsc = new Tone.OmniOscillator().toDestination().start();
         * omniOsc.type = "pwm";
         * // modulationFrequency is parameter which is available
         * // only when the type is "pwm".
         * omniOsc.modulationFrequency.value = 0.5;
         */
        get type() {
            let prefix = "";
            if (["am", "fm", "fat"].some(p => this._sourceType === p)) {
                prefix = this._sourceType;
            }
            return prefix + this._oscillator.type;
        }
        set type(type) {
            if (type.substr(0, 2) === "fm") {
                this._createNewOscillator("fm");
                this._oscillator = this._oscillator;
                this._oscillator.type = type.substr(2);
            }
            else if (type.substr(0, 2) === "am") {
                this._createNewOscillator("am");
                this._oscillator = this._oscillator;
                this._oscillator.type = type.substr(2);
            }
            else if (type.substr(0, 3) === "fat") {
                this._createNewOscillator("fat");
                this._oscillator = this._oscillator;
                this._oscillator.type = type.substr(3);
            }
            else if (type === "pwm") {
                this._createNewOscillator("pwm");
                this._oscillator = this._oscillator;
            }
            else if (type === "pulse") {
                this._createNewOscillator("pulse");
            }
            else {
                this._createNewOscillator("oscillator");
                this._oscillator = this._oscillator;
                this._oscillator.type = type;
            }
        }
        /**
         * The value is an empty array when the type is not "custom".
         * This is not available on "pwm" and "pulse" oscillator types.
         * See [[Oscillator.partials]]
         */
        get partials() {
            return this._oscillator.partials;
        }
        set partials(partials) {
            if (!this._getOscType(this._oscillator, "pulse") && !this._getOscType(this._oscillator, "pwm")) {
                this._oscillator.partials = partials;
            }
        }
        get partialCount() {
            return this._oscillator.partialCount;
        }
        set partialCount(partialCount) {
            if (!this._getOscType(this._oscillator, "pulse") && !this._getOscType(this._oscillator, "pwm")) {
                this._oscillator.partialCount = partialCount;
            }
        }
        set(props) {
            // make sure the type is set first
            if (Reflect.has(props, "type") && props.type) {
                this.type = props.type;
            }
            // then set the rest
            super.set(props);
            return this;
        }
        /**
         * connect the oscillator to the frequency and detune signals
         */
        _createNewOscillator(oscType) {
            if (oscType !== this._sourceType) {
                this._sourceType = oscType;
                const OscConstructor = OmniOscillatorSourceMap[oscType];
                // short delay to avoid clicks on the change
                const now = this.now();
                if (this._oscillator) {
                    const oldOsc = this._oscillator;
                    oldOsc.stop(now);
                    // dispose the old one
                    this.context.setTimeout(() => oldOsc.dispose(), this.blockTime);
                }
                this._oscillator = new OscConstructor({
                    context: this.context,
                });
                this.frequency.connect(this._oscillator.frequency);
                this.detune.connect(this._oscillator.detune);
                this._oscillator.connect(this.output);
                this._oscillator.onstop = () => this.onstop(this);
                if (this.state === "started") {
                    this._oscillator.start(now);
                }
            }
        }
        get phase() {
            return this._oscillator.phase;
        }
        set phase(phase) {
            this._oscillator.phase = phase;
        }
        /**
         * The source type of the oscillator.
         * @example
         * const omniOsc = new Tone.OmniOscillator(440, "fmsquare");
         * console.log(omniOsc.sourceType); // 'fm'
         */
        get sourceType() {
            return this._sourceType;
        }
        set sourceType(sType) {
            // the basetype defaults to sine
            let baseType = "sine";
            if (this._oscillator.type !== "pwm" && this._oscillator.type !== "pulse") {
                baseType = this._oscillator.type;
            }
            // set the type
            if (sType === "fm") {
                this.type = "fm" + baseType;
            }
            else if (sType === "am") {
                this.type = "am" + baseType;
            }
            else if (sType === "fat") {
                this.type = "fat" + baseType;
            }
            else if (sType === "oscillator") {
                this.type = baseType;
            }
            else if (sType === "pulse") {
                this.type = "pulse";
            }
            else if (sType === "pwm") {
                this.type = "pwm";
            }
        }
        _getOscType(osc, sourceType) {
            return osc instanceof OmniOscillatorSourceMap[sourceType];
        }
        /**
         * The base type of the oscillator. See [[Oscillator.baseType]]
         * @example
         * const omniOsc = new Tone.OmniOscillator(440, "fmsquare4");
         * console.log(omniOsc.sourceType, omniOsc.baseType, omniOsc.partialCount);
         */
        get baseType() {
            return this._oscillator.baseType;
        }
        set baseType(baseType) {
            if (!this._getOscType(this._oscillator, "pulse") &&
                !this._getOscType(this._oscillator, "pwm") &&
                baseType !== "pulse" && baseType !== "pwm") {
                this._oscillator.baseType = baseType;
            }
        }
        /**
         * The width of the oscillator when sourceType === "pulse".
         * See [[PWMOscillator.width]]
         */
        get width() {
            if (this._getOscType(this._oscillator, "pulse")) {
                return this._oscillator.width;
            }
            else {
                return undefined;
            }
        }
        /**
         * The number of detuned oscillators when sourceType === "fat".
         * See [[FatOscillator.count]]
         */
        get count() {
            if (this._getOscType(this._oscillator, "fat")) {
                return this._oscillator.count;
            }
            else {
                return undefined;
            }
        }
        set count(count) {
            if (this._getOscType(this._oscillator, "fat") && isNumber(count)) {
                this._oscillator.count = count;
            }
        }
        /**
         * The detune spread between the oscillators when sourceType === "fat".
         * See [[FatOscillator.count]]
         */
        get spread() {
            if (this._getOscType(this._oscillator, "fat")) {
                return this._oscillator.spread;
            }
            else {
                return undefined;
            }
        }
        set spread(spread) {
            if (this._getOscType(this._oscillator, "fat") && isNumber(spread)) {
                this._oscillator.spread = spread;
            }
        }
        /**
         * The type of the modulator oscillator. Only if the oscillator is set to "am" or "fm" types.
         * See [[AMOscillator]] or [[FMOscillator]]
         */
        get modulationType() {
            if (this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) {
                return this._oscillator.modulationType;
            }
            else {
                return undefined;
            }
        }
        set modulationType(mType) {
            if ((this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) && isString(mType)) {
                this._oscillator.modulationType = mType;
            }
        }
        /**
         * The modulation index when the sourceType === "fm"
         * See [[FMOscillator]].
         */
        get modulationIndex() {
            if (this._getOscType(this._oscillator, "fm")) {
                return this._oscillator.modulationIndex;
            }
            else {
                return undefined;
            }
        }
        /**
         * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.
         * See [[AMOscillator]] or [[FMOscillator]]
         */
        get harmonicity() {
            if (this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) {
                return this._oscillator.harmonicity;
            }
            else {
                return undefined;
            }
        }
        /**
         * The modulationFrequency Signal of the oscillator when sourceType === "pwm"
         * see [[PWMOscillator]]
         * @min 0.1
         * @max 5
         */
        get modulationFrequency() {
            if (this._getOscType(this._oscillator, "pwm")) {
                return this._oscillator.modulationFrequency;
            }
            else {
                return undefined;
            }
        }
        asArray(length = 1024) {
            return __awaiter(this, void 0, void 0, function* () {
                return generateWaveform(this, length);
            });
        }
        dispose() {
            super.dispose();
            this.detune.dispose();
            this.frequency.dispose();
            this._oscillator.dispose();
            return this;
        }
    }

    /**
     * Add a signal and a number or two signals. When no value is
     * passed into the constructor, Tone.Add will sum input and `addend`
     * If a value is passed into the constructor, the it will be added to the input.
     *
     * @example
     * return Tone.Offline(() => {
     * 	const add = new Tone.Add(2).toDestination();
     * 	add.addend.setValueAtTime(1, 0.2);
     * 	const signal = new Tone.Signal(2);
     * 	// add a signal and a scalar
     * 	signal.connect(add);
     * 	signal.setValueAtTime(1, 0.1);
     * }, 0.5, 1);
     * @category Signal
     */
    class Add extends Signal {
        constructor() {
            super(Object.assign(optionsFromArguments(Add.getDefaults(), arguments, ["value"])));
            this.override = false;
            this.name = "Add";
            /**
             * the summing node
             */
            this._sum = new Gain({ context: this.context });
            this.input = this._sum;
            this.output = this._sum;
            /**
             * The value which is added to the input signal
             */
            this.addend = this._param;
            connectSeries(this._constantSource, this._sum);
        }
        static getDefaults() {
            return Object.assign(Signal.getDefaults(), {
                value: 0,
            });
        }
        dispose() {
            super.dispose();
            this._sum.dispose();
            return this;
        }
    }

    /**
     * Performs a linear scaling on an input signal.
     * Scales a NormalRange input to between
     * outputMin and outputMax.
     *
     * @example
     * const scale = new Tone.Scale(50, 100);
     * const signal = new Tone.Signal(0.5).connect(scale);
     * // the output of scale equals 75
     * @category Signal
     */
    class Scale extends SignalOperator {
        constructor() {
            super(Object.assign(optionsFromArguments(Scale.getDefaults(), arguments, ["min", "max"])));
            this.name = "Scale";
            const options = optionsFromArguments(Scale.getDefaults(), arguments, ["min", "max"]);
            this._mult = this.input = new Multiply({
                context: this.context,
                value: options.max - options.min,
            });
            this._add = this.output = new Add({
                context: this.context,
                value: options.min,
            });
            this._min = options.min;
            this._max = options.max;
            this.input.connect(this.output);
        }
        static getDefaults() {
            return Object.assign(SignalOperator.getDefaults(), {
                max: 1,
                min: 0,
            });
        }
        /**
         * The minimum output value. This number is output when the value input value is 0.
         */
        get min() {
            return this._min;
        }
        set min(min) {
            this._min = min;
            this._setRange();
        }
        /**
         * The maximum output value. This number is output when the value input value is 1.
         */
        get max() {
            return this._max;
        }
        set max(max) {
            this._max = max;
            this._setRange();
        }
        /**
         * set the values
         */
        _setRange() {
            this._add.value = this._min;
            this._mult.value = this._max - this._min;
        }
        dispose() {
            super.dispose();
            this._add.dispose();
            this._mult.dispose();
            return this;
        }
    }

    /**
     * Tone.Zero outputs 0's at audio-rate. The reason this has to be
     * it's own class is that many browsers optimize out Tone.Signal
     * with a value of 0 and will not process nodes further down the graph.
     * @category Signal
     */
    class Zero extends SignalOperator {
        constructor() {
            super(Object.assign(optionsFromArguments(Zero.getDefaults(), arguments)));
            this.name = "Zero";
            /**
             * The gain node which connects the constant source to the output
             */
            this._gain = new Gain({ context: this.context });
            /**
             * Only outputs 0
             */
            this.output = this._gain;
            /**
             * no input node
             */
            this.input = undefined;
            connect(this.context.getConstant(0), this._gain);
        }
        /**
         * clean up
         */
        dispose() {
            super.dispose();
            disconnect(this.context.getConstant(0), this._gain);
            return this;
        }
    }

    /**
     * LFO stands for low frequency oscillator. LFO produces an output signal
     * which can be attached to an AudioParam or Tone.Signal
     * in order to modulate that parameter with an oscillator. The LFO can
     * also be synced to the transport to start/stop and change when the tempo changes.
     * @example
     * return Tone.Offline(() => {
     * 	const lfo = new Tone.LFO("4n", 400, 4000).start().toDestination();
     * }, 0.5, 1);
     * @category Source
     */
    class LFO extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(LFO.getDefaults(), arguments, ["frequency", "min", "max"]));
            this.name = "LFO";
            /**
             * The value that the LFO outputs when it's stopped
             */
            this._stoppedValue = 0;
            /**
             * A private placeholder for the units
             */
            this._units = "number";
            /**
             * If the input value is converted using the [[units]]
             */
            this.convert = true;
            /**
             * Private methods borrowed from Param
             */
            // @ts-ignore
            this._fromType = Param.prototype._fromType;
            // @ts-ignore
            this._toType = Param.prototype._toType;
            // @ts-ignore
            this._is = Param.prototype._is;
            // @ts-ignore
            this._clampValue = Param.prototype._clampValue;
            const options = optionsFromArguments(LFO.getDefaults(), arguments, ["frequency", "min", "max"]);
            // @ts-ignore
            this._oscillator = new Oscillator({
                context: this.context,
                frequency: options.frequency,
                type: options.type,
            });
            this.frequency = this._oscillator.frequency;
            this._amplitudeGain = new Gain({
                context: this.context,
                gain: options.amplitude,
                units: "normalRange",
            });
            this.amplitude = this._amplitudeGain.gain;
            this._stoppedSignal = new Signal({
                context: this.context,
                units: "audioRange",
                value: 0,
            });
            this._zeros = new Zero({ context: this.context });
            this._a2g = new AudioToGain({ context: this.context });
            this._scaler = this.output = new Scale({
                context: this.context,
                max: options.max,
                min: options.min,
            });
            this.units = options.units;
            this.min = options.min;
            this.max = options.max;
            // connect it up
            this._oscillator.chain(this._a2g, this._amplitudeGain, this._scaler);
            this._zeros.connect(this._a2g);
            this._stoppedSignal.connect(this._a2g);
            readOnly(this, ["amplitude", "frequency"]);
            this.phase = options.phase;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                amplitude: 1,
                frequency: "4n",
                max: 1,
                min: 0,
                phase: 0,
                type: "sine",
                units: "number",
            });
        }
        /**
         * Start the LFO.
         * @param time The time the LFO will start
         */
        start(time) {
            time = this.toSeconds(time);
            this._stoppedSignal.setValueAtTime(0, time);
            this._oscillator.start(time);
            return this;
        }
        /**
         * Stop the LFO.
         * @param  time The time the LFO will stop
         */
        stop(time) {
            time = this.toSeconds(time);
            this._stoppedSignal.setValueAtTime(this._stoppedValue, time);
            this._oscillator.stop(time);
            return this;
        }
        /**
         * Sync the start/stop/pause to the transport
         * and the frequency to the bpm of the transport
         * @example
         * const lfo = new Tone.LFO("8n");
         * lfo.sync().start(0);
         * // the rate of the LFO will always be an eighth note, even as the tempo changes
         */
        sync() {
            this._oscillator.sync();
            this._oscillator.syncFrequency();
            return this;
        }
        /**
         * unsync the LFO from transport control
         */
        unsync() {
            this._oscillator.unsync();
            this._oscillator.unsyncFrequency();
            return this;
        }
        /**
         * The minimum output of the LFO.
         */
        get min() {
            return this._toType(this._scaler.min);
        }
        set min(min) {
            min = this._fromType(min);
            this._scaler.min = min;
        }
        /**
         * The maximum output of the LFO.
         */
        get max() {
            return this._toType(this._scaler.max);
        }
        set max(max) {
            max = this._fromType(max);
            this._scaler.max = max;
        }
        /**
         * The type of the oscillator: See [[Oscillator.type]]
         */
        get type() {
            return this._oscillator.type;
        }
        set type(type) {
            this._oscillator.type = type;
            this._stoppedValue = this._oscillator.getInitialValue();
            this._stoppedSignal.value = this._stoppedValue;
        }
        /**
         * The phase of the LFO.
         */
        get phase() {
            return this._oscillator.phase;
        }
        set phase(phase) {
            this._oscillator.phase = phase;
            this._stoppedValue = this._oscillator.getInitialValue();
            this._stoppedSignal.value = this._stoppedValue;
        }
        /**
         * The output units of the LFO.
         */
        get units() {
            return this._units;
        }
        set units(val) {
            const currentMin = this.min;
            const currentMax = this.max;
            // convert the min and the max
            this._units = val;
            this.min = currentMin;
            this.max = currentMax;
        }
        /**
         * Returns the playback state of the source, either "started" or "stopped".
         */
        get state() {
            return this._oscillator.state;
        }
        /**
         * @param node the destination to connect to
         * @param outputNum the optional output number
         * @param inputNum the input number
         */
        connect(node, outputNum, inputNum) {
            if (node instanceof Param || node instanceof Signal) {
                this.convert = node.convert;
                this.units = node.units;
            }
            connectSignal(this, node, outputNum, inputNum);
            return this;
        }
        dispose() {
            super.dispose();
            this._oscillator.dispose();
            this._stoppedSignal.dispose();
            this._zeros.dispose();
            this._scaler.dispose();
            this._a2g.dispose();
            this._amplitudeGain.dispose();
            this.amplitude.dispose();
            return this;
        }
    }

    /**
     * Assert that the number is in the given range.
     */
    function range(min, max = Infinity) {
        const valueMap = new WeakMap();
        return function (target, propertyKey) {
            Reflect.defineProperty(target, propertyKey, {
                configurable: true,
                enumerable: true,
                get: function () {
                    return valueMap.get(this);
                },
                set: function (newValue) {
                    assertRange(newValue, min, max);
                    valueMap.set(this, newValue);
                }
            });
        };
    }
    /**
     * Convert the time to seconds and assert that the time is in between the two
     * values when being set.
     */
    function timeRange(min, max = Infinity) {
        const valueMap = new WeakMap();
        return function (target, propertyKey) {
            Reflect.defineProperty(target, propertyKey, {
                configurable: true,
                enumerable: true,
                get: function () {
                    return valueMap.get(this);
                },
                set: function (newValue) {
                    assertRange(this.toSeconds(newValue), min, max);
                    valueMap.set(this, newValue);
                }
            });
        };
    }

    /**
     * Player is an audio file player with start, loop, and stop functions.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/gong_1.mp3").toDestination();
     * // play as soon as the buffer is loaded
     * player.autostart = true;
     * @category Source
     */
    class Player extends Source {
        constructor() {
            super(optionsFromArguments(Player.getDefaults(), arguments, ["url", "onload"]));
            this.name = "Player";
            /**
             * All of the active buffer source nodes
             */
            this._activeSources = new Set();
            const options = optionsFromArguments(Player.getDefaults(), arguments, ["url", "onload"]);
            this._buffer = new ToneAudioBuffer({
                onload: this._onload.bind(this, options.onload),
                onerror: options.onerror,
                reverse: options.reverse,
                url: options.url,
            });
            this.autostart = options.autostart;
            this._loop = options.loop;
            this._loopStart = options.loopStart;
            this._loopEnd = options.loopEnd;
            this._playbackRate = options.playbackRate;
            this.fadeIn = options.fadeIn;
            this.fadeOut = options.fadeOut;
        }
        static getDefaults() {
            return Object.assign(Source.getDefaults(), {
                autostart: false,
                fadeIn: 0,
                fadeOut: 0,
                loop: false,
                loopEnd: 0,
                loopStart: 0,
                onload: noOp,
                onerror: noOp,
                playbackRate: 1,
                reverse: false,
            });
        }
        /**
         * Load the audio file as an audio buffer.
         * Decodes the audio asynchronously and invokes
         * the callback once the audio buffer loads.
         * Note: this does not need to be called if a url
         * was passed in to the constructor. Only use this
         * if you want to manually load a new url.
         * @param url The url of the buffer to load. Filetype support depends on the browser.
         */
        load(url) {
            return __awaiter(this, void 0, void 0, function* () {
                yield this._buffer.load(url);
                this._onload();
                return this;
            });
        }
        /**
         * Internal callback when the buffer is loaded.
         */
        _onload(callback = noOp) {
            callback();
            if (this.autostart) {
                this.start();
            }
        }
        /**
         * Internal callback when the buffer is done playing.
         */
        _onSourceEnd(source) {
            // invoke the onstop function
            this.onstop(this);
            // delete the source from the active sources
            this._activeSources.delete(source);
            if (this._activeSources.size === 0 && !this._synced &&
                this._state.getValueAtTime(this.now()) === "started") {
                // remove the 'implicitEnd' event and replace with an explicit end
                this._state.cancel(this.now());
                this._state.setStateAtTime("stopped", this.now());
            }
        }
        /**
         * Play the buffer at the given startTime. Optionally add an offset
         * and/or duration which will play the buffer from a position
         * within the buffer for the given duration.
         *
         * @param  time When the player should start.
         * @param  offset The offset from the beginning of the sample to start at.
         * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)
         */
        start(time, offset, duration) {
            super.start(time, offset, duration);
            return this;
        }
        /**
         * Internal start method
         */
        _start(startTime, offset, duration) {
            // if it's a loop the default offset is the loopStart point
            if (this._loop) {
                offset = defaultArg(offset, this._loopStart);
            }
            else {
                // otherwise the default offset is 0
                offset = defaultArg(offset, 0);
            }
            // compute the values in seconds
            let computedOffset = this.toSeconds(offset);
            // if it's synced, it should factor in the playback rate for computing the offset
            if (this._synced) {
                computedOffset *= this._playbackRate;
            }
            // compute the duration which is either the passed in duration of the buffer.duration - offset
            const origDuration = duration;
            duration = defaultArg(duration, Math.max(this._buffer.duration - computedOffset, 0));
            let computedDuration = this.toSeconds(duration);
            // scale it by the playback rate
            computedDuration = computedDuration / this._playbackRate;
            // get the start time
            startTime = this.toSeconds(startTime);
            // make the source
            const source = new ToneBufferSource({
                url: this._buffer,
                context: this.context,
                fadeIn: this.fadeIn,
                fadeOut: this.fadeOut,
                loop: this._loop,
                loopEnd: this._loopEnd,
                loopStart: this._loopStart,
                onended: this._onSourceEnd.bind(this),
                playbackRate: this._playbackRate,
            }).connect(this.output);
            // set the looping properties
            if (!this._loop && !this._synced) {
                // cancel the previous stop
                this._state.cancel(startTime + computedDuration);
                // if it's not looping, set the state change at the end of the sample
                this._state.setStateAtTime("stopped", startTime + computedDuration, {
                    implicitEnd: true,
                });
            }
            // add it to the array of active sources
            this._activeSources.add(source);
            // start it
            if (this._loop && isUndef(origDuration)) {
                source.start(startTime, computedOffset);
            }
            else {
                // subtract the fade out time
                source.start(startTime, computedOffset, computedDuration - this.toSeconds(this.fadeOut));
            }
        }
        /**
         * Stop playback.
         */
        _stop(time) {
            const computedTime = this.toSeconds(time);
            this._activeSources.forEach(source => source.stop(computedTime));
        }
        /**
         * Stop and then restart the player from the beginning (or offset)
         * @param  time When the player should start.
         * @param  offset The offset from the beginning of the sample to start at.
         * @param  duration How long the sample should play. If no duration is given,
         * 					it will default to the full length of the sample (minus any offset)
         */
        restart(time, offset, duration) {
            super.restart(time, offset, duration);
            return this;
        }
        _restart(time, offset, duration) {
            this._stop(time);
            this._start(time, offset, duration);
        }
        /**
         * Seek to a specific time in the player's buffer. If the
         * source is no longer playing at that time, it will stop.
         * @param offset The time to seek to.
         * @param when The time for the seek event to occur.
         * @example
         * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/gurgling_theremin_1.mp3", () => {
         * 	player.start();
         * 	// seek to the offset in 1 second from now
         * 	player.seek(0.4, "+1");
         * }).toDestination();
         */
        seek(offset, when) {
            const computedTime = this.toSeconds(when);
            if (this._state.getValueAtTime(computedTime) === "started") {
                const computedOffset = this.toSeconds(offset);
                // if it's currently playing, stop it
                this._stop(computedTime);
                // restart it at the given time
                this._start(computedTime, computedOffset);
            }
            return this;
        }
        /**
         * Set the loop start and end. Will only loop if loop is set to true.
         * @param loopStart The loop start time
         * @param loopEnd The loop end time
         * @example
         * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/malevoices_aa2_F3.mp3").toDestination();
         * // loop between the given points
         * player.setLoopPoints(0.2, 0.3);
         * player.loop = true;
         * player.autostart = true;
         */
        setLoopPoints(loopStart, loopEnd) {
            this.loopStart = loopStart;
            this.loopEnd = loopEnd;
            return this;
        }
        /**
         * If loop is true, the loop will start at this position.
         */
        get loopStart() {
            return this._loopStart;
        }
        set loopStart(loopStart) {
            this._loopStart = loopStart;
            if (this.buffer.loaded) {
                assertRange(this.toSeconds(loopStart), 0, this.buffer.duration);
            }
            // get the current source
            this._activeSources.forEach(source => {
                source.loopStart = loopStart;
            });
        }
        /**
         * If loop is true, the loop will end at this position.
         */
        get loopEnd() {
            return this._loopEnd;
        }
        set loopEnd(loopEnd) {
            this._loopEnd = loopEnd;
            if (this.buffer.loaded) {
                assertRange(this.toSeconds(loopEnd), 0, this.buffer.duration);
            }
            // get the current source
            this._activeSources.forEach(source => {
                source.loopEnd = loopEnd;
            });
        }
        /**
         * The audio buffer belonging to the player.
         */
        get buffer() {
            return this._buffer;
        }
        set buffer(buffer) {
            this._buffer.set(buffer);
        }
        /**
         * If the buffer should loop once it's over.
         * @example
         * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/breakbeat.mp3").toDestination();
         * player.loop = true;
         * player.autostart = true;
         */
        get loop() {
            return this._loop;
        }
        set loop(loop) {
            // if no change, do nothing
            if (this._loop === loop) {
                return;
            }
            this._loop = loop;
            // set the loop of all of the sources
            this._activeSources.forEach(source => {
                source.loop = loop;
            });
            if (loop) {
                // remove the next stopEvent
                const stopEvent = this._state.getNextState("stopped", this.now());
                if (stopEvent) {
                    this._state.cancel(stopEvent.time);
                }
            }
        }
        /**
         * Normal speed is 1. The pitch will change with the playback rate.
         * @example
         * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/femalevoices_aa2_A5.mp3").toDestination();
         * // play at 1/4 speed
         * player.playbackRate = 0.25;
         * // play as soon as the buffer is loaded
         * player.autostart = true;
         */
        get playbackRate() {
            return this._playbackRate;
        }
        set playbackRate(rate) {
            this._playbackRate = rate;
            const now = this.now();
            // cancel the stop event since it's at a different time now
            const stopEvent = this._state.getNextState("stopped", now);
            if (stopEvent && stopEvent.implicitEnd) {
                this._state.cancel(stopEvent.time);
                this._activeSources.forEach(source => source.cancelStop());
            }
            // set all the sources
            this._activeSources.forEach(source => {
                source.playbackRate.setValueAtTime(rate, now);
            });
        }
        /**
         * If the buffer should be reversed
         * @example
         * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/chime_1.mp3").toDestination();
         * player.autostart = true;
         * player.reverse = true;
         */
        get reverse() {
            return this._buffer.reverse;
        }
        set reverse(rev) {
            this._buffer.reverse = rev;
        }
        /**
         * If the buffer is loaded
         */
        get loaded() {
            return this._buffer.loaded;
        }
        dispose() {
            super.dispose();
            // disconnect all of the players
            this._activeSources.forEach(source => source.dispose());
            this._activeSources.clear();
            this._buffer.dispose();
            return this;
        }
    }
    __decorate([
        timeRange(0)
    ], Player.prototype, "fadeIn", void 0);
    __decorate([
        timeRange(0)
    ], Player.prototype, "fadeOut", void 0);

    /**
     * Players combines multiple [[Player]] objects.
     * @category Source
     */
    class Players extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Players.getDefaults(), arguments, ["urls", "onload"], "urls"));
            this.name = "Players";
            /**
             * Players has no input.
             */
            this.input = undefined;
            /**
             * The container of all of the players
             */
            this._players = new Map();
            const options = optionsFromArguments(Players.getDefaults(), arguments, ["urls", "onload"], "urls");
            /**
             * The output volume node
             */
            this._volume = this.output = new Volume({
                context: this.context,
                volume: options.volume,
            });
            this.volume = this._volume.volume;
            readOnly(this, "volume");
            this._buffers = new ToneAudioBuffers({
                urls: options.urls,
                onload: options.onload,
                baseUrl: options.baseUrl,
                onerror: options.onerror
            });
            // mute initially
            this.mute = options.mute;
            this._fadeIn = options.fadeIn;
            this._fadeOut = options.fadeOut;
        }
        static getDefaults() {
            return Object.assign(Source.getDefaults(), {
                baseUrl: "",
                fadeIn: 0,
                fadeOut: 0,
                mute: false,
                onload: noOp,
                onerror: noOp,
                urls: {},
                volume: 0,
            });
        }
        /**
         * Mute the output.
         */
        get mute() {
            return this._volume.mute;
        }
        set mute(mute) {
            this._volume.mute = mute;
        }
        /**
         * The fadeIn time of the envelope applied to the source.
         */
        get fadeIn() {
            return this._fadeIn;
        }
        set fadeIn(fadeIn) {
            this._fadeIn = fadeIn;
            this._players.forEach(player => {
                player.fadeIn = fadeIn;
            });
        }
        /**
         * The fadeOut time of the each of the sources.
         */
        get fadeOut() {
            return this._fadeOut;
        }
        set fadeOut(fadeOut) {
            this._fadeOut = fadeOut;
            this._players.forEach(player => {
                player.fadeOut = fadeOut;
            });
        }
        /**
         * The state of the players object. Returns "started" if any of the players are playing.
         */
        get state() {
            const playing = Array.from(this._players).some(([_, player]) => player.state === "started");
            return playing ? "started" : "stopped";
        }
        /**
         * True if the buffers object has a buffer by that name.
         * @param name  The key or index of the buffer.
         */
        has(name) {
            return this._buffers.has(name);
        }
        /**
         * Get a player by name.
         * @param  name  The players name as defined in the constructor object or `add` method.
         */
        player(name) {
            assert(this.has(name), `No Player with the name ${name} exists on this object`);
            if (!this._players.has(name)) {
                const player = new Player({
                    context: this.context,
                    fadeIn: this._fadeIn,
                    fadeOut: this._fadeOut,
                    url: this._buffers.get(name),
                }).connect(this.output);
                this._players.set(name, player);
            }
            return this._players.get(name);
        }
        /**
         * If all the buffers are loaded or not
         */
        get loaded() {
            return this._buffers.loaded;
        }
        /**
         * Add a player by name and url to the Players
         * @param  name A unique name to give the player
         * @param  url  Either the url of the bufer or a buffer which will be added with the given name.
         * @param callback  The callback to invoke when the url is loaded.
         */
        add(name, url, callback) {
            assert(!this._buffers.has(name), "A buffer with that name already exists on this object");
            this._buffers.add(name, url, callback);
            return this;
        }
        /**
         * Stop all of the players at the given time
         * @param time The time to stop all of the players.
         */
        stopAll(time) {
            this._players.forEach(player => player.stop(time));
            return this;
        }
        dispose() {
            super.dispose();
            this._volume.dispose();
            this.volume.dispose();
            this._players.forEach(player => player.dispose());
            this._buffers.dispose();
            return this;
        }
    }

    /**
     * GrainPlayer implements [granular synthesis](https://en.wikipedia.org/wiki/Granular_synthesis).
     * Granular Synthesis enables you to adjust pitch and playback rate independently. The grainSize is the
     * amount of time each small chunk of audio is played for and the overlap is the
     * amount of crossfading transition time between successive grains.
     * @category Source
     */
    class GrainPlayer extends Source {
        constructor() {
            super(optionsFromArguments(GrainPlayer.getDefaults(), arguments, ["url", "onload"]));
            this.name = "GrainPlayer";
            /**
             * Internal loopStart value
             */
            this._loopStart = 0;
            /**
             * Internal loopStart value
             */
            this._loopEnd = 0;
            /**
             * All of the currently playing BufferSources
             */
            this._activeSources = [];
            const options = optionsFromArguments(GrainPlayer.getDefaults(), arguments, ["url", "onload"]);
            this.buffer = new ToneAudioBuffer({
                onload: options.onload,
                onerror: options.onerror,
                reverse: options.reverse,
                url: options.url,
            });
            this._clock = new Clock({
                context: this.context,
                callback: this._tick.bind(this),
                frequency: 1 / options.grainSize
            });
            this._playbackRate = options.playbackRate;
            this._grainSize = options.grainSize;
            this._overlap = options.overlap;
            this.detune = options.detune;
            // setup
            this.overlap = options.overlap;
            this.loop = options.loop;
            this.playbackRate = options.playbackRate;
            this.grainSize = options.grainSize;
            this.loopStart = options.loopStart;
            this.loopEnd = options.loopEnd;
            this.reverse = options.reverse;
            this._clock.on("stop", this._onstop.bind(this));
        }
        static getDefaults() {
            return Object.assign(Source.getDefaults(), {
                onload: noOp,
                onerror: noOp,
                overlap: 0.1,
                grainSize: 0.2,
                playbackRate: 1,
                detune: 0,
                loop: false,
                loopStart: 0,
                loopEnd: 0,
                reverse: false
            });
        }
        /**
         * Internal start method
         */
        _start(time, offset, duration) {
            offset = defaultArg(offset, 0);
            offset = this.toSeconds(offset);
            time = this.toSeconds(time);
            const grainSize = 1 / this._clock.frequency.getValueAtTime(time);
            this._clock.start(time, offset / grainSize);
            if (duration) {
                this.stop(time + this.toSeconds(duration));
            }
        }
        /**
         * Stop and then restart the player from the beginning (or offset)
         * @param  time When the player should start.
         * @param  offset The offset from the beginning of the sample to start at.
         * @param  duration How long the sample should play. If no duration is given,
         * 					it will default to the full length of the sample (minus any offset)
         */
        restart(time, offset, duration) {
            super.restart(time, offset, duration);
            return this;
        }
        _restart(time, offset, duration) {
            this._stop(time);
            this._start(time, offset, duration);
        }
        /**
         * Internal stop method
         */
        _stop(time) {
            this._clock.stop(time);
        }
        /**
         * Invoked when the clock is stopped
         */
        _onstop(time) {
            // stop the players
            this._activeSources.forEach((source) => {
                source.fadeOut = 0;
                source.stop(time);
            });
            this.onstop(this);
        }
        /**
         * Invoked on each clock tick. scheduled a new grain at this time.
         */
        _tick(time) {
            // check if it should stop looping
            const ticks = this._clock.getTicksAtTime(time);
            const offset = ticks * this._grainSize;
            this.log("offset", offset);
            if (!this.loop && offset > this.buffer.duration) {
                this.stop(time);
                return;
            }
            // at the beginning of the file, the fade in should be 0
            const fadeIn = offset < this._overlap ? 0 : this._overlap;
            // create a buffer source
            const source = new ToneBufferSource({
                context: this.context,
                url: this.buffer,
                fadeIn: fadeIn,
                fadeOut: this._overlap,
                loop: this.loop,
                loopStart: this._loopStart,
                loopEnd: this._loopEnd,
                // compute the playbackRate based on the detune
                playbackRate: intervalToFrequencyRatio(this.detune / 100)
            }).connect(this.output);
            source.start(time, this._grainSize * ticks);
            source.stop(time + this._grainSize / this.playbackRate);
            // add it to the active sources
            this._activeSources.push(source);
            // remove it when it's done
            source.onended = () => {
                const index = this._activeSources.indexOf(source);
                if (index !== -1) {
                    this._activeSources.splice(index, 1);
                }
            };
        }
        /**
         * The playback rate of the sample
         */
        get playbackRate() {
            return this._playbackRate;
        }
        set playbackRate(rate) {
            assertRange(rate, 0.001);
            this._playbackRate = rate;
            this.grainSize = this._grainSize;
        }
        /**
         * The loop start time.
         */
        get loopStart() {
            return this._loopStart;
        }
        set loopStart(time) {
            if (this.buffer.loaded) {
                assertRange(this.toSeconds(time), 0, this.buffer.duration);
            }
            this._loopStart = this.toSeconds(time);
        }
        /**
         * The loop end time.
         */
        get loopEnd() {
            return this._loopEnd;
        }
        set loopEnd(time) {
            if (this.buffer.loaded) {
                assertRange(this.toSeconds(time), 0, this.buffer.duration);
            }
            this._loopEnd = this.toSeconds(time);
        }
        /**
         * The direction the buffer should play in
         */
        get reverse() {
            return this.buffer.reverse;
        }
        set reverse(rev) {
            this.buffer.reverse = rev;
        }
        /**
         * The size of each chunk of audio that the
         * buffer is chopped into and played back at.
         */
        get grainSize() {
            return this._grainSize;
        }
        set grainSize(size) {
            this._grainSize = this.toSeconds(size);
            this._clock.frequency.setValueAtTime(this._playbackRate / this._grainSize, this.now());
        }
        /**
         * The duration of the cross-fade between successive grains.
         */
        get overlap() {
            return this._overlap;
        }
        set overlap(time) {
            const computedTime = this.toSeconds(time);
            assertRange(computedTime, 0);
            this._overlap = computedTime;
        }
        /**
         * If all the buffer is loaded
         */
        get loaded() {
            return this.buffer.loaded;
        }
        dispose() {
            super.dispose();
            this.buffer.dispose();
            this._clock.dispose();
            this._activeSources.forEach((source) => source.dispose());
            return this;
        }
    }

    /**
     * Return the absolute value of an incoming signal.
     *
     * @example
     * return Tone.Offline(() => {
     * 	const abs = new Tone.Abs().toDestination();
     * 	const signal = new Tone.Signal(1);
     * 	signal.rampTo(-1, 0.5);
     * 	signal.connect(abs);
     * }, 0.5, 1);
     * @category Signal
     */
    class Abs extends SignalOperator {
        constructor() {
            super(...arguments);
            this.name = "Abs";
            /**
             * The node which converts the audio ranges
             */
            this._abs = new WaveShaper({
                context: this.context,
                mapping: val => {
                    if (Math.abs(val) < 0.001) {
                        return 0;
                    }
                    else {
                        return Math.abs(val);
                    }
                },
            });
            /**
             * The AudioRange input [-1, 1]
             */
            this.input = this._abs;
            /**
             * The output range [0, 1]
             */
            this.output = this._abs;
        }
        /**
         * clean up
         */
        dispose() {
            super.dispose();
            this._abs.dispose();
            return this;
        }
    }

    /**
     * GainToAudio converts an input in NormalRange [0,1] to AudioRange [-1,1].
     * See [[AudioToGain]].
     * @category Signal
     */
    class GainToAudio extends SignalOperator {
        constructor() {
            super(...arguments);
            this.name = "GainToAudio";
            /**
             * The node which converts the audio ranges
             */
            this._norm = new WaveShaper({
                context: this.context,
                mapping: x => Math.abs(x) * 2 - 1,
            });
            /**
             * The NormalRange input [0, 1]
             */
            this.input = this._norm;
            /**
             * The AudioRange output [-1, 1]
             */
            this.output = this._norm;
        }
        /**
         * clean up
         */
        dispose() {
            super.dispose();
            this._norm.dispose();
            return this;
        }
    }

    /**
     * Negate the incoming signal. i.e. an input signal of 10 will output -10
     *
     * @example
     * const neg = new Tone.Negate();
     * const sig = new Tone.Signal(-2).connect(neg);
     * // output of neg is positive 2.
     * @category Signal
     */
    class Negate extends SignalOperator {
        constructor() {
            super(...arguments);
            this.name = "Negate";
            /**
             * negation is done by multiplying by -1
             */
            this._multiply = new Multiply({
                context: this.context,
                value: -1,
            });
            /**
             * The input and output are equal to the multiply node
             */
            this.input = this._multiply;
            this.output = this._multiply;
        }
        /**
         * clean up
         * @returns {Negate} this
         */
        dispose() {
            super.dispose();
            this._multiply.dispose();
            return this;
        }
    }

    /**
     * Subtract the signal connected to the input is subtracted from the signal connected
     * The subtrahend.
     *
     * @example
     * // subtract a scalar from a signal
     * const sub = new Tone.Subtract(1);
     * const sig = new Tone.Signal(4).connect(sub);
     * // the output of sub is 3.
     * @example
     * // subtract two signals
     * const sub = new Tone.Subtract();
     * const sigA = new Tone.Signal(10);
     * const sigB = new Tone.Signal(2.5);
     * sigA.connect(sub);
     * sigB.connect(sub.subtrahend);
     * // output of sub is 7.5
     * @category Signal
     */
    class Subtract extends Signal {
        constructor() {
            super(Object.assign(optionsFromArguments(Subtract.getDefaults(), arguments, ["value"])));
            this.override = false;
            this.name = "Subtract";
            /**
             * the summing node
             */
            this._sum = new Gain({ context: this.context });
            this.input = this._sum;
            this.output = this._sum;
            /**
             * Negate the input of the second input before connecting it to the summing node.
             */
            this._neg = new Negate({ context: this.context });
            /**
             * The value which is subtracted from the main signal
             */
            this.subtrahend = this._param;
            connectSeries(this._constantSource, this._neg, this._sum);
        }
        static getDefaults() {
            return Object.assign(Signal.getDefaults(), {
                value: 0,
            });
        }
        dispose() {
            super.dispose();
            this._neg.dispose();
            this._sum.dispose();
            return this;
        }
    }

    /**
     * GreaterThanZero outputs 1 when the input is strictly greater than zero
     * @example
     * return Tone.Offline(() => {
     * 	const gt0 = new Tone.GreaterThanZero().toDestination();
     * 	const sig = new Tone.Signal(0.5).connect(gt0);
     * 	sig.setValueAtTime(-1, 0.05);
     * }, 0.1, 1);
     * @category Signal
     */
    class GreaterThanZero extends SignalOperator {
        constructor() {
            super(Object.assign(optionsFromArguments(GreaterThanZero.getDefaults(), arguments)));
            this.name = "GreaterThanZero";
            this._thresh = this.output = new WaveShaper({
                context: this.context,
                length: 127,
                mapping: (val) => {
                    if (val <= 0) {
                        return 0;
                    }
                    else {
                        return 1;
                    }
                },
            });
            this._scale = this.input = new Multiply({
                context: this.context,
                value: 10000
            });
            // connections
            this._scale.connect(this._thresh);
        }
        dispose() {
            super.dispose();
            this._scale.dispose();
            this._thresh.dispose();
            return this;
        }
    }

    /**
     * Output 1 if the signal is greater than the value, otherwise outputs 0.
     * can compare two signals or a signal and a number.
     *
     * @example
     * return Tone.Offline(() => {
     * 	const gt = new Tone.GreaterThan(2).toDestination();
     * 	const sig = new Tone.Signal(4).connect(gt);
     * }, 0.1, 1);
     * @category Signal
     */
    class GreaterThan extends Signal {
        constructor() {
            super(Object.assign(optionsFromArguments(GreaterThan.getDefaults(), arguments, ["value"])));
            this.name = "GreaterThan";
            this.override = false;
            const options = optionsFromArguments(GreaterThan.getDefaults(), arguments, ["value"]);
            this._subtract = this.input = new Subtract({
                context: this.context,
                value: options.value
            });
            this._gtz = this.output = new GreaterThanZero({ context: this.context });
            this.comparator = this._param = this._subtract.subtrahend;
            readOnly(this, "comparator");
            // connect
            this._subtract.connect(this._gtz);
        }
        static getDefaults() {
            return Object.assign(Signal.getDefaults(), {
                value: 0,
            });
        }
        dispose() {
            super.dispose();
            this._gtz.dispose();
            this._subtract.dispose();
            this.comparator.dispose();
            return this;
        }
    }

    /**
     * Pow applies an exponent to the incoming signal. The incoming signal must be AudioRange [-1, 1]
     *
     * @example
     * const pow = new Tone.Pow(2);
     * const sig = new Tone.Signal(0.5).connect(pow);
     * // output of pow is 0.25.
     * @category Signal
     */
    class Pow extends SignalOperator {
        constructor() {
            super(Object.assign(optionsFromArguments(Pow.getDefaults(), arguments, ["value"])));
            this.name = "Pow";
            const options = optionsFromArguments(Pow.getDefaults(), arguments, ["value"]);
            this._exponentScaler = this.input = this.output = new WaveShaper({
                context: this.context,
                mapping: this._expFunc(options.value),
                length: 8192,
            });
            this._exponent = options.value;
        }
        static getDefaults() {
            return Object.assign(SignalOperator.getDefaults(), {
                value: 1,
            });
        }
        /**
         * the function which maps the waveshaper
         * @param exponent exponent value
         */
        _expFunc(exponent) {
            return (val) => {
                return Math.pow(Math.abs(val), exponent);
            };
        }
        /**
         * The value of the exponent.
         */
        get value() {
            return this._exponent;
        }
        set value(exponent) {
            this._exponent = exponent;
            this._exponentScaler.setMap(this._expFunc(this._exponent));
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this._exponentScaler.dispose();
            return this;
        }
    }

    /**
     * Performs an exponential scaling on an input signal.
     * Scales a NormalRange value [0,1] exponentially
     * to the output range of outputMin to outputMax.
     * @example
     * const scaleExp = new Tone.ScaleExp(0, 100, 2);
     * const signal = new Tone.Signal(0.5).connect(scaleExp);
     * @category Signal
     */
    class ScaleExp extends Scale {
        constructor() {
            super(Object.assign(optionsFromArguments(ScaleExp.getDefaults(), arguments, ["min", "max", "exponent"])));
            this.name = "ScaleExp";
            const options = optionsFromArguments(ScaleExp.getDefaults(), arguments, ["min", "max", "exponent"]);
            this.input = this._exp = new Pow({
                context: this.context,
                value: options.exponent,
            });
            this._exp.connect(this._mult);
        }
        static getDefaults() {
            return Object.assign(Scale.getDefaults(), {
                exponent: 1,
            });
        }
        /**
         * Instead of interpolating linearly between the [[min]] and
         * [[max]] values, setting the exponent will interpolate between
         * the two values with an exponential curve.
         */
        get exponent() {
            return this._exp.value;
        }
        set exponent(exp) {
            this._exp.value = exp;
        }
        dispose() {
            super.dispose();
            this._exp.dispose();
            return this;
        }
    }

    /**
     * Adds the ability to synchronize the signal to the [[Transport]]
     */
    class SyncedSignal extends Signal {
        constructor() {
            super(optionsFromArguments(Signal.getDefaults(), arguments, ["value", "units"]));
            this.name = "SyncedSignal";
            /**
             * Don't override when something is connected to the input
             */
            this.override = false;
            const options = optionsFromArguments(Signal.getDefaults(), arguments, ["value", "units"]);
            this._lastVal = options.value;
            this._synced = this.context.transport.scheduleRepeat(this._onTick.bind(this), "1i");
            this._syncedCallback = this._anchorValue.bind(this);
            this.context.transport.on("start", this._syncedCallback);
            this.context.transport.on("pause", this._syncedCallback);
            this.context.transport.on("stop", this._syncedCallback);
            // disconnect the constant source from the output and replace it with another one
            this._constantSource.disconnect();
            this._constantSource.stop(0);
            // create a new one
            this._constantSource = this.output = new ToneConstantSource({
                context: this.context,
                offset: options.value,
                units: options.units,
            }).start(0);
            this.setValueAtTime(options.value, 0);
        }
        /**
         * Callback which is invoked every tick.
         */
        _onTick(time) {
            const val = super.getValueAtTime(this.context.transport.seconds);
            // approximate ramp curves with linear ramps
            if (this._lastVal !== val) {
                this._lastVal = val;
                this._constantSource.offset.setValueAtTime(val, time);
            }
        }
        /**
         * Anchor the value at the start and stop of the Transport
         */
        _anchorValue(time) {
            const val = super.getValueAtTime(this.context.transport.seconds);
            this._lastVal = val;
            this._constantSource.offset.cancelAndHoldAtTime(time);
            this._constantSource.offset.setValueAtTime(val, time);
        }
        getValueAtTime(time) {
            const computedTime = new TransportTimeClass(this.context, time).toSeconds();
            return super.getValueAtTime(computedTime);
        }
        setValueAtTime(value, time) {
            const computedTime = new TransportTimeClass(this.context, time).toSeconds();
            super.setValueAtTime(value, computedTime);
            return this;
        }
        linearRampToValueAtTime(value, time) {
            const computedTime = new TransportTimeClass(this.context, time).toSeconds();
            super.linearRampToValueAtTime(value, computedTime);
            return this;
        }
        exponentialRampToValueAtTime(value, time) {
            const computedTime = new TransportTimeClass(this.context, time).toSeconds();
            super.exponentialRampToValueAtTime(value, computedTime);
            return this;
        }
        setTargetAtTime(value, startTime, timeConstant) {
            const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();
            super.setTargetAtTime(value, computedTime, timeConstant);
            return this;
        }
        cancelScheduledValues(startTime) {
            const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();
            super.cancelScheduledValues(computedTime);
            return this;
        }
        setValueCurveAtTime(values, startTime, duration, scaling) {
            const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();
            duration = this.toSeconds(duration);
            super.setValueCurveAtTime(values, computedTime, duration, scaling);
            return this;
        }
        cancelAndHoldAtTime(time) {
            const computedTime = new TransportTimeClass(this.context, time).toSeconds();
            super.cancelAndHoldAtTime(computedTime);
            return this;
        }
        setRampPoint(time) {
            const computedTime = new TransportTimeClass(this.context, time).toSeconds();
            super.setRampPoint(computedTime);
            return this;
        }
        exponentialRampTo(value, rampTime, startTime) {
            const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();
            super.exponentialRampTo(value, rampTime, computedTime);
            return this;
        }
        linearRampTo(value, rampTime, startTime) {
            const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();
            super.linearRampTo(value, rampTime, computedTime);
            return this;
        }
        targetRampTo(value, rampTime, startTime) {
            const computedTime = new TransportTimeClass(this.context, startTime).toSeconds();
            super.targetRampTo(value, rampTime, computedTime);
            return this;
        }
        dispose() {
            super.dispose();
            this.context.transport.clear(this._synced);
            this.context.transport.off("start", this._syncedCallback);
            this.context.transport.off("pause", this._syncedCallback);
            this.context.transport.off("stop", this._syncedCallback);
            this._constantSource.dispose();
            return this;
        }
    }

    /**
     * Envelope is an [ADSR](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope)
     * envelope generator. Envelope outputs a signal which
     * can be connected to an AudioParam or Tone.Signal.
     * ```
     *           /\
     *          /  \
     *         /    \
     *        /      \
     *       /        \___________
     *      /                     \
     *     /                       \
     *    /                         \
     *   /                           \
     * ```
     * @example
     * return Tone.Offline(() => {
     * 	const env = new Tone.Envelope({
     * 		attack: 0.1,
     * 		decay: 0.2,
     * 		sustain: 0.5,
     * 		release: 0.8,
     * 	}).toDestination();
     * 	env.triggerAttackRelease(0.5);
     * }, 1.5, 1);
     * @category Component
     */
    class Envelope extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Envelope.getDefaults(), arguments, ["attack", "decay", "sustain", "release"]));
            this.name = "Envelope";
            /**
             * the signal which is output.
             */
            this._sig = new Signal({
                context: this.context,
                value: 0,
            });
            /**
             * The output signal of the envelope
             */
            this.output = this._sig;
            /**
             * Envelope has no input
             */
            this.input = undefined;
            const options = optionsFromArguments(Envelope.getDefaults(), arguments, ["attack", "decay", "sustain", "release"]);
            this.attack = options.attack;
            this.decay = options.decay;
            this.sustain = options.sustain;
            this.release = options.release;
            this.attackCurve = options.attackCurve;
            this.releaseCurve = options.releaseCurve;
            this.decayCurve = options.decayCurve;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                attack: 0.01,
                attackCurve: "linear",
                decay: 0.1,
                decayCurve: "exponential",
                release: 1,
                releaseCurve: "exponential",
                sustain: 0.5,
            });
        }
        /**
         * Read the current value of the envelope. Useful for
         * synchronizing visual output to the envelope.
         */
        get value() {
            return this.getValueAtTime(this.now());
        }
        /**
         * Get the curve
         * @param  curve
         * @param  direction  In/Out
         * @return The curve name
         */
        _getCurve(curve, direction) {
            if (isString(curve)) {
                return curve;
            }
            else {
                // look up the name in the curves array
                let curveName;
                for (curveName in EnvelopeCurves) {
                    if (EnvelopeCurves[curveName][direction] === curve) {
                        return curveName;
                    }
                }
                // return the custom curve
                return curve;
            }
        }
        /**
         * Assign a the curve to the given name using the direction
         * @param  name
         * @param  direction In/Out
         * @param  curve
         */
        _setCurve(name, direction, curve) {
            // check if it's a valid type
            if (isString(curve) && Reflect.has(EnvelopeCurves, curve)) {
                const curveDef = EnvelopeCurves[curve];
                if (isObject(curveDef)) {
                    if (name !== "_decayCurve") {
                        this[name] = curveDef[direction];
                    }
                }
                else {
                    this[name] = curveDef;
                }
            }
            else if (isArray(curve) && name !== "_decayCurve") {
                this[name] = curve;
            }
            else {
                throw new Error("Envelope: invalid curve: " + curve);
            }
        }
        /**
         * The shape of the attack.
         * Can be any of these strings:
         * * "linear"
         * * "exponential"
         * * "sine"
         * * "cosine"
         * * "bounce"
         * * "ripple"
         * * "step"
         *
         * Can also be an array which describes the curve. Values
         * in the array are evenly subdivided and linearly
         * interpolated over the duration of the attack.
         * @example
         * return Tone.Offline(() => {
         * 	const env = new Tone.Envelope(0.4).toDestination();
         * 	env.attackCurve = "linear";
         * 	env.triggerAttack();
         * }, 1, 1);
         */
        get attackCurve() {
            return this._getCurve(this._attackCurve, "In");
        }
        set attackCurve(curve) {
            this._setCurve("_attackCurve", "In", curve);
        }
        /**
         * The shape of the release. See the attack curve types.
         * @example
         * return Tone.Offline(() => {
         * 	const env = new Tone.Envelope({
         * 		release: 0.8
         * 	}).toDestination();
         * 	env.triggerAttack();
         * 	// release curve could also be defined by an array
         * 	env.releaseCurve = [1, 0.3, 0.4, 0.2, 0.7, 0];
         * 	env.triggerRelease(0.2);
         * }, 1, 1);
         */
        get releaseCurve() {
            return this._getCurve(this._releaseCurve, "Out");
        }
        set releaseCurve(curve) {
            this._setCurve("_releaseCurve", "Out", curve);
        }
        /**
         * The shape of the decay either "linear" or "exponential"
         * @example
         * return Tone.Offline(() => {
         * 	const env = new Tone.Envelope({
         * 		sustain: 0.1,
         * 		decay: 0.5
         * 	}).toDestination();
         * 	env.decayCurve = "linear";
         * 	env.triggerAttack();
         * }, 1, 1);
         */
        get decayCurve() {
            return this._decayCurve;
        }
        set decayCurve(curve) {
            assert(["linear", "exponential"].some(c => c === curve), `Invalid envelope curve: ${curve}`);
            this._decayCurve = curve;
        }
        /**
         * Trigger the attack/decay portion of the ADSR envelope.
         * @param  time When the attack should start.
         * @param velocity The velocity of the envelope scales the vales.
         *                             number between 0-1
         * @example
         * const env = new Tone.AmplitudeEnvelope().toDestination();
         * const osc = new Tone.Oscillator().connect(env).start();
         * // trigger the attack 0.5 seconds from now with a velocity of 0.2
         * env.triggerAttack("+0.5", 0.2);
         */
        triggerAttack(time, velocity = 1) {
            this.log("triggerAttack", time, velocity);
            time = this.toSeconds(time);
            const originalAttack = this.toSeconds(this.attack);
            let attack = originalAttack;
            const decay = this.toSeconds(this.decay);
            // check if it's not a complete attack
            const currentValue = this.getValueAtTime(time);
            if (currentValue > 0) {
                // subtract the current value from the attack time
                const attackRate = 1 / attack;
                const remainingDistance = 1 - currentValue;
                // the attack is now the remaining time
                attack = remainingDistance / attackRate;
            }
            // attack
            if (attack < this.sampleTime) {
                this._sig.cancelScheduledValues(time);
                // case where the attack time is 0 should set instantly
                this._sig.setValueAtTime(velocity, time);
            }
            else if (this._attackCurve === "linear") {
                this._sig.linearRampTo(velocity, attack, time);
            }
            else if (this._attackCurve === "exponential") {
                this._sig.targetRampTo(velocity, attack, time);
            }
            else {
                this._sig.cancelAndHoldAtTime(time);
                let curve = this._attackCurve;
                // find the starting position in the curve
                for (let i = 1; i < curve.length; i++) {
                    // the starting index is between the two values
                    if (curve[i - 1] <= currentValue && currentValue <= curve[i]) {
                        curve = this._attackCurve.slice(i);
                        // the first index is the current value
                        curve[0] = currentValue;
                        break;
                    }
                }
                this._sig.setValueCurveAtTime(curve, time, attack, velocity);
            }
            // decay
            if (decay && this.sustain < 1) {
                const decayValue = velocity * this.sustain;
                const decayStart = time + attack;
                this.log("decay", decayStart);
                if (this._decayCurve === "linear") {
                    this._sig.linearRampToValueAtTime(decayValue, decay + decayStart);
                }
                else {
                    this._sig.exponentialApproachValueAtTime(decayValue, decayStart, decay);
                }
            }
            return this;
        }
        /**
         * Triggers the release of the envelope.
         * @param  time When the release portion of the envelope should start.
         * @example
         * const env = new Tone.AmplitudeEnvelope().toDestination();
         * const osc = new Tone.Oscillator({
         * 	type: "sawtooth"
         * }).connect(env).start();
         * env.triggerAttack();
         * // trigger the release half a second after the attack
         * env.triggerRelease("+0.5");
         */
        triggerRelease(time) {
            this.log("triggerRelease", time);
            time = this.toSeconds(time);
            const currentValue = this.getValueAtTime(time);
            if (currentValue > 0) {
                const release = this.toSeconds(this.release);
                if (release < this.sampleTime) {
                    this._sig.setValueAtTime(0, time);
                }
                else if (this._releaseCurve === "linear") {
                    this._sig.linearRampTo(0, release, time);
                }
                else if (this._releaseCurve === "exponential") {
                    this._sig.targetRampTo(0, release, time);
                }
                else {
                    assert(isArray(this._releaseCurve), "releaseCurve must be either 'linear', 'exponential' or an array");
                    this._sig.cancelAndHoldAtTime(time);
                    this._sig.setValueCurveAtTime(this._releaseCurve, time, release, currentValue);
                }
            }
            return this;
        }
        /**
         * Get the scheduled value at the given time. This will
         * return the unconverted (raw) value.
         * @example
         * const env = new Tone.Envelope(0.5, 1, 0.4, 2);
         * env.triggerAttackRelease(2);
         * setInterval(() => console.log(env.getValueAtTime(Tone.now())), 100);
         */
        getValueAtTime(time) {
            return this._sig.getValueAtTime(time);
        }
        /**
         * triggerAttackRelease is shorthand for triggerAttack, then waiting
         * some duration, then triggerRelease.
         * @param duration The duration of the sustain.
         * @param time When the attack should be triggered.
         * @param velocity The velocity of the envelope.
         * @example
         * const env = new Tone.AmplitudeEnvelope().toDestination();
         * const osc = new Tone.Oscillator().connect(env).start();
         * // trigger the release 0.5 seconds after the attack
         * env.triggerAttackRelease(0.5);
         */
        triggerAttackRelease(duration, time, velocity = 1) {
            time = this.toSeconds(time);
            this.triggerAttack(time, velocity);
            this.triggerRelease(time + this.toSeconds(duration));
            return this;
        }
        /**
         * Cancels all scheduled envelope changes after the given time.
         */
        cancel(after) {
            this._sig.cancelScheduledValues(this.toSeconds(after));
            return this;
        }
        /**
         * Connect the envelope to a destination node.
         */
        connect(destination, outputNumber = 0, inputNumber = 0) {
            connectSignal(this, destination, outputNumber, inputNumber);
            return this;
        }
        /**
         * Render the envelope curve to an array of the given length.
         * Good for visualizing the envelope curve. Rescales the duration of the
         * envelope to fit the length.
         */
        asArray(length = 1024) {
            return __awaiter(this, void 0, void 0, function* () {
                const duration = length / this.context.sampleRate;
                const context = new OfflineContext(1, duration, this.context.sampleRate);
                // normalize the ADSR for the given duration with 20% sustain time
                const attackPortion = this.toSeconds(this.attack) + this.toSeconds(this.decay);
                const envelopeDuration = attackPortion + this.toSeconds(this.release);
                const sustainTime = envelopeDuration * 0.1;
                const totalDuration = envelopeDuration + sustainTime;
                // @ts-ignore
                const clone = new this.constructor(Object.assign(this.get(), {
                    attack: duration * this.toSeconds(this.attack) / totalDuration,
                    decay: duration * this.toSeconds(this.decay) / totalDuration,
                    release: duration * this.toSeconds(this.release) / totalDuration,
                    context
                }));
                clone._sig.toDestination();
                clone.triggerAttackRelease(duration * (attackPortion + sustainTime) / totalDuration, 0);
                const buffer = yield context.render();
                return buffer.getChannelData(0);
            });
        }
        dispose() {
            super.dispose();
            this._sig.dispose();
            return this;
        }
    }
    __decorate([
        timeRange(0)
    ], Envelope.prototype, "attack", void 0);
    __decorate([
        timeRange(0)
    ], Envelope.prototype, "decay", void 0);
    __decorate([
        range(0, 1)
    ], Envelope.prototype, "sustain", void 0);
    __decorate([
        timeRange(0)
    ], Envelope.prototype, "release", void 0);
    /**
     * Generate some complex envelope curves.
     */
    const EnvelopeCurves = (() => {
        const curveLen = 128;
        let i;
        let k;
        // cosine curve
        const cosineCurve = [];
        for (i = 0; i < curveLen; i++) {
            cosineCurve[i] = Math.sin((i / (curveLen - 1)) * (Math.PI / 2));
        }
        // ripple curve
        const rippleCurve = [];
        const rippleCurveFreq = 6.4;
        for (i = 0; i < curveLen - 1; i++) {
            k = (i / (curveLen - 1));
            const sineWave = Math.sin(k * (Math.PI * 2) * rippleCurveFreq - Math.PI / 2) + 1;
            rippleCurve[i] = sineWave / 10 + k * 0.83;
        }
        rippleCurve[curveLen - 1] = 1;
        // stairs curve
        const stairsCurve = [];
        const steps = 5;
        for (i = 0; i < curveLen; i++) {
            stairsCurve[i] = Math.ceil((i / (curveLen - 1)) * steps) / steps;
        }
        // in-out easing curve
        const sineCurve = [];
        for (i = 0; i < curveLen; i++) {
            k = i / (curveLen - 1);
            sineCurve[i] = 0.5 * (1 - Math.cos(Math.PI * k));
        }
        // a bounce curve
        const bounceCurve = [];
        for (i = 0; i < curveLen; i++) {
            k = i / (curveLen - 1);
            const freq = Math.pow(k, 3) * 4 + 0.2;
            const val = Math.cos(freq * Math.PI * 2 * k);
            bounceCurve[i] = Math.abs(val * (1 - k));
        }
        /**
         * Invert a value curve to make it work for the release
         */
        function invertCurve(curve) {
            const out = new Array(curve.length);
            for (let j = 0; j < curve.length; j++) {
                out[j] = 1 - curve[j];
            }
            return out;
        }
        /**
         * reverse the curve
         */
        function reverseCurve(curve) {
            return curve.slice(0).reverse();
        }
        /**
         * attack and release curve arrays
         */
        return {
            bounce: {
                In: invertCurve(bounceCurve),
                Out: bounceCurve,
            },
            cosine: {
                In: cosineCurve,
                Out: reverseCurve(cosineCurve),
            },
            exponential: "exponential",
            linear: "linear",
            ripple: {
                In: rippleCurve,
                Out: invertCurve(rippleCurve),
            },
            sine: {
                In: sineCurve,
                Out: invertCurve(sineCurve),
            },
            step: {
                In: stairsCurve,
                Out: invertCurve(stairsCurve),
            },
        };
    })();

    /**
     * Base-class for all instruments
     */
    class Instrument extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Instrument.getDefaults(), arguments));
            /**
             * Keep track of all events scheduled to the transport
             * when the instrument is 'synced'
             */
            this._scheduledEvents = [];
            /**
             * If the instrument is currently synced
             */
            this._synced = false;
            this._original_triggerAttack = this.triggerAttack;
            this._original_triggerRelease = this.triggerRelease;
            const options = optionsFromArguments(Instrument.getDefaults(), arguments);
            this._volume = this.output = new Volume({
                context: this.context,
                volume: options.volume,
            });
            this.volume = this._volume.volume;
            readOnly(this, "volume");
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                volume: 0,
            });
        }
        /**
         * Sync the instrument to the Transport. All subsequent calls of
         * [[triggerAttack]] and [[triggerRelease]] will be scheduled along the transport.
         * @example
         * const fmSynth = new Tone.FMSynth().toDestination();
         * fmSynth.volume.value = -6;
         * fmSynth.sync();
         * // schedule 3 notes when the transport first starts
         * fmSynth.triggerAttackRelease("C4", "8n", 0);
         * fmSynth.triggerAttackRelease("E4", "8n", "8n");
         * fmSynth.triggerAttackRelease("G4", "8n", "4n");
         * // start the transport to hear the notes
         * Tone.Transport.start();
         */
        sync() {
            if (this._syncState()) {
                this._syncMethod("triggerAttack", 1);
                this._syncMethod("triggerRelease", 0);
            }
            return this;
        }
        /**
         * set _sync
         */
        _syncState() {
            let changed = false;
            if (!this._synced) {
                this._synced = true;
                changed = true;
            }
            return changed;
        }
        /**
         * Wrap the given method so that it can be synchronized
         * @param method Which method to wrap and sync
         * @param  timePosition What position the time argument appears in
         */
        _syncMethod(method, timePosition) {
            const originalMethod = this["_original_" + method] = this[method];
            this[method] = (...args) => {
                const time = args[timePosition];
                const id = this.context.transport.schedule((t) => {
                    args[timePosition] = t;
                    originalMethod.apply(this, args);
                }, time);
                this._scheduledEvents.push(id);
            };
        }
        /**
         * Unsync the instrument from the Transport
         */
        unsync() {
            this._scheduledEvents.forEach(id => this.context.transport.clear(id));
            this._scheduledEvents = [];
            if (this._synced) {
                this._synced = false;
                this.triggerAttack = this._original_triggerAttack;
                this.triggerRelease = this._original_triggerRelease;
            }
            return this;
        }
        /**
         * Trigger the attack and then the release after the duration.
         * @param  note     The note to trigger.
         * @param  duration How long the note should be held for before
         *                         triggering the release. This value must be greater than 0.
         * @param time  When the note should be triggered.
         * @param  velocity The velocity the note should be triggered at.
         * @example
         * const synth = new Tone.Synth().toDestination();
         * // trigger "C4" for the duration of an 8th note
         * synth.triggerAttackRelease("C4", "8n");
         */
        triggerAttackRelease(note, duration, time, velocity) {
            const computedTime = this.toSeconds(time);
            const computedDuration = this.toSeconds(duration);
            this.triggerAttack(note, computedTime, velocity);
            this.triggerRelease(computedTime + computedDuration);
            return this;
        }
        /**
         * clean up
         * @returns {Instrument} this
         */
        dispose() {
            super.dispose();
            this._volume.dispose();
            this.unsync();
            this._scheduledEvents = [];
            return this;
        }
    }

    /**
     * Abstract base class for other monophonic instruments to extend.
     */
    class Monophonic extends Instrument {
        constructor() {
            super(optionsFromArguments(Monophonic.getDefaults(), arguments));
            const options = optionsFromArguments(Monophonic.getDefaults(), arguments);
            this.portamento = options.portamento;
            this.onsilence = options.onsilence;
        }
        static getDefaults() {
            return Object.assign(Instrument.getDefaults(), {
                detune: 0,
                onsilence: noOp,
                portamento: 0,
            });
        }
        /**
         * Trigger the attack of the note optionally with a given velocity.
         * @param  note The note to trigger.
         * @param  time When the note should start.
         * @param  velocity The velocity scaler determines how "loud" the note will be triggered.
         * @example
         * const synth = new Tone.Synth().toDestination();
         * // trigger the note a half second from now at half velocity
         * synth.triggerAttack("C4", "+0.5", 0.5);
         */
        triggerAttack(note, time, velocity = 1) {
            this.log("triggerAttack", note, time, velocity);
            const seconds = this.toSeconds(time);
            this._triggerEnvelopeAttack(seconds, velocity);
            this.setNote(note, seconds);
            return this;
        }
        /**
         * Trigger the release portion of the envelope
         * @param  time If no time is given, the release happens immediatly
         * @example
         * const synth = new Tone.Synth().toDestination();
         * synth.triggerAttack("C4");
         * // trigger the release a second from now
         * synth.triggerRelease("+1");
         */
        triggerRelease(time) {
            this.log("triggerRelease", time);
            const seconds = this.toSeconds(time);
            this._triggerEnvelopeRelease(seconds);
            return this;
        }
        /**
         * Set the note at the given time. If no time is given, the note
         * will set immediately.
         * @param note The note to change to.
         * @param  time The time when the note should be set.
         * @example
         * const synth = new Tone.Synth().toDestination();
         * synth.triggerAttack("C4");
         * // change to F#6 in one quarter note from now.
         * synth.setNote("F#6", "+4n");
         */
        setNote(note, time) {
            const computedTime = this.toSeconds(time);
            const computedFrequency = note instanceof FrequencyClass ? note.toFrequency() : note;
            if (this.portamento > 0 && this.getLevelAtTime(computedTime) > 0.05) {
                const portTime = this.toSeconds(this.portamento);
                this.frequency.exponentialRampTo(computedFrequency, portTime, computedTime);
            }
            else {
                this.frequency.setValueAtTime(computedFrequency, computedTime);
            }
            return this;
        }
    }
    __decorate([
        timeRange(0)
    ], Monophonic.prototype, "portamento", void 0);

    /**
     * AmplitudeEnvelope is a Tone.Envelope connected to a gain node.
     * Unlike Tone.Envelope, which outputs the envelope's value, AmplitudeEnvelope accepts
     * an audio signal as the input and will apply the envelope to the amplitude
     * of the signal.
     * Read more about ADSR Envelopes on [Wikipedia](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope).
     *
     * @example
     * return Tone.Offline(() => {
     * 	const ampEnv = new Tone.AmplitudeEnvelope({
     * 		attack: 0.1,
     * 		decay: 0.2,
     * 		sustain: 1.0,
     * 		release: 0.8
     * 	}).toDestination();
     * 	// create an oscillator and connect it
     * 	const osc = new Tone.Oscillator().connect(ampEnv).start();
     * 	// trigger the envelopes attack and release "8t" apart
     * 	ampEnv.triggerAttackRelease("8t");
     * }, 1.5, 1);
     * @category Component
     */
    class AmplitudeEnvelope extends Envelope {
        constructor() {
            super(optionsFromArguments(AmplitudeEnvelope.getDefaults(), arguments, ["attack", "decay", "sustain", "release"]));
            this.name = "AmplitudeEnvelope";
            this._gainNode = new Gain({
                context: this.context,
                gain: 0,
            });
            this.output = this._gainNode;
            this.input = this._gainNode;
            this._sig.connect(this._gainNode.gain);
            this.output = this._gainNode;
            this.input = this._gainNode;
        }
        /**
         * Clean up
         */
        dispose() {
            super.dispose();
            this._gainNode.dispose();
            return this;
        }
    }

    /**
     * Synth is composed simply of a [[OmniOscillator]] routed through an [[AmplitudeEnvelope]].
     * ```
     * +----------------+   +-------------------+
     * | OmniOscillator +>--> AmplitudeEnvelope +>--> Output
     * +----------------+   +-------------------+
     * ```
     * @example
     * const synth = new Tone.Synth().toDestination();
     * synth.triggerAttackRelease("C4", "8n");
     * @category Instrument
     */
    class Synth extends Monophonic {
        constructor() {
            super(optionsFromArguments(Synth.getDefaults(), arguments));
            this.name = "Synth";
            const options = optionsFromArguments(Synth.getDefaults(), arguments);
            this.oscillator = new OmniOscillator(Object.assign({
                context: this.context,
                detune: options.detune,
                onstop: () => this.onsilence(this),
            }, options.oscillator));
            this.frequency = this.oscillator.frequency;
            this.detune = this.oscillator.detune;
            this.envelope = new AmplitudeEnvelope(Object.assign({
                context: this.context,
            }, options.envelope));
            // connect the oscillators to the output
            this.oscillator.chain(this.envelope, this.output);
            readOnly(this, ["oscillator", "frequency", "detune", "envelope"]);
        }
        static getDefaults() {
            return Object.assign(Monophonic.getDefaults(), {
                envelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {
                    attack: 0.005,
                    decay: 0.1,
                    release: 1,
                    sustain: 0.3,
                }),
                oscillator: Object.assign(omitFromObject(OmniOscillator.getDefaults(), [...Object.keys(Source.getDefaults()), "frequency", "detune"]), {
                    type: "triangle",
                }),
            });
        }
        /**
         * start the attack portion of the envelope
         * @param time the time the attack should start
         * @param velocity the velocity of the note (0-1)
         */
        _triggerEnvelopeAttack(time, velocity) {
            // the envelopes
            this.envelope.triggerAttack(time, velocity);
            this.oscillator.start(time);
            // if there is no release portion, stop the oscillator
            if (this.envelope.sustain === 0) {
                const computedAttack = this.toSeconds(this.envelope.attack);
                const computedDecay = this.toSeconds(this.envelope.decay);
                this.oscillator.stop(time + computedAttack + computedDecay);
            }
        }
        /**
         * start the release portion of the envelope
         * @param time the time the release should start
         */
        _triggerEnvelopeRelease(time) {
            this.envelope.triggerRelease(time);
            this.oscillator.stop(time + this.toSeconds(this.envelope.release));
        }
        getLevelAtTime(time) {
            time = this.toSeconds(time);
            return this.envelope.getValueAtTime(time);
        }
        /**
         * clean up
         */
        dispose() {
            super.dispose();
            this.oscillator.dispose();
            this.envelope.dispose();
            return this;
        }
    }

    /**
     * Base class for both AM and FM synths
     */
    class ModulationSynth extends Monophonic {
        constructor() {
            super(optionsFromArguments(ModulationSynth.getDefaults(), arguments));
            this.name = "ModulationSynth";
            const options = optionsFromArguments(ModulationSynth.getDefaults(), arguments);
            this._carrier = new Synth({
                context: this.context,
                oscillator: options.oscillator,
                envelope: options.envelope,
                onsilence: () => this.onsilence(this),
                volume: -10,
            });
            this._modulator = new Synth({
                context: this.context,
                oscillator: options.modulation,
                envelope: options.modulationEnvelope,
                volume: -10,
            });
            this.oscillator = this._carrier.oscillator;
            this.envelope = this._carrier.envelope;
            this.modulation = this._modulator.oscillator;
            this.modulationEnvelope = this._modulator.envelope;
            this.frequency = new Signal({
                context: this.context,
                units: "frequency",
            });
            this.detune = new Signal({
                context: this.context,
                value: options.detune,
                units: "cents"
            });
            this.harmonicity = new Multiply({
                context: this.context,
                value: options.harmonicity,
                minValue: 0,
            });
            this._modulationNode = new Gain({
                context: this.context,
                gain: 0,
            });
            readOnly(this, ["frequency", "harmonicity", "oscillator", "envelope", "modulation", "modulationEnvelope", "detune"]);
        }
        static getDefaults() {
            return Object.assign(Monophonic.getDefaults(), {
                harmonicity: 3,
                oscillator: Object.assign(omitFromObject(OmniOscillator.getDefaults(), [
                    ...Object.keys(Source.getDefaults()),
                    "frequency",
                    "detune"
                ]), {
                    type: "sine"
                }),
                envelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {
                    attack: 0.01,
                    decay: 0.01,
                    sustain: 1,
                    release: 0.5
                }),
                modulation: Object.assign(omitFromObject(OmniOscillator.getDefaults(), [
                    ...Object.keys(Source.getDefaults()),
                    "frequency",
                    "detune"
                ]), {
                    type: "square"
                }),
                modulationEnvelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {
                    attack: 0.5,
                    decay: 0.0,
                    sustain: 1,
                    release: 0.5
                })
            });
        }
        /**
         * Trigger the attack portion of the note
         */
        _triggerEnvelopeAttack(time, velocity) {
            // @ts-ignore
            this._carrier._triggerEnvelopeAttack(time, velocity);
            // @ts-ignore
            this._modulator._triggerEnvelopeAttack(time, velocity);
        }
        /**
         * Trigger the release portion of the note
         */
        _triggerEnvelopeRelease(time) {
            // @ts-ignore
            this._carrier._triggerEnvelopeRelease(time);
            // @ts-ignore
            this._modulator._triggerEnvelopeRelease(time);
            return this;
        }
        getLevelAtTime(time) {
            time = this.toSeconds(time);
            return this.envelope.getValueAtTime(time);
        }
        dispose() {
            super.dispose();
            this._carrier.dispose();
            this._modulator.dispose();
            this.frequency.dispose();
            this.detune.dispose();
            this.harmonicity.dispose();
            this._modulationNode.dispose();
            return this;
        }
    }

    /**
     * AMSynth uses the output of one Tone.Synth to modulate the
     * amplitude of another Tone.Synth. The harmonicity (the ratio between
     * the two signals) affects the timbre of the output signal greatly.
     * Read more about Amplitude Modulation Synthesis on
     * [SoundOnSound](https://web.archive.org/web/20160404103653/http://www.soundonsound.com:80/sos/mar00/articles/synthsecrets.htm).
     *
     * @example
     * const synth = new Tone.AMSynth().toDestination();
     * synth.triggerAttackRelease("C4", "4n");
     *
     * @category Instrument
     */
    class AMSynth extends ModulationSynth {
        constructor() {
            super(optionsFromArguments(AMSynth.getDefaults(), arguments));
            this.name = "AMSynth";
            this._modulationScale = new AudioToGain({
                context: this.context,
            });
            // control the two voices frequency
            this.frequency.connect(this._carrier.frequency);
            this.frequency.chain(this.harmonicity, this._modulator.frequency);
            this.detune.fan(this._carrier.detune, this._modulator.detune);
            this._modulator.chain(this._modulationScale, this._modulationNode.gain);
            this._carrier.chain(this._modulationNode, this.output);
        }
        dispose() {
            super.dispose();
            this._modulationScale.dispose();
            return this;
        }
    }

    /**
     * Thin wrapper around the native Web Audio [BiquadFilterNode](https://webaudio.github.io/web-audio-api/#biquadfilternode).
     * BiquadFilter is similar to [[Filter]] but doesn't have the option to set the "rolloff" value.
     * @category Component
     */
    class BiquadFilter extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(BiquadFilter.getDefaults(), arguments, ["frequency", "type"]));
            this.name = "BiquadFilter";
            const options = optionsFromArguments(BiquadFilter.getDefaults(), arguments, ["frequency", "type"]);
            this._filter = this.context.createBiquadFilter();
            this.input = this.output = this._filter;
            this.Q = new Param({
                context: this.context,
                units: "number",
                value: options.Q,
                param: this._filter.Q,
            });
            this.frequency = new Param({
                context: this.context,
                units: "frequency",
                value: options.frequency,
                param: this._filter.frequency,
            });
            this.detune = new Param({
                context: this.context,
                units: "cents",
                value: options.detune,
                param: this._filter.detune,
            });
            this.gain = new Param({
                context: this.context,
                units: "gain",
                value: options.gain,
                param: this._filter.gain,
            });
            this.type = options.type;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                Q: 1,
                type: "lowpass",
                frequency: 350,
                detune: 0,
                gain: 0,
            });
        }
        /**
         * The type of this BiquadFilterNode. For a complete list of types and their attributes, see the
         * [Web Audio API](https://webaudio.github.io/web-audio-api/#dom-biquadfiltertype-lowpass)
         */
        get type() {
            return this._filter.type;
        }
        set type(type) {
            const types = ["lowpass", "highpass", "bandpass",
                "lowshelf", "highshelf", "notch", "allpass", "peaking"];
            assert(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);
            this._filter.type = type;
        }
        /**
         * Get the frequency response curve. This curve represents how the filter
         * responses to frequencies between 20hz-20khz.
         * @param  len The number of values to return
         * @return The frequency response curve between 20-20kHz
         */
        getFrequencyResponse(len = 128) {
            // start with all 1s
            const freqValues = new Float32Array(len);
            for (let i = 0; i < len; i++) {
                const norm = Math.pow(i / len, 2);
                const freq = norm * (20000 - 20) + 20;
                freqValues[i] = freq;
            }
            const magValues = new Float32Array(len);
            const phaseValues = new Float32Array(len);
            // clone the filter to remove any connections which may be changing the value
            const filterClone = this.context.createBiquadFilter();
            filterClone.type = this.type;
            filterClone.Q.value = this.Q.value;
            filterClone.frequency.value = this.frequency.value;
            filterClone.gain.value = this.gain.value;
            filterClone.getFrequencyResponse(freqValues, magValues, phaseValues);
            return magValues;
        }
        dispose() {
            super.dispose();
            this._filter.disconnect();
            this.Q.dispose();
            this.frequency.dispose();
            this.gain.dispose();
            this.detune.dispose();
            return this;
        }
    }

    /**
     * Tone.Filter is a filter which allows for all of the same native methods
     * as the [BiquadFilterNode](http://webaudio.github.io/web-audio-api/#the-biquadfilternode-interface).
     * Tone.Filter has the added ability to set the filter rolloff at -12
     * (default), -24 and -48.
     * @example
     * const filter = new Tone.Filter(1500, "highpass").toDestination();
     * filter.frequency.rampTo(20000, 10);
     * const noise = new Tone.Noise().connect(filter).start();
     * @category Component
     */
    class Filter extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Filter.getDefaults(), arguments, ["frequency", "type", "rolloff"]));
            this.name = "Filter";
            this.input = new Gain({ context: this.context });
            this.output = new Gain({ context: this.context });
            this._filters = [];
            const options = optionsFromArguments(Filter.getDefaults(), arguments, ["frequency", "type", "rolloff"]);
            this._filters = [];
            this.Q = new Signal({
                context: this.context,
                units: "positive",
                value: options.Q,
            });
            this.frequency = new Signal({
                context: this.context,
                units: "frequency",
                value: options.frequency,
            });
            this.detune = new Signal({
                context: this.context,
                units: "cents",
                value: options.detune,
            });
            this.gain = new Signal({
                context: this.context,
                units: "decibels",
                value: options.gain,
            });
            this._type = options.type;
            this.rolloff = options.rolloff;
            readOnly(this, ["detune", "frequency", "gain", "Q"]);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                Q: 1,
                detune: 0,
                frequency: 350,
                gain: 0,
                rolloff: -12,
                type: "lowpass",
            });
        }
        /**
         * The type of the filter. Types: "lowpass", "highpass",
         * "bandpass", "lowshelf", "highshelf", "notch", "allpass", or "peaking".
         */
        get type() {
            return this._type;
        }
        set type(type) {
            const types = ["lowpass", "highpass", "bandpass",
                "lowshelf", "highshelf", "notch", "allpass", "peaking"];
            assert(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);
            this._type = type;
            this._filters.forEach(filter => filter.type = type);
        }
        /**
         * The rolloff of the filter which is the drop in db
         * per octave. Implemented internally by cascading filters.
         * Only accepts the values -12, -24, -48 and -96.
         */
        get rolloff() {
            return this._rolloff;
        }
        set rolloff(rolloff) {
            const rolloffNum = isNumber(rolloff) ? rolloff : parseInt(rolloff, 10);
            const possibilities = [-12, -24, -48, -96];
            let cascadingCount = possibilities.indexOf(rolloffNum);
            // check the rolloff is valid
            assert(cascadingCount !== -1, `rolloff can only be ${possibilities.join(", ")}`);
            cascadingCount += 1;
            this._rolloff = rolloffNum;
            this.input.disconnect();
            this._filters.forEach(filter => filter.disconnect());
            this._filters = new Array(cascadingCount);
            for (let count = 0; count < cascadingCount; count++) {
                const filter = new BiquadFilter({
                    context: this.context,
                });
                filter.type = this._type;
                this.frequency.connect(filter.frequency);
                this.detune.connect(filter.detune);
                this.Q.connect(filter.Q);
                this.gain.connect(filter.gain);
                this._filters[count] = filter;
            }
            this._internalChannels = this._filters;
            connectSeries(this.input, ...this._internalChannels, this.output);
        }
        /**
         * Get the frequency response curve. This curve represents how the filter
         * responses to frequencies between 20hz-20khz.
         * @param  len The number of values to return
         * @return The frequency response curve between 20-20kHz
         */
        getFrequencyResponse(len = 128) {
            const filterClone = new BiquadFilter({
                frequency: this.frequency.value,
                gain: this.gain.value,
                Q: this.Q.value,
                type: this._type,
                detune: this.detune.value,
            });
            // start with all 1s
            const totalResponse = new Float32Array(len).map(() => 1);
            this._filters.forEach(() => {
                const response = filterClone.getFrequencyResponse(len);
                response.forEach((val, i) => totalResponse[i] *= val);
            });
            filterClone.dispose();
            return totalResponse;
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this._filters.forEach(filter => {
                filter.dispose();
            });
            writable(this, ["detune", "frequency", "gain", "Q"]);
            this.frequency.dispose();
            this.Q.dispose();
            this.detune.dispose();
            this.gain.dispose();
            return this;
        }
    }

    /**
     * FrequencyEnvelope is an [[Envelope]] which ramps between [[baseFrequency]]
     * and [[octaves]]. It can also have an optional [[exponent]] to adjust the curve
     * which it ramps.
     * @example
     * const oscillator = new Tone.Oscillator().toDestination().start();
     * const freqEnv = new Tone.FrequencyEnvelope({
     * 	attack: 0.2,
     * 	baseFrequency: "C2",
     * 	octaves: 4
     * });
     * freqEnv.connect(oscillator.frequency);
     * freqEnv.triggerAttack();
     * @category Component
     */
    class FrequencyEnvelope extends Envelope {
        constructor() {
            super(optionsFromArguments(FrequencyEnvelope.getDefaults(), arguments, ["attack", "decay", "sustain", "release"]));
            this.name = "FrequencyEnvelope";
            const options = optionsFromArguments(FrequencyEnvelope.getDefaults(), arguments, ["attack", "decay", "sustain", "release"]);
            this._octaves = options.octaves;
            this._baseFrequency = this.toFrequency(options.baseFrequency);
            this._exponent = this.input = new Pow({
                context: this.context,
                value: options.exponent
            });
            this._scale = this.output = new Scale({
                context: this.context,
                min: this._baseFrequency,
                max: this._baseFrequency * Math.pow(2, this._octaves),
            });
            this._sig.chain(this._exponent, this._scale);
        }
        static getDefaults() {
            return Object.assign(Envelope.getDefaults(), {
                baseFrequency: 200,
                exponent: 1,
                octaves: 4,
            });
        }
        /**
         * The envelope's minimum output value. This is the value which it
         * starts at.
         */
        get baseFrequency() {
            return this._baseFrequency;
        }
        set baseFrequency(min) {
            const freq = this.toFrequency(min);
            assertRange(freq, 0);
            this._baseFrequency = freq;
            this._scale.min = this._baseFrequency;
            // update the max value when the min changes
            this.octaves = this._octaves;
        }
        /**
         * The number of octaves above the baseFrequency that the
         * envelope will scale to.
         */
        get octaves() {
            return this._octaves;
        }
        set octaves(octaves) {
            assertRange(octaves, 0);
            this._octaves = octaves;
            this._scale.max = this._baseFrequency * Math.pow(2, octaves);
        }
        /**
         * The envelope's exponent value.
         */
        get exponent() {
            return this._exponent.value;
        }
        set exponent(exponent) {
            this._exponent.value = exponent;
        }
        /**
         * Clean up
         */
        dispose() {
            super.dispose();
            this._exponent.dispose();
            this._scale.dispose();
            return this;
        }
    }

    /**
     * MonoSynth is composed of one `oscillator`, one `filter`, and two `envelopes`.
     * The amplitude of the Oscillator and the cutoff frequency of the
     * Filter are controlled by Envelopes.
     * <img src="https://docs.google.com/drawings/d/1gaY1DF9_Hzkodqf8JI1Cg2VZfwSElpFQfI94IQwad38/pub?w=924&h=240">
     * @example
     * const synth = new Tone.MonoSynth({
     * 	oscillator: {
     * 		type: "square"
     * 	},
     * 	envelope: {
     * 		attack: 0.1
     * 	}
     * }).toDestination();
     * synth.triggerAttackRelease("C4", "8n");
     * @category Instrument
     */
    class MonoSynth extends Monophonic {
        constructor() {
            super(optionsFromArguments(MonoSynth.getDefaults(), arguments));
            this.name = "MonoSynth";
            const options = optionsFromArguments(MonoSynth.getDefaults(), arguments);
            this.oscillator = new OmniOscillator(Object.assign(options.oscillator, {
                context: this.context,
                detune: options.detune,
                onstop: () => this.onsilence(this),
            }));
            this.frequency = this.oscillator.frequency;
            this.detune = this.oscillator.detune;
            this.filter = new Filter(Object.assign(options.filter, { context: this.context }));
            this.filterEnvelope = new FrequencyEnvelope(Object.assign(options.filterEnvelope, { context: this.context }));
            this.envelope = new AmplitudeEnvelope(Object.assign(options.envelope, { context: this.context }));
            // connect the oscillators to the output
            this.oscillator.chain(this.filter, this.envelope, this.output);
            // connect the filter envelope
            this.filterEnvelope.connect(this.filter.frequency);
            readOnly(this, ["oscillator", "frequency", "detune", "filter", "filterEnvelope", "envelope"]);
        }
        static getDefaults() {
            return Object.assign(Monophonic.getDefaults(), {
                envelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {
                    attack: 0.005,
                    decay: 0.1,
                    release: 1,
                    sustain: 0.9,
                }),
                filter: Object.assign(omitFromObject(Filter.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {
                    Q: 1,
                    rolloff: -12,
                    type: "lowpass",
                }),
                filterEnvelope: Object.assign(omitFromObject(FrequencyEnvelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {
                    attack: 0.6,
                    baseFrequency: 200,
                    decay: 0.2,
                    exponent: 2,
                    octaves: 3,
                    release: 2,
                    sustain: 0.5,
                }),
                oscillator: Object.assign(omitFromObject(OmniOscillator.getDefaults(), Object.keys(Source.getDefaults())), {
                    type: "sawtooth",
                }),
            });
        }
        /**
         * start the attack portion of the envelope
         * @param time the time the attack should start
         * @param velocity the velocity of the note (0-1)
         */
        _triggerEnvelopeAttack(time, velocity = 1) {
            this.envelope.triggerAttack(time, velocity);
            this.filterEnvelope.triggerAttack(time);
            this.oscillator.start(time);
            if (this.envelope.sustain === 0) {
                const computedAttack = this.toSeconds(this.envelope.attack);
                const computedDecay = this.toSeconds(this.envelope.decay);
                this.oscillator.stop(time + computedAttack + computedDecay);
            }
        }
        /**
         * start the release portion of the envelope
         * @param time the time the release should start
         */
        _triggerEnvelopeRelease(time) {
            this.envelope.triggerRelease(time);
            this.filterEnvelope.triggerRelease(time);
            this.oscillator.stop(time + this.toSeconds(this.envelope.release));
        }
        getLevelAtTime(time) {
            time = this.toSeconds(time);
            return this.envelope.getValueAtTime(time);
        }
        dispose() {
            super.dispose();
            this.oscillator.dispose();
            this.envelope.dispose();
            this.filterEnvelope.dispose();
            this.filter.dispose();
            return this;
        }
    }

    /**
     * DuoSynth is a monophonic synth composed of two [[MonoSynths]] run in parallel with control over the
     * frequency ratio between the two voices and vibrato effect.
     * @example
     * const duoSynth = new Tone.DuoSynth().toDestination();
     * duoSynth.triggerAttackRelease("C4", "2n");
     * @category Instrument
     */
    class DuoSynth extends Monophonic {
        constructor() {
            super(optionsFromArguments(DuoSynth.getDefaults(), arguments));
            this.name = "DuoSynth";
            const options = optionsFromArguments(DuoSynth.getDefaults(), arguments);
            this.voice0 = new MonoSynth(Object.assign(options.voice0, {
                context: this.context,
                onsilence: () => this.onsilence(this)
            }));
            this.voice1 = new MonoSynth(Object.assign(options.voice1, {
                context: this.context,
            }));
            this.harmonicity = new Multiply({
                context: this.context,
                units: "positive",
                value: options.harmonicity,
            });
            this._vibrato = new LFO({
                frequency: options.vibratoRate,
                context: this.context,
                min: -50,
                max: 50
            });
            // start the vibrato immediately
            this._vibrato.start();
            this.vibratoRate = this._vibrato.frequency;
            this._vibratoGain = new Gain({
                context: this.context,
                units: "normalRange",
                gain: options.vibratoAmount
            });
            this.vibratoAmount = this._vibratoGain.gain;
            this.frequency = new Signal({
                context: this.context,
                units: "frequency",
                value: 440
            });
            this.detune = new Signal({
                context: this.context,
                units: "cents",
                value: options.detune
            });
            // control the two voices frequency
            this.frequency.connect(this.voice0.frequency);
            this.frequency.chain(this.harmonicity, this.voice1.frequency);
            this._vibrato.connect(this._vibratoGain);
            this._vibratoGain.fan(this.voice0.detune, this.voice1.detune);
            this.detune.fan(this.voice0.detune, this.voice1.detune);
            this.voice0.connect(this.output);
            this.voice1.connect(this.output);
            readOnly(this, ["voice0", "voice1", "frequency", "vibratoAmount", "vibratoRate"]);
        }
        getLevelAtTime(time) {
            time = this.toSeconds(time);
            return this.voice0.envelope.getValueAtTime(time) + this.voice1.envelope.getValueAtTime(time);
        }
        static getDefaults() {
            return deepMerge(Monophonic.getDefaults(), {
                vibratoAmount: 0.5,
                vibratoRate: 5,
                harmonicity: 1.5,
                voice0: deepMerge(omitFromObject(MonoSynth.getDefaults(), Object.keys(Monophonic.getDefaults())), {
                    filterEnvelope: {
                        attack: 0.01,
                        decay: 0.0,
                        sustain: 1,
                        release: 0.5
                    },
                    envelope: {
                        attack: 0.01,
                        decay: 0.0,
                        sustain: 1,
                        release: 0.5
                    }
                }),
                voice1: deepMerge(omitFromObject(MonoSynth.getDefaults(), Object.keys(Monophonic.getDefaults())), {
                    filterEnvelope: {
                        attack: 0.01,
                        decay: 0.0,
                        sustain: 1,
                        release: 0.5
                    },
                    envelope: {
                        attack: 0.01,
                        decay: 0.0,
                        sustain: 1,
                        release: 0.5
                    }
                }),
            });
        }
        /**
         * Trigger the attack portion of the note
         */
        _triggerEnvelopeAttack(time, velocity) {
            // @ts-ignore
            this.voice0._triggerEnvelopeAttack(time, velocity);
            // @ts-ignore
            this.voice1._triggerEnvelopeAttack(time, velocity);
        }
        /**
         * Trigger the release portion of the note
         */
        _triggerEnvelopeRelease(time) {
            // @ts-ignore
            this.voice0._triggerEnvelopeRelease(time);
            // @ts-ignore
            this.voice1._triggerEnvelopeRelease(time);
            return this;
        }
        dispose() {
            super.dispose();
            this.voice0.dispose();
            this.voice1.dispose();
            this.frequency.dispose();
            this.detune.dispose();
            this._vibrato.dispose();
            this.vibratoRate.dispose();
            this._vibratoGain.dispose();
            this.harmonicity.dispose();
            return this;
        }
    }

    /**
     * FMSynth is composed of two Tone.Synths where one Tone.Synth modulates
     * the frequency of a second Tone.Synth. A lot of spectral content
     * can be explored using the modulationIndex parameter. Read more about
     * frequency modulation synthesis on Sound On Sound: [Part 1](https://web.archive.org/web/20160403123704/http://www.soundonsound.com/sos/apr00/articles/synthsecrets.htm), [Part 2](https://web.archive.org/web/20160403115835/http://www.soundonsound.com/sos/may00/articles/synth.htm).
     *
     * @example
     * const fmSynth = new Tone.FMSynth().toDestination();
     * fmSynth.triggerAttackRelease("C5", "4n");
     *
     * @category Instrument
     */
    class FMSynth extends ModulationSynth {
        constructor() {
            super(optionsFromArguments(FMSynth.getDefaults(), arguments));
            this.name = "FMSynth";
            const options = optionsFromArguments(FMSynth.getDefaults(), arguments);
            this.modulationIndex = new Multiply({
                context: this.context,
                value: options.modulationIndex,
            });
            // control the two voices frequency
            this.frequency.connect(this._carrier.frequency);
            this.frequency.chain(this.harmonicity, this._modulator.frequency);
            this.frequency.chain(this.modulationIndex, this._modulationNode);
            this.detune.fan(this._carrier.detune, this._modulator.detune);
            this._modulator.connect(this._modulationNode.gain);
            this._modulationNode.connect(this._carrier.frequency);
            this._carrier.connect(this.output);
        }
        static getDefaults() {
            return Object.assign(ModulationSynth.getDefaults(), {
                modulationIndex: 10,
            });
        }
        dispose() {
            super.dispose();
            this.modulationIndex.dispose();
            return this;
        }
    }

    /**
     * Inharmonic ratio of frequencies based on the Roland TR-808
     * Taken from https://ccrma.stanford.edu/papers/tr-808-cymbal-physically-informed-circuit-bendable-digital-model
     */
    const inharmRatios = [1.0, 1.483, 1.932, 2.546, 2.630, 3.897];
    /**
     * A highly inharmonic and spectrally complex source with a highpass filter
     * and amplitude envelope which is good for making metallophone sounds.
     * Based on CymbalSynth by [@polyrhythmatic](https://github.com/polyrhythmatic).
     * Inspiration from [Sound on Sound](https://shorturl.at/rSZ12).
     * @category Instrument
     */
    class MetalSynth extends Monophonic {
        constructor() {
            super(optionsFromArguments(MetalSynth.getDefaults(), arguments));
            this.name = "MetalSynth";
            /**
             * The array of FMOscillators
             */
            this._oscillators = [];
            /**
             * The frequency multipliers
             */
            this._freqMultipliers = [];
            const options = optionsFromArguments(MetalSynth.getDefaults(), arguments);
            this.detune = new Signal({
                context: this.context,
                units: "cents",
                value: options.detune,
            });
            this.frequency = new Signal({
                context: this.context,
                units: "frequency",
            });
            this._amplitude = new Gain({
                context: this.context,
                gain: 0,
            }).connect(this.output);
            this._highpass = new Filter({
                // Q: -3.0102999566398125,
                Q: 0,
                context: this.context,
                type: "highpass",
            }).connect(this._amplitude);
            for (let i = 0; i < inharmRatios.length; i++) {
                const osc = new FMOscillator({
                    context: this.context,
                    harmonicity: options.harmonicity,
                    modulationIndex: options.modulationIndex,
                    modulationType: "square",
                    onstop: i === 0 ? () => this.onsilence(this) : noOp,
                    type: "square",
                });
                osc.connect(this._highpass);
                this._oscillators[i] = osc;
                const mult = new Multiply({
                    context: this.context,
                    value: inharmRatios[i],
                });
                this._freqMultipliers[i] = mult;
                this.frequency.chain(mult, osc.frequency);
                this.detune.connect(osc.detune);
            }
            this._filterFreqScaler = new Scale({
                context: this.context,
                max: 7000,
                min: this.toFrequency(options.resonance),
            });
            this.envelope = new Envelope({
                attack: options.envelope.attack,
                attackCurve: "linear",
                context: this.context,
                decay: options.envelope.decay,
                release: options.envelope.release,
                sustain: 0,
            });
            this.envelope.chain(this._filterFreqScaler, this._highpass.frequency);
            this.envelope.connect(this._amplitude.gain);
            // set the octaves
            this._octaves = options.octaves;
            this.octaves = options.octaves;
        }
        static getDefaults() {
            return deepMerge(Monophonic.getDefaults(), {
                envelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {
                    attack: 0.001,
                    decay: 1.4,
                    release: 0.2,
                }),
                harmonicity: 5.1,
                modulationIndex: 32,
                octaves: 1.5,
                resonance: 4000,
            });
        }
        /**
         * Trigger the attack.
         * @param time When the attack should be triggered.
         * @param velocity The velocity that the envelope should be triggered at.
         */
        _triggerEnvelopeAttack(time, velocity = 1) {
            this.envelope.triggerAttack(time, velocity);
            this._oscillators.forEach(osc => osc.start(time));
            if (this.envelope.sustain === 0) {
                this._oscillators.forEach(osc => {
                    osc.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));
                });
            }
            return this;
        }
        /**
         * Trigger the release of the envelope.
         * @param time When the release should be triggered.
         */
        _triggerEnvelopeRelease(time) {
            this.envelope.triggerRelease(time);
            this._oscillators.forEach(osc => osc.stop(time + this.toSeconds(this.envelope.release)));
            return this;
        }
        getLevelAtTime(time) {
            time = this.toSeconds(time);
            return this.envelope.getValueAtTime(time);
        }
        /**
         * The modulationIndex of the oscillators which make up the source.
         * see [[FMOscillator.modulationIndex]]
         * @min 1
         * @max 100
         */
        get modulationIndex() {
            return this._oscillators[0].modulationIndex.value;
        }
        set modulationIndex(val) {
            this._oscillators.forEach(osc => (osc.modulationIndex.value = val));
        }
        /**
         * The harmonicity of the oscillators which make up the source.
         * see Tone.FMOscillator.harmonicity
         * @min 0.1
         * @max 10
         */
        get harmonicity() {
            return this._oscillators[0].harmonicity.value;
        }
        set harmonicity(val) {
            this._oscillators.forEach(osc => (osc.harmonicity.value = val));
        }
        /**
         * The lower level of the highpass filter which is attached to the envelope.
         * This value should be between [0, 7000]
         * @min 0
         * @max 7000
         */
        get resonance() {
            return this._filterFreqScaler.min;
        }
        set resonance(val) {
            this._filterFreqScaler.min = this.toFrequency(val);
            this.octaves = this._octaves;
        }
        /**
         * The number of octaves above the "resonance" frequency
         * that the filter ramps during the attack/decay envelope
         * @min 0
         * @max 8
         */
        get octaves() {
            return this._octaves;
        }
        set octaves(val) {
            this._octaves = val;
            this._filterFreqScaler.max = this._filterFreqScaler.min * Math.pow(2, val);
        }
        dispose() {
            super.dispose();
            this._oscillators.forEach(osc => osc.dispose());
            this._freqMultipliers.forEach(freqMult => freqMult.dispose());
            this.frequency.dispose();
            this.detune.dispose();
            this._filterFreqScaler.dispose();
            this._amplitude.dispose();
            this.envelope.dispose();
            this._highpass.dispose();
            return this;
        }
    }

    /**
     * MembraneSynth makes kick and tom sounds using a single oscillator
     * with an amplitude envelope and frequency ramp. A Tone.OmniOscillator
     * is routed through a Tone.AmplitudeEnvelope to the output. The drum
     * quality of the sound comes from the frequency envelope applied
     * during MembraneSynth.triggerAttack(note). The frequency envelope
     * starts at <code>note * .octaves</code> and ramps to <code>note</code>
     * over the duration of <code>.pitchDecay</code>.
     * @example
     * const synth = new Tone.MembraneSynth().toDestination();
     * synth.triggerAttackRelease("C2", "8n");
     * @category Instrument
     */
    class MembraneSynth extends Synth {
        constructor() {
            super(optionsFromArguments(MembraneSynth.getDefaults(), arguments));
            this.name = "MembraneSynth";
            /**
             * Portamento is ignored in this synth. use pitch decay instead.
             */
            this.portamento = 0;
            const options = optionsFromArguments(MembraneSynth.getDefaults(), arguments);
            this.pitchDecay = options.pitchDecay;
            this.octaves = options.octaves;
            readOnly(this, ["oscillator", "envelope"]);
        }
        static getDefaults() {
            return deepMerge(Monophonic.getDefaults(), Synth.getDefaults(), {
                envelope: {
                    attack: 0.001,
                    attackCurve: "exponential",
                    decay: 0.4,
                    release: 1.4,
                    sustain: 0.01,
                },
                octaves: 10,
                oscillator: {
                    type: "sine",
                },
                pitchDecay: 0.05,
            });
        }
        setNote(note, time) {
            const seconds = this.toSeconds(time);
            const hertz = this.toFrequency(note instanceof FrequencyClass ? note.toFrequency() : note);
            const maxNote = hertz * this.octaves;
            this.oscillator.frequency.setValueAtTime(maxNote, seconds);
            this.oscillator.frequency.exponentialRampToValueAtTime(hertz, seconds + this.toSeconds(this.pitchDecay));
            return this;
        }
        dispose() {
            super.dispose();
            return this;
        }
    }
    __decorate([
        range(0)
    ], MembraneSynth.prototype, "octaves", void 0);
    __decorate([
        timeRange(0)
    ], MembraneSynth.prototype, "pitchDecay", void 0);

    /**
     * Tone.NoiseSynth is composed of [[Noise]] through an [[AmplitudeEnvelope]].
     * ```
     * +-------+   +-------------------+
     * | Noise +>--> AmplitudeEnvelope +>--> Output
     * +-------+   +-------------------+
     * ```
     * @example
     * const noiseSynth = new Tone.NoiseSynth().toDestination();
     * noiseSynth.triggerAttackRelease("8n", 0.05);
     * @category Instrument
     */
    class NoiseSynth extends Instrument {
        constructor() {
            super(optionsFromArguments(NoiseSynth.getDefaults(), arguments));
            this.name = "NoiseSynth";
            const options = optionsFromArguments(NoiseSynth.getDefaults(), arguments);
            this.noise = new Noise(Object.assign({
                context: this.context,
            }, options.noise));
            this.envelope = new AmplitudeEnvelope(Object.assign({
                context: this.context,
            }, options.envelope));
            // connect the noise to the output
            this.noise.chain(this.envelope, this.output);
        }
        static getDefaults() {
            return Object.assign(Instrument.getDefaults(), {
                envelope: Object.assign(omitFromObject(Envelope.getDefaults(), Object.keys(ToneAudioNode.getDefaults())), {
                    decay: 0.1,
                    sustain: 0.0,
                }),
                noise: Object.assign(omitFromObject(Noise.getDefaults(), Object.keys(Source.getDefaults())), {
                    type: "white",
                }),
            });
        }
        /**
         * Start the attack portion of the envelopes. Unlike other
         * instruments, Tone.NoiseSynth doesn't have a note.
         * @example
         * const noiseSynth = new Tone.NoiseSynth().toDestination();
         * noiseSynth.triggerAttack();
         */
        triggerAttack(time, velocity = 1) {
            time = this.toSeconds(time);
            // the envelopes
            this.envelope.triggerAttack(time, velocity);
            // start the noise
            this.noise.start(time);
            if (this.envelope.sustain === 0) {
                this.noise.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));
            }
            return this;
        }
        /**
         * Start the release portion of the envelopes.
         */
        triggerRelease(time) {
            time = this.toSeconds(time);
            this.envelope.triggerRelease(time);
            this.noise.stop(time + this.toSeconds(this.envelope.release));
            return this;
        }
        sync() {
            if (this._syncState()) {
                this._syncMethod("triggerAttack", 0);
                this._syncMethod("triggerRelease", 0);
            }
            return this;
        }
        triggerAttackRelease(duration, time, velocity = 1) {
            time = this.toSeconds(time);
            duration = this.toSeconds(duration);
            this.triggerAttack(time, velocity);
            this.triggerRelease(time + duration);
            return this;
        }
        dispose() {
            super.dispose();
            this.noise.dispose();
            this.envelope.dispose();
            return this;
        }
    }

    /**
     * All of the classes or functions which are loaded into the AudioWorkletGlobalScope
     */
    const workletContext = new Set();
    /**
     * Add a class to the AudioWorkletGlobalScope
     */
    function addToWorklet(classOrFunction) {
        workletContext.add(classOrFunction);
    }
    /**
     * Register a processor in the AudioWorkletGlobalScope with the given name
     */
    function registerProcessor(name, classDesc) {
        const processor = /* javascript */ `registerProcessor("${name}", ${classDesc})`;
        workletContext.add(processor);
    }
    /**
     * Get all of the modules which have been registered to the AudioWorkletGlobalScope
     */
    function getWorkletGlobalScope() {
        return Array.from(workletContext).join("\n");
    }

    class ToneAudioWorklet extends ToneAudioNode {
        constructor(options) {
            super(options);
            this.name = "ToneAudioWorklet";
            /**
             * The constructor options for the node
             */
            this.workletOptions = {};
            /**
             * Callback which is invoked when there is an error in the processing
             */
            this.onprocessorerror = noOp;
            const blobUrl = URL.createObjectURL(new Blob([getWorkletGlobalScope()], { type: "text/javascript" }));
            const name = this._audioWorkletName();
            this._dummyGain = this.context.createGain();
            this._dummyParam = this._dummyGain.gain;
            // Register the processor
            this.context.addAudioWorkletModule(blobUrl, name).then(() => {
                // create the worklet when it's read
                if (!this.disposed) {
                    this._worklet = this.context.createAudioWorkletNode(name, this.workletOptions);
                    this._worklet.onprocessorerror = this.onprocessorerror.bind(this);
                    this.onReady(this._worklet);
                }
            });
        }
        dispose() {
            super.dispose();
            this._dummyGain.disconnect();
            if (this._worklet) {
                this._worklet.port.postMessage("dispose");
                this._worklet.disconnect();
            }
            return this;
        }
    }

    const toneAudioWorkletProcessor = /* javascript */ `
	/**
	 * The base AudioWorkletProcessor for use in Tone.js. Works with the [[ToneAudioWorklet]]. 
	 */
	class ToneAudioWorkletProcessor extends AudioWorkletProcessor {

		constructor(options) {
			
			super(options);
			/**
			 * If the processor was disposed or not. Keep alive until it's disposed.
			 */
			this.disposed = false;
		   	/** 
			 * The number of samples in the processing block
			 */
			this.blockSize = 128;
			/**
			 * the sample rate
			 */
			this.sampleRate = sampleRate;

			this.port.onmessage = (event) => {
				// when it receives a dispose 
				if (event.data === "dispose") {
					this.disposed = true;
				}
			};
		}
	}
`;
    addToWorklet(toneAudioWorkletProcessor);

    const singleIOProcess = /* javascript */ `
	/**
	 * Abstract class for a single input/output processor. 
	 * has a 'generate' function which processes one sample at a time
	 */
	class SingleIOProcessor extends ToneAudioWorkletProcessor {

		constructor(options) {
			super(Object.assign(options, {
				numberOfInputs: 1,
				numberOfOutputs: 1
			}));
			/**
			 * Holds the name of the parameter and a single value of that
			 * parameter at the current sample
			 * @type { [name: string]: number }
			 */
			this.params = {}
		}

		/**
		 * Generate an output sample from the input sample and parameters
		 * @abstract
		 * @param input number
		 * @param channel number
		 * @param parameters { [name: string]: number }
		 * @returns number
		 */
		generate(){}

		/**
		 * Update the private params object with the 
		 * values of the parameters at the given index
		 * @param parameters { [name: string]: Float32Array },
		 * @param index number
		 */
		updateParams(parameters, index) {
			for (const paramName in parameters) {
				const param = parameters[paramName];
				if (param.length > 1) {
					this.params[paramName] = parameters[paramName][index];
				} else {
					this.params[paramName] = parameters[paramName][0];
				}
			}
		}

		/**
		 * Process a single frame of the audio
		 * @param inputs Float32Array[][]
		 * @param outputs Float32Array[][]
		 */
		process(inputs, outputs, parameters) {
			const input = inputs[0];
			const output = outputs[0];
			// get the parameter values
			const channelCount = Math.max(input && input.length || 0, output.length);
			for (let sample = 0; sample < this.blockSize; sample++) {
				this.updateParams(parameters, sample);
				for (let channel = 0; channel < channelCount; channel++) {
					const inputSample = input && input.length ? input[channel][sample] : 0;
					output[channel][sample] = this.generate(inputSample, channel, this.params);
				}
			}
			return !this.disposed;
		}
	};
`;
    addToWorklet(singleIOProcess);

    const delayLine = /* javascript */ `
	/**
	 * A multichannel buffer for use within an AudioWorkletProcessor as a delay line
	 */
	class DelayLine {
		
		constructor(size, channels) {
			this.buffer = [];
			this.writeHead = []
			this.size = size;

			// create the empty channels
			for (let i = 0; i < channels; i++) {
				this.buffer[i] = new Float32Array(this.size);
				this.writeHead[i] = 0;
			}
		}

		/**
		 * Push a value onto the end
		 * @param channel number
		 * @param value number
		 */
		push(channel, value) {
			this.writeHead[channel] += 1;
			if (this.writeHead[channel] > this.size) {
				this.writeHead[channel] = 0;
			}
			this.buffer[channel][this.writeHead[channel]] = value;
		}

		/**
		 * Get the recorded value of the channel given the delay
		 * @param channel number
		 * @param delay number delay samples
		 */
		get(channel, delay) {
			let readHead = this.writeHead[channel] - Math.floor(delay);
			if (readHead < 0) {
				readHead += this.size;
			}
			return this.buffer[channel][readHead];
		}
	}
`;
    addToWorklet(delayLine);

    const workletName = "feedback-comb-filter";
    const feedbackCombFilter = /* javascript */ `
	class FeedbackCombFilterWorklet extends SingleIOProcessor {

		constructor(options) {
			super(options);
			this.delayLine = new DelayLine(this.sampleRate, options.channelCount || 2);
		}

		static get parameterDescriptors() {
			return [{
				name: "delayTime",
				defaultValue: 0.1,
				minValue: 0,
				maxValue: 1,
				automationRate: "k-rate"
			}, {
				name: "feedback",
				defaultValue: 0.5,
				minValue: 0,
				maxValue: 0.9999,
				automationRate: "k-rate"
			}];
		}

		generate(input, channel, parameters) {
			const delayedSample = this.delayLine.get(channel, parameters.delayTime * this.sampleRate);
			this.delayLine.push(channel, input + delayedSample * parameters.feedback);
			return delayedSample;
		}
	}
`;
    registerProcessor(workletName, feedbackCombFilter);

    /**
     * Comb filters are basic building blocks for physical modeling. Read more
     * about comb filters on [CCRMA's website](https://ccrma.stanford.edu/~jos/pasp/Feedback_Comb_Filters.html).
     *
     * This comb filter is implemented with the AudioWorkletNode which allows it to have feedback delays less than the
     * Web Audio processing block of 128 samples. There is a polyfill for browsers that don't yet support the
     * AudioWorkletNode, but it will add some latency and have slower performance than the AudioWorkletNode.
     * @category Component
     */
    class FeedbackCombFilter extends ToneAudioWorklet {
        constructor() {
            super(optionsFromArguments(FeedbackCombFilter.getDefaults(), arguments, ["delayTime", "resonance"]));
            this.name = "FeedbackCombFilter";
            const options = optionsFromArguments(FeedbackCombFilter.getDefaults(), arguments, ["delayTime", "resonance"]);
            this.input = new Gain({ context: this.context });
            this.output = new Gain({ context: this.context });
            this.delayTime = new Param({
                context: this.context,
                value: options.delayTime,
                units: "time",
                minValue: 0,
                maxValue: 1,
                param: this._dummyParam,
                swappable: true,
            });
            this.resonance = new Param({
                context: this.context,
                value: options.resonance,
                units: "normalRange",
                param: this._dummyParam,
                swappable: true,
            });
            readOnly(this, ["resonance", "delayTime"]);
        }
        _audioWorkletName() {
            return workletName;
        }
        /**
         * The default parameters
         */
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                delayTime: 0.1,
                resonance: 0.5,
            });
        }
        onReady(node) {
            connectSeries(this.input, node, this.output);
            const delayTime = node.parameters.get("delayTime");
            this.delayTime.setParam(delayTime);
            const feedback = node.parameters.get("feedback");
            this.resonance.setParam(feedback);
        }
        dispose() {
            super.dispose();
            this.input.dispose();
            this.output.dispose();
            this.delayTime.dispose();
            this.resonance.dispose();
            return this;
        }
    }

    /**
     * A one pole filter with 6db-per-octave rolloff. Either "highpass" or "lowpass".
     * Note that changing the type or frequency may result in a discontinuity which
     * can sound like a click or pop.
     * References:
     * * http://www.earlevel.com/main/2012/12/15/a-one-pole-filter/
     * * http://www.dspguide.com/ch19/2.htm
     * * https://github.com/vitaliy-bobrov/js-rocks/blob/master/src/app/audio/effects/one-pole-filters.ts
     * @category Component
     */
    class OnePoleFilter extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(OnePoleFilter.getDefaults(), arguments, ["frequency", "type"]));
            this.name = "OnePoleFilter";
            const options = optionsFromArguments(OnePoleFilter.getDefaults(), arguments, ["frequency", "type"]);
            this._frequency = options.frequency;
            this._type = options.type;
            this.input = new Gain({ context: this.context });
            this.output = new Gain({ context: this.context });
            this._createFilter();
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                frequency: 880,
                type: "lowpass"
            });
        }
        /**
         * Create a filter and dispose the old one
         */
        _createFilter() {
            const oldFilter = this._filter;
            const freq = this.toFrequency(this._frequency);
            const t = 1 / (2 * Math.PI * freq);
            if (this._type === "lowpass") {
                const a0 = 1 / (t * this.context.sampleRate);
                const b1 = a0 - 1;
                this._filter = this.context.createIIRFilter([a0, 0], [1, b1]);
            }
            else {
                const b1 = 1 / (t * this.context.sampleRate) - 1;
                this._filter = this.context.createIIRFilter([1, -1], [1, b1]);
            }
            this.input.chain(this._filter, this.output);
            if (oldFilter) {
                // dispose it on the next block
                this.context.setTimeout(() => {
                    if (!this.disposed) {
                        this.input.disconnect(oldFilter);
                        oldFilter.disconnect();
                    }
                }, this.blockTime);
            }
        }
        /**
         * The frequency value.
         */
        get frequency() {
            return this._frequency;
        }
        set frequency(fq) {
            this._frequency = fq;
            this._createFilter();
        }
        /**
         * The OnePole Filter type, either "highpass" or "lowpass"
         */
        get type() {
            return this._type;
        }
        set type(t) {
            this._type = t;
            this._createFilter();
        }
        /**
         * Get the frequency response curve. This curve represents how the filter
         * responses to frequencies between 20hz-20khz.
         * @param  len The number of values to return
         * @return The frequency response curve between 20-20kHz
         */
        getFrequencyResponse(len = 128) {
            const freqValues = new Float32Array(len);
            for (let i = 0; i < len; i++) {
                const norm = Math.pow(i / len, 2);
                const freq = norm * (20000 - 20) + 20;
                freqValues[i] = freq;
            }
            const magValues = new Float32Array(len);
            const phaseValues = new Float32Array(len);
            this._filter.getFrequencyResponse(freqValues, magValues, phaseValues);
            return magValues;
        }
        dispose() {
            super.dispose();
            this.input.dispose();
            this.output.dispose();
            this._filter.disconnect();
            return this;
        }
    }

    /**
     * A lowpass feedback comb filter. It is similar to
     * [[FeedbackCombFilter]], but includes a lowpass filter.
     * @category Component
     */
    class LowpassCombFilter extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(LowpassCombFilter.getDefaults(), arguments, ["delayTime", "resonance", "dampening"]));
            this.name = "LowpassCombFilter";
            const options = optionsFromArguments(LowpassCombFilter.getDefaults(), arguments, ["delayTime", "resonance", "dampening"]);
            this._combFilter = this.output = new FeedbackCombFilter({
                context: this.context,
                delayTime: options.delayTime,
                resonance: options.resonance,
            });
            this.delayTime = this._combFilter.delayTime;
            this.resonance = this._combFilter.resonance;
            this._lowpass = this.input = new OnePoleFilter({
                context: this.context,
                frequency: options.dampening,
                type: "lowpass",
            });
            // connections
            this._lowpass.connect(this._combFilter);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                dampening: 3000,
                delayTime: 0.1,
                resonance: 0.5,
            });
        }
        /**
         * The dampening control of the feedback
         */
        get dampening() {
            return this._lowpass.frequency;
        }
        set dampening(fq) {
            this._lowpass.frequency = fq;
        }
        dispose() {
            super.dispose();
            this._combFilter.dispose();
            this._lowpass.dispose();
            return this;
        }
    }

    /**
     * Karplus-String string synthesis.
     * @example
     * const plucky = new Tone.PluckSynth().toDestination();
     * plucky.triggerAttack("C4", "+0.5");
     * plucky.triggerAttack("C3", "+1");
     * plucky.triggerAttack("C2", "+1.5");
     * plucky.triggerAttack("C1", "+2");
     * @category Instrument
     */
    class PluckSynth extends Instrument {
        constructor() {
            super(optionsFromArguments(PluckSynth.getDefaults(), arguments));
            this.name = "PluckSynth";
            const options = optionsFromArguments(PluckSynth.getDefaults(), arguments);
            this._noise = new Noise({
                context: this.context,
                type: "pink"
            });
            this.attackNoise = options.attackNoise;
            this._lfcf = new LowpassCombFilter({
                context: this.context,
                dampening: options.dampening,
                resonance: options.resonance,
            });
            this.resonance = options.resonance;
            this.release = options.release;
            this._noise.connect(this._lfcf);
            this._lfcf.connect(this.output);
        }
        static getDefaults() {
            return deepMerge(Instrument.getDefaults(), {
                attackNoise: 1,
                dampening: 4000,
                resonance: 0.7,
                release: 1,
            });
        }
        /**
         * The dampening control. i.e. the lowpass filter frequency of the comb filter
         * @min 0
         * @max 7000
         */
        get dampening() {
            return this._lfcf.dampening;
        }
        set dampening(fq) {
            this._lfcf.dampening = fq;
        }
        triggerAttack(note, time) {
            const freq = this.toFrequency(note);
            time = this.toSeconds(time);
            const delayAmount = 1 / freq;
            this._lfcf.delayTime.setValueAtTime(delayAmount, time);
            this._noise.start(time);
            this._noise.stop(time + delayAmount * this.attackNoise);
            this._lfcf.resonance.cancelScheduledValues(time);
            this._lfcf.resonance.setValueAtTime(this.resonance, time);
            return this;
        }
        /**
         * Ramp down the [[resonance]] to 0 over the duration of the release time.
         */
        triggerRelease(time) {
            this._lfcf.resonance.linearRampTo(0, this.release, time);
            return this;
        }
        dispose() {
            super.dispose();
            this._noise.dispose();
            this._lfcf.dispose();
            return this;
        }
    }

    /**
     * PolySynth handles voice creation and allocation for any
     * instruments passed in as the second paramter. PolySynth is
     * not a synthesizer by itself, it merely manages voices of
     * one of the other types of synths, allowing any of the
     * monophonic synthesizers to be polyphonic.
     *
     * @example
     * const synth = new Tone.PolySynth().toDestination();
     * // set the attributes across all the voices using 'set'
     * synth.set({ detune: -1200 });
     * // play a chord
     * synth.triggerAttackRelease(["C4", "E4", "A4"], 1);
     * @category Instrument
     */
    class PolySynth extends Instrument {
        constructor() {
            super(optionsFromArguments(PolySynth.getDefaults(), arguments, ["voice", "options"]));
            this.name = "PolySynth";
            /**
             * The voices which are not currently in use
             */
            this._availableVoices = [];
            /**
             * The currently active voices
             */
            this._activeVoices = [];
            /**
             * All of the allocated voices for this synth.
             */
            this._voices = [];
            /**
             * The GC timeout. Held so that it could be cancelled when the node is disposed.
             */
            this._gcTimeout = -1;
            /**
             * A moving average of the number of active voices
             */
            this._averageActiveVoices = 0;
            const options = optionsFromArguments(PolySynth.getDefaults(), arguments, ["voice", "options"]);
            // check against the old API (pre 14.3.0)
            assert(!isNumber(options.voice), "DEPRECATED: The polyphony count is no longer the first argument.");
            const defaults = options.voice.getDefaults();
            this.options = Object.assign(defaults, options.options);
            this.voice = options.voice;
            this.maxPolyphony = options.maxPolyphony;
            // create the first voice
            this._dummyVoice = this._getNextAvailableVoice();
            // remove it from the voices list
            const index = this._voices.indexOf(this._dummyVoice);
            this._voices.splice(index, 1);
            // kick off the GC interval
            this._gcTimeout = this.context.setInterval(this._collectGarbage.bind(this), 1);
        }
        static getDefaults() {
            return Object.assign(Instrument.getDefaults(), {
                maxPolyphony: 32,
                options: {},
                voice: Synth,
            });
        }
        /**
         * The number of active voices.
         */
        get activeVoices() {
            return this._activeVoices.length;
        }
        /**
         * Invoked when the source is done making sound, so that it can be
         * readded to the pool of available voices
         */
        _makeVoiceAvailable(voice) {
            this._availableVoices.push(voice);
            // remove the midi note from 'active voices'
            const activeVoiceIndex = this._activeVoices.findIndex((e) => e.voice === voice);
            this._activeVoices.splice(activeVoiceIndex, 1);
        }
        /**
         * Get an available voice from the pool of available voices.
         * If one is not available and the maxPolyphony limit is reached,
         * steal a voice, otherwise return null.
         */
        _getNextAvailableVoice() {
            // if there are available voices, return the first one
            if (this._availableVoices.length) {
                return this._availableVoices.shift();
            }
            else if (this._voices.length < this.maxPolyphony) {
                // otherwise if there is still more maxPolyphony, make a new voice
                const voice = new this.voice(Object.assign(this.options, {
                    context: this.context,
                    onsilence: this._makeVoiceAvailable.bind(this),
                }));
                voice.connect(this.output);
                this._voices.push(voice);
                return voice;
            }
            else {
                warn("Max polyphony exceeded. Note dropped.");
            }
        }
        /**
         * Occasionally check if there are any allocated voices which can be cleaned up.
         */
        _collectGarbage() {
            this._averageActiveVoices = Math.max(this._averageActiveVoices * 0.95, this.activeVoices);
            if (this._availableVoices.length && this._voices.length > Math.ceil(this._averageActiveVoices + 1)) {
                // take off an available note
                const firstAvail = this._availableVoices.shift();
                const index = this._voices.indexOf(firstAvail);
                this._voices.splice(index, 1);
                if (!this.context.isOffline) {
                    firstAvail.dispose();
                }
            }
        }
        /**
         * Internal method which triggers the attack
         */
        _triggerAttack(notes, time, velocity) {
            notes.forEach(note => {
                const midiNote = new MidiClass(this.context, note).toMidi();
                const voice = this._getNextAvailableVoice();
                if (voice) {
                    voice.triggerAttack(note, time, velocity);
                    this._activeVoices.push({
                        midi: midiNote, voice, released: false,
                    });
                    this.log("triggerAttack", note, time);
                }
            });
        }
        /**
         * Internal method which triggers the release
         */
        _triggerRelease(notes, time) {
            notes.forEach(note => {
                const midiNote = new MidiClass(this.context, note).toMidi();
                const event = this._activeVoices.find(({ midi, released }) => midi === midiNote && !released);
                if (event) {
                    // trigger release on that note
                    event.voice.triggerRelease(time);
                    // mark it as released
                    event.released = true;
                    this.log("triggerRelease", note, time);
                }
            });
        }
        /**
         * Schedule the attack/release events. If the time is in the future, then it should set a timeout
         * to wait for just-in-time scheduling
         */
        _scheduleEvent(type, notes, time, velocity) {
            assert(!this.disposed, "Synth was already disposed");
            // if the notes are greater than this amount of time in the future, they should be scheduled with setTimeout
            if (time <= this.now()) {
                // do it immediately
                if (type === "attack") {
                    this._triggerAttack(notes, time, velocity);
                }
                else {
                    this._triggerRelease(notes, time);
                }
            }
            else {
                // schedule it to start in the future
                this.context.setTimeout(() => {
                    this._scheduleEvent(type, notes, time, velocity);
                }, time - this.now());
            }
        }
        /**
         * Trigger the attack portion of the note
         * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.
         * @param  time  The start time of the note.
         * @param velocity The velocity of the note.
         * @example
         * const synth = new Tone.PolySynth(Tone.FMSynth).toDestination();
         * // trigger a chord immediately with a velocity of 0.2
         * synth.triggerAttack(["Ab3", "C4", "F5"], Tone.now(), 0.2);
         */
        triggerAttack(notes, time, velocity) {
            if (!Array.isArray(notes)) {
                notes = [notes];
            }
            const computedTime = this.toSeconds(time);
            this._scheduleEvent("attack", notes, computedTime, velocity);
            return this;
        }
        /**
         * Trigger the release of the note. Unlike monophonic instruments,
         * a note (or array of notes) needs to be passed in as the first argument.
         * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.
         * @param  time  When the release will be triggered.
         * @example
         * @example
         * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();
         * poly.triggerAttack(["Ab3", "C4", "F5"]);
         * // trigger the release of the given notes.
         * poly.triggerRelease(["Ab3", "C4"], "+1");
         * poly.triggerRelease("F5", "+3");
         */
        triggerRelease(notes, time) {
            if (!Array.isArray(notes)) {
                notes = [notes];
            }
            const computedTime = this.toSeconds(time);
            this._scheduleEvent("release", notes, computedTime);
            return this;
        }
        /**
         * Trigger the attack and release after the specified duration
         * @param  notes The notes to play. Accepts a single  Frequency or an array of frequencies.
         * @param  duration the duration of the note
         * @param  time  if no time is given, defaults to now
         * @param  velocity the velocity of the attack (0-1)
         * @example
         * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();
         * // can pass in an array of durations as well
         * poly.triggerAttackRelease(["Eb3", "G4", "Bb4", "D5"], [4, 3, 2, 1]);
         */
        triggerAttackRelease(notes, duration, time, velocity) {
            const computedTime = this.toSeconds(time);
            this.triggerAttack(notes, computedTime, velocity);
            if (isArray(duration)) {
                assert(isArray(notes), "If the duration is an array, the notes must also be an array");
                notes = notes;
                for (let i = 0; i < notes.length; i++) {
                    const d = duration[Math.min(i, duration.length - 1)];
                    const durationSeconds = this.toSeconds(d);
                    assert(durationSeconds > 0, "The duration must be greater than 0");
                    this.triggerRelease(notes[i], computedTime + durationSeconds);
                }
            }
            else {
                const durationSeconds = this.toSeconds(duration);
                assert(durationSeconds > 0, "The duration must be greater than 0");
                this.triggerRelease(notes, computedTime + durationSeconds);
            }
            return this;
        }
        sync() {
            if (this._syncState()) {
                this._syncMethod("triggerAttack", 1);
                this._syncMethod("triggerRelease", 1);
            }
            return this;
        }
        /**
         * Set a member/attribute of the voices
         * @example
         * const poly = new Tone.PolySynth().toDestination();
         * // set all of the voices using an options object for the synth type
         * poly.set({
         * 	envelope: {
         * 		attack: 0.25
         * 	}
         * });
         * poly.triggerAttackRelease("Bb3", 0.2);
         */
        set(options) {
            // remove options which are controlled by the PolySynth
            const sanitizedOptions = omitFromObject(options, ["onsilence", "context"]);
            // store all of the options
            this.options = deepMerge(this.options, sanitizedOptions);
            this._voices.forEach(voice => voice.set(sanitizedOptions));
            this._dummyVoice.set(sanitizedOptions);
            return this;
        }
        get() {
            return this._dummyVoice.get();
        }
        /**
         * Trigger the release portion of all the currently active voices immediately.
         * Useful for silencing the synth.
         */
        releaseAll(time) {
            const computedTime = this.toSeconds(time);
            this._activeVoices.forEach(({ voice }) => {
                voice.triggerRelease(computedTime);
            });
            return this;
        }
        dispose() {
            super.dispose();
            this._dummyVoice.dispose();
            this._voices.forEach(v => v.dispose());
            this._activeVoices = [];
            this._availableVoices = [];
            this.context.clearInterval(this._gcTimeout);
            return this;
        }
    }

    /**
     * Pass in an object which maps the note's pitch or midi value to the url,
     * then you can trigger the attack and release of that note like other instruments.
     * By automatically repitching the samples, it is possible to play pitches which
     * were not explicitly included which can save loading time.
     *
     * For sample or buffer playback where repitching is not necessary,
     * use [[Player]].
     * @example
     * const sampler = new Tone.Sampler({
     * 	urls: {
     * 		A1: "A1.mp3",
     * 		A2: "A2.mp3",
     * 	},
     * 	baseUrl: "https://tonejs.github.io/audio/casio/",
     * 	onload: () => {
     * 		sampler.triggerAttackRelease(["C1", "E1", "G1", "B1"], 0.5);
     * 	}
     * }).toDestination();
     * @category Instrument
     */
    class Sampler extends Instrument {
        constructor() {
            super(optionsFromArguments(Sampler.getDefaults(), arguments, ["urls", "onload", "baseUrl"], "urls"));
            this.name = "Sampler";
            /**
             * The object of all currently playing BufferSources
             */
            this._activeSources = new Map();
            const options = optionsFromArguments(Sampler.getDefaults(), arguments, ["urls", "onload", "baseUrl"], "urls");
            const urlMap = {};
            Object.keys(options.urls).forEach((note) => {
                const noteNumber = parseInt(note, 10);
                assert(isNote(note)
                    || (isNumber(noteNumber) && isFinite(noteNumber)), `url key is neither a note or midi pitch: ${note}`);
                if (isNote(note)) {
                    // convert the note name to MIDI
                    const mid = new FrequencyClass(this.context, note).toMidi();
                    urlMap[mid] = options.urls[note];
                }
                else if (isNumber(noteNumber) && isFinite(noteNumber)) {
                    // otherwise if it's numbers assume it's midi
                    urlMap[noteNumber] = options.urls[noteNumber];
                }
            });
            this._buffers = new ToneAudioBuffers({
                urls: urlMap,
                onload: options.onload,
                baseUrl: options.baseUrl,
                onerror: options.onerror,
            });
            this.attack = options.attack;
            this.release = options.release;
            this.curve = options.curve;
            // invoke the callback if it's already loaded
            if (this._buffers.loaded) {
                // invoke onload deferred
                Promise.resolve().then(options.onload);
            }
        }
        static getDefaults() {
            return Object.assign(Instrument.getDefaults(), {
                attack: 0,
                baseUrl: "",
                curve: "exponential",
                onload: noOp,
                onerror: noOp,
                release: 0.1,
                urls: {},
            });
        }
        /**
         * Returns the difference in steps between the given midi note at the closets sample.
         */
        _findClosest(midi) {
            // searches within 8 octaves of the given midi note
            const MAX_INTERVAL = 96;
            let interval = 0;
            while (interval < MAX_INTERVAL) {
                // check above and below
                if (this._buffers.has(midi + interval)) {
                    return -interval;
                }
                else if (this._buffers.has(midi - interval)) {
                    return interval;
                }
                interval++;
            }
            throw new Error(`No available buffers for note: ${midi}`);
        }
        /**
         * @param  notes	The note to play, or an array of notes.
         * @param  time     When to play the note
         * @param  velocity The velocity to play the sample back.
         */
        triggerAttack(notes, time, velocity = 1) {
            this.log("triggerAttack", notes, time, velocity);
            if (!Array.isArray(notes)) {
                notes = [notes];
            }
            notes.forEach(note => {
                const midiFloat = ftomf(new FrequencyClass(this.context, note).toFrequency());
                const midi = Math.round(midiFloat);
                const remainder = midiFloat - midi;
                // find the closest note pitch
                const difference = this._findClosest(midi);
                const closestNote = midi - difference;
                const buffer = this._buffers.get(closestNote);
                const playbackRate = intervalToFrequencyRatio(difference + remainder);
                // play that note
                const source = new ToneBufferSource({
                    url: buffer,
                    context: this.context,
                    curve: this.curve,
                    fadeIn: this.attack,
                    fadeOut: this.release,
                    playbackRate,
                }).connect(this.output);
                source.start(time, 0, buffer.duration / playbackRate, velocity);
                // add it to the active sources
                if (!isArray(this._activeSources.get(midi))) {
                    this._activeSources.set(midi, []);
                }
                this._activeSources.get(midi).push(source);
                // remove it when it's done
                source.onended = () => {
                    if (this._activeSources && this._activeSources.has(midi)) {
                        const sources = this._activeSources.get(midi);
                        const index = sources.indexOf(source);
                        if (index !== -1) {
                            sources.splice(index, 1);
                        }
                    }
                };
            });
            return this;
        }
        /**
         * @param  notes	The note to release, or an array of notes.
         * @param  time     	When to release the note.
         */
        triggerRelease(notes, time) {
            this.log("triggerRelease", notes, time);
            if (!Array.isArray(notes)) {
                notes = [notes];
            }
            notes.forEach(note => {
                const midi = new FrequencyClass(this.context, note).toMidi();
                // find the note
                if (this._activeSources.has(midi) && this._activeSources.get(midi).length) {
                    const sources = this._activeSources.get(midi);
                    time = this.toSeconds(time);
                    sources.forEach(source => {
                        source.stop(time);
                    });
                    this._activeSources.set(midi, []);
                }
            });
            return this;
        }
        /**
         * Release all currently active notes.
         * @param  time     	When to release the notes.
         */
        releaseAll(time) {
            const computedTime = this.toSeconds(time);
            this._activeSources.forEach(sources => {
                while (sources.length) {
                    const source = sources.shift();
                    source.stop(computedTime);
                }
            });
            return this;
        }
        sync() {
            if (this._syncState()) {
                this._syncMethod("triggerAttack", 1);
                this._syncMethod("triggerRelease", 1);
            }
            return this;
        }
        /**
         * Invoke the attack phase, then after the duration, invoke the release.
         * @param  notes	The note to play and release, or an array of notes.
         * @param  duration The time the note should be held
         * @param  time     When to start the attack
         * @param  velocity The velocity of the attack
         */
        triggerAttackRelease(notes, duration, time, velocity = 1) {
            const computedTime = this.toSeconds(time);
            this.triggerAttack(notes, computedTime, velocity);
            if (isArray(duration)) {
                assert(isArray(notes), "notes must be an array when duration is array");
                notes.forEach((note, index) => {
                    const d = duration[Math.min(index, duration.length - 1)];
                    this.triggerRelease(note, computedTime + this.toSeconds(d));
                });
            }
            else {
                this.triggerRelease(notes, computedTime + this.toSeconds(duration));
            }
            return this;
        }
        /**
         * Add a note to the sampler.
         * @param  note      The buffer's pitch.
         * @param  url  Either the url of the buffer, or a buffer which will be added with the given name.
         * @param  callback  The callback to invoke when the url is loaded.
         */
        add(note, url, callback) {
            assert(isNote(note) || isFinite(note), `note must be a pitch or midi: ${note}`);
            if (isNote(note)) {
                // convert the note name to MIDI
                const mid = new FrequencyClass(this.context, note).toMidi();
                this._buffers.add(mid, url, callback);
            }
            else {
                // otherwise if it's numbers assume it's midi
                this._buffers.add(note, url, callback);
            }
            return this;
        }
        /**
         * If the buffers are loaded or not
         */
        get loaded() {
            return this._buffers.loaded;
        }
        /**
         * Clean up
         */
        dispose() {
            super.dispose();
            this._buffers.dispose();
            this._activeSources.forEach(sources => {
                sources.forEach(source => source.dispose());
            });
            this._activeSources.clear();
            return this;
        }
    }
    __decorate([
        timeRange(0)
    ], Sampler.prototype, "attack", void 0);
    __decorate([
        timeRange(0)
    ], Sampler.prototype, "release", void 0);

    /**
     * ToneEvent abstracts away this.context.transport.schedule and provides a schedulable
     * callback for a single or repeatable events along the timeline.
     *
     * @example
     * const synth = new Tone.PolySynth().toDestination();
     * const chordEvent = new Tone.ToneEvent(((time, chord) => {
     * 	// the chord as well as the exact time of the event
     * 	// are passed in as arguments to the callback function
     * 	synth.triggerAttackRelease(chord, 0.5, time);
     * }), ["D4", "E4", "F4"]);
     * // start the chord at the beginning of the transport timeline
     * chordEvent.start();
     * // loop it every measure for 8 measures
     * chordEvent.loop = 8;
     * chordEvent.loopEnd = "1m";
     * @category Event
     */
    class ToneEvent extends ToneWithContext {
        constructor() {
            super(optionsFromArguments(ToneEvent.getDefaults(), arguments, ["callback", "value"]));
            this.name = "ToneEvent";
            /**
             * Tracks the scheduled events
             */
            this._state = new StateTimeline("stopped");
            /**
             * A delay time from when the event is scheduled to start
             */
            this._startOffset = 0;
            const options = optionsFromArguments(ToneEvent.getDefaults(), arguments, ["callback", "value"]);
            this._loop = options.loop;
            this.callback = options.callback;
            this.value = options.value;
            this._loopStart = this.toTicks(options.loopStart);
            this._loopEnd = this.toTicks(options.loopEnd);
            this._playbackRate = options.playbackRate;
            this._probability = options.probability;
            this._humanize = options.humanize;
            this.mute = options.mute;
            this._playbackRate = options.playbackRate;
            this._state.increasing = true;
            // schedule the events for the first time
            this._rescheduleEvents();
        }
        static getDefaults() {
            return Object.assign(ToneWithContext.getDefaults(), {
                callback: noOp,
                humanize: false,
                loop: false,
                loopEnd: "1m",
                loopStart: 0,
                mute: false,
                playbackRate: 1,
                probability: 1,
                value: null,
            });
        }
        /**
         * Reschedule all of the events along the timeline
         * with the updated values.
         * @param after Only reschedules events after the given time.
         */
        _rescheduleEvents(after = -1) {
            // if no argument is given, schedules all of the events
            this._state.forEachFrom(after, event => {
                let duration;
                if (event.state === "started") {
                    if (event.id !== -1) {
                        this.context.transport.clear(event.id);
                    }
                    const startTick = event.time + Math.round(this.startOffset / this._playbackRate);
                    if (this._loop === true || isNumber(this._loop) && this._loop > 1) {
                        duration = Infinity;
                        if (isNumber(this._loop)) {
                            duration = (this._loop) * this._getLoopDuration();
                        }
                        const nextEvent = this._state.getAfter(startTick);
                        if (nextEvent !== null) {
                            duration = Math.min(duration, nextEvent.time - startTick);
                        }
                        if (duration !== Infinity) {
                            // schedule a stop since it's finite duration
                            this._state.setStateAtTime("stopped", startTick + duration + 1, { id: -1 });
                            duration = new TicksClass(this.context, duration);
                        }
                        const interval = new TicksClass(this.context, this._getLoopDuration());
                        event.id = this.context.transport.scheduleRepeat(this._tick.bind(this), interval, new TicksClass(this.context, startTick), duration);
                    }
                    else {
                        event.id = this.context.transport.schedule(this._tick.bind(this), new TicksClass(this.context, startTick));
                    }
                }
            });
        }
        /**
         * Returns the playback state of the note, either "started" or "stopped".
         */
        get state() {
            return this._state.getValueAtTime(this.context.transport.ticks);
        }
        /**
         * The start from the scheduled start time.
         */
        get startOffset() {
            return this._startOffset;
        }
        set startOffset(offset) {
            this._startOffset = offset;
        }
        /**
         * The probability of the notes being triggered.
         */
        get probability() {
            return this._probability;
        }
        set probability(prob) {
            this._probability = prob;
        }
        /**
         * If set to true, will apply small random variation
         * to the callback time. If the value is given as a time, it will randomize
         * by that amount.
         * @example
         * const event = new Tone.ToneEvent();
         * event.humanize = true;
         */
        get humanize() {
            return this._humanize;
        }
        set humanize(variation) {
            this._humanize = variation;
        }
        /**
         * Start the note at the given time.
         * @param  time  When the event should start.
         */
        start(time) {
            const ticks = this.toTicks(time);
            if (this._state.getValueAtTime(ticks) === "stopped") {
                this._state.add({
                    id: -1,
                    state: "started",
                    time: ticks,
                });
                this._rescheduleEvents(ticks);
            }
            return this;
        }
        /**
         * Stop the Event at the given time.
         * @param  time  When the event should stop.
         */
        stop(time) {
            this.cancel(time);
            const ticks = this.toTicks(time);
            if (this._state.getValueAtTime(ticks) === "started") {
                this._state.setStateAtTime("stopped", ticks, { id: -1 });
                const previousEvent = this._state.getBefore(ticks);
                let reschedulTime = ticks;
                if (previousEvent !== null) {
                    reschedulTime = previousEvent.time;
                }
                this._rescheduleEvents(reschedulTime);
            }
            return this;
        }
        /**
         * Cancel all scheduled events greater than or equal to the given time
         * @param  time  The time after which events will be cancel.
         */
        cancel(time) {
            time = defaultArg(time, -Infinity);
            const ticks = this.toTicks(time);
            this._state.forEachFrom(ticks, event => {
                this.context.transport.clear(event.id);
            });
            this._state.cancel(ticks);
            return this;
        }
        /**
         * The callback function invoker. Also
         * checks if the Event is done playing
         * @param  time  The time of the event in seconds
         */
        _tick(time) {
            const ticks = this.context.transport.getTicksAtTime(time);
            if (!this.mute && this._state.getValueAtTime(ticks) === "started") {
                if (this.probability < 1 && Math.random() > this.probability) {
                    return;
                }
                if (this.humanize) {
                    let variation = 0.02;
                    if (!isBoolean(this.humanize)) {
                        variation = this.toSeconds(this.humanize);
                    }
                    time += (Math.random() * 2 - 1) * variation;
                }
                this.callback(time, this.value);
            }
        }
        /**
         * Get the duration of the loop.
         */
        _getLoopDuration() {
            return Math.round((this._loopEnd - this._loopStart) / this._playbackRate);
        }
        /**
         * If the note should loop or not
         * between ToneEvent.loopStart and
         * ToneEvent.loopEnd. If set to true,
         * the event will loop indefinitely,
         * if set to a number greater than 1
         * it will play a specific number of
         * times, if set to false, 0 or 1, the
         * part will only play once.
         */
        get loop() {
            return this._loop;
        }
        set loop(loop) {
            this._loop = loop;
            this._rescheduleEvents();
        }
        /**
         * The playback rate of the note. Defaults to 1.
         * @example
         * const note = new Tone.ToneEvent();
         * note.loop = true;
         * // repeat the note twice as fast
         * note.playbackRate = 2;
         */
        get playbackRate() {
            return this._playbackRate;
        }
        set playbackRate(rate) {
            this._playbackRate = rate;
            this._rescheduleEvents();
        }
        /**
         * The loopEnd point is the time the event will loop
         * if ToneEvent.loop is true.
         */
        get loopEnd() {
            return new TicksClass(this.context, this._loopEnd).toSeconds();
        }
        set loopEnd(loopEnd) {
            this._loopEnd = this.toTicks(loopEnd);
            if (this._loop) {
                this._rescheduleEvents();
            }
        }
        /**
         * The time when the loop should start.
         */
        get loopStart() {
            return new TicksClass(this.context, this._loopStart).toSeconds();
        }
        set loopStart(loopStart) {
            this._loopStart = this.toTicks(loopStart);
            if (this._loop) {
                this._rescheduleEvents();
            }
        }
        /**
         * The current progress of the loop interval.
         * Returns 0 if the event is not started yet or
         * it is not set to loop.
         */
        get progress() {
            if (this._loop) {
                const ticks = this.context.transport.ticks;
                const lastEvent = this._state.get(ticks);
                if (lastEvent !== null && lastEvent.state === "started") {
                    const loopDuration = this._getLoopDuration();
                    const progress = (ticks - lastEvent.time) % loopDuration;
                    return progress / loopDuration;
                }
                else {
                    return 0;
                }
            }
            else {
                return 0;
            }
        }
        dispose() {
            super.dispose();
            this.cancel();
            this._state.dispose();
            return this;
        }
    }

    /**
     * Loop creates a looped callback at the
     * specified interval. The callback can be
     * started, stopped and scheduled along
     * the Transport's timeline.
     * @example
     * const loop = new Tone.Loop((time) => {
     * 	// triggered every eighth note.
     * 	console.log(time);
     * }, "8n").start(0);
     * Tone.Transport.start();
     * @category Event
     */
    class Loop extends ToneWithContext {
        constructor() {
            super(optionsFromArguments(Loop.getDefaults(), arguments, ["callback", "interval"]));
            this.name = "Loop";
            const options = optionsFromArguments(Loop.getDefaults(), arguments, ["callback", "interval"]);
            this._event = new ToneEvent({
                context: this.context,
                callback: this._tick.bind(this),
                loop: true,
                loopEnd: options.interval,
                playbackRate: options.playbackRate,
                probability: options.probability
            });
            this.callback = options.callback;
            // set the iterations
            this.iterations = options.iterations;
        }
        static getDefaults() {
            return Object.assign(ToneWithContext.getDefaults(), {
                interval: "4n",
                callback: noOp,
                playbackRate: 1,
                iterations: Infinity,
                probability: 1,
                mute: false,
                humanize: false
            });
        }
        /**
         * Start the loop at the specified time along the Transport's timeline.
         * @param  time  When to start the Loop.
         */
        start(time) {
            this._event.start(time);
            return this;
        }
        /**
         * Stop the loop at the given time.
         * @param  time  When to stop the Loop.
         */
        stop(time) {
            this._event.stop(time);
            return this;
        }
        /**
         * Cancel all scheduled events greater than or equal to the given time
         * @param  time  The time after which events will be cancel.
         */
        cancel(time) {
            this._event.cancel(time);
            return this;
        }
        /**
         * Internal function called when the notes should be called
         * @param time  The time the event occurs
         */
        _tick(time) {
            this.callback(time);
        }
        /**
         * The state of the Loop, either started or stopped.
         */
        get state() {
            return this._event.state;
        }
        /**
         * The progress of the loop as a value between 0-1. 0, when the loop is stopped or done iterating.
         */
        get progress() {
            return this._event.progress;
        }
        /**
         * The time between successive callbacks.
         * @example
         * const loop = new Tone.Loop();
         * loop.interval = "8n"; // loop every 8n
         */
        get interval() {
            return this._event.loopEnd;
        }
        set interval(interval) {
            this._event.loopEnd = interval;
        }
        /**
         * The playback rate of the loop. The normal playback rate is 1 (no change).
         * A `playbackRate` of 2 would be twice as fast.
         */
        get playbackRate() {
            return this._event.playbackRate;
        }
        set playbackRate(rate) {
            this._event.playbackRate = rate;
        }
        /**
         * Random variation +/-0.01s to the scheduled time.
         * Or give it a time value which it will randomize by.
         */
        get humanize() {
            return this._event.humanize;
        }
        set humanize(variation) {
            this._event.humanize = variation;
        }
        /**
         * The probably of the callback being invoked.
         */
        get probability() {
            return this._event.probability;
        }
        set probability(prob) {
            this._event.probability = prob;
        }
        /**
         * Muting the Loop means that no callbacks are invoked.
         */
        get mute() {
            return this._event.mute;
        }
        set mute(mute) {
            this._event.mute = mute;
        }
        /**
         * The number of iterations of the loop. The default value is `Infinity` (loop forever).
         */
        get iterations() {
            if (this._event.loop === true) {
                return Infinity;
            }
            else {
                return this._event.loop;
            }
        }
        set iterations(iters) {
            if (iters === Infinity) {
                this._event.loop = true;
            }
            else {
                this._event.loop = iters;
            }
        }
        dispose() {
            super.dispose();
            this._event.dispose();
            return this;
        }
    }

    /**
     * Part is a collection ToneEvents which can be started/stopped and looped as a single unit.
     *
     * @example
     * const synth = new Tone.Synth().toDestination();
     * const part = new Tone.Part(((time, note) => {
     * 	// the notes given as the second element in the array
     * 	// will be passed in as the second argument
     * 	synth.triggerAttackRelease(note, "8n", time);
     * }), [[0, "C2"], ["0:2", "C3"], ["0:3:2", "G2"]]);
     * Tone.Transport.start();
     * @example
     * const synth = new Tone.Synth().toDestination();
     * // use an array of objects as long as the object has a "time" attribute
     * const part = new Tone.Part(((time, value) => {
     * 	// the value is an object which contains both the note and the velocity
     * 	synth.triggerAttackRelease(value.note, "8n", time, value.velocity);
     * }), [{ time: 0, note: "C3", velocity: 0.9 },
     * 	{ time: "0:2", note: "C4", velocity: 0.5 }
     * ]).start(0);
     * Tone.Transport.start();
     * @category Event
     */
    class Part extends ToneEvent {
        constructor() {
            super(optionsFromArguments(Part.getDefaults(), arguments, ["callback", "events"]));
            this.name = "Part";
            /**
             * Tracks the scheduled events
             */
            this._state = new StateTimeline("stopped");
            /**
             * The events that belong to this part
             */
            this._events = new Set();
            const options = optionsFromArguments(Part.getDefaults(), arguments, ["callback", "events"]);
            // make sure things are assigned in the right order
            this._state.increasing = true;
            // add the events
            options.events.forEach(event => {
                if (isArray(event)) {
                    this.add(event[0], event[1]);
                }
                else {
                    this.add(event);
                }
            });
        }
        static getDefaults() {
            return Object.assign(ToneEvent.getDefaults(), {
                events: [],
            });
        }
        /**
         * Start the part at the given time.
         * @param  time    When to start the part.
         * @param  offset  The offset from the start of the part to begin playing at.
         */
        start(time, offset) {
            const ticks = this.toTicks(time);
            if (this._state.getValueAtTime(ticks) !== "started") {
                offset = defaultArg(offset, this._loop ? this._loopStart : 0);
                if (this._loop) {
                    offset = defaultArg(offset, this._loopStart);
                }
                else {
                    offset = defaultArg(offset, 0);
                }
                const computedOffset = this.toTicks(offset);
                this._state.add({
                    id: -1,
                    offset: computedOffset,
                    state: "started",
                    time: ticks,
                });
                this._forEach(event => {
                    this._startNote(event, ticks, computedOffset);
                });
            }
            return this;
        }
        /**
         * Start the event in the given event at the correct time given
         * the ticks and offset and looping.
         * @param  event
         * @param  ticks
         * @param  offset
         */
        _startNote(event, ticks, offset) {
            ticks -= offset;
            if (this._loop) {
                if (event.startOffset >= this._loopStart && event.startOffset < this._loopEnd) {
                    if (event.startOffset < offset) {
                        // start it on the next loop
                        ticks += this._getLoopDuration();
                    }
                    event.start(new TicksClass(this.context, ticks));
                }
                else if (event.startOffset < this._loopStart && event.startOffset >= offset) {
                    event.loop = false;
                    event.start(new TicksClass(this.context, ticks));
                }
            }
            else if (event.startOffset >= offset) {
                event.start(new TicksClass(this.context, ticks));
            }
        }
        get startOffset() {
            return this._startOffset;
        }
        set startOffset(offset) {
            this._startOffset = offset;
            this._forEach(event => {
                event.startOffset += this._startOffset;
            });
        }
        /**
         * Stop the part at the given time.
         * @param  time  When to stop the part.
         */
        stop(time) {
            const ticks = this.toTicks(time);
            this._state.cancel(ticks);
            this._state.setStateAtTime("stopped", ticks);
            this._forEach(event => {
                event.stop(time);
            });
            return this;
        }
        /**
         * Get/Set an Event's value at the given time.
         * If a value is passed in and no event exists at
         * the given time, one will be created with that value.
         * If two events are at the same time, the first one will
         * be returned.
         * @example
         * const part = new Tone.Part();
         * part.at("1m"); // returns the part at the first measure
         * part.at("2m", "C2"); // set the value at "2m" to C2.
         * // if an event didn't exist at that time, it will be created.
         * @param time The time of the event to get or set.
         * @param value If a value is passed in, the value of the event at the given time will be set to it.
         */
        at(time, value) {
            const timeInTicks = new TransportTimeClass(this.context, time).toTicks();
            const tickTime = new TicksClass(this.context, 1).toSeconds();
            const iterator = this._events.values();
            let result = iterator.next();
            while (!result.done) {
                const event = result.value;
                if (Math.abs(timeInTicks - event.startOffset) < tickTime) {
                    if (isDefined(value)) {
                        event.value = value;
                    }
                    return event;
                }
                result = iterator.next();
            }
            // if there was no event at that time, create one
            if (isDefined(value)) {
                this.add(time, value);
                // return the new event
                return this.at(time);
            }
            else {
                return null;
            }
        }
        add(time, value) {
            // extract the parameters
            if (time instanceof Object && Reflect.has(time, "time")) {
                value = time;
                time = value.time;
            }
            const ticks = this.toTicks(time);
            let event;
            if (value instanceof ToneEvent) {
                event = value;
                event.callback = this._tick.bind(this);
            }
            else {
                event = new ToneEvent({
                    callback: this._tick.bind(this),
                    context: this.context,
                    value,
                });
            }
            // the start offset
            event.startOffset = ticks;
            // initialize the values
            event.set({
                humanize: this.humanize,
                loop: this.loop,
                loopEnd: this.loopEnd,
                loopStart: this.loopStart,
                playbackRate: this.playbackRate,
                probability: this.probability,
            });
            this._events.add(event);
            // start the note if it should be played right now
            this._restartEvent(event);
            return this;
        }
        /**
         * Restart the given event
         */
        _restartEvent(event) {
            this._state.forEach((stateEvent) => {
                if (stateEvent.state === "started") {
                    this._startNote(event, stateEvent.time, stateEvent.offset);
                }
                else {
                    // stop the note
                    event.stop(new TicksClass(this.context, stateEvent.time));
                }
            });
        }
        remove(time, value) {
            // extract the parameters
            if (isObject(time) && time.hasOwnProperty("time")) {
                value = time;
                time = value.time;
            }
            time = this.toTicks(time);
            this._events.forEach(event => {
                if (event.startOffset === time) {
                    if (isUndef(value) || (isDefined(value) && event.value === value)) {
                        this._events.delete(event);
                        event.dispose();
                    }
                }
            });
            return this;
        }
        /**
         * Remove all of the notes from the group.
         */
        clear() {
            this._forEach(event => event.dispose());
            this._events.clear();
            return this;
        }
        /**
         * Cancel scheduled state change events: i.e. "start" and "stop".
         * @param after The time after which to cancel the scheduled events.
         */
        cancel(after) {
            this._forEach(event => event.cancel(after));
            this._state.cancel(this.toTicks(after));
            return this;
        }
        /**
         * Iterate over all of the events
         */
        _forEach(callback) {
            if (this._events) {
                this._events.forEach(event => {
                    if (event instanceof Part) {
                        event._forEach(callback);
                    }
                    else {
                        callback(event);
                    }
                });
            }
            return this;
        }
        /**
         * Set the attribute of all of the events
         * @param  attr  the attribute to set
         * @param  value      The value to set it to
         */
        _setAll(attr, value) {
            this._forEach(event => {
                event[attr] = value;
            });
        }
        /**
         * Internal tick method
         * @param  time  The time of the event in seconds
         */
        _tick(time, value) {
            if (!this.mute) {
                this.callback(time, value);
            }
        }
        /**
         * Determine if the event should be currently looping
         * given the loop boundries of this Part.
         * @param  event  The event to test
         */
        _testLoopBoundries(event) {
            if (this._loop && (event.startOffset < this._loopStart || event.startOffset >= this._loopEnd)) {
                event.cancel(0);
            }
            else if (event.state === "stopped") {
                // reschedule it if it's stopped
                this._restartEvent(event);
            }
        }
        get probability() {
            return this._probability;
        }
        set probability(prob) {
            this._probability = prob;
            this._setAll("probability", prob);
        }
        get humanize() {
            return this._humanize;
        }
        set humanize(variation) {
            this._humanize = variation;
            this._setAll("humanize", variation);
        }
        /**
         * If the part should loop or not
         * between Part.loopStart and
         * Part.loopEnd. If set to true,
         * the part will loop indefinitely,
         * if set to a number greater than 1
         * it will play a specific number of
         * times, if set to false, 0 or 1, the
         * part will only play once.
         * @example
         * const part = new Tone.Part();
         * // loop the part 8 times
         * part.loop = 8;
         */
        get loop() {
            return this._loop;
        }
        set loop(loop) {
            this._loop = loop;
            this._forEach(event => {
                event.loopStart = this.loopStart;
                event.loopEnd = this.loopEnd;
                event.loop = loop;
                this._testLoopBoundries(event);
            });
        }
        /**
         * The loopEnd point determines when it will
         * loop if Part.loop is true.
         */
        get loopEnd() {
            return new TicksClass(this.context, this._loopEnd).toSeconds();
        }
        set loopEnd(loopEnd) {
            this._loopEnd = this.toTicks(loopEnd);
            if (this._loop) {
                this._forEach(event => {
                    event.loopEnd = loopEnd;
                    this._testLoopBoundries(event);
                });
            }
        }
        /**
         * The loopStart point determines when it will
         * loop if Part.loop is true.
         */
        get loopStart() {
            return new TicksClass(this.context, this._loopStart).toSeconds();
        }
        set loopStart(loopStart) {
            this._loopStart = this.toTicks(loopStart);
            if (this._loop) {
                this._forEach(event => {
                    event.loopStart = this.loopStart;
                    this._testLoopBoundries(event);
                });
            }
        }
        /**
         * The playback rate of the part
         */
        get playbackRate() {
            return this._playbackRate;
        }
        set playbackRate(rate) {
            this._playbackRate = rate;
            this._setAll("playbackRate", rate);
        }
        /**
         * The number of scheduled notes in the part.
         */
        get length() {
            return this._events.size;
        }
        dispose() {
            super.dispose();
            this.clear();
            return this;
        }
    }

    /**
     * Start at the first value and go up to the last
     */
    function* upPatternGen(values) {
        let index = 0;
        while (index < values.length) {
            index = clampToArraySize(index, values);
            yield values[index];
            index++;
        }
    }
    /**
     * Start at the last value and go down to 0
     */
    function* downPatternGen(values) {
        let index = values.length - 1;
        while (index >= 0) {
            index = clampToArraySize(index, values);
            yield values[index];
            index--;
        }
    }
    /**
     * Infinitely yield the generator
     */
    function* infiniteGen(values, gen) {
        while (true) {
            yield* gen(values);
        }
    }
    /**
     * Make sure that the index is in the given range
     */
    function clampToArraySize(index, values) {
        return clamp(index, 0, values.length - 1);
    }
    /**
     * Alternate between two generators
     */
    function* alternatingGenerator(values, directionUp) {
        let index = directionUp ? 0 : values.length - 1;
        while (true) {
            index = clampToArraySize(index, values);
            yield values[index];
            if (directionUp) {
                index++;
                if (index >= values.length - 1) {
                    directionUp = false;
                }
            }
            else {
                index--;
                if (index <= 0) {
                    directionUp = true;
                }
            }
        }
    }
    /**
     * Starting from the bottom move up 2, down 1
     */
    function* jumpUp(values) {
        let index = 0;
        let stepIndex = 0;
        while (index < values.length) {
            index = clampToArraySize(index, values);
            yield values[index];
            stepIndex++;
            index += (stepIndex % 2 ? 2 : -1);
        }
    }
    /**
     * Starting from the top move down 2, up 1
     */
    function* jumpDown(values) {
        let index = values.length - 1;
        let stepIndex = 0;
        while (index >= 0) {
            index = clampToArraySize(index, values);
            yield values[index];
            stepIndex++;
            index += (stepIndex % 2 ? -2 : 1);
        }
    }
    /**
     * Choose a random index each time
     */
    function* randomGen(values) {
        while (true) {
            const randomIndex = Math.floor(Math.random() * values.length);
            yield values[randomIndex];
        }
    }
    /**
     * Randomly go through all of the values once before choosing a new random order
     */
    function* randomOnce(values) {
        // create an array of indices
        const copy = [];
        for (let i = 0; i < values.length; i++) {
            copy.push(i);
        }
        while (copy.length > 0) {
            // random choose an index, and then remove it so it's not chosen again
            const randVal = copy.splice(Math.floor(copy.length * Math.random()), 1);
            const index = clampToArraySize(randVal[0], values);
            yield values[index];
        }
    }
    /**
     * Randomly choose to walk up or down 1 index in the values array
     */
    function* randomWalk(values) {
        // randomly choose a starting index in the values array
        let index = Math.floor(Math.random() * values.length);
        while (true) {
            if (index === 0) {
                index++; // at bottom of array, so force upward step
            }
            else if (index === values.length - 1) {
                index--; // at top of array, so force downward step
            }
            else if (Math.random() < 0.5) { // else choose random downward or upward step
                index--;
            }
            else {
                index++;
            }
            yield values[index];
        }
    }
    /**
     * PatternGenerator returns a generator which will iterate over the given array
     * of values and yield the items according to the passed in pattern
     * @param values An array of values to iterate over
     * @param pattern The name of the pattern use when iterating over
     * @param index Where to start in the offset of the values array
     */
    function* PatternGenerator(values, pattern = "up", index = 0) {
        // safeguards
        assert(values.length > 0, "The array must have more than one value in it");
        switch (pattern) {
            case "up":
                yield* infiniteGen(values, upPatternGen);
            case "down":
                yield* infiniteGen(values, downPatternGen);
            case "upDown":
                yield* alternatingGenerator(values, true);
            case "downUp":
                yield* alternatingGenerator(values, false);
            case "alternateUp":
                yield* infiniteGen(values, jumpUp);
            case "alternateDown":
                yield* infiniteGen(values, jumpDown);
            case "random":
                yield* randomGen(values);
            case "randomOnce":
                yield* infiniteGen(values, randomOnce);
            case "randomWalk":
                yield* randomWalk(values);
        }
    }

    /**
     * Pattern arpeggiates between the given notes
     * in a number of patterns.
     * @example
     * const pattern = new Tone.Pattern((time, note) => {
     * 	// the order of the notes passed in depends on the pattern
     * }, ["C2", "D4", "E5", "A6"], "upDown");
     * @category Event
     */
    class Pattern extends Loop {
        constructor() {
            super(optionsFromArguments(Pattern.getDefaults(), arguments, ["callback", "values", "pattern"]));
            this.name = "Pattern";
            const options = optionsFromArguments(Pattern.getDefaults(), arguments, ["callback", "values", "pattern"]);
            this.callback = options.callback;
            this._values = options.values;
            this._pattern = PatternGenerator(options.values, options.pattern);
            this._type = options.pattern;
        }
        static getDefaults() {
            return Object.assign(Loop.getDefaults(), {
                pattern: "up",
                values: [],
                callback: noOp,
            });
        }
        /**
         * Internal function called when the notes should be called
         */
        _tick(time) {
            const value = this._pattern.next();
            this._value = value.value;
            this.callback(time, this._value);
        }
        /**
         * The array of events.
         */
        get values() {
            return this._values;
        }
        set values(val) {
            this._values = val;
            // reset the pattern
            this.pattern = this._type;
        }
        /**
         * The current value of the pattern.
         */
        get value() {
            return this._value;
        }
        /**
         * The pattern type. See Tone.CtrlPattern for the full list of patterns.
         */
        get pattern() {
            return this._type;
        }
        set pattern(pattern) {
            this._type = pattern;
            this._pattern = PatternGenerator(this._values, this._type);
        }
    }

    /**
     * A sequence is an alternate notation of a part. Instead
     * of passing in an array of [time, event] pairs, pass
     * in an array of events which will be spaced at the
     * given subdivision. Sub-arrays will subdivide that beat
     * by the number of items are in the array.
     * Sequence notation inspiration from [Tidal](http://yaxu.org/tidal/)
     * @example
     * const synth = new Tone.Synth().toDestination();
     * const seq = new Tone.Sequence((time, note) => {
     * 	synth.triggerAttackRelease(note, 0.1, time);
     * 	// subdivisions are given as subarrays
     * }, ["C4", ["E4", "D4", "E4"], "G4", ["A4", "G4"]]).start(0);
     * Tone.Transport.start();
     * @category Event
     */
    class Sequence extends ToneEvent {
        constructor() {
            super(optionsFromArguments(Sequence.getDefaults(), arguments, ["callback", "events", "subdivision"]));
            this.name = "Sequence";
            /**
             * The object responsible for scheduling all of the events
             */
            this._part = new Part({
                callback: this._seqCallback.bind(this),
                context: this.context,
            });
            /**
             * private reference to all of the sequence proxies
             */
            this._events = [];
            /**
             * The proxied array
             */
            this._eventsArray = [];
            const options = optionsFromArguments(Sequence.getDefaults(), arguments, ["callback", "events", "subdivision"]);
            this._subdivision = this.toTicks(options.subdivision);
            this.events = options.events;
            // set all of the values
            this.loop = options.loop;
            this.loopStart = options.loopStart;
            this.loopEnd = options.loopEnd;
            this.playbackRate = options.playbackRate;
            this.probability = options.probability;
            this.humanize = options.humanize;
            this.mute = options.mute;
            this.playbackRate = options.playbackRate;
        }
        static getDefaults() {
            return Object.assign(omitFromObject(ToneEvent.getDefaults(), ["value"]), {
                events: [],
                loop: true,
                loopEnd: 0,
                loopStart: 0,
                subdivision: "8n",
            });
        }
        /**
         * The internal callback for when an event is invoked
         */
        _seqCallback(time, value) {
            if (value !== null) {
                this.callback(time, value);
            }
        }
        /**
         * The sequence
         */
        get events() {
            return this._events;
        }
        set events(s) {
            this.clear();
            this._eventsArray = s;
            this._events = this._createSequence(this._eventsArray);
            this._eventsUpdated();
        }
        /**
         * Start the part at the given time.
         * @param  time    When to start the part.
         * @param  offset  The offset index to start at
         */
        start(time, offset) {
            this._part.start(time, offset ? this._indexTime(offset) : offset);
            return this;
        }
        /**
         * Stop the part at the given time.
         * @param  time  When to stop the part.
         */
        stop(time) {
            this._part.stop(time);
            return this;
        }
        /**
         * The subdivision of the sequence. This can only be
         * set in the constructor. The subdivision is the
         * interval between successive steps.
         */
        get subdivision() {
            return new TicksClass(this.context, this._subdivision).toSeconds();
        }
        /**
         * Create a sequence proxy which can be monitored to create subsequences
         */
        _createSequence(array) {
            return new Proxy(array, {
                get: (target, property) => {
                    // property is index in this case
                    return target[property];
                },
                set: (target, property, value) => {
                    if (isString(property) && isFinite(parseInt(property, 10))) {
                        if (isArray(value)) {
                            target[property] = this._createSequence(value);
                        }
                        else {
                            target[property] = value;
                        }
                    }
                    else {
                        target[property] = value;
                    }
                    this._eventsUpdated();
                    // return true to accept the changes
                    return true;
                },
            });
        }
        /**
         * When the sequence has changed, all of the events need to be recreated
         */
        _eventsUpdated() {
            this._part.clear();
            this._rescheduleSequence(this._eventsArray, this._subdivision, this.startOffset);
            // update the loopEnd
            this.loopEnd = this.loopEnd;
        }
        /**
         * reschedule all of the events that need to be rescheduled
         */
        _rescheduleSequence(sequence, subdivision, startOffset) {
            sequence.forEach((value, index) => {
                const eventOffset = index * (subdivision) + startOffset;
                if (isArray(value)) {
                    this._rescheduleSequence(value, subdivision / value.length, eventOffset);
                }
                else {
                    const startTime = new TicksClass(this.context, eventOffset, "i").toSeconds();
                    this._part.add(startTime, value);
                }
            });
        }
        /**
         * Get the time of the index given the Sequence's subdivision
         * @param  index
         * @return The time of that index
         */
        _indexTime(index) {
            return new TicksClass(this.context, index * (this._subdivision) + this.startOffset).toSeconds();
        }
        /**
         * Clear all of the events
         */
        clear() {
            this._part.clear();
            return this;
        }
        dispose() {
            super.dispose();
            this._part.dispose();
            return this;
        }
        //-------------------------------------
        // PROXY CALLS
        //-------------------------------------
        get loop() {
            return this._part.loop;
        }
        set loop(l) {
            this._part.loop = l;
        }
        /**
         * The index at which the sequence should start looping
         */
        get loopStart() {
            return this._loopStart;
        }
        set loopStart(index) {
            this._loopStart = index;
            this._part.loopStart = this._indexTime(index);
        }
        /**
         * The index at which the sequence should end looping
         */
        get loopEnd() {
            return this._loopEnd;
        }
        set loopEnd(index) {
            this._loopEnd = index;
            if (index === 0) {
                this._part.loopEnd = this._indexTime(this._eventsArray.length);
            }
            else {
                this._part.loopEnd = this._indexTime(index);
            }
        }
        get startOffset() {
            return this._part.startOffset;
        }
        set startOffset(start) {
            this._part.startOffset = start;
        }
        get playbackRate() {
            return this._part.playbackRate;
        }
        set playbackRate(rate) {
            this._part.playbackRate = rate;
        }
        get probability() {
            return this._part.probability;
        }
        set probability(prob) {
            this._part.probability = prob;
        }
        get progress() {
            return this._part.progress;
        }
        get humanize() {
            return this._part.humanize;
        }
        set humanize(variation) {
            this._part.humanize = variation;
        }
        /**
         * The number of scheduled events
         */
        get length() {
            return this._part.length;
        }
    }

    /**
     * Tone.Crossfade provides equal power fading between two inputs.
     * More on crossfading technique [here](https://en.wikipedia.org/wiki/Fade_(audio_engineering)#Crossfading).
     * ```
     *                                             +---------+
     *                                            +> input a +>--+
     * +-----------+   +---------------------+     |         |   |
     * | 1s signal +>--> stereoPannerNode  L +>----> gain    |   |
     * +-----------+   |                     |     +---------+   |
     *               +-> pan               R +>-+                |   +--------+
     *               | +---------------------+  |                +---> output +>
     *  +------+     |                          |  +---------+   |   +--------+
     *  | fade +>----+                          | +> input b +>--+
     *  +------+                                |  |         |
     *                                          +--> gain    |
     *                                             +---------+
     * ```
     * @example
     * const crossFade = new Tone.CrossFade().toDestination();
     * // connect two inputs Tone.to a/b
     * const inputA = new Tone.Oscillator(440, "square").connect(crossFade.a).start();
     * const inputB = new Tone.Oscillator(440, "sine").connect(crossFade.b).start();
     * // use the fade to control the mix between the two
     * crossFade.fade.value = 0.5;
     * @category Component
     */
    class CrossFade extends ToneAudioNode {
        constructor() {
            super(Object.assign(optionsFromArguments(CrossFade.getDefaults(), arguments, ["fade"])));
            this.name = "CrossFade";
            /**
             * The crossfading is done by a StereoPannerNode
             */
            this._panner = this.context.createStereoPanner();
            /**
             * Split the output of the panner node into two values used to control the gains.
             */
            this._split = this.context.createChannelSplitter(2);
            /**
             * Convert the fade value into an audio range value so it can be connected
             * to the panner.pan AudioParam
             */
            this._g2a = new GainToAudio({ context: this.context });
            /**
             * The input which is at full level when fade = 0
             */
            this.a = new Gain({
                context: this.context,
                gain: 0,
            });
            /**
             * The input which is at full level when fade = 1
             */
            this.b = new Gain({
                context: this.context,
                gain: 0,
            });
            /**
             * The output is a mix between `a` and `b` at the ratio of `fade`
             */
            this.output = new Gain({ context: this.context });
            this._internalChannels = [this.a, this.b];
            const options = optionsFromArguments(CrossFade.getDefaults(), arguments, ["fade"]);
            this.fade = new Signal({
                context: this.context,
                units: "normalRange",
                value: options.fade,
            });
            readOnly(this, "fade");
            this.context.getConstant(1).connect(this._panner);
            this._panner.connect(this._split);
            // this is necessary for standardized-audio-context
            // doesn't make any difference for the native AudioContext
            // https://github.com/chrisguttandin/standardized-audio-context/issues/647
            this._panner.channelCount = 1;
            this._panner.channelCountMode = "explicit";
            connect(this._split, this.a.gain, 0);
            connect(this._split, this.b.gain, 1);
            this.fade.chain(this._g2a, this._panner.pan);
            this.a.connect(this.output);
            this.b.connect(this.output);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                fade: 0.5,
            });
        }
        dispose() {
            super.dispose();
            this.a.dispose();
            this.b.dispose();
            this.output.dispose();
            this.fade.dispose();
            this._g2a.dispose();
            this._panner.disconnect();
            this._split.disconnect();
            return this;
        }
    }

    /**
     * Effect is the base class for effects. Connect the effect between
     * the effectSend and effectReturn GainNodes, then control the amount of
     * effect which goes to the output using the wet control.
     */
    class Effect extends ToneAudioNode {
        constructor(options) {
            super(options);
            this.name = "Effect";
            /**
             * the drywet knob to control the amount of effect
             */
            this._dryWet = new CrossFade({ context: this.context });
            /**
             * The wet control is how much of the effected
             * will pass through to the output. 1 = 100% effected
             * signal, 0 = 100% dry signal.
             */
            this.wet = this._dryWet.fade;
            /**
             * connect the effectSend to the input of hte effect
             */
            this.effectSend = new Gain({ context: this.context });
            /**
             * connect the output of the effect to the effectReturn
             */
            this.effectReturn = new Gain({ context: this.context });
            /**
             * The effect input node
             */
            this.input = new Gain({ context: this.context });
            /**
             * The effect output
             */
            this.output = this._dryWet;
            // connections
            this.input.fan(this._dryWet.a, this.effectSend);
            this.effectReturn.connect(this._dryWet.b);
            this.wet.setValueAtTime(options.wet, 0);
            this._internalChannels = [this.effectReturn, this.effectSend];
            readOnly(this, "wet");
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                wet: 1,
            });
        }
        /**
         * chains the effect in between the effectSend and effectReturn
         */
        connectEffect(effect) {
            // add it to the internal channels
            this._internalChannels.push(effect);
            this.effectSend.chain(effect, this.effectReturn);
            return this;
        }
        dispose() {
            super.dispose();
            this._dryWet.dispose();
            this.effectSend.dispose();
            this.effectReturn.dispose();
            this.wet.dispose();
            return this;
        }
    }

    /**
     * Base class for LFO-based effects.
     */
    class LFOEffect extends Effect {
        constructor(options) {
            super(options);
            this.name = "LFOEffect";
            this._lfo = new LFO({
                context: this.context,
                frequency: options.frequency,
                amplitude: options.depth,
            });
            this.depth = this._lfo.amplitude;
            this.frequency = this._lfo.frequency;
            this.type = options.type;
            readOnly(this, ["frequency", "depth"]);
        }
        static getDefaults() {
            return Object.assign(Effect.getDefaults(), {
                frequency: 1,
                type: "sine",
                depth: 1,
            });
        }
        /**
         * Start the effect.
         */
        start(time) {
            this._lfo.start(time);
            return this;
        }
        /**
         * Stop the lfo
         */
        stop(time) {
            this._lfo.stop(time);
            return this;
        }
        /**
         * Sync the filter to the transport. See [[LFO.sync]]
         */
        sync() {
            this._lfo.sync();
            return this;
        }
        /**
         * Unsync the filter from the transport.
         */
        unsync() {
            this._lfo.unsync();
            return this;
        }
        /**
         * The type of the LFO's oscillator: See [[Oscillator.type]]
         * @example
         * const autoFilter = new Tone.AutoFilter().start().toDestination();
         * const noise = new Tone.Noise().start().connect(autoFilter);
         * autoFilter.type = "square";
         */
        get type() {
            return this._lfo.type;
        }
        set type(type) {
            this._lfo.type = type;
        }
        dispose() {
            super.dispose();
            this._lfo.dispose();
            this.frequency.dispose();
            this.depth.dispose();
            return this;
        }
    }

    /**
     * AutoFilter is a Tone.Filter with a Tone.LFO connected to the filter cutoff frequency.
     * Setting the LFO rate and depth allows for control over the filter modulation rate
     * and depth.
     *
     * @example
     * // create an autofilter and start it's LFO
     * const autoFilter = new Tone.AutoFilter("4n").toDestination().start();
     * // route an oscillator through the filter and start it
     * const oscillator = new Tone.Oscillator().connect(autoFilter).start();
     * @category Effect
     */
    class AutoFilter extends LFOEffect {
        constructor() {
            super(optionsFromArguments(AutoFilter.getDefaults(), arguments, ["frequency", "baseFrequency", "octaves"]));
            this.name = "AutoFilter";
            const options = optionsFromArguments(AutoFilter.getDefaults(), arguments, ["frequency", "baseFrequency", "octaves"]);
            this.filter = new Filter(Object.assign(options.filter, {
                context: this.context,
            }));
            // connections
            this.connectEffect(this.filter);
            this._lfo.connect(this.filter.frequency);
            this.octaves = options.octaves;
            this.baseFrequency = options.baseFrequency;
        }
        static getDefaults() {
            return Object.assign(LFOEffect.getDefaults(), {
                baseFrequency: 200,
                octaves: 2.6,
                filter: {
                    type: "lowpass",
                    rolloff: -12,
                    Q: 1,
                }
            });
        }
        /**
         * The minimum value of the filter's cutoff frequency.
         */
        get baseFrequency() {
            return this._lfo.min;
        }
        set baseFrequency(freq) {
            this._lfo.min = this.toFrequency(freq);
            // and set the max
            this.octaves = this._octaves;
        }
        /**
         * The maximum value of the filter's cutoff frequency.
         */
        get octaves() {
            return this._octaves;
        }
        set octaves(oct) {
            this._octaves = oct;
            this._lfo.max = this._lfo.min * Math.pow(2, oct);
        }
        dispose() {
            super.dispose();
            this.filter.dispose();
            return this;
        }
    }

    /**
     * Panner is an equal power Left/Right Panner. It is a wrapper around the StereoPannerNode.
     * @example
     * return Tone.Offline(() => {
     * // move the input signal from right to left
     * 	const panner = new Tone.Panner(1).toDestination();
     * 	panner.pan.rampTo(-1, 0.5);
     * 	const osc = new Tone.Oscillator(100).connect(panner).start();
     * }, 0.5, 2);
     * @category Component
     */
    class Panner extends ToneAudioNode {
        constructor() {
            super(Object.assign(optionsFromArguments(Panner.getDefaults(), arguments, ["pan"])));
            this.name = "Panner";
            /**
             * the panner node
             */
            this._panner = this.context.createStereoPanner();
            this.input = this._panner;
            this.output = this._panner;
            const options = optionsFromArguments(Panner.getDefaults(), arguments, ["pan"]);
            this.pan = new Param({
                context: this.context,
                param: this._panner.pan,
                value: options.pan,
                minValue: -1,
                maxValue: 1,
            });
            // this is necessary for standardized-audio-context
            // doesn't make any difference for the native AudioContext
            // https://github.com/chrisguttandin/standardized-audio-context/issues/647
            this._panner.channelCount = options.channelCount;
            this._panner.channelCountMode = "explicit";
            // initial value
            readOnly(this, "pan");
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                pan: 0,
                channelCount: 1,
            });
        }
        dispose() {
            super.dispose();
            this._panner.disconnect();
            this.pan.dispose();
            return this;
        }
    }

    /**
     * AutoPanner is a [[Panner]] with an [[LFO]] connected to the pan amount.
     * [Related Reading](https://www.ableton.com/en/blog/autopan-chopper-effect-and-more-liveschool/).
     *
     * @example
     * // create an autopanner and start it
     * const autoPanner = new Tone.AutoPanner("4n").toDestination().start();
     * // route an oscillator through the panner and start it
     * const oscillator = new Tone.Oscillator().connect(autoPanner).start();
     * @category Effect
     */
    class AutoPanner extends LFOEffect {
        constructor() {
            super(optionsFromArguments(AutoPanner.getDefaults(), arguments, ["frequency"]));
            this.name = "AutoPanner";
            const options = optionsFromArguments(AutoPanner.getDefaults(), arguments, ["frequency"]);
            this._panner = new Panner({
                context: this.context,
                channelCount: options.channelCount
            });
            // connections
            this.connectEffect(this._panner);
            this._lfo.connect(this._panner.pan);
            this._lfo.min = -1;
            this._lfo.max = 1;
        }
        static getDefaults() {
            return Object.assign(LFOEffect.getDefaults(), {
                channelCount: 1
            });
        }
        dispose() {
            super.dispose();
            this._panner.dispose();
            return this;
        }
    }

    /**
     * Follower is a simple envelope follower.
     * It's implemented by applying a lowpass filter to the absolute value of the incoming signal.
     * ```
     *          +-----+    +---------------+
     * Input +--> Abs +----> OnePoleFilter +--> Output
     *          +-----+    +---------------+
     * ```
     * @category Component
     */
    class Follower extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Follower.getDefaults(), arguments, ["smoothing"]));
            this.name = "Follower";
            const options = optionsFromArguments(Follower.getDefaults(), arguments, ["smoothing"]);
            this._abs = this.input = new Abs({ context: this.context });
            this._lowpass = this.output = new OnePoleFilter({
                context: this.context,
                frequency: 1 / this.toSeconds(options.smoothing),
                type: "lowpass"
            });
            this._abs.connect(this._lowpass);
            this._smoothing = options.smoothing;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                smoothing: 0.05
            });
        }
        /**
         * The amount of time it takes a value change to arrive at the updated value.
         */
        get smoothing() {
            return this._smoothing;
        }
        set smoothing(smoothing) {
            this._smoothing = smoothing;
            this._lowpass.frequency = 1 / this.toSeconds(this.smoothing);
        }
        dispose() {
            super.dispose();
            this._abs.dispose();
            this._lowpass.dispose();
            return this;
        }
    }

    /**
     * AutoWah connects a [[Follower]] to a [[Filter]].
     * The frequency of the filter, follows the input amplitude curve.
     * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna).
     *
     * @example
     * const autoWah = new Tone.AutoWah(50, 6, -30).toDestination();
     * // initialize the synth and connect to autowah
     * const synth = new Tone.Synth().connect(autoWah);
     * // Q value influences the effect of the wah - default is 2
     * autoWah.Q.value = 6;
     * // more audible on higher notes
     * synth.triggerAttackRelease("C4", "8n");
     * @category Effect
     */
    class AutoWah extends Effect {
        constructor() {
            super(optionsFromArguments(AutoWah.getDefaults(), arguments, ["baseFrequency", "octaves", "sensitivity"]));
            this.name = "AutoWah";
            const options = optionsFromArguments(AutoWah.getDefaults(), arguments, ["baseFrequency", "octaves", "sensitivity"]);
            this._follower = new Follower({
                context: this.context,
                smoothing: options.follower,
            });
            this._sweepRange = new ScaleExp({
                context: this.context,
                min: 0,
                max: 1,
                exponent: 0.5,
            });
            this._baseFrequency = this.toFrequency(options.baseFrequency);
            this._octaves = options.octaves;
            this._inputBoost = new Gain({ context: this.context });
            this._bandpass = new Filter({
                context: this.context,
                rolloff: -48,
                frequency: 0,
                Q: options.Q,
            });
            this._peaking = new Filter({
                context: this.context,
                type: "peaking"
            });
            this._peaking.gain.value = options.gain;
            this.gain = this._peaking.gain;
            this.Q = this._bandpass.Q;
            // the control signal path
            this.effectSend.chain(this._inputBoost, this._follower, this._sweepRange);
            this._sweepRange.connect(this._bandpass.frequency);
            this._sweepRange.connect(this._peaking.frequency);
            // the filtered path
            this.effectSend.chain(this._bandpass, this._peaking, this.effectReturn);
            // set the initial value
            this._setSweepRange();
            this.sensitivity = options.sensitivity;
            readOnly(this, ["gain", "Q"]);
        }
        static getDefaults() {
            return Object.assign(Effect.getDefaults(), {
                baseFrequency: 100,
                octaves: 6,
                sensitivity: 0,
                Q: 2,
                gain: 2,
                follower: 0.2,
            });
        }
        /**
         * The number of octaves that the filter will sweep above the baseFrequency.
         */
        get octaves() {
            return this._octaves;
        }
        set octaves(octaves) {
            this._octaves = octaves;
            this._setSweepRange();
        }
        /**
         * The follower's smoothing time
         */
        get follower() {
            return this._follower.smoothing;
        }
        set follower(follower) {
            this._follower.smoothing = follower;
        }
        /**
         * The base frequency from which the sweep will start from.
         */
        get baseFrequency() {
            return this._baseFrequency;
        }
        set baseFrequency(baseFreq) {
            this._baseFrequency = this.toFrequency(baseFreq);
            this._setSweepRange();
        }
        /**
         * The sensitivity to control how responsive to the input signal the filter is.
         */
        get sensitivity() {
            return gainToDb(1 / this._inputBoost.gain.value);
        }
        set sensitivity(sensitivity) {
            this._inputBoost.gain.value = 1 / dbToGain(sensitivity);
        }
        /**
         * sets the sweep range of the scaler
         */
        _setSweepRange() {
            this._sweepRange.min = this._baseFrequency;
            this._sweepRange.max = Math.min(this._baseFrequency * Math.pow(2, this._octaves), this.context.sampleRate / 2);
        }
        dispose() {
            super.dispose();
            this._follower.dispose();
            this._sweepRange.dispose();
            this._bandpass.dispose();
            this._peaking.dispose();
            this._inputBoost.dispose();
            return this;
        }
    }

    const workletName$1 = "bit-crusher";
    const bitCrusherWorklet = /* javascript */ `
	class BitCrusherWorklet extends SingleIOProcessor {

		static get parameterDescriptors() {
			return [{
				name: "bits",
				defaultValue: 12,
				minValue: 1,
				maxValue: 16,
				automationRate: 'k-rate'
			}];
		}

		generate(input, _channel, parameters) {
			const step = Math.pow(0.5, parameters.bits - 1);
			const val = step * Math.floor(input / step + 0.5);
			return val;
		}
	}
`;
    registerProcessor(workletName$1, bitCrusherWorklet);

    /**
     * BitCrusher down-samples the incoming signal to a different bit depth.
     * Lowering the bit depth of the signal creates distortion. Read more about BitCrushing
     * on [Wikipedia](https://en.wikipedia.org/wiki/Bitcrusher).
     * @example
     * // initialize crusher and route a synth through it
     * const crusher = new Tone.BitCrusher(4).toDestination();
     * const synth = new Tone.Synth().connect(crusher);
     * synth.triggerAttackRelease("C2", 2);
     *
     * @category Effect
     */
    class BitCrusher extends Effect {
        constructor() {
            super(optionsFromArguments(BitCrusher.getDefaults(), arguments, ["bits"]));
            this.name = "BitCrusher";
            const options = optionsFromArguments(BitCrusher.getDefaults(), arguments, ["bits"]);
            this._bitCrusherWorklet = new BitCrusherWorklet({
                context: this.context,
                bits: options.bits,
            });
            // connect it up
            this.connectEffect(this._bitCrusherWorklet);
            this.bits = this._bitCrusherWorklet.bits;
        }
        static getDefaults() {
            return Object.assign(Effect.getDefaults(), {
                bits: 4,
            });
        }
        dispose() {
            super.dispose();
            this._bitCrusherWorklet.dispose();
            return this;
        }
    }
    /**
     * Internal class which creates an AudioWorklet to do the bit crushing
     */
    class BitCrusherWorklet extends ToneAudioWorklet {
        constructor() {
            super(optionsFromArguments(BitCrusherWorklet.getDefaults(), arguments));
            this.name = "BitCrusherWorklet";
            const options = optionsFromArguments(BitCrusherWorklet.getDefaults(), arguments);
            this.input = new Gain({ context: this.context });
            this.output = new Gain({ context: this.context });
            this.bits = new Param({
                context: this.context,
                value: options.bits,
                units: "positive",
                minValue: 1,
                maxValue: 16,
                param: this._dummyParam,
                swappable: true,
            });
        }
        static getDefaults() {
            return Object.assign(ToneAudioWorklet.getDefaults(), {
                bits: 12,
            });
        }
        _audioWorkletName() {
            return workletName$1;
        }
        onReady(node) {
            connectSeries(this.input, node, this.output);
            const bits = node.parameters.get("bits");
            this.bits.setParam(bits);
        }
        dispose() {
            super.dispose();
            this.input.dispose();
            this.output.dispose();
            this.bits.dispose();
            return this;
        }
    }

    /**
     * Chebyshev is a waveshaper which is good
     * for making different types of distortion sounds.
     * Note that odd orders sound very different from even ones,
     * and order = 1 is no change.
     * Read more at [music.columbia.edu](http://music.columbia.edu/cmc/musicandcomputers/chapter4/04_06.php).
     * @example
     * // create a new cheby
     * const cheby = new Tone.Chebyshev(50).toDestination();
     * // create a monosynth connected to our cheby
     * const synth = new Tone.MonoSynth().connect(cheby);
     * synth.triggerAttackRelease("C2", 0.4);
     * @category Effect
     */
    class Chebyshev extends Effect {
        constructor() {
            super(optionsFromArguments(Chebyshev.getDefaults(), arguments, ["order"]));
            this.name = "Chebyshev";
            const options = optionsFromArguments(Chebyshev.getDefaults(), arguments, ["order"]);
            this._shaper = new WaveShaper({
                context: this.context,
                length: 4096
            });
            this._order = options.order;
            this.connectEffect(this._shaper);
            this.order = options.order;
            this.oversample = options.oversample;
        }
        static getDefaults() {
            return Object.assign(Effect.getDefaults(), {
                order: 1,
                oversample: "none"
            });
        }
        /**
         * get the coefficient for that degree
         * @param  x the x value
         * @param  degree
         * @param  memo memoize the computed value. this speeds up computation greatly.
         */
        _getCoefficient(x, degree, memo) {
            if (memo.has(degree)) {
                return memo.get(degree);
            }
            else if (degree === 0) {
                memo.set(degree, 0);
            }
            else if (degree === 1) {
                memo.set(degree, x);
            }
            else {
                memo.set(degree, 2 * x * this._getCoefficient(x, degree - 1, memo) - this._getCoefficient(x, degree - 2, memo));
            }
            return memo.get(degree);
        }
        /**
         * The order of the Chebyshev polynomial which creates the equation which is applied to the incoming
         * signal through a Tone.WaveShaper. The equations are in the form:
         * ```
         * order 2: 2x^2 + 1
         * order 3: 4x^3 + 3x
         * ```
         * @min 1
         * @max 100
         */
        get order() {
            return this._order;
        }
        set order(order) {
            this._order = order;
            this._shaper.setMap((x => {
                return this._getCoefficient(x, order, new Map());
            }));
        }
        /**
         * The oversampling of the effect. Can either be "none", "2x" or "4x".
         */
        get oversample() {
            return this._shaper.oversample;
        }
        set oversample(oversampling) {
            this._shaper.oversample = oversampling;
        }
        dispose() {
            super.dispose();
            this._shaper.dispose();
            return this;
        }
    }

    /**
     * Split splits an incoming signal into the number of given channels.
     *
     * @example
     * const split = new Tone.Split();
     * // stereoSignal.connect(split);
     * @category Component
     */
    class Split extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Split.getDefaults(), arguments, ["channels"]));
            this.name = "Split";
            const options = optionsFromArguments(Split.getDefaults(), arguments, ["channels"]);
            this._splitter = this.input = this.output = this.context.createChannelSplitter(options.channels);
            this._internalChannels = [this._splitter];
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                channels: 2,
            });
        }
        dispose() {
            super.dispose();
            this._splitter.disconnect();
            return this;
        }
    }

    /**
     * Merge brings multiple mono input channels into a single multichannel output channel.
     *
     * @example
     * const merge = new Tone.Merge().toDestination();
     * // routing a sine tone in the left channel
     * const osc = new Tone.Oscillator().connect(merge, 0, 0).start();
     * // and noise in the right channel
     * const noise = new Tone.Noise().connect(merge, 0, 1).start();;
     * @category Component
     */
    class Merge extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Merge.getDefaults(), arguments, ["channels"]));
            this.name = "Merge";
            const options = optionsFromArguments(Merge.getDefaults(), arguments, ["channels"]);
            this._merger = this.output = this.input = this.context.createChannelMerger(options.channels);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                channels: 2,
            });
        }
        dispose() {
            super.dispose();
            this._merger.disconnect();
            return this;
        }
    }

    /**
     * Base class for Stereo effects.
     */
    class StereoEffect extends ToneAudioNode {
        constructor(options) {
            super(options);
            this.name = "StereoEffect";
            this.input = new Gain({ context: this.context });
            // force mono sources to be stereo
            this.input.channelCount = 2;
            this.input.channelCountMode = "explicit";
            this._dryWet = this.output = new CrossFade({
                context: this.context,
                fade: options.wet
            });
            this.wet = this._dryWet.fade;
            this._split = new Split({ context: this.context, channels: 2 });
            this._merge = new Merge({ context: this.context, channels: 2 });
            // connections
            this.input.connect(this._split);
            // dry wet connections
            this.input.connect(this._dryWet.a);
            this._merge.connect(this._dryWet.b);
            readOnly(this, ["wet"]);
        }
        /**
         * Connect the left part of the effect
         */
        connectEffectLeft(...nodes) {
            this._split.connect(nodes[0], 0, 0);
            connectSeries(...nodes);
            connect(nodes[nodes.length - 1], this._merge, 0, 0);
        }
        /**
         * Connect the right part of the effect
         */
        connectEffectRight(...nodes) {
            this._split.connect(nodes[0], 1, 0);
            connectSeries(...nodes);
            connect(nodes[nodes.length - 1], this._merge, 0, 1);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                wet: 1,
            });
        }
        dispose() {
            super.dispose();
            this._dryWet.dispose();
            this._split.dispose();
            this._merge.dispose();
            return this;
        }
    }

    /**
     * Base class for stereo feedback effects where the effectReturn is fed back into the same channel.
     */
    class StereoFeedbackEffect extends StereoEffect {
        constructor(options) {
            super(options);
            this.feedback = new Signal({
                context: this.context,
                value: options.feedback,
                units: "normalRange"
            });
            this._feedbackL = new Gain({ context: this.context });
            this._feedbackR = new Gain({ context: this.context });
            this._feedbackSplit = new Split({ context: this.context, channels: 2 });
            this._feedbackMerge = new Merge({ context: this.context, channels: 2 });
            this._merge.connect(this._feedbackSplit);
            this._feedbackMerge.connect(this._split);
            // the left output connected to the left input
            this._feedbackSplit.connect(this._feedbackL, 0, 0);
            this._feedbackL.connect(this._feedbackMerge, 0, 0);
            // the right output connected to the right input
            this._feedbackSplit.connect(this._feedbackR, 1, 0);
            this._feedbackR.connect(this._feedbackMerge, 0, 1);
            // the feedback control
            this.feedback.fan(this._feedbackL.gain, this._feedbackR.gain);
            readOnly(this, ["feedback"]);
        }
        static getDefaults() {
            return Object.assign(StereoEffect.getDefaults(), {
                feedback: 0.5,
            });
        }
        dispose() {
            super.dispose();
            this.feedback.dispose();
            this._feedbackL.dispose();
            this._feedbackR.dispose();
            this._feedbackSplit.dispose();
            this._feedbackMerge.dispose();
            return this;
        }
    }

    /**
     * Chorus is a stereo chorus effect composed of a left and right delay with an [[LFO]] applied to the delayTime of each channel.
     * When [[feedback]] is set to a value larger than 0, you also get Flanger-type effects.
     * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna/blob/master/tuna.js).
     * Read more on the chorus effect on [SoundOnSound](http://www.soundonsound.com/sos/jun04/articles/synthsecrets.htm).
     *
     * @example
     * const chorus = new Tone.Chorus(4, 2.5, 0.5);
     * const synth = new Tone.PolySynth().connect(chorus);
     * synth.triggerAttackRelease(["C3", "E3", "G3"], "8n");
     *
     * @category Effect
     */
    class Chorus extends StereoFeedbackEffect {
        constructor() {
            super(optionsFromArguments(Chorus.getDefaults(), arguments, ["frequency", "delayTime", "depth"]));
            this.name = "Chorus";
            const options = optionsFromArguments(Chorus.getDefaults(), arguments, ["frequency", "delayTime", "depth"]);
            this._depth = options.depth;
            this._delayTime = options.delayTime / 1000;
            this._lfoL = new LFO({
                context: this.context,
                frequency: options.frequency,
                min: 0,
                max: 1,
            });
            this._lfoR = new LFO({
                context: this.context,
                frequency: options.frequency,
                min: 0,
                max: 1,
                phase: 180
            });
            this._delayNodeL = new Delay({ context: this.context });
            this._delayNodeR = new Delay({ context: this.context });
            this.frequency = this._lfoL.frequency;
            readOnly(this, ["frequency"]);
            // have one LFO frequency control the other
            this._lfoL.frequency.connect(this._lfoR.frequency);
            // connections
            this.connectEffectLeft(this._delayNodeL);
            this.connectEffectRight(this._delayNodeR);
            // lfo setup
            this._lfoL.connect(this._delayNodeL.delayTime);
            this._lfoR.connect(this._delayNodeR.delayTime);
            // set the initial values
            this.depth = this._depth;
            this.type = options.type;
            this.spread = options.spread;
        }
        static getDefaults() {
            return Object.assign(StereoFeedbackEffect.getDefaults(), {
                frequency: 1.5,
                delayTime: 3.5,
                depth: 0.7,
                type: "sine",
                spread: 180,
                feedback: 0,
                wet: 0.5,
            });
        }
        /**
         * The depth of the effect. A depth of 1 makes the delayTime
         * modulate between 0 and 2*delayTime (centered around the delayTime).
         */
        get depth() {
            return this._depth;
        }
        set depth(depth) {
            this._depth = depth;
            const deviation = this._delayTime * depth;
            this._lfoL.min = Math.max(this._delayTime - deviation, 0);
            this._lfoL.max = this._delayTime + deviation;
            this._lfoR.min = Math.max(this._delayTime - deviation, 0);
            this._lfoR.max = this._delayTime + deviation;
        }
        /**
         * The delayTime in milliseconds of the chorus. A larger delayTime
         * will give a more pronounced effect. Nominal range a delayTime
         * is between 2 and 20ms.
         */
        get delayTime() {
            return this._delayTime * 1000;
        }
        set delayTime(delayTime) {
            this._delayTime = delayTime / 1000;
            this.depth = this._depth;
        }
        /**
         * The oscillator type of the LFO.
         */
        get type() {
            return this._lfoL.type;
        }
        set type(type) {
            this._lfoL.type = type;
            this._lfoR.type = type;
        }
        /**
         * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.
         * When set to 180, LFO's will be panned hard left and right respectively.
         */
        get spread() {
            return this._lfoR.phase - this._lfoL.phase;
        }
        set spread(spread) {
            this._lfoL.phase = 90 - (spread / 2);
            this._lfoR.phase = (spread / 2) + 90;
        }
        /**
         * Start the effect.
         */
        start(time) {
            this._lfoL.start(time);
            this._lfoR.start(time);
            return this;
        }
        /**
         * Stop the lfo
         */
        stop(time) {
            this._lfoL.stop(time);
            this._lfoR.stop(time);
            return this;
        }
        /**
         * Sync the filter to the transport. See [[LFO.sync]]
         */
        sync() {
            this._lfoL.sync();
            this._lfoR.sync();
            return this;
        }
        /**
         * Unsync the filter from the transport.
         */
        unsync() {
            this._lfoL.unsync();
            this._lfoR.unsync();
            return this;
        }
        dispose() {
            super.dispose();
            this._lfoL.dispose();
            this._lfoR.dispose();
            this._delayNodeL.dispose();
            this._delayNodeR.dispose();
            this.frequency.dispose();
            return this;
        }
    }

    /**
     * A simple distortion effect using Tone.WaveShaper.
     * Algorithm from [this stackoverflow answer](http://stackoverflow.com/a/22313408).
     *
     * @example
     * const dist = new Tone.Distortion(0.8).toDestination();
     * const fm = new Tone.FMSynth().connect(dist);
     * fm.triggerAttackRelease("A1", "8n");
     * @category Effect
     */
    class Distortion extends Effect {
        constructor() {
            super(optionsFromArguments(Distortion.getDefaults(), arguments, ["distortion"]));
            this.name = "Distortion";
            const options = optionsFromArguments(Distortion.getDefaults(), arguments, ["distortion"]);
            this._shaper = new WaveShaper({
                context: this.context,
                length: 4096,
            });
            this._distortion = options.distortion;
            this.connectEffect(this._shaper);
            this.distortion = options.distortion;
            this.oversample = options.oversample;
        }
        static getDefaults() {
            return Object.assign(Effect.getDefaults(), {
                distortion: 0.4,
                oversample: "none",
            });
        }
        /**
         * The amount of distortion. Nominal range is between 0 and 1.
         */
        get distortion() {
            return this._distortion;
        }
        set distortion(amount) {
            this._distortion = amount;
            const k = amount * 100;
            const deg = Math.PI / 180;
            this._shaper.setMap((x) => {
                if (Math.abs(x) < 0.001) {
                    // should output 0 when input is 0
                    return 0;
                }
                else {
                    return (3 + k) * x * 20 * deg / (Math.PI + k * Math.abs(x));
                }
            });
        }
        /**
         * The oversampling of the effect. Can either be "none", "2x" or "4x".
         */
        get oversample() {
            return this._shaper.oversample;
        }
        set oversample(oversampling) {
            this._shaper.oversample = oversampling;
        }
        dispose() {
            super.dispose();
            this._shaper.dispose();
            return this;
        }
    }

    /**
     * FeedbackEffect provides a loop between an audio source and its own output.
     * This is a base-class for feedback effects.
     */
    class FeedbackEffect extends Effect {
        constructor(options) {
            super(options);
            this.name = "FeedbackEffect";
            this._feedbackGain = new Gain({
                context: this.context,
                gain: options.feedback,
                units: "normalRange",
            });
            this.feedback = this._feedbackGain.gain;
            readOnly(this, "feedback");
            // the feedback loop
            this.effectReturn.chain(this._feedbackGain, this.effectSend);
        }
        static getDefaults() {
            return Object.assign(Effect.getDefaults(), {
                feedback: 0.125,
            });
        }
        dispose() {
            super.dispose();
            this._feedbackGain.dispose();
            this.feedback.dispose();
            return this;
        }
    }

    /**
     * FeedbackDelay is a DelayNode in which part of output signal is fed back into the delay.
     *
     * @param delayTime The delay applied to the incoming signal.
     * @param feedback The amount of the effected signal which is fed back through the delay.
     * @example
     * const feedbackDelay = new Tone.FeedbackDelay("8n", 0.5).toDestination();
     * const tom = new Tone.MembraneSynth({
     * 	octaves: 4,
     * 	pitchDecay: 0.1
     * }).connect(feedbackDelay);
     * tom.triggerAttackRelease("A2", "32n");
     * @category Effect
     */
    class FeedbackDelay extends FeedbackEffect {
        constructor() {
            super(optionsFromArguments(FeedbackDelay.getDefaults(), arguments, ["delayTime", "feedback"]));
            this.name = "FeedbackDelay";
            const options = optionsFromArguments(FeedbackDelay.getDefaults(), arguments, ["delayTime", "feedback"]);
            this._delayNode = new Delay({
                context: this.context,
                delayTime: options.delayTime,
                maxDelay: options.maxDelay,
            });
            this.delayTime = this._delayNode.delayTime;
            // connect it up
            this.connectEffect(this._delayNode);
            readOnly(this, "delayTime");
        }
        static getDefaults() {
            return Object.assign(FeedbackEffect.getDefaults(), {
                delayTime: 0.25,
                maxDelay: 1,
            });
        }
        dispose() {
            super.dispose();
            this._delayNode.dispose();
            this.delayTime.dispose();
            return this;
        }
    }

    /**
     * PhaseShiftAllpass is an very efficient implementation of a Hilbert Transform
     * using two Allpass filter banks whose outputs have a phase difference of 90°.
     * Here the `offset90` phase is offset by +90° in relation to `output`.
     * Coefficients and structure was developed by Olli Niemitalo.
     * For more details see: http://yehar.com/blog/?p=368
     * @category Component
     */
    class PhaseShiftAllpass extends ToneAudioNode {
        constructor(options) {
            super(options);
            this.name = "PhaseShiftAllpass";
            this.input = new Gain({ context: this.context });
            /**
             * The phase shifted output
             */
            this.output = new Gain({ context: this.context });
            /**
             * The PhaseShifted allpass output
             */
            this.offset90 = new Gain({ context: this.context });
            const allpassBank1Values = [0.6923878, 0.9360654322959, 0.9882295226860, 0.9987488452737];
            const allpassBank2Values = [0.4021921162426, 0.8561710882420, 0.9722909545651, 0.9952884791278];
            this._bank0 = this._createAllPassFilterBank(allpassBank1Values);
            this._bank1 = this._createAllPassFilterBank(allpassBank2Values);
            this._oneSampleDelay = this.context.createIIRFilter([0.0, 1.0], [1.0, 0.0]);
            // connect Allpass filter banks
            connectSeries(this.input, ...this._bank0, this._oneSampleDelay, this.output);
            connectSeries(this.input, ...this._bank1, this.offset90);
        }
        /**
         * Create all of the IIR filters from an array of values using the coefficient calculation.
         */
        _createAllPassFilterBank(bankValues) {
            const nodes = bankValues.map(value => {
                const coefficients = [[value * value, 0, -1], [1, 0, -(value * value)]];
                return this.context.createIIRFilter(coefficients[0], coefficients[1]);
            });
            return nodes;
        }
        dispose() {
            super.dispose();
            this.input.dispose();
            this.output.dispose();
            this.offset90.dispose();
            this._bank0.forEach(f => f.disconnect());
            this._bank1.forEach(f => f.disconnect());
            this._oneSampleDelay.disconnect();
            return this;
        }
    }

    /**
     * FrequencyShifter can be used to shift all frequencies of a signal by a fixed amount.
     * The amount can be changed at audio rate and the effect is applied in real time.
     * The frequency shifting is implemented with a technique called single side band modulation using a ring modulator.
     * Note: Contrary to pitch shifting, all frequencies are shifted by the same amount,
     * destroying the harmonic relationship between them. This leads to the classic ring modulator timbre distortion.
     * The algorithm will produces some aliasing towards the high end, especially if your source material
     * contains a lot of high frequencies. Unfortunatelly the webaudio API does not support resampling
     * buffers in real time, so it is not possible to fix it properly. Depending on the use case it might
     * be an option to low pass filter your input before frequency shifting it to get ride of the aliasing.
     * You can find a very detailed description of the algorithm here: https://larzeitlin.github.io/RMFS/
     *
     * @example
     * const input = new Tone.Oscillator(230, "sawtooth").start();
     * const shift = new Tone.FrequencyShifter(42).toDestination();
     * input.connect(shift);
     * @category Effect
     */
    class FrequencyShifter extends Effect {
        constructor() {
            super(optionsFromArguments(FrequencyShifter.getDefaults(), arguments, ["frequency"]));
            this.name = "FrequencyShifter";
            const options = optionsFromArguments(FrequencyShifter.getDefaults(), arguments, ["frequency"]);
            this.frequency = new Signal({
                context: this.context,
                units: "frequency",
                value: options.frequency,
                minValue: -this.context.sampleRate / 2,
                maxValue: this.context.sampleRate / 2,
            });
            this._sine = new ToneOscillatorNode({
                context: this.context,
                type: "sine",
            });
            this._cosine = new Oscillator({
                context: this.context,
                phase: -90,
                type: "sine",
            });
            this._sineMultiply = new Multiply({ context: this.context });
            this._cosineMultiply = new Multiply({ context: this.context });
            this._negate = new Negate({ context: this.context });
            this._add = new Add({ context: this.context });
            this._phaseShifter = new PhaseShiftAllpass({ context: this.context });
            this.effectSend.connect(this._phaseShifter);
            // connect the carrier frequency signal to the two oscillators
            this.frequency.fan(this._sine.frequency, this._cosine.frequency);
            this._phaseShifter.offset90.connect(this._cosineMultiply);
            this._cosine.connect(this._cosineMultiply.factor);
            this._phaseShifter.connect(this._sineMultiply);
            this._sine.connect(this._sineMultiply.factor);
            this._sineMultiply.connect(this._negate);
            this._cosineMultiply.connect(this._add);
            this._negate.connect(this._add.addend);
            this._add.connect(this.effectReturn);
            // start the oscillators at the same time
            const now = this.immediate();
            this._sine.start(now);
            this._cosine.start(now);
        }
        static getDefaults() {
            return Object.assign(Effect.getDefaults(), {
                frequency: 0,
            });
        }
        dispose() {
            super.dispose();
            this.frequency.dispose();
            this._add.dispose();
            this._cosine.dispose();
            this._cosineMultiply.dispose();
            this._negate.dispose();
            this._phaseShifter.dispose();
            this._sine.dispose();
            this._sineMultiply.dispose();
            return this;
        }
    }

    /**
     * An array of comb filter delay values from Freeverb implementation
     */
    const combFilterTunings = [1557 / 44100, 1617 / 44100, 1491 / 44100, 1422 / 44100, 1277 / 44100, 1356 / 44100, 1188 / 44100, 1116 / 44100];
    /**
     * An array of allpass filter frequency values from Freeverb implementation
     */
    const allpassFilterFrequencies = [225, 556, 441, 341];
    /**
     * Freeverb is a reverb based on [Freeverb](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html).
     * Read more on reverb on [Sound On Sound](https://web.archive.org/web/20160404083902/http://www.soundonsound.com:80/sos/feb01/articles/synthsecrets.asp).
     * Freeverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using [[Reverb]].
     * @example
     * const freeverb = new Tone.Freeverb().toDestination();
     * freeverb.dampening = 1000;
     * // routing synth through the reverb
     * const synth = new Tone.NoiseSynth().connect(freeverb);
     * synth.triggerAttackRelease(0.05);
     * @category Effect
     */
    class Freeverb extends StereoEffect {
        constructor() {
            super(optionsFromArguments(Freeverb.getDefaults(), arguments, ["roomSize", "dampening"]));
            this.name = "Freeverb";
            /**
             * the comb filters
             */
            this._combFilters = [];
            /**
             * the allpass filters on the left
             */
            this._allpassFiltersL = [];
            /**
             * the allpass filters on the right
             */
            this._allpassFiltersR = [];
            const options = optionsFromArguments(Freeverb.getDefaults(), arguments, ["roomSize", "dampening"]);
            this.roomSize = new Signal({
                context: this.context,
                value: options.roomSize,
                units: "normalRange",
            });
            // make the allpass filters on the right
            this._allpassFiltersL = allpassFilterFrequencies.map(freq => {
                const allpassL = this.context.createBiquadFilter();
                allpassL.type = "allpass";
                allpassL.frequency.value = freq;
                return allpassL;
            });
            // make the allpass filters on the left
            this._allpassFiltersR = allpassFilterFrequencies.map(freq => {
                const allpassR = this.context.createBiquadFilter();
                allpassR.type = "allpass";
                allpassR.frequency.value = freq;
                return allpassR;
            });
            // make the comb filters
            this._combFilters = combFilterTunings.map((delayTime, index) => {
                const lfpf = new LowpassCombFilter({
                    context: this.context,
                    dampening: options.dampening,
                    delayTime,
                });
                if (index < combFilterTunings.length / 2) {
                    this.connectEffectLeft(lfpf, ...this._allpassFiltersL);
                }
                else {
                    this.connectEffectRight(lfpf, ...this._allpassFiltersR);
                }
                this.roomSize.connect(lfpf.resonance);
                return lfpf;
            });
            readOnly(this, ["roomSize"]);
        }
        static getDefaults() {
            return Object.assign(StereoEffect.getDefaults(), {
                roomSize: 0.7,
                dampening: 3000
            });
        }
        /**
         * The amount of dampening of the reverberant signal.
         */
        get dampening() {
            return this._combFilters[0].dampening;
        }
        set dampening(d) {
            this._combFilters.forEach(c => c.dampening = d);
        }
        dispose() {
            super.dispose();
            this._allpassFiltersL.forEach(al => al.disconnect());
            this._allpassFiltersR.forEach(ar => ar.disconnect());
            this._combFilters.forEach(cf => cf.dispose());
            this.roomSize.dispose();
            return this;
        }
    }

    /**
     * an array of the comb filter delay time values
     */
    const combFilterDelayTimes = [1687 / 25000, 1601 / 25000, 2053 / 25000, 2251 / 25000];
    /**
     * the resonances of each of the comb filters
     */
    const combFilterResonances = [0.773, 0.802, 0.753, 0.733];
    /**
     * the allpass filter frequencies
     */
    const allpassFilterFreqs = [347, 113, 37];
    /**
     * JCReverb is a simple [Schroeder Reverberator](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Reverberators.html)
     * tuned by John Chowning in 1970.
     * It is made up of three allpass filters and four [[FeedbackCombFilter]].
     * JCReverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using [[Reverb]].
     * @example
     * const reverb = new Tone.JCReverb(0.4).toDestination();
     * const delay = new Tone.FeedbackDelay(0.5);
     * // connecting the synth to reverb through delay
     * const synth = new Tone.DuoSynth().chain(delay, reverb);
     * synth.triggerAttackRelease("A4", "8n");
     *
     * @category Effect
     */
    class JCReverb extends StereoEffect {
        constructor() {
            super(optionsFromArguments(JCReverb.getDefaults(), arguments, ["roomSize"]));
            this.name = "JCReverb";
            /**
             * a series of allpass filters
             */
            this._allpassFilters = [];
            /**
             * parallel feedback comb filters
             */
            this._feedbackCombFilters = [];
            const options = optionsFromArguments(JCReverb.getDefaults(), arguments, ["roomSize"]);
            this.roomSize = new Signal({
                context: this.context,
                value: options.roomSize,
                units: "normalRange",
            });
            this._scaleRoomSize = new Scale({
                context: this.context,
                min: -0.733,
                max: 0.197,
            });
            // make the allpass filters
            this._allpassFilters = allpassFilterFreqs.map(freq => {
                const allpass = this.context.createBiquadFilter();
                allpass.type = "allpass";
                allpass.frequency.value = freq;
                return allpass;
            });
            // and the comb filters
            this._feedbackCombFilters = combFilterDelayTimes.map((delayTime, index) => {
                const fbcf = new FeedbackCombFilter({
                    context: this.context,
                    delayTime,
                });
                this._scaleRoomSize.connect(fbcf.resonance);
                fbcf.resonance.value = combFilterResonances[index];
                if (index < combFilterDelayTimes.length / 2) {
                    this.connectEffectLeft(...this._allpassFilters, fbcf);
                }
                else {
                    this.connectEffectRight(...this._allpassFilters, fbcf);
                }
                return fbcf;
            });
            // chain the allpass filters together
            this.roomSize.connect(this._scaleRoomSize);
            readOnly(this, ["roomSize"]);
        }
        static getDefaults() {
            return Object.assign(StereoEffect.getDefaults(), {
                roomSize: 0.5,
            });
        }
        dispose() {
            super.dispose();
            this._allpassFilters.forEach(apf => apf.disconnect());
            this._feedbackCombFilters.forEach(fbcf => fbcf.dispose());
            this.roomSize.dispose();
            this._scaleRoomSize.dispose();
            return this;
        }
    }

    /**
     * Just like a [[StereoFeedbackEffect]], but the feedback is routed from left to right
     * and right to left instead of on the same channel.
     * ```
     * +--------------------------------+ feedbackL <-----------------------------------+
     * |                                                                                |
     * +-->                          +----->        +---->                          +-----+
     *      feedbackMerge +--> split        (EFFECT)       merge +--> feedbackSplit     | |
     * +-->                          +----->        +---->                          +---+ |
     * |                                                                                  |
     * +--------------------------------+ feedbackR <-------------------------------------+
     * ```
     */
    class StereoXFeedbackEffect extends StereoFeedbackEffect {
        constructor(options) {
            super(options);
            // the left output connected to the right input
            this._feedbackL.disconnect();
            this._feedbackL.connect(this._feedbackMerge, 0, 1);
            // the left output connected to the right input
            this._feedbackR.disconnect();
            this._feedbackR.connect(this._feedbackMerge, 0, 0);
            readOnly(this, ["feedback"]);
        }
    }

    /**
     * PingPongDelay is a feedback delay effect where the echo is heard
     * first in one channel and next in the opposite channel. In a stereo
     * system these are the right and left channels.
     * PingPongDelay in more simplified terms is two Tone.FeedbackDelays
     * with independent delay values. Each delay is routed to one channel
     * (left or right), and the channel triggered second will always
     * trigger at the same interval after the first.
     * @example
     * const pingPong = new Tone.PingPongDelay("4n", 0.2).toDestination();
     * const drum = new Tone.MembraneSynth().connect(pingPong);
     * drum.triggerAttackRelease("C4", "32n");
     * @category Effect
     */
    class PingPongDelay extends StereoXFeedbackEffect {
        constructor() {
            super(optionsFromArguments(PingPongDelay.getDefaults(), arguments, ["delayTime", "feedback"]));
            this.name = "PingPongDelay";
            const options = optionsFromArguments(PingPongDelay.getDefaults(), arguments, ["delayTime", "feedback"]);
            this._leftDelay = new Delay({
                context: this.context,
                maxDelay: options.maxDelay,
            });
            this._rightDelay = new Delay({
                context: this.context,
                maxDelay: options.maxDelay
            });
            this._rightPreDelay = new Delay({
                context: this.context,
                maxDelay: options.maxDelay
            });
            this.delayTime = new Signal({
                context: this.context,
                units: "time",
                value: options.delayTime,
            });
            // connect it up
            this.connectEffectLeft(this._leftDelay);
            this.connectEffectRight(this._rightPreDelay, this._rightDelay);
            this.delayTime.fan(this._leftDelay.delayTime, this._rightDelay.delayTime, this._rightPreDelay.delayTime);
            // rearranged the feedback to be after the rightPreDelay
            this._feedbackL.disconnect();
            this._feedbackL.connect(this._rightDelay);
            readOnly(this, ["delayTime"]);
        }
        static getDefaults() {
            return Object.assign(StereoXFeedbackEffect.getDefaults(), {
                delayTime: 0.25,
                maxDelay: 1
            });
        }
        dispose() {
            super.dispose();
            this._leftDelay.dispose();
            this._rightDelay.dispose();
            this._rightPreDelay.dispose();
            this.delayTime.dispose();
            return this;
        }
    }

    /**
     * PitchShift does near-realtime pitch shifting to the incoming signal.
     * The effect is achieved by speeding up or slowing down the delayTime
     * of a DelayNode using a sawtooth wave.
     * Algorithm found in [this pdf](http://dsp-book.narod.ru/soundproc.pdf).
     * Additional reference by [Miller Pucket](http://msp.ucsd.edu/techniques/v0.11/book-html/node115.html).
     * @category Effect
     */
    class PitchShift extends FeedbackEffect {
        constructor() {
            super(optionsFromArguments(PitchShift.getDefaults(), arguments, ["pitch"]));
            this.name = "PitchShift";
            const options = optionsFromArguments(PitchShift.getDefaults(), arguments, ["pitch"]);
            this._frequency = new Signal({ context: this.context });
            this._delayA = new Delay({
                maxDelay: 1,
                context: this.context
            });
            this._lfoA = new LFO({
                context: this.context,
                min: 0,
                max: 0.1,
                type: "sawtooth"
            }).connect(this._delayA.delayTime);
            this._delayB = new Delay({
                maxDelay: 1,
                context: this.context
            });
            this._lfoB = new LFO({
                context: this.context,
                min: 0,
                max: 0.1,
                type: "sawtooth",
                phase: 180
            }).connect(this._delayB.delayTime);
            this._crossFade = new CrossFade({ context: this.context });
            this._crossFadeLFO = new LFO({
                context: this.context,
                min: 0,
                max: 1,
                type: "triangle",
                phase: 90
            }).connect(this._crossFade.fade);
            this._feedbackDelay = new Delay({
                delayTime: options.delayTime,
                context: this.context,
            });
            this.delayTime = this._feedbackDelay.delayTime;
            readOnly(this, "delayTime");
            this._pitch = options.pitch;
            this._windowSize = options.windowSize;
            // connect the two delay lines up
            this._delayA.connect(this._crossFade.a);
            this._delayB.connect(this._crossFade.b);
            // connect the frequency
            this._frequency.fan(this._lfoA.frequency, this._lfoB.frequency, this._crossFadeLFO.frequency);
            // route the input
            this.effectSend.fan(this._delayA, this._delayB);
            this._crossFade.chain(this._feedbackDelay, this.effectReturn);
            // start the LFOs at the same time
            const now = this.now();
            this._lfoA.start(now);
            this._lfoB.start(now);
            this._crossFadeLFO.start(now);
            // set the initial value
            this.windowSize = this._windowSize;
        }
        static getDefaults() {
            return Object.assign(FeedbackEffect.getDefaults(), {
                pitch: 0,
                windowSize: 0.1,
                delayTime: 0,
                feedback: 0
            });
        }
        /**
         * Repitch the incoming signal by some interval (measured in semi-tones).
         * @example
         * const pitchShift = new Tone.PitchShift().toDestination();
         * const osc = new Tone.Oscillator().connect(pitchShift).start().toDestination();
         * pitchShift.pitch = -12; // down one octave
         * pitchShift.pitch = 7; // up a fifth
         */
        get pitch() {
            return this._pitch;
        }
        set pitch(interval) {
            this._pitch = interval;
            let factor = 0;
            if (interval < 0) {
                this._lfoA.min = 0;
                this._lfoA.max = this._windowSize;
                this._lfoB.min = 0;
                this._lfoB.max = this._windowSize;
                factor = intervalToFrequencyRatio(interval - 1) + 1;
            }
            else {
                this._lfoA.min = this._windowSize;
                this._lfoA.max = 0;
                this._lfoB.min = this._windowSize;
                this._lfoB.max = 0;
                factor = intervalToFrequencyRatio(interval) - 1;
            }
            this._frequency.value = factor * (1.2 / this._windowSize);
        }
        /**
         * The window size corresponds roughly to the sample length in a looping sampler.
         * Smaller values are desirable for a less noticeable delay time of the pitch shifted
         * signal, but larger values will result in smoother pitch shifting for larger intervals.
         * A nominal range of 0.03 to 0.1 is recommended.
         */
        get windowSize() {
            return this._windowSize;
        }
        set windowSize(size) {
            this._windowSize = this.toSeconds(size);
            this.pitch = this._pitch;
        }
        dispose() {
            super.dispose();
            this._frequency.dispose();
            this._delayA.dispose();
            this._delayB.dispose();
            this._lfoA.dispose();
            this._lfoB.dispose();
            this._crossFade.dispose();
            this._crossFadeLFO.dispose();
            this._feedbackDelay.dispose();
            return this;
        }
    }

    /**
     * Phaser is a phaser effect. Phasers work by changing the phase
     * of different frequency components of an incoming signal. Read more on
     * [Wikipedia](https://en.wikipedia.org/wiki/Phaser_(effect)).
     * Inspiration for this phaser comes from [Tuna.js](https://github.com/Dinahmoe/tuna/).
     * @example
     * const phaser = new Tone.Phaser({
     * 	frequency: 15,
     * 	octaves: 5,
     * 	baseFrequency: 1000
     * }).toDestination();
     * const synth = new Tone.FMSynth().connect(phaser);
     * synth.triggerAttackRelease("E3", "2n");
     * @category Effect
     */
    class Phaser extends StereoEffect {
        constructor() {
            super(optionsFromArguments(Phaser.getDefaults(), arguments, ["frequency", "octaves", "baseFrequency"]));
            this.name = "Phaser";
            const options = optionsFromArguments(Phaser.getDefaults(), arguments, ["frequency", "octaves", "baseFrequency"]);
            this._lfoL = new LFO({
                context: this.context,
                frequency: options.frequency,
                min: 0,
                max: 1
            });
            this._lfoR = new LFO({
                context: this.context,
                frequency: options.frequency,
                min: 0,
                max: 1,
                phase: 180,
            });
            this._baseFrequency = this.toFrequency(options.baseFrequency);
            this._octaves = options.octaves;
            this.Q = new Signal({
                context: this.context,
                value: options.Q,
                units: "positive",
            });
            this._filtersL = this._makeFilters(options.stages, this._lfoL);
            this._filtersR = this._makeFilters(options.stages, this._lfoR);
            this.frequency = this._lfoL.frequency;
            this.frequency.value = options.frequency;
            // connect them up
            this.connectEffectLeft(...this._filtersL);
            this.connectEffectRight(...this._filtersR);
            // control the frequency with one LFO
            this._lfoL.frequency.connect(this._lfoR.frequency);
            // set the options
            this.baseFrequency = options.baseFrequency;
            this.octaves = options.octaves;
            // start the lfo
            this._lfoL.start();
            this._lfoR.start();
            readOnly(this, ["frequency", "Q"]);
        }
        static getDefaults() {
            return Object.assign(StereoEffect.getDefaults(), {
                frequency: 0.5,
                octaves: 3,
                stages: 10,
                Q: 10,
                baseFrequency: 350,
            });
        }
        _makeFilters(stages, connectToFreq) {
            const filters = [];
            // make all the filters
            for (let i = 0; i < stages; i++) {
                const filter = this.context.createBiquadFilter();
                filter.type = "allpass";
                this.Q.connect(filter.Q);
                connectToFreq.connect(filter.frequency);
                filters.push(filter);
            }
            return filters;
        }
        /**
         * The number of octaves the phase goes above the baseFrequency
         */
        get octaves() {
            return this._octaves;
        }
        set octaves(octaves) {
            this._octaves = octaves;
            const max = this._baseFrequency * Math.pow(2, octaves);
            this._lfoL.max = max;
            this._lfoR.max = max;
        }
        /**
         * The the base frequency of the filters.
         */
        get baseFrequency() {
            return this._baseFrequency;
        }
        set baseFrequency(freq) {
            this._baseFrequency = this.toFrequency(freq);
            this._lfoL.min = this._baseFrequency;
            this._lfoR.min = this._baseFrequency;
            this.octaves = this._octaves;
        }
        dispose() {
            super.dispose();
            this.Q.dispose();
            this._lfoL.dispose();
            this._lfoR.dispose();
            this._filtersL.forEach(f => f.disconnect());
            this._filtersR.forEach(f => f.disconnect());
            this.frequency.dispose();
            return this;
        }
    }

    /**
     * Simple convolution created with decaying noise.
     * Generates an Impulse Response Buffer
     * with Tone.Offline then feeds the IR into ConvolverNode.
     * The impulse response generation is async, so you have
     * to wait until [[ready]] resolves before it will make a sound.
     *
     * Inspiration from [ReverbGen](https://github.com/adelespinasse/reverbGen).
     * Copyright (c) 2014 Alan deLespinasse Apache 2.0 License.
     *
     * @category Effect
     */
    class Reverb extends Effect {
        constructor() {
            super(optionsFromArguments(Reverb.getDefaults(), arguments, ["decay"]));
            this.name = "Reverb";
            /**
             * Convolver node
             */
            this._convolver = this.context.createConvolver();
            /**
             * Resolves when the reverb buffer is generated. Whenever either [[decay]]
             * or [[preDelay]] are set, you have to wait until [[ready]] resolves
             * before the IR is generated with the latest values.
             */
            this.ready = Promise.resolve();
            const options = optionsFromArguments(Reverb.getDefaults(), arguments, ["decay"]);
            this._decay = options.decay;
            this._preDelay = options.preDelay;
            this.generate();
            this.connectEffect(this._convolver);
        }
        static getDefaults() {
            return Object.assign(Effect.getDefaults(), {
                decay: 1.5,
                preDelay: 0.01,
            });
        }
        /**
         * The duration of the reverb.
         */
        get decay() {
            return this._decay;
        }
        set decay(time) {
            time = this.toSeconds(time);
            assertRange(time, 0.001);
            this._decay = time;
            this.generate();
        }
        /**
         * The amount of time before the reverb is fully ramped in.
         */
        get preDelay() {
            return this._preDelay;
        }
        set preDelay(time) {
            time = this.toSeconds(time);
            assertRange(time, 0);
            this._preDelay = time;
            this.generate();
        }
        /**
         * Generate the Impulse Response. Returns a promise while the IR is being generated.
         * @return Promise which returns this object.
         */
        generate() {
            return __awaiter(this, void 0, void 0, function* () {
                const previousReady = this.ready;
                // create a noise burst which decays over the duration in each channel
                const context = new OfflineContext(2, this._decay + this._preDelay, this.context.sampleRate);
                const noiseL = new Noise({ context });
                const noiseR = new Noise({ context });
                const merge = new Merge({ context });
                noiseL.connect(merge, 0, 0);
                noiseR.connect(merge, 0, 1);
                const gainNode = new Gain({ context }).toDestination();
                merge.connect(gainNode);
                noiseL.start(0);
                noiseR.start(0);
                // predelay
                gainNode.gain.setValueAtTime(0, 0);
                gainNode.gain.setValueAtTime(1, this._preDelay);
                // decay
                gainNode.gain.exponentialApproachValueAtTime(0, this._preDelay, this.decay);
                // render the buffer
                const renderPromise = context.render();
                this.ready = renderPromise.then(noOp);
                // wait for the previous `ready` to resolve
                yield previousReady;
                // set the buffer
                this._convolver.buffer = (yield renderPromise).get();
                return this;
            });
        }
        dispose() {
            super.dispose();
            this._convolver.disconnect();
            return this;
        }
    }

    /**
     * Mid/Side processing separates the the 'mid' signal (which comes out of both the left and the right channel)
     * and the 'side' (which only comes out of the the side channels).
     * ```
     * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right
     * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right
     * ```
     * @category Component
     */
    class MidSideSplit extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(MidSideSplit.getDefaults(), arguments));
            this.name = "MidSideSplit";
            this._split = this.input = new Split({
                channels: 2,
                context: this.context
            });
            this._midAdd = new Add({ context: this.context });
            this.mid = new Multiply({
                context: this.context,
                value: Math.SQRT1_2,
            });
            this._sideSubtract = new Subtract({ context: this.context });
            this.side = new Multiply({
                context: this.context,
                value: Math.SQRT1_2,
            });
            this._split.connect(this._midAdd, 0);
            this._split.connect(this._midAdd.addend, 1);
            this._split.connect(this._sideSubtract, 0);
            this._split.connect(this._sideSubtract.subtrahend, 1);
            this._midAdd.connect(this.mid);
            this._sideSubtract.connect(this.side);
        }
        dispose() {
            super.dispose();
            this.mid.dispose();
            this.side.dispose();
            this._midAdd.dispose();
            this._sideSubtract.dispose();
            this._split.dispose();
            return this;
        }
    }

    /**
     * MidSideMerge merges the mid and side signal after they've been separated by [[MidSideSplit]]
     * ```
     * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right
     * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right
     * ```
     * @category Component
     */
    class MidSideMerge extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(MidSideMerge.getDefaults(), arguments));
            this.name = "MidSideMerge";
            this.mid = new Gain({ context: this.context });
            this.side = new Gain({ context: this.context });
            this._left = new Add({ context: this.context });
            this._leftMult = new Multiply({
                context: this.context,
                value: Math.SQRT1_2
            });
            this._right = new Subtract({ context: this.context });
            this._rightMult = new Multiply({
                context: this.context,
                value: Math.SQRT1_2
            });
            this._merge = this.output = new Merge({ context: this.context });
            this.mid.fan(this._left);
            this.side.connect(this._left.addend);
            this.mid.connect(this._right);
            this.side.connect(this._right.subtrahend);
            this._left.connect(this._leftMult);
            this._right.connect(this._rightMult);
            this._leftMult.connect(this._merge, 0, 0);
            this._rightMult.connect(this._merge, 0, 1);
        }
        dispose() {
            super.dispose();
            this.mid.dispose();
            this.side.dispose();
            this._leftMult.dispose();
            this._rightMult.dispose();
            this._left.dispose();
            this._right.dispose();
            return this;
        }
    }

    /**
     * Mid/Side processing separates the the 'mid' signal
     * (which comes out of both the left and the right channel)
     * and the 'side' (which only comes out of the the side channels)
     * and effects them separately before being recombined.
     * Applies a Mid/Side seperation and recombination.
     * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).
     * This is a base-class for Mid/Side Effects.
     * @category Effect
     */
    class MidSideEffect extends Effect {
        constructor(options) {
            super(options);
            this.name = "MidSideEffect";
            this._midSideMerge = new MidSideMerge({ context: this.context });
            this._midSideSplit = new MidSideSplit({ context: this.context });
            this._midSend = this._midSideSplit.mid;
            this._sideSend = this._midSideSplit.side;
            this._midReturn = this._midSideMerge.mid;
            this._sideReturn = this._midSideMerge.side;
            // the connections
            this.effectSend.connect(this._midSideSplit);
            this._midSideMerge.connect(this.effectReturn);
        }
        /**
         * Connect the mid chain of the effect
         */
        connectEffectMid(...nodes) {
            this._midSend.chain(...nodes, this._midReturn);
        }
        /**
         * Connect the side chain of the effect
         */
        connectEffectSide(...nodes) {
            this._sideSend.chain(...nodes, this._sideReturn);
        }
        dispose() {
            super.dispose();
            this._midSideSplit.dispose();
            this._midSideMerge.dispose();
            this._midSend.dispose();
            this._sideSend.dispose();
            this._midReturn.dispose();
            this._sideReturn.dispose();
            return this;
        }
    }

    /**
     * Applies a width factor to the mid/side seperation.
     * 0 is all mid and 1 is all side.
     * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).
     * ```
     * Mid *= 2*(1-width)<br>
     * Side *= 2*width
     * ```
     * @category Effect
     */
    class StereoWidener extends MidSideEffect {
        constructor() {
            super(optionsFromArguments(StereoWidener.getDefaults(), arguments, ["width"]));
            this.name = "StereoWidener";
            const options = optionsFromArguments(StereoWidener.getDefaults(), arguments, ["width"]);
            this.width = new Signal({
                context: this.context,
                value: options.width,
                units: "normalRange",
            });
            readOnly(this, ["width"]);
            this._twoTimesWidthMid = new Multiply({
                context: this.context,
                value: 2,
            });
            this._twoTimesWidthSide = new Multiply({
                context: this.context,
                value: 2,
            });
            this._midMult = new Multiply({ context: this.context });
            this._twoTimesWidthMid.connect(this._midMult.factor);
            this.connectEffectMid(this._midMult);
            this._oneMinusWidth = new Subtract({ context: this.context });
            this._oneMinusWidth.connect(this._twoTimesWidthMid);
            connect(this.context.getConstant(1), this._oneMinusWidth);
            this.width.connect(this._oneMinusWidth.subtrahend);
            this._sideMult = new Multiply({ context: this.context });
            this.width.connect(this._twoTimesWidthSide);
            this._twoTimesWidthSide.connect(this._sideMult.factor);
            this.connectEffectSide(this._sideMult);
        }
        static getDefaults() {
            return Object.assign(MidSideEffect.getDefaults(), {
                width: 0.5,
            });
        }
        dispose() {
            super.dispose();
            this.width.dispose();
            this._midMult.dispose();
            this._sideMult.dispose();
            this._twoTimesWidthMid.dispose();
            this._twoTimesWidthSide.dispose();
            this._oneMinusWidth.dispose();
            return this;
        }
    }

    /**
     * Tremolo modulates the amplitude of an incoming signal using an [[LFO]].
     * The effect is a stereo effect where the modulation phase is inverted in each channel.
     *
     * @example
     * // create a tremolo and start it's LFO
     * const tremolo = new Tone.Tremolo(9, 0.75).toDestination().start();
     * // route an oscillator through the tremolo and start it
     * const oscillator = new Tone.Oscillator().connect(tremolo).start();
     *
     * @category Effect
     */
    class Tremolo extends StereoEffect {
        constructor() {
            super(optionsFromArguments(Tremolo.getDefaults(), arguments, ["frequency", "depth"]));
            this.name = "Tremolo";
            const options = optionsFromArguments(Tremolo.getDefaults(), arguments, ["frequency", "depth"]);
            this._lfoL = new LFO({
                context: this.context,
                type: options.type,
                min: 1,
                max: 0,
            });
            this._lfoR = new LFO({
                context: this.context,
                type: options.type,
                min: 1,
                max: 0,
            });
            this._amplitudeL = new Gain({ context: this.context });
            this._amplitudeR = new Gain({ context: this.context });
            this.frequency = new Signal({
                context: this.context,
                value: options.frequency,
                units: "frequency",
            });
            this.depth = new Signal({
                context: this.context,
                value: options.depth,
                units: "normalRange",
            });
            readOnly(this, ["frequency", "depth"]);
            this.connectEffectLeft(this._amplitudeL);
            this.connectEffectRight(this._amplitudeR);
            this._lfoL.connect(this._amplitudeL.gain);
            this._lfoR.connect(this._amplitudeR.gain);
            this.frequency.fan(this._lfoL.frequency, this._lfoR.frequency);
            this.depth.fan(this._lfoR.amplitude, this._lfoL.amplitude);
            this.spread = options.spread;
        }
        static getDefaults() {
            return Object.assign(StereoEffect.getDefaults(), {
                frequency: 10,
                type: "sine",
                depth: 0.5,
                spread: 180,
            });
        }
        /**
         * Start the tremolo.
         */
        start(time) {
            this._lfoL.start(time);
            this._lfoR.start(time);
            return this;
        }
        /**
         * Stop the tremolo.
         */
        stop(time) {
            this._lfoL.stop(time);
            this._lfoR.stop(time);
            return this;
        }
        /**
         * Sync the effect to the transport.
         */
        sync() {
            this._lfoL.sync();
            this._lfoR.sync();
            this.context.transport.syncSignal(this.frequency);
            return this;
        }
        /**
         * Unsync the filter from the transport
         */
        unsync() {
            this._lfoL.unsync();
            this._lfoR.unsync();
            this.context.transport.unsyncSignal(this.frequency);
            return this;
        }
        /**
         * The oscillator type.
         */
        get type() {
            return this._lfoL.type;
        }
        set type(type) {
            this._lfoL.type = type;
            this._lfoR.type = type;
        }
        /**
         * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.
         * When set to 180, LFO's will be panned hard left and right respectively.
         */
        get spread() {
            return this._lfoR.phase - this._lfoL.phase; // 180
        }
        set spread(spread) {
            this._lfoL.phase = 90 - (spread / 2);
            this._lfoR.phase = (spread / 2) + 90;
        }
        dispose() {
            super.dispose();
            this._lfoL.dispose();
            this._lfoR.dispose();
            this._amplitudeL.dispose();
            this._amplitudeR.dispose();
            this.frequency.dispose();
            this.depth.dispose();
            return this;
        }
    }

    /**
     * A Vibrato effect composed of a Tone.Delay and a Tone.LFO. The LFO
     * modulates the delayTime of the delay, causing the pitch to rise and fall.
     * @category Effect
     */
    class Vibrato extends Effect {
        constructor() {
            super(optionsFromArguments(Vibrato.getDefaults(), arguments, ["frequency", "depth"]));
            this.name = "Vibrato";
            const options = optionsFromArguments(Vibrato.getDefaults(), arguments, ["frequency", "depth"]);
            this._delayNode = new Delay({
                context: this.context,
                delayTime: 0,
                maxDelay: options.maxDelay,
            });
            this._lfo = new LFO({
                context: this.context,
                type: options.type,
                min: 0,
                max: options.maxDelay,
                frequency: options.frequency,
                phase: -90 // offse the phase so the resting position is in the center
            }).start().connect(this._delayNode.delayTime);
            this.frequency = this._lfo.frequency;
            this.depth = this._lfo.amplitude;
            this.depth.value = options.depth;
            readOnly(this, ["frequency", "depth"]);
            this.effectSend.chain(this._delayNode, this.effectReturn);
        }
        static getDefaults() {
            return Object.assign(Effect.getDefaults(), {
                maxDelay: 0.005,
                frequency: 5,
                depth: 0.1,
                type: "sine"
            });
        }
        /**
         * Type of oscillator attached to the Vibrato.
         */
        get type() {
            return this._lfo.type;
        }
        set type(type) {
            this._lfo.type = type;
        }
        dispose() {
            super.dispose();
            this._delayNode.dispose();
            this._lfo.dispose();
            this.frequency.dispose();
            this.depth.dispose();
            return this;
        }
    }

    /**
     * Wrapper around the native Web Audio's [AnalyserNode](http://webaudio.github.io/web-audio-api/#idl-def-AnalyserNode).
     * Extracts FFT or Waveform data from the incoming signal.
     * @category Component
     */
    class Analyser extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Analyser.getDefaults(), arguments, ["type", "size"]));
            this.name = "Analyser";
            /**
             * The analyser node.
             */
            this._analysers = [];
            /**
             * The buffer that the FFT data is written to
             */
            this._buffers = [];
            const options = optionsFromArguments(Analyser.getDefaults(), arguments, ["type", "size"]);
            this.input = this.output = this._gain = new Gain({ context: this.context });
            this._split = new Split({
                context: this.context,
                channels: options.channels,
            });
            this.input.connect(this._split);
            assertRange(options.channels, 1);
            // create the analysers
            for (let channel = 0; channel < options.channels; channel++) {
                this._analysers[channel] = this.context.createAnalyser();
                this._split.connect(this._analysers[channel], channel, 0);
            }
            // set the values initially
            this.size = options.size;
            this.type = options.type;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                size: 1024,
                smoothing: 0.8,
                type: "fft",
                channels: 1,
            });
        }
        /**
         * Run the analysis given the current settings. If [[channels]] = 1,
         * it will return a Float32Array. If [[channels]] > 1, it will
         * return an array of Float32Arrays where each index in the array
         * represents the analysis done on a channel.
         */
        getValue() {
            this._analysers.forEach((analyser, index) => {
                const buffer = this._buffers[index];
                if (this._type === "fft") {
                    analyser.getFloatFrequencyData(buffer);
                }
                else if (this._type === "waveform") {
                    analyser.getFloatTimeDomainData(buffer);
                }
            });
            if (this.channels === 1) {
                return this._buffers[0];
            }
            else {
                return this._buffers;
            }
        }
        /**
         * The size of analysis. This must be a power of two in the range 16 to 16384.
         */
        get size() {
            return this._analysers[0].frequencyBinCount;
        }
        set size(size) {
            this._analysers.forEach((analyser, index) => {
                analyser.fftSize = size * 2;
                this._buffers[index] = new Float32Array(size);
            });
        }
        /**
         * The number of channels the analyser does the analysis on. Channel
         * separation is done using [[Split]]
         */
        get channels() {
            return this._analysers.length;
        }
        /**
         * The analysis function returned by analyser.getValue(), either "fft" or "waveform".
         */
        get type() {
            return this._type;
        }
        set type(type) {
            assert(type === "waveform" || type === "fft", `Analyser: invalid type: ${type}`);
            this._type = type;
        }
        /**
         * 0 represents no time averaging with the last analysis frame.
         */
        get smoothing() {
            return this._analysers[0].smoothingTimeConstant;
        }
        set smoothing(val) {
            this._analysers.forEach(a => a.smoothingTimeConstant = val);
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            this._analysers.forEach(a => a.disconnect());
            this._split.dispose();
            this._gain.dispose();
            return this;
        }
    }

    /**
     * The base class for Metering classes.
     */
    class MeterBase extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(MeterBase.getDefaults(), arguments));
            this.name = "MeterBase";
            this.input = this.output = this._analyser = new Analyser({
                context: this.context,
                size: 256,
                type: "waveform",
            });
        }
        dispose() {
            super.dispose();
            this._analyser.dispose();
            return this;
        }
    }

    /**
     * Meter gets the [RMS](https://en.wikipedia.org/wiki/Root_mean_square)
     * of an input signal. It can also get the raw value of the input signal.
     *
     * @example
     * const meter = new Tone.Meter();
     * const mic = new Tone.UserMedia();
     * mic.open();
     * // connect mic to the meter
     * mic.connect(meter);
     * // the current level of the mic
     * setInterval(() => console.log(meter.getValue()), 100);
     * @category Component
     */
    class Meter extends MeterBase {
        constructor() {
            super(optionsFromArguments(Meter.getDefaults(), arguments, ["smoothing"]));
            this.name = "Meter";
            /**
             * The previous frame's value
             */
            this._rms = 0;
            const options = optionsFromArguments(Meter.getDefaults(), arguments, ["smoothing"]);
            this.input = this.output = this._analyser = new Analyser({
                context: this.context,
                size: 256,
                type: "waveform",
                channels: options.channels,
            });
            this.smoothing = options.smoothing,
                this.normalRange = options.normalRange;
        }
        static getDefaults() {
            return Object.assign(MeterBase.getDefaults(), {
                smoothing: 0.8,
                normalRange: false,
                channels: 1,
            });
        }
        /**
         * Use [[getValue]] instead. For the previous getValue behavior, use DCMeter.
         * @deprecated
         */
        getLevel() {
            warn("'getLevel' has been changed to 'getValue'");
            return this.getValue();
        }
        /**
         * Get the current value of the incoming signal.
         * Output is in decibels when [[normalRange]] is `false`.
         * If [[channels]] = 1, then the output is a single number
         * representing the value of the input signal. When [[channels]] > 1,
         * then each channel is returned as a value in a number array.
         */
        getValue() {
            const aValues = this._analyser.getValue();
            const channelValues = this.channels === 1 ? [aValues] : aValues;
            const vals = channelValues.map(values => {
                const totalSquared = values.reduce((total, current) => total + current * current, 0);
                const rms = Math.sqrt(totalSquared / values.length);
                // the rms can only fall at the rate of the smoothing
                // but can jump up instantly
                this._rms = Math.max(rms, this._rms * this.smoothing);
                return this.normalRange ? this._rms : gainToDb(this._rms);
            });
            if (this.channels === 1) {
                return vals[0];
            }
            else {
                return vals;
            }
        }
        /**
         * The number of channels of analysis.
         */
        get channels() {
            return this._analyser.channels;
        }
        dispose() {
            super.dispose();
            this._analyser.dispose();
            return this;
        }
    }

    /**
     * Get the current frequency data of the connected audio source using a fast Fourier transform.
     * @category Component
     */
    class FFT extends MeterBase {
        constructor() {
            super(optionsFromArguments(FFT.getDefaults(), arguments, ["size"]));
            this.name = "FFT";
            const options = optionsFromArguments(FFT.getDefaults(), arguments, ["size"]);
            this.normalRange = options.normalRange;
            this._analyser.type = "fft";
            this.size = options.size;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                normalRange: false,
                size: 1024,
                smoothing: 0.8,
            });
        }
        /**
         * Gets the current frequency data from the connected audio source.
         * Returns the frequency data of length [[size]] as a Float32Array of decibel values.
         */
        getValue() {
            const values = this._analyser.getValue();
            return values.map(v => this.normalRange ? dbToGain(v) : v);
        }
        /**
         * The size of analysis. This must be a power of two in the range 16 to 16384.
         * Determines the size of the array returned by [[getValue]] (i.e. the number of
         * frequency bins). Large FFT sizes may be costly to compute.
         */
        get size() {
            return this._analyser.size;
        }
        set size(size) {
            this._analyser.size = size;
        }
        /**
         * 0 represents no time averaging with the last analysis frame.
         */
        get smoothing() {
            return this._analyser.smoothing;
        }
        set smoothing(val) {
            this._analyser.smoothing = val;
        }
        /**
         * Returns the frequency value in hertz of each of the indices of the FFT's [[getValue]] response.
         * @example
         * const fft = new Tone.FFT(32);
         * console.log([0, 1, 2, 3, 4].map(index => fft.getFrequencyOfIndex(index)));
         */
        getFrequencyOfIndex(index) {
            assert(0 <= index && index < this.size, `index must be greater than or equal to 0 and less than ${this.size}`);
            return index * this.context.sampleRate / (this.size * 2);
        }
    }

    /**
     * DCMeter gets the raw value of the input signal at the current time.
     *
     * @example
     * const meter = new Tone.DCMeter();
     * const mic = new Tone.UserMedia();
     * mic.open();
     * // connect mic to the meter
     * mic.connect(meter);
     * // the current level of the mic
     * const level = meter.getValue();
     * @category Component
     */
    class DCMeter extends MeterBase {
        constructor() {
            super(optionsFromArguments(DCMeter.getDefaults(), arguments));
            this.name = "DCMeter";
            this._analyser.type = "waveform";
            this._analyser.size = 256;
        }
        /**
         * Get the signal value of the incoming signal
         */
        getValue() {
            const value = this._analyser.getValue();
            return value[0];
        }
    }

    /**
     * Get the current waveform data of the connected audio source.
     * @category Component
     */
    class Waveform extends MeterBase {
        constructor() {
            super(optionsFromArguments(Waveform.getDefaults(), arguments, ["size"]));
            this.name = "Waveform";
            const options = optionsFromArguments(Waveform.getDefaults(), arguments, ["size"]);
            this._analyser.type = "waveform";
            this.size = options.size;
        }
        static getDefaults() {
            return Object.assign(MeterBase.getDefaults(), {
                size: 1024,
            });
        }
        /**
         * Return the waveform for the current time as a Float32Array where each value in the array
         * represents a sample in the waveform.
         */
        getValue() {
            return this._analyser.getValue();
        }
        /**
         * The size of analysis. This must be a power of two in the range 16 to 16384.
         * Determines the size of the array returned by [[getValue]].
         */
        get size() {
            return this._analyser.size;
        }
        set size(size) {
            this._analyser.size = size;
        }
    }

    /**
     * Solo lets you isolate a specific audio stream. When an instance is set to `solo=true`,
     * it will mute all other instances of Solo.
     * @example
     * const soloA = new Tone.Solo().toDestination();
     * const oscA = new Tone.Oscillator("C4", "sawtooth").connect(soloA);
     * const soloB = new Tone.Solo().toDestination();
     * const oscB = new Tone.Oscillator("E4", "square").connect(soloB);
     * soloA.solo = true;
     * // no audio will pass through soloB
     * @category Component
     */
    class Solo extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Solo.getDefaults(), arguments, ["solo"]));
            this.name = "Solo";
            const options = optionsFromArguments(Solo.getDefaults(), arguments, ["solo"]);
            this.input = this.output = new Gain({
                context: this.context,
            });
            if (!Solo._allSolos.has(this.context)) {
                Solo._allSolos.set(this.context, new Set());
            }
            Solo._allSolos.get(this.context).add(this);
            // set initially
            this.solo = options.solo;
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                solo: false,
            });
        }
        /**
         * Isolates this instance and mutes all other instances of Solo.
         * Only one instance can be soloed at a time. A soloed
         * instance will report `solo=false` when another instance is soloed.
         */
        get solo() {
            return this._isSoloed();
        }
        set solo(solo) {
            if (solo) {
                this._addSolo();
            }
            else {
                this._removeSolo();
            }
            Solo._allSolos.get(this.context).forEach(instance => instance._updateSolo());
        }
        /**
         * If the current instance is muted, i.e. another instance is soloed
         */
        get muted() {
            return this.input.gain.value === 0;
        }
        /**
         * Add this to the soloed array
         */
        _addSolo() {
            if (!Solo._soloed.has(this.context)) {
                Solo._soloed.set(this.context, new Set());
            }
            Solo._soloed.get(this.context).add(this);
        }
        /**
         * Remove this from the soloed array
         */
        _removeSolo() {
            if (Solo._soloed.has(this.context)) {
                Solo._soloed.get(this.context).delete(this);
            }
        }
        /**
         * Is this on the soloed array
         */
        _isSoloed() {
            return Solo._soloed.has(this.context) && Solo._soloed.get(this.context).has(this);
        }
        /**
         * Returns true if no one is soloed
         */
        _noSolos() {
            // either does not have any soloed added
            return !Solo._soloed.has(this.context) ||
                // or has a solo set but doesn't include any items
                (Solo._soloed.has(this.context) && Solo._soloed.get(this.context).size === 0);
        }
        /**
         * Solo the current instance and unsolo all other instances.
         */
        _updateSolo() {
            if (this._isSoloed()) {
                this.input.gain.value = 1;
            }
            else if (this._noSolos()) {
                // no one is soloed
                this.input.gain.value = 1;
            }
            else {
                this.input.gain.value = 0;
            }
        }
        dispose() {
            super.dispose();
            Solo._allSolos.get(this.context).delete(this);
            this._removeSolo();
            return this;
        }
    }
    /**
     * Hold all of the solo'ed tracks belonging to a specific context
     */
    Solo._allSolos = new Map();
    /**
     * Hold the currently solo'ed instance(s)
     */
    Solo._soloed = new Map();

    /**
     * PanVol is a Tone.Panner and Tone.Volume in one.
     * @example
     * // pan the incoming signal left and drop the volume
     * const panVol = new Tone.PanVol(-0.25, -12).toDestination();
     * const osc = new Tone.Oscillator().connect(panVol).start();
     * @category Component
     */
    class PanVol extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(PanVol.getDefaults(), arguments, ["pan", "volume"]));
            this.name = "PanVol";
            const options = optionsFromArguments(PanVol.getDefaults(), arguments, ["pan", "volume"]);
            this._panner = this.input = new Panner({
                context: this.context,
                pan: options.pan,
                channelCount: options.channelCount,
            });
            this.pan = this._panner.pan;
            this._volume = this.output = new Volume({
                context: this.context,
                volume: options.volume,
            });
            this.volume = this._volume.volume;
            // connections
            this._panner.connect(this._volume);
            this.mute = options.mute;
            readOnly(this, ["pan", "volume"]);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                mute: false,
                pan: 0,
                volume: 0,
                channelCount: 1,
            });
        }
        /**
         * Mute/unmute the volume
         */
        get mute() {
            return this._volume.mute;
        }
        set mute(mute) {
            this._volume.mute = mute;
        }
        dispose() {
            super.dispose();
            this._panner.dispose();
            this.pan.dispose();
            this._volume.dispose();
            this.volume.dispose();
            return this;
        }
    }

    /**
     * Channel provides a channel strip interface with volume, pan, solo and mute controls.
     * See [[PanVol]] and [[Solo]]
     * @example
     * // pan the incoming signal left and drop the volume 12db
     * const channel = new Tone.Channel(-0.25, -12);
     * @category Component
     */
    class Channel extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Channel.getDefaults(), arguments, ["volume", "pan"]));
            this.name = "Channel";
            const options = optionsFromArguments(Channel.getDefaults(), arguments, ["volume", "pan"]);
            this._solo = this.input = new Solo({
                solo: options.solo,
                context: this.context,
            });
            this._panVol = this.output = new PanVol({
                context: this.context,
                pan: options.pan,
                volume: options.volume,
                mute: options.mute,
                channelCount: options.channelCount
            });
            this.pan = this._panVol.pan;
            this.volume = this._panVol.volume;
            this._solo.connect(this._panVol);
            readOnly(this, ["pan", "volume"]);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                pan: 0,
                volume: 0,
                mute: false,
                solo: false,
                channelCount: 1,
            });
        }
        /**
         * Solo/unsolo the channel. Soloing is only relative to other [[Channels]] and [[Solo]] instances
         */
        get solo() {
            return this._solo.solo;
        }
        set solo(solo) {
            this._solo.solo = solo;
        }
        /**
         * If the current instance is muted, i.e. another instance is soloed,
         * or the channel is muted
         */
        get muted() {
            return this._solo.muted || this.mute;
        }
        /**
         * Mute/unmute the volume
         */
        get mute() {
            return this._panVol.mute;
        }
        set mute(mute) {
            this._panVol.mute = mute;
        }
        /**
         * Get the gain node belonging to the bus name. Create it if
         * it doesn't exist
         * @param name The bus name
         */
        _getBus(name) {
            if (!Channel.buses.has(name)) {
                Channel.buses.set(name, new Gain({ context: this.context }));
            }
            return Channel.buses.get(name);
        }
        /**
         * Send audio to another channel using a string. `send` is a lot like
         * [[connect]], except it uses a string instead of an object. This can
         * be useful in large applications to decouple sections since [[send]]
         * and [[receive]] can be invoked separately in order to connect an object
         * @param name The channel name to send the audio
         * @param volume The amount of the signal to send.
         * 	Defaults to 0db, i.e. send the entire signal
         * @returns Returns the gain node of this connection.
         */
        send(name, volume = 0) {
            const bus = this._getBus(name);
            const sendKnob = new Gain({
                context: this.context,
                units: "decibels",
                gain: volume,
            });
            this.connect(sendKnob);
            sendKnob.connect(bus);
            return sendKnob;
        }
        /**
         * Receive audio from a channel which was connected with [[send]].
         * @param name The channel name to receive audio from.
         */
        receive(name) {
            const bus = this._getBus(name);
            bus.connect(this);
            return this;
        }
        dispose() {
            super.dispose();
            this._panVol.dispose();
            this.pan.dispose();
            this.volume.dispose();
            this._solo.dispose();
            return this;
        }
    }
    /**
     * Store the send/receive channels by name.
     */
    Channel.buses = new Map();

    /**
     * Split the incoming signal into three bands (low, mid, high)
     * with two crossover frequency controls.
     * ```
     *            +----------------------+
     *          +-> input < lowFrequency +------------------> low
     *          | +----------------------+
     *          |
     *          | +--------------------------------------+
     * input ---+-> lowFrequency < input < highFrequency +--> mid
     *          | +--------------------------------------+
     *          |
     *          | +-----------------------+
     *          +-> highFrequency < input +-----------------> high
     *            +-----------------------+
     * ```
     * @category Component
     */
    class MultibandSplit extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(MultibandSplit.getDefaults(), arguments, ["lowFrequency", "highFrequency"]));
            this.name = "MultibandSplit";
            /**
             * the input
             */
            this.input = new Gain({ context: this.context });
            /**
             * no output node, use either low, mid or high outputs
             */
            this.output = undefined;
            /**
             * The low band.
             */
            this.low = new Filter({
                context: this.context,
                frequency: 0,
                type: "lowpass",
            });
            /**
             * the lower filter of the mid band
             */
            this._lowMidFilter = new Filter({
                context: this.context,
                frequency: 0,
                type: "highpass",
            });
            /**
             * The mid band output.
             */
            this.mid = new Filter({
                context: this.context,
                frequency: 0,
                type: "lowpass",
            });
            /**
             * The high band output.
             */
            this.high = new Filter({
                context: this.context,
                frequency: 0,
                type: "highpass",
            });
            this._internalChannels = [this.low, this.mid, this.high];
            const options = optionsFromArguments(MultibandSplit.getDefaults(), arguments, ["lowFrequency", "highFrequency"]);
            this.lowFrequency = new Signal({
                context: this.context,
                units: "frequency",
                value: options.lowFrequency,
            });
            this.highFrequency = new Signal({
                context: this.context,
                units: "frequency",
                value: options.highFrequency,
            });
            this.Q = new Signal({
                context: this.context,
                units: "positive",
                value: options.Q,
            });
            this.input.fan(this.low, this.high);
            this.input.chain(this._lowMidFilter, this.mid);
            // the frequency control signal
            this.lowFrequency.fan(this.low.frequency, this._lowMidFilter.frequency);
            this.highFrequency.fan(this.mid.frequency, this.high.frequency);
            // the Q value
            this.Q.connect(this.low.Q);
            this.Q.connect(this._lowMidFilter.Q);
            this.Q.connect(this.mid.Q);
            this.Q.connect(this.high.Q);
            readOnly(this, ["high", "mid", "low", "highFrequency", "lowFrequency"]);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                Q: 1,
                highFrequency: 2500,
                lowFrequency: 400,
            });
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            writable(this, ["high", "mid", "low", "highFrequency", "lowFrequency"]);
            this.low.dispose();
            this._lowMidFilter.dispose();
            this.mid.dispose();
            this.high.dispose();
            this.lowFrequency.dispose();
            this.highFrequency.dispose();
            this.Q.dispose();
            return this;
        }
    }

    /**
     * Tone.Listener is a thin wrapper around the AudioListener. Listener combined
     * with [[Panner3D]] makes up the Web Audio API's 3D panning system. Panner3D allows you
     * to place sounds in 3D and Listener allows you to navigate the 3D sound environment from
     * a first-person perspective. There is only one listener per audio context.
     */
    class Listener extends ToneAudioNode {
        constructor() {
            super(...arguments);
            this.name = "Listener";
            this.positionX = new Param({
                context: this.context,
                param: this.context.rawContext.listener.positionX,
            });
            this.positionY = new Param({
                context: this.context,
                param: this.context.rawContext.listener.positionY,
            });
            this.positionZ = new Param({
                context: this.context,
                param: this.context.rawContext.listener.positionZ,
            });
            this.forwardX = new Param({
                context: this.context,
                param: this.context.rawContext.listener.forwardX,
            });
            this.forwardY = new Param({
                context: this.context,
                param: this.context.rawContext.listener.forwardY,
            });
            this.forwardZ = new Param({
                context: this.context,
                param: this.context.rawContext.listener.forwardZ,
            });
            this.upX = new Param({
                context: this.context,
                param: this.context.rawContext.listener.upX,
            });
            this.upY = new Param({
                context: this.context,
                param: this.context.rawContext.listener.upY,
            });
            this.upZ = new Param({
                context: this.context,
                param: this.context.rawContext.listener.upZ,
            });
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                positionX: 0,
                positionY: 0,
                positionZ: 0,
                forwardX: 0,
                forwardY: 0,
                forwardZ: -1,
                upX: 0,
                upY: 1,
                upZ: 0,
            });
        }
        dispose() {
            super.dispose();
            this.positionX.dispose();
            this.positionY.dispose();
            this.positionZ.dispose();
            this.forwardX.dispose();
            this.forwardY.dispose();
            this.forwardZ.dispose();
            this.upX.dispose();
            this.upY.dispose();
            this.upZ.dispose();
            return this;
        }
    }
    //-------------------------------------
    // 	INITIALIZATION
    //-------------------------------------
    onContextInit(context => {
        context.listener = new Listener({ context });
    });
    onContextClose(context => {
        context.listener.dispose();
    });

    /**
     * A spatialized panner node which supports equalpower or HRTF panning.
     * @category Component
     */
    class Panner3D extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Panner3D.getDefaults(), arguments, ["positionX", "positionY", "positionZ"]));
            this.name = "Panner3D";
            const options = optionsFromArguments(Panner3D.getDefaults(), arguments, ["positionX", "positionY", "positionZ"]);
            this._panner = this.input = this.output = this.context.createPanner();
            // set some values
            this.panningModel = options.panningModel;
            this.maxDistance = options.maxDistance;
            this.distanceModel = options.distanceModel;
            this.coneOuterGain = options.coneOuterGain;
            this.coneOuterAngle = options.coneOuterAngle;
            this.coneInnerAngle = options.coneInnerAngle;
            this.refDistance = options.refDistance;
            this.rolloffFactor = options.rolloffFactor;
            this.positionX = new Param({
                context: this.context,
                param: this._panner.positionX,
                value: options.positionX,
            });
            this.positionY = new Param({
                context: this.context,
                param: this._panner.positionY,
                value: options.positionY,
            });
            this.positionZ = new Param({
                context: this.context,
                param: this._panner.positionZ,
                value: options.positionZ,
            });
            this.orientationX = new Param({
                context: this.context,
                param: this._panner.orientationX,
                value: options.orientationX,
            });
            this.orientationY = new Param({
                context: this.context,
                param: this._panner.orientationY,
                value: options.orientationY,
            });
            this.orientationZ = new Param({
                context: this.context,
                param: this._panner.orientationZ,
                value: options.orientationZ,
            });
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                coneInnerAngle: 360,
                coneOuterAngle: 360,
                coneOuterGain: 0,
                distanceModel: "inverse",
                maxDistance: 10000,
                orientationX: 0,
                orientationY: 0,
                orientationZ: 0,
                panningModel: "equalpower",
                positionX: 0,
                positionY: 0,
                positionZ: 0,
                refDistance: 1,
                rolloffFactor: 1,
            });
        }
        /**
         * Sets the position of the source in 3d space.
         */
        setPosition(x, y, z) {
            this.positionX.value = x;
            this.positionY.value = y;
            this.positionZ.value = z;
            return this;
        }
        /**
         * Sets the orientation of the source in 3d space.
         */
        setOrientation(x, y, z) {
            this.orientationX.value = x;
            this.orientationY.value = y;
            this.orientationZ.value = z;
            return this;
        }
        /**
         * The panning model. Either "equalpower" or "HRTF".
         */
        get panningModel() {
            return this._panner.panningModel;
        }
        set panningModel(val) {
            this._panner.panningModel = val;
        }
        /**
         * A reference distance for reducing volume as source move further from the listener
         */
        get refDistance() {
            return this._panner.refDistance;
        }
        set refDistance(val) {
            this._panner.refDistance = val;
        }
        /**
         * Describes how quickly the volume is reduced as source moves away from listener.
         */
        get rolloffFactor() {
            return this._panner.rolloffFactor;
        }
        set rolloffFactor(val) {
            this._panner.rolloffFactor = val;
        }
        /**
         * The distance model used by,  "linear", "inverse", or "exponential".
         */
        get distanceModel() {
            return this._panner.distanceModel;
        }
        set distanceModel(val) {
            this._panner.distanceModel = val;
        }
        /**
         * The angle, in degrees, inside of which there will be no volume reduction
         */
        get coneInnerAngle() {
            return this._panner.coneInnerAngle;
        }
        set coneInnerAngle(val) {
            this._panner.coneInnerAngle = val;
        }
        /**
         * The angle, in degrees, outside of which the volume will be reduced
         * to a constant value of coneOuterGain
         */
        get coneOuterAngle() {
            return this._panner.coneOuterAngle;
        }
        set coneOuterAngle(val) {
            this._panner.coneOuterAngle = val;
        }
        /**
         * The gain outside of the coneOuterAngle
         */
        get coneOuterGain() {
            return this._panner.coneOuterGain;
        }
        set coneOuterGain(val) {
            this._panner.coneOuterGain = val;
        }
        /**
         * The maximum distance between source and listener,
         * after which the volume will not be reduced any further.
         */
        get maxDistance() {
            return this._panner.maxDistance;
        }
        set maxDistance(val) {
            this._panner.maxDistance = val;
        }
        dispose() {
            super.dispose();
            this._panner.disconnect();
            this.orientationX.dispose();
            this.orientationY.dispose();
            this.orientationZ.dispose();
            this.positionX.dispose();
            this.positionY.dispose();
            this.positionZ.dispose();
            return this;
        }
    }

    /**
     * A wrapper around the MediaRecorder API. Unlike the rest of Tone.js, this module does not offer
     * any sample-accurate scheduling because it is not a feature of the MediaRecorder API.
     * This is only natively supported in Chrome and Firefox.
     * For a cross-browser shim, install (audio-recorder-polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].
     * @example
     * const recorder = new Tone.Recorder();
     * const synth = new Tone.Synth().connect(recorder);
     * // start recording
     * recorder.start();
     * // generate a few notes
     * synth.triggerAttackRelease("C3", 0.5);
     * synth.triggerAttackRelease("C4", 0.5, "+1");
     * synth.triggerAttackRelease("C5", 0.5, "+2");
     * // wait for the notes to end and stop the recording
     * setTimeout(async () => {
     * 	// the recorded audio is returned as a blob
     * 	const recording = await recorder.stop();
     * 	// download the recording by creating an anchor element and blob url
     * 	const url = URL.createObjectURL(recording);
     * 	const anchor = document.createElement("a");
     * 	anchor.download = "recording.webm";
     * 	anchor.href = url;
     * 	anchor.click();
     * }, 4000);
     * @category Component
     */
    class Recorder extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Recorder.getDefaults(), arguments));
            this.name = "Recorder";
            const options = optionsFromArguments(Recorder.getDefaults(), arguments);
            this.input = new Gain({
                context: this.context
            });
            assert(Recorder.supported, "Media Recorder API is not available");
            this._stream = this.context.createMediaStreamDestination();
            this.input.connect(this._stream);
            this._recorder = new MediaRecorder(this._stream.stream, {
                mimeType: options.mimeType
            });
        }
        static getDefaults() {
            return ToneAudioNode.getDefaults();
        }
        /**
         * The mime type is the format that the audio is encoded in. For Chrome
         * that is typically webm encoded as "vorbis".
         */
        get mimeType() {
            return this._recorder.mimeType;
        }
        /**
         * Test if your platform supports the Media Recorder API. If it's not available,
         * try installing this (polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].
         */
        static get supported() {
            return theWindow !== null && Reflect.has(theWindow, "MediaRecorder");
        }
        /**
         * Get the playback state of the Recorder, either "started", "stopped" or "paused"
         */
        get state() {
            if (this._recorder.state === "inactive") {
                return "stopped";
            }
            else if (this._recorder.state === "paused") {
                return "paused";
            }
            else {
                return "started";
            }
        }
        /**
         * Start the Recorder. Returns a promise which resolves
         * when the recorder has started.
         */
        start() {
            return __awaiter(this, void 0, void 0, function* () {
                assert(this.state !== "started", "Recorder is already started");
                const startPromise = new Promise(done => {
                    const handleStart = () => {
                        this._recorder.removeEventListener("start", handleStart, false);
                        done();
                    };
                    this._recorder.addEventListener("start", handleStart, false);
                });
                this._recorder.start();
                return yield startPromise;
            });
        }
        /**
         * Stop the recorder. Returns a promise with the recorded content until this point
         * encoded as [[mimeType]]
         */
        stop() {
            return __awaiter(this, void 0, void 0, function* () {
                assert(this.state !== "stopped", "Recorder is not started");
                const dataPromise = new Promise(done => {
                    const handleData = (e) => {
                        this._recorder.removeEventListener("dataavailable", handleData, false);
                        done(e.data);
                    };
                    this._recorder.addEventListener("dataavailable", handleData, false);
                });
                this._recorder.stop();
                return yield dataPromise;
            });
        }
        /**
         * Pause the recorder
         */
        pause() {
            assert(this.state === "started", "Recorder must be started");
            this._recorder.pause();
            return this;
        }
        dispose() {
            super.dispose();
            this.input.dispose();
            this._stream.disconnect();
            return this;
        }
    }

    /**
     * Compressor is a thin wrapper around the Web Audio
     * [DynamicsCompressorNode](http://webaudio.github.io/web-audio-api/#the-dynamicscompressornode-interface).
     * Compression reduces the volume of loud sounds or amplifies quiet sounds
     * by narrowing or "compressing" an audio signal's dynamic range.
     * Read more on [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_range_compression).
     * @example
     * const comp = new Tone.Compressor(-30, 3);
     * @category Component
     */
    class Compressor extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Compressor.getDefaults(), arguments, ["threshold", "ratio"]));
            this.name = "Compressor";
            /**
             * the compressor node
             */
            this._compressor = this.context.createDynamicsCompressor();
            this.input = this._compressor;
            this.output = this._compressor;
            const options = optionsFromArguments(Compressor.getDefaults(), arguments, ["threshold", "ratio"]);
            this.threshold = new Param({
                minValue: this._compressor.threshold.minValue,
                maxValue: this._compressor.threshold.maxValue,
                context: this.context,
                convert: false,
                param: this._compressor.threshold,
                units: "decibels",
                value: options.threshold,
            });
            this.attack = new Param({
                minValue: this._compressor.attack.minValue,
                maxValue: this._compressor.attack.maxValue,
                context: this.context,
                param: this._compressor.attack,
                units: "time",
                value: options.attack,
            });
            this.release = new Param({
                minValue: this._compressor.release.minValue,
                maxValue: this._compressor.release.maxValue,
                context: this.context,
                param: this._compressor.release,
                units: "time",
                value: options.release,
            });
            this.knee = new Param({
                minValue: this._compressor.knee.minValue,
                maxValue: this._compressor.knee.maxValue,
                context: this.context,
                convert: false,
                param: this._compressor.knee,
                units: "decibels",
                value: options.knee,
            });
            this.ratio = new Param({
                minValue: this._compressor.ratio.minValue,
                maxValue: this._compressor.ratio.maxValue,
                context: this.context,
                convert: false,
                param: this._compressor.ratio,
                units: "positive",
                value: options.ratio,
            });
            // set the defaults
            readOnly(this, ["knee", "release", "attack", "ratio", "threshold"]);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                attack: 0.003,
                knee: 30,
                ratio: 12,
                release: 0.25,
                threshold: -24,
            });
        }
        /**
         * A read-only decibel value for metering purposes, representing the current amount of gain
         * reduction that the compressor is applying to the signal. If fed no signal the value will be 0 (no gain reduction).
         */
        get reduction() {
            return this._compressor.reduction;
        }
        dispose() {
            super.dispose();
            this._compressor.disconnect();
            this.attack.dispose();
            this.release.dispose();
            this.threshold.dispose();
            this.ratio.dispose();
            this.knee.dispose();
            return this;
        }
    }

    /**
     * Gate only passes a signal through when the incoming
     * signal exceeds a specified threshold. It uses [[Follower]] to follow the ampltiude
     * of the incoming signal and compares it to the [[threshold]] value using [[GreaterThan]].
     *
     * @example
     * const gate = new Tone.Gate(-30, 0.2).toDestination();
     * const mic = new Tone.UserMedia().connect(gate);
     * // the gate will only pass through the incoming
     * // signal when it's louder than -30db
     * @category Component
     */
    class Gate extends ToneAudioNode {
        constructor() {
            super(Object.assign(optionsFromArguments(Gate.getDefaults(), arguments, ["threshold", "smoothing"])));
            this.name = "Gate";
            const options = optionsFromArguments(Gate.getDefaults(), arguments, ["threshold", "smoothing"]);
            this._follower = new Follower({
                context: this.context,
                smoothing: options.smoothing,
            });
            this._gt = new GreaterThan({
                context: this.context,
                value: dbToGain(options.threshold),
            });
            this.input = new Gain({ context: this.context });
            this._gate = this.output = new Gain({ context: this.context });
            // connections
            this.input.connect(this._gate);
            // the control signal
            this.input.chain(this._follower, this._gt, this._gate.gain);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                smoothing: 0.1,
                threshold: -40
            });
        }
        /**
         * The threshold of the gate in decibels
         */
        get threshold() {
            return gainToDb(this._gt.value);
        }
        set threshold(thresh) {
            this._gt.value = dbToGain(thresh);
        }
        /**
         * The attack/decay speed of the gate. See [[Follower.smoothing]]
         */
        get smoothing() {
            return this._follower.smoothing;
        }
        set smoothing(smoothingTime) {
            this._follower.smoothing = smoothingTime;
        }
        dispose() {
            super.dispose();
            this.input.dispose();
            this._follower.dispose();
            this._gt.dispose();
            this._gate.dispose();
            return this;
        }
    }

    /**
     * Limiter will limit the loudness of an incoming signal.
     * It is composed of a [[Compressor]] with a fast attack
     * and release and max ratio. Limiters are commonly used to safeguard against
     * signal clipping. Unlike a compressor, limiters do not provide
     * smooth gain reduction and almost completely prevent
     * additional gain above the threshold.
     *
     * @example
     * const limiter = new Tone.Limiter(-20).toDestination();
     * const oscillator = new Tone.Oscillator().connect(limiter);
     * oscillator.start();
     * @category Component
     */
    class Limiter extends ToneAudioNode {
        constructor() {
            super(Object.assign(optionsFromArguments(Limiter.getDefaults(), arguments, ["threshold"])));
            this.name = "Limiter";
            const options = optionsFromArguments(Limiter.getDefaults(), arguments, ["threshold"]);
            this._compressor = this.input = this.output = new Compressor({
                context: this.context,
                ratio: 20,
                attack: 0,
                release: 0,
                threshold: options.threshold
            });
            this.threshold = this._compressor.threshold;
            readOnly(this, "threshold");
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                threshold: -12
            });
        }
        /**
         * A read-only decibel value for metering purposes, representing the current amount of gain
         * reduction that the compressor is applying to the signal.
         */
        get reduction() {
            return this._compressor.reduction;
        }
        dispose() {
            super.dispose();
            this._compressor.dispose();
            this.threshold.dispose();
            return this;
        }
    }

    /**
     * MidSideCompressor applies two different compressors to the [[mid]]
     * and [[side]] signal components of the input. See [[MidSideSplit]] and [[MidSideMerge]].
     * @category Component
     */
    class MidSideCompressor extends ToneAudioNode {
        constructor() {
            super(Object.assign(optionsFromArguments(MidSideCompressor.getDefaults(), arguments)));
            this.name = "MidSideCompressor";
            const options = optionsFromArguments(MidSideCompressor.getDefaults(), arguments);
            this._midSideSplit = this.input = new MidSideSplit({ context: this.context });
            this._midSideMerge = this.output = new MidSideMerge({ context: this.context });
            this.mid = new Compressor(Object.assign(options.mid, { context: this.context }));
            this.side = new Compressor(Object.assign(options.side, { context: this.context }));
            this._midSideSplit.mid.chain(this.mid, this._midSideMerge.mid);
            this._midSideSplit.side.chain(this.side, this._midSideMerge.side);
            readOnly(this, ["mid", "side"]);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                mid: {
                    ratio: 3,
                    threshold: -24,
                    release: 0.03,
                    attack: 0.02,
                    knee: 16
                },
                side: {
                    ratio: 6,
                    threshold: -30,
                    release: 0.25,
                    attack: 0.03,
                    knee: 10
                }
            });
        }
        dispose() {
            super.dispose();
            this.mid.dispose();
            this.side.dispose();
            this._midSideSplit.dispose();
            this._midSideMerge.dispose();
            return this;
        }
    }

    /**
     * A compressor with separate controls over low/mid/high dynamics. See [[Compressor]] and [[MultibandSplit]]
     *
     * @example
     * const multiband = new Tone.MultibandCompressor({
     * 	lowFrequency: 200,
     * 	highFrequency: 1300,
     * 	low: {
     * 		threshold: -12
     * 	}
     * });
     * @category Component
     */
    class MultibandCompressor extends ToneAudioNode {
        constructor() {
            super(Object.assign(optionsFromArguments(MultibandCompressor.getDefaults(), arguments)));
            this.name = "MultibandCompressor";
            const options = optionsFromArguments(MultibandCompressor.getDefaults(), arguments);
            this._splitter = this.input = new MultibandSplit({
                context: this.context,
                lowFrequency: options.lowFrequency,
                highFrequency: options.highFrequency
            });
            this.lowFrequency = this._splitter.lowFrequency;
            this.highFrequency = this._splitter.highFrequency;
            this.output = new Gain({ context: this.context });
            this.low = new Compressor(Object.assign(options.low, { context: this.context }));
            this.mid = new Compressor(Object.assign(options.mid, { context: this.context }));
            this.high = new Compressor(Object.assign(options.high, { context: this.context }));
            // connect the compressor
            this._splitter.low.chain(this.low, this.output);
            this._splitter.mid.chain(this.mid, this.output);
            this._splitter.high.chain(this.high, this.output);
            readOnly(this, ["high", "mid", "low", "highFrequency", "lowFrequency"]);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                lowFrequency: 250,
                highFrequency: 2000,
                low: {
                    ratio: 6,
                    threshold: -30,
                    release: 0.25,
                    attack: 0.03,
                    knee: 10
                },
                mid: {
                    ratio: 3,
                    threshold: -24,
                    release: 0.03,
                    attack: 0.02,
                    knee: 16
                },
                high: {
                    ratio: 3,
                    threshold: -24,
                    release: 0.03,
                    attack: 0.02,
                    knee: 16
                },
            });
        }
        dispose() {
            super.dispose();
            this._splitter.dispose();
            this.low.dispose();
            this.mid.dispose();
            this.high.dispose();
            this.output.dispose();
            return this;
        }
    }

    /**
     * EQ3 provides 3 equalizer bins: Low/Mid/High.
     * @category Component
     */
    class EQ3 extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(EQ3.getDefaults(), arguments, ["low", "mid", "high"]));
            this.name = "EQ3";
            /**
             * the output
             */
            this.output = new Gain({ context: this.context });
            this._internalChannels = [];
            const options = optionsFromArguments(EQ3.getDefaults(), arguments, ["low", "mid", "high"]);
            this.input = this._multibandSplit = new MultibandSplit({
                context: this.context,
                highFrequency: options.highFrequency,
                lowFrequency: options.lowFrequency,
            });
            this._lowGain = new Gain({
                context: this.context,
                gain: options.low,
                units: "decibels",
            });
            this._midGain = new Gain({
                context: this.context,
                gain: options.mid,
                units: "decibels",
            });
            this._highGain = new Gain({
                context: this.context,
                gain: options.high,
                units: "decibels",
            });
            this.low = this._lowGain.gain;
            this.mid = this._midGain.gain;
            this.high = this._highGain.gain;
            this.Q = this._multibandSplit.Q;
            this.lowFrequency = this._multibandSplit.lowFrequency;
            this.highFrequency = this._multibandSplit.highFrequency;
            // the frequency bands
            this._multibandSplit.low.chain(this._lowGain, this.output);
            this._multibandSplit.mid.chain(this._midGain, this.output);
            this._multibandSplit.high.chain(this._highGain, this.output);
            readOnly(this, ["low", "mid", "high", "lowFrequency", "highFrequency"]);
            this._internalChannels = [this._multibandSplit];
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                high: 0,
                highFrequency: 2500,
                low: 0,
                lowFrequency: 400,
                mid: 0,
            });
        }
        /**
         * Clean up.
         */
        dispose() {
            super.dispose();
            writable(this, ["low", "mid", "high", "lowFrequency", "highFrequency"]);
            this._multibandSplit.dispose();
            this.lowFrequency.dispose();
            this.highFrequency.dispose();
            this._lowGain.dispose();
            this._midGain.dispose();
            this._highGain.dispose();
            this.low.dispose();
            this.mid.dispose();
            this.high.dispose();
            this.Q.dispose();
            return this;
        }
    }

    /**
     * Convolver is a wrapper around the Native Web Audio
     * [ConvolverNode](http://webaudio.github.io/web-audio-api/#the-convolvernode-interface).
     * Convolution is useful for reverb and filter emulation. Read more about convolution reverb on
     * [Wikipedia](https://en.wikipedia.org/wiki/Convolution_reverb).
     *
     * @example
     * // initializing the convolver with an impulse response
     * const convolver = new Tone.Convolver("./path/to/ir.wav").toDestination();
     * @category Component
     */
    class Convolver extends ToneAudioNode {
        constructor() {
            super(optionsFromArguments(Convolver.getDefaults(), arguments, ["url", "onload"]));
            this.name = "Convolver";
            /**
             * The native ConvolverNode
             */
            this._convolver = this.context.createConvolver();
            const options = optionsFromArguments(Convolver.getDefaults(), arguments, ["url", "onload"]);
            this._buffer = new ToneAudioBuffer(options.url, buffer => {
                this.buffer = buffer;
                options.onload();
            });
            this.input = new Gain({ context: this.context });
            this.output = new Gain({ context: this.context });
            // set if it's already loaded, set it immediately
            if (this._buffer.loaded) {
                this.buffer = this._buffer;
            }
            // initially set normalization
            this.normalize = options.normalize;
            // connect it up
            this.input.chain(this._convolver, this.output);
        }
        static getDefaults() {
            return Object.assign(ToneAudioNode.getDefaults(), {
                normalize: true,
                onload: noOp,
            });
        }
        /**
         * Load an impulse response url as an audio buffer.
         * Decodes the audio asynchronously and invokes
         * the callback once the audio buffer loads.
         * @param url The url of the buffer to load. filetype support depends on the browser.
         */
        load(url) {
            return __awaiter(this, void 0, void 0, function* () {
                this.buffer = yield this._buffer.load(url);
            });
        }
        /**
         * The convolver's buffer
         */
        get buffer() {
            if (this._buffer.length) {
                return this._buffer;
            }
            else {
                return null;
            }
        }
        set buffer(buffer) {
            if (buffer) {
                this._buffer.set(buffer);
            }
            // if it's already got a buffer, create a new one
            if (this._convolver.buffer) {
                // disconnect the old one
                this.input.disconnect();
                this._convolver.disconnect();
                // create and connect a new one
                this._convolver = this.context.createConvolver();
                this.input.chain(this._convolver, this.output);
            }
            const buff = this._buffer.get();
            this._convolver.buffer = buff ? buff : null;
        }
        /**
         * The normalize property of the ConvolverNode interface is a boolean that
         * controls whether the impulse response from the buffer will be scaled by
         * an equal-power normalization when the buffer attribute is set, or not.
         */
        get normalize() {
            return this._convolver.normalize;
        }
        set normalize(norm) {
            this._convolver.normalize = norm;
        }
        dispose() {
            super.dispose();
            this._buffer.dispose();
            this._convolver.disconnect();
            return this;
        }
    }

    /**
     * The current audio context time of the global [[Context]].
     * See [[Context.now]]
     * @category Core
     */
    function now() {
        return getContext().now();
    }
    /**
     * The current audio context time of the global [[Context]] without the [[Context.lookAhead]]
     * See [[Context.immediate]]
     * @category Core
     */
    function immediate() {
        return getContext().immediate();
    }
    /**
     * The Transport object belonging to the global Tone.js Context.
     * See [[Transport]]
     * @category Core
     */
    const Transport$1 = getContext().transport;
    /**
     * The Transport object belonging to the global Tone.js Context.
     * See [[Transport]]
     * @category Core
     */
    function getTransport() {
        return getContext().transport;
    }
    /**
     * The Destination (output) belonging to the global Tone.js Context.
     * See [[Destination]]
     * @category Core
     */
    const Destination$1 = getContext().destination;
    /**
     * @deprecated Use [[Destination]]
     */
    const Master = getContext().destination;
    /**
     * The Destination (output) belonging to the global Tone.js Context.
     * See [[Destination]]
     * @category Core
     */
    function getDestination() {
        return getContext().destination;
    }
    /**
     * The [[Listener]] belonging to the global Tone.js Context.
     * @category Core
     */
    const Listener$1 = getContext().listener;
    /**
     * The [[Listener]] belonging to the global Tone.js Context.
     * @category Core
     */
    function getListener() {
        return getContext().listener;
    }
    /**
     * Draw is used to synchronize the draw frame with the Transport's callbacks.
     * See [[Draw]]
     * @category Core
     */
    const Draw$1 = getContext().draw;
    /**
     * Get the singleton attached to the global context.
     * Draw is used to synchronize the draw frame with the Transport's callbacks.
     * See [[Draw]]
     * @category Core
     */
    function getDraw() {
        return getContext().draw;
    }
    /**
     * A reference to the global context
     * See [[Context]]
     */
    const context = getContext();
    /**
     * Promise which resolves when all of the loading promises are resolved.
     * Alias for static [[ToneAudioBuffer.loaded]] method.
     * @category Core
     */
    function loaded() {
        return ToneAudioBuffer.loaded();
    }
    const Buffer = ToneAudioBuffer;
    const Buffers = ToneAudioBuffers;
    const BufferSource = ToneBufferSource;

    var Tone$1 = /*#__PURE__*/Object.freeze({
        __proto__: null,
        now: now,
        immediate: immediate,
        Transport: Transport$1,
        getTransport: getTransport,
        Destination: Destination$1,
        Master: Master,
        getDestination: getDestination,
        Listener: Listener$1,
        getListener: getListener,
        Draw: Draw$1,
        getDraw: getDraw,
        context: context,
        loaded: loaded,
        Buffer: Buffer,
        Buffers: Buffers,
        BufferSource: BufferSource,
        getContext: getContext,
        setContext: setContext,
        start: start,
        supported: isSupported,
        dbToGain: dbToGain,
        gainToDb: gainToDb,
        intervalToFrequencyRatio: intervalToFrequencyRatio,
        ftom: ftom,
        mtof: mtof,
        optionsFromArguments: optionsFromArguments,
        defaultArg: defaultArg,
        Clock: Clock,
        Context: Context,
        BaseContext: BaseContext,
        Delay: Delay,
        Gain: Gain,
        Offline: Offline,
        OfflineContext: OfflineContext,
        Param: Param,
        ToneAudioBuffer: ToneAudioBuffer,
        ToneAudioBuffers: ToneAudioBuffers,
        ToneAudioNode: ToneAudioNode,
        connectSeries: connectSeries,
        connect: connect,
        disconnect: disconnect,
        FrequencyClass: FrequencyClass,
        Frequency: Frequency,
        MidiClass: MidiClass,
        Midi: Midi,
        TimeClass: TimeClass,
        Time: Time,
        TicksClass: TicksClass,
        Ticks: Ticks,
        TransportTimeClass: TransportTimeClass,
        TransportTime: TransportTime,
        Emitter: Emitter,
        IntervalTimeline: IntervalTimeline,
        StateTimeline: StateTimeline,
        Timeline: Timeline,
        isUndef: isUndef,
        isDefined: isDefined,
        isFunction: isFunction,
        isNumber: isNumber,
        isObject: isObject,
        isBoolean: isBoolean,
        isArray: isArray,
        isString: isString,
        isNote: isNote,
        Unit: Units,
        debug: Debug,
        Noise: Noise,
        UserMedia: UserMedia,
        Oscillator: Oscillator,
        AMOscillator: AMOscillator,
        FMOscillator: FMOscillator,
        PulseOscillator: PulseOscillator,
        FatOscillator: FatOscillator,
        PWMOscillator: PWMOscillator,
        OmniOscillator: OmniOscillator,
        ToneOscillatorNode: ToneOscillatorNode,
        LFO: LFO,
        ToneBufferSource: ToneBufferSource,
        Player: Player,
        Players: Players,
        GrainPlayer: GrainPlayer,
        Add: Add,
        Abs: Abs,
        AudioToGain: AudioToGain,
        GainToAudio: GainToAudio,
        GreaterThan: GreaterThan,
        GreaterThanZero: GreaterThanZero,
        Multiply: Multiply,
        Negate: Negate,
        Pow: Pow,
        Signal: Signal,
        connectSignal: connectSignal,
        Scale: Scale,
        ScaleExp: ScaleExp,
        Subtract: Subtract,
        SyncedSignal: SyncedSignal,
        WaveShaper: WaveShaper,
        Zero: Zero,
        AMSynth: AMSynth,
        DuoSynth: DuoSynth,
        FMSynth: FMSynth,
        MetalSynth: MetalSynth,
        MembraneSynth: MembraneSynth,
        MonoSynth: MonoSynth,
        NoiseSynth: NoiseSynth,
        PluckSynth: PluckSynth,
        PolySynth: PolySynth,
        Sampler: Sampler,
        Synth: Synth,
        Loop: Loop,
        Part: Part,
        Pattern: Pattern,
        Sequence: Sequence,
        ToneEvent: ToneEvent,
        AutoFilter: AutoFilter,
        AutoPanner: AutoPanner,
        AutoWah: AutoWah,
        BitCrusher: BitCrusher,
        Chebyshev: Chebyshev,
        Chorus: Chorus,
        Distortion: Distortion,
        FeedbackDelay: FeedbackDelay,
        FrequencyShifter: FrequencyShifter,
        Freeverb: Freeverb,
        JCReverb: JCReverb,
        PingPongDelay: PingPongDelay,
        PitchShift: PitchShift,
        Phaser: Phaser,
        Reverb: Reverb,
        StereoWidener: StereoWidener,
        Tremolo: Tremolo,
        Vibrato: Vibrato,
        Analyser: Analyser,
        Meter: Meter,
        FFT: FFT,
        DCMeter: DCMeter,
        Waveform: Waveform,
        Follower: Follower,
        Channel: Channel,
        CrossFade: CrossFade,
        Merge: Merge,
        MidSideMerge: MidSideMerge,
        MidSideSplit: MidSideSplit,
        MultibandSplit: MultibandSplit,
        Panner: Panner,
        Panner3D: Panner3D,
        PanVol: PanVol,
        Recorder: Recorder,
        Solo: Solo,
        Split: Split,
        Volume: Volume,
        Compressor: Compressor,
        Gate: Gate,
        Limiter: Limiter,
        MidSideCompressor: MidSideCompressor,
        MultibandCompressor: MultibandCompressor,
        AmplitudeEnvelope: AmplitudeEnvelope,
        Envelope: Envelope,
        FrequencyEnvelope: FrequencyEnvelope,
        EQ3: EQ3,
        Filter: Filter,
        OnePoleFilter: OnePoleFilter,
        FeedbackCombFilter: FeedbackCombFilter,
        LowpassCombFilter: LowpassCombFilter,
        Convolver: Convolver,
        BiquadFilter: BiquadFilter,
        version: version
    });

    var version$1 = '5.12.0';

    var version_1 = version$1;

    //    Copyright (C) 2014-2018 Gregory Dyke (gregdyke at gmail dot com)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    var spacing = {};

    spacing.FONTEM = 360;
    spacing.FONTSIZE = 30;
    spacing.STEP = spacing.FONTSIZE*93/720;
    spacing.SPACE = 10;
    spacing.TOPNOTE = 15;
    spacing.STAVEHEIGHT = 100;
    spacing.INDENT = 50;

    var abc_spacing = spacing;

    //    abc_parse.js: parses a string representing ABC Music Notation into a usable internal structure.
    //    Copyright (C) 2010-2018 Paul Rosen (paul at paulrosen dot net)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    var parseCommon = {};

    parseCommon.clone = function(source) {
    	var destination = {};
    	for (var property in source)
    		if (source.hasOwnProperty(property))
    			destination[property] = source[property];
    	return destination;
    };

    parseCommon.cloneArray = function(source) {
    	var destination = [];
    	for (var i = 0; i < source.length; i++) {
    		destination.push(parseCommon.clone(source[i]));
    	}
    	return destination;
    };

    parseCommon.cloneHashOfHash = function(source) {
    	var destination = {};
    	for (var property in source)
    		if (source.hasOwnProperty(property))
    			destination[property] = parseCommon.clone(source[property]);
    	return destination;
    };

    parseCommon.cloneHashOfArrayOfHash = function(source) {
    	var destination = {};
    	for (var property in source)
    		if (source.hasOwnProperty(property))
    			destination[property] = parseCommon.cloneArray(source[property]);
    	return destination;
    };

    parseCommon.gsub = function(source, pattern, replacement) {
    	return source.split(pattern).join(replacement);
    };

    parseCommon.strip = function(str) {
    	return str.replace(/^\s+/, '').replace(/\s+$/, '');
    };

    parseCommon.startsWith = function(str, pattern) {
    	return str.indexOf(pattern) === 0;
    };

    parseCommon.endsWith = function(str, pattern) {
    	var d = str.length - pattern.length;
    	return d >= 0 && str.lastIndexOf(pattern) === d;
    };

    parseCommon.each = function(arr, iterator, context) {
    	for (var i = 0, length = arr.length; i < length; i++)
    	  iterator.apply(context, [arr[i],i]);
    };

    parseCommon.last = function(arr) {
    	if (arr.length === 0)
    		return null;
    	return arr[arr.length-1];
    };

    parseCommon.compact = function(arr) {
    	var output = [];
    	for (var i = 0; i < arr.length; i++) {
    		if (arr[i])
    			output.push(arr[i]);
    	}
    	return output;
    };

    parseCommon.detect = function(arr, iterator) {
    	for (var i = 0; i < arr.length; i++) {
    		if (iterator(arr[i]))
    			return true;
    	}
    	return false;
    };

    // The following is a polyfill for Object.remove for IE9, IE10, and IE11.
    // from:https://github.com/jserz/js_piece/blob/master/DOM/ChildNode/remove()/remove().md
    (function (arr) {
    	arr.forEach(function (item) {
    		if (item.hasOwnProperty('remove')) {
    			return;
    		}
    		Object.defineProperty(item, 'remove', {
    			configurable: true,
    			enumerable: true,
    			writable: true,
    			value: function remove() {
    				if (this.parentNode !== null)
    					this.parentNode.removeChild(this);
    			}
    		});
    	});
    })([Element.prototype, CharacterData.prototype, DocumentType.prototype]);

    var abc_common = parseCommon;

    var TimingCallbacks = function(target, params) {
    	var self = this;
    	if (!params) params = {};
    	self.qpm = params.qpm ? parseInt(params.qpm, 10) : null;
    	if (!self.qpm) {
    		var tempo = target.metaText ? target.metaText.tempo : null;
    		self.qpm = target.getBpm(tempo);
    	}
    	self.extraMeasuresAtBeginning = params.extraMeasuresAtBeginning ? parseInt(params.extraMeasuresAtBeginning, 10) : 0;
    	self.beatCallback = params.beatCallback; // This is called for each beat.
    	self.eventCallback = params.eventCallback;   // This is called for each note or rest encountered.
    	self.lineEndCallback = params.lineEndCallback;   // This is called when the end of a line is approaching.
    	self.lineEndAnticipation = params.lineEndAnticipation ? parseInt(params.lineEndAnticipation, 10) : 0;   // How many milliseconds before the end should the call happen.
    	self.beatSubdivisions = params.beatSubdivisions ? parseInt(params.beatSubdivisions, 10) : 1; // how many callbacks per beat is desired.

    	self.replaceTarget = function(newTarget) {
    		newTarget.setTiming(self.qpm, self.extraMeasuresAtBeginning);
    		if (newTarget.noteTimings.length === 0)
    			newTarget.setTiming(0,0);
    		if (self.lineEndCallback) {
    			self.lineEndTimings = getLineEndTimings(newTarget.noteTimings, self.lineEndAnticipation);
    		}
    		self.noteTimings = newTarget.noteTimings;
    	};

    	self.replaceTarget(target);
    	if (self.noteTimings.length === 0)
    		return;

    	// noteTimings contains an array of events sorted by time. Events that happen at the same time are in the same element of the array.
    	self.noteTimings = target.noteTimings;
    	self.millisecondsPerBeat = 1000 / (self.qpm / 60) / self.beatSubdivisions;
    	self.lastMoment = self.noteTimings[self.noteTimings.length-1].milliseconds;
    	self.totalBeats = Math.round(self.lastMoment / self.millisecondsPerBeat);

    	self.startTime = null;
    	self.currentBeat = 0;
    	self.currentEvent = 0;
    	self.isPaused = false;
    	self.isRunning = false;
    	self.pausedTime = null;
    	self.justUnpaused = false;

    	self.newSeekPercent = 0;
    	self.justSeeked = false;

    	function setCurrentLocation(timestamp) {
    		// First find the relative amount to move: that is, the difference between the current percentage and the passed in percent.
    		var currentPercent = (timestamp - self.startTime) / self.lastMoment;
    		var percentDifference = currentPercent - self.newSeekPercent;
    		var timeDifference = self.lastMoment * percentDifference;
    		self.startTime = self.startTime + timeDifference;

    		var currentTime = timestamp - self.startTime;
    		currentTime += 50; // Add a little slop because this function isn't called exactly.

    		var oldBeat = self.currentBeat;
    		self.currentBeat = Math.floor(currentTime / self.millisecondsPerBeat);
    		if (self.beatCallback && oldBeat !== self.currentBeat) // If the movement caused the beat to change, then immediately report it to the client.
    			self.beatCallback(self.currentBeat / self.beatSubdivisions, self.totalBeats / self.beatSubdivisions, self.lastMoment);

    		self.currentEvent = 0;
    		while (self.noteTimings.length > self.currentEvent && self.noteTimings[self.currentEvent].milliseconds < currentTime) {
    			self.currentEvent++;
    		}
    		if (self.eventCallback && self.currentEvent > 0 && self.noteTimings[self.currentEvent - 1].type === 'event')
    			self.eventCallback(self.noteTimings[self.currentEvent - 1]);

    		// console.log("currentPercent="+currentPercent+
    		// 	" newSeekPercent="+self.newSeekPercent+
    		// 	" percentDifference="+percentDifference+
    		// 	" timeDifference=",timeDifference+
    		// 	" currentBeat="+self.currentBeat+
    		// 	" currentEvent="+self.currentEvent);
    	}

    	self.doTiming = function (timestamp) {
    		if (!self.startTime) {
    			self.startTime = timestamp;
    		} else if (self.justUnpaused) {
    			// Add the amount we paused to the start time to get the right place.
    			var timePaused = (timestamp - self.pausedTime);
    			self.startTime += timePaused;
    		}
    		self.justUnpaused = false;

    		if (self.justSeeked) {
    			setCurrentLocation(timestamp);
    			self.justSeeked = false;
    		}
    		if (self.isPaused) {
    			self.pausedTime = timestamp;
    		} else if (self.isRunning) {
    			var currentTime = timestamp - self.startTime;
    			currentTime += 50; // Add a little slop because this function isn't called exactly.
    			while (self.noteTimings.length > self.currentEvent && self.noteTimings[self.currentEvent].milliseconds < currentTime) {
    				if (self.eventCallback && self.noteTimings[self.currentEvent].type === 'event')
    					self.eventCallback(self.noteTimings[self.currentEvent]);
    				self.currentEvent++;
    			}
    			if (currentTime < self.lastMoment) {
    				requestAnimationFrame(self.doTiming);
    				if (self.currentBeat * self.millisecondsPerBeat < currentTime) {
    					if (self.beatCallback)
    						self.beatCallback(self.currentBeat / self.beatSubdivisions, self.totalBeats / self.beatSubdivisions, self.lastMoment);
    					self.currentBeat++;
    				}
    			} else if (self.currentBeat <= self.totalBeats) {
    				// Because of timing issues (for instance, if the browser tab isn't active), the beat callbacks might not have happened when they are supposed to. To keep the client programs from having to deal with that, this will keep calling the loop until all of them have been sent.
    				if (self.beatCallback) {
    					self.beatCallback(self.currentBeat / self.beatSubdivisions, self.totalBeats / self.beatSubdivisions, self.lastMoment);
    					self.currentBeat++;
    					requestAnimationFrame(self.doTiming);
    				}
    			}

    			if (self.lineEndCallback && self.lineEndTimings.length && self.lineEndTimings[0].milliseconds <= currentTime) {
    				self.lineEndCallback(self.lineEndTimings[0]);
    				self.lineEndTimings.shift();
    			}

    			if (currentTime >= self.lastMoment && self.eventCallback)
    				self.eventCallback(null);
    		}
    	};

    	self.start = function() {
    		self.isRunning = true;
    		if (self.isPaused) {
    			self.isPaused = false;
    			self.justUnpaused = true;
    		}
    		requestAnimationFrame(self.doTiming);
    	};
    	self.pause = function() {
    		self.isPaused = true;
    		self.isRunning = false;
    	};
    	self.reset = function() {
    		self.currentBeat = 0;
    		self.currentEvent = 0;
    		self.startTime = null;
    		self.pausedTime = null;
    		if (self.lineEndCallback) {
    			self.lineEndTimings = getLineEndTimings(self.noteTimings, self.lineEndAnticipation);
    		}
    	};
    	self.stop = function() {
    		self.pause();
    		self.reset();
    	};
    	self.setProgress = function(percent) {
    		// this is passed a value between 0 and 1.
    		// the effect of this function is to move startTime so that the callbacks happen correctly for the new seek.
    		if (percent < 0) percent = 0;
    		if (percent > 1) percent = 1;

    		self.newSeekPercent = percent;
    		self.justSeeked = true;
    		requestAnimationFrame(self.doTiming);
    	};
    };

    function getLineEndTimings(timings, anticipation) {
    	// Returns an array of milliseconds to call the lineEndCallback.
    	// This figures out the timing of the beginning of each line and subtracts the anticipation from it.
    	var callbackTimes = [];
    	var lastTop = null;
    	for (var i = 0; i < timings.length; i++) {
    		var timing = timings[i];
    		if (timing.top !== lastTop) {
    			callbackTimes.push({ milliseconds: timing.milliseconds - anticipation, top: timing.top, bottom: timing.top+timing.height });
    			lastTop = timing.top;
    		}
    	}
    	return callbackTimes;
    }

    var abc_timing_callbacks = TimingCallbacks;

    //    abc_animation.js: handles animating the music in real time.
    //    Copyright (C) 2014-2018 Paul Rosen (paul at paulrosen dot net)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.





    var animation = {};

    (function() {

    	var timer;
    	var cursor;
    	animation.startAnimation = function(paper, tune, options) {
    		//options.bpm
    		//options.showCursor
    		//options.hideCurrentMeasure
    		//options.hideFinishedMeasures
    		if (timer) {
    			timer.stop();
    			timer = undefined;
    		}

    		if (options.showCursor) {
    			cursor = paper.querySelector('.abcjs-cursor');
    			if (!cursor) {
    				cursor = document.createElement('DIV');
    				cursor.className = 'abcjs-cursor cursor';
    				cursor.style.position = 'absolute';

    				paper.appendChild(cursor);
    				paper.style.position = 'relative';
    			}
    		}

    		function hideMeasures(elements) {
    			for (var i = 0; i < elements.length; i++) {
    				var element = elements[i];
    				if (!element.classList.contains('abcjs-bar'))
    					element.style.display = "none";
    			}
    		}

    		var lastMeasure;
    		function disappearMeasuresAfter(selector) {
    			if (lastMeasure) {
    				var elements = paper.querySelectorAll(lastMeasure);
    				hideMeasures(elements);
    			}
    			lastMeasure = selector;
    		}

    		function disappearMeasuresBefore(selector) {
    			var elements = paper.querySelectorAll(selector);
    			hideMeasures(elements);
    		}

    		function measureCallback(selector) {
    			if (options.hideCurrentMeasure) {
    				disappearMeasuresBefore(selector);
    			} else if (options.hideFinishedMeasures) {
    				disappearMeasuresAfter(selector);
    			}
    		}

    		function getLineAndMeasure(element) {
    			return '.abcjs-l' + element.line + '.abcjs-m' + element.measureNumber;
    		}

    		function setCursor(range) {
    			if (range) {
    				if (range.measureStart) {
    					var selector = getLineAndMeasure(range);
    					if (selector)
    						measureCallback(selector);
    				}
    				if (cursor) {
    					cursor.style.left = range.left + "px";
    					cursor.style.top = range.top + "px";
    					cursor.style.width = range.width + "px";
    					cursor.style.height = range.height + "px";
    				}
    			} else {
    				timer.stop();
    				timer = undefined;
    			}
    		}

    		timer = new abc_timing_callbacks(tune, {
    			qpm: options.bpm,
    			eventCallback: setCursor
    		});
    		timer.start();
    	};

    	animation.pauseAnimation = function(pause) {
    		if (timer) {
    			if (pause)
    				timer.pause();
    			else
    				timer.start();
    		}
    	};

    	animation.stopAnimation = function() {
    		if (timer) {
    			timer.stop();
    			timer = undefined;
    		}
    	};

    })();

    var abc_animation = animation;

    /*global window */



    var parseDirective = {};

    (function() {
    	var tokenizer;
    	var warn;
    	var multilineVars;
    	var tune;
    	parseDirective.initialize = function(tokenizer_, warn_, multilineVars_, tune_) {
    		tokenizer = tokenizer_;
    		warn = warn_;
    		multilineVars = multilineVars_;
    		tune = tune_;
    		initializeFonts();
    	};

    	function initializeFonts() {
    		multilineVars.annotationfont  = { face: "Helvetica", size: 12, weight: "normal", style: "normal", decoration: "none" };
    		multilineVars.gchordfont  = { face: "Helvetica", size: 12, weight: "normal", style: "normal", decoration: "none" };
    		multilineVars.historyfont  = { face: "\"Times New Roman\"", size: 16, weight: "normal", style: "normal", decoration: "none" };
    		multilineVars.infofont  = { face: "\"Times New Roman\"", size: 14, weight: "normal", style: "italic", decoration: "none" };
    		multilineVars.measurefont  = { face: "\"Times New Roman\"", size: 14, weight: "normal", style: "italic", decoration: "none" };
    		multilineVars.partsfont  = { face: "\"Times New Roman\"", size: 15, weight: "normal", style: "normal", decoration: "none" };
    		multilineVars.repeatfont  = { face: "\"Times New Roman\"", size: 13, weight: "normal", style: "normal", decoration: "none" };
    		multilineVars.textfont  = { face: "\"Times New Roman\"", size: 16, weight: "normal", style: "normal", decoration: "none" };
    		multilineVars.tripletfont = {face: "Times", size: 11, weight: "normal", style: "italic", decoration: "none"};
    		multilineVars.vocalfont  = { face: "\"Times New Roman\"", size: 13, weight: "bold", style: "normal", decoration: "none" };
    		multilineVars.wordsfont  = { face: "\"Times New Roman\"", size: 16, weight: "normal", style: "normal", decoration: "none" };

    		// These fonts are global for the entire tune.
    		tune.formatting.composerfont  = { face: "\"Times New Roman\"", size: 14, weight: "normal", style: "italic", decoration: "none" };
    		tune.formatting.subtitlefont  = { face: "\"Times New Roman\"", size: 16, weight: "normal", style: "normal", decoration: "none" };
    		tune.formatting.tempofont  = { face: "\"Times New Roman\"", size: 15, weight: "bold", style: "normal", decoration: "none" };
    		tune.formatting.titlefont  = { face: "\"Times New Roman\"", size: 20, weight: "normal", style: "normal", decoration: "none" };
    		tune.formatting.footerfont  = { face: "\"Times New Roman\"", size: 12, weight: "normal", style: "normal", decoration: "none" };
    		tune.formatting.headerfont  = { face: "\"Times New Roman\"", size: 12, weight: "normal", style: "normal", decoration: "none" };
    		tune.formatting.voicefont  = { face: "\"Times New Roman\"", size: 13, weight: "bold", style: "normal", decoration: "none" };

    		// these are the default fonts for these element types. In the printer, these fonts might change as the tune progresses.
    		tune.formatting.annotationfont  = multilineVars.annotationfont;
    		tune.formatting.gchordfont  = multilineVars.gchordfont;
    		tune.formatting.historyfont  = multilineVars.historyfont;
    		tune.formatting.infofont  = multilineVars.infofont;
    		tune.formatting.measurefont  = multilineVars.measurefont;
    		tune.formatting.partsfont  = multilineVars.partsfont;
    		tune.formatting.repeatfont  = multilineVars.repeatfont;
    		tune.formatting.textfont  = multilineVars.textfont;
    		tune.formatting.tripletfont  = multilineVars.tripletfont;
    		tune.formatting.vocalfont  = multilineVars.vocalfont;
    		tune.formatting.wordsfont  = multilineVars.wordsfont;
    	}

    	var fontTypeCanHaveBox = { gchordfont: true, measurefont: true, partsfont: true };

    	var fontTranslation = function(fontFace) {
    		// This translates Postscript fonts for a web alternative.
    		// Note that the postscript fonts contain italic and bold info in them, so what is returned is a hash.

    		switch (fontFace) {
    			case "Arial-Italic":
    				return { face: "Arial", weight: "normal", style: "italic", decoration: "none" };
    			case "Arial-Bold":
    				return { face: "Arial", weight: "bold", style: "normal", decoration: "none" };
    			case "Bookman-Demi":
    				return { face: "Bookman,serif", weight: "bold", style: "normal", decoration: "none" };
    			case "Bookman-DemiItalic":
    				return { face: "Bookman,serif", weight: "bold", style: "italic", decoration: "none" };
    			case "Bookman-Light":
    				return { face: "Bookman,serif", weight: "normal", style: "normal", decoration: "none" };
    			case "Bookman-LightItalic":
    				return { face: "Bookman,serif", weight: "normal", style: "italic", decoration: "none" };
    			case "Courier":
    				return { face: "\"Courier New\"", weight: "normal", style: "normal", decoration: "none" };
    			case "Courier-Oblique":
    				return { face: "\"Courier New\"", weight: "normal", style: "italic", decoration: "none" };
    			case "Courier-Bold":
    				return { face: "\"Courier New\"", weight: "bold", style: "normal", decoration: "none" };
    			case "Courier-BoldOblique":
    				return { face: "\"Courier New\"", weight: "bold", style: "italic", decoration: "none" };
    			case "AvantGarde-Book":
    				return { face: "AvantGarde,Arial", weight: "normal", style: "normal", decoration: "none" };
    			case "AvantGarde-BookOblique":
    				return { face: "AvantGarde,Arial", weight: "normal", style: "italic", decoration: "none" };
    			case "AvantGarde-Demi":
    			case "Avant-Garde-Demi":
    				return { face: "AvantGarde,Arial", weight: "bold", style: "normal", decoration: "none" };
    			case "AvantGarde-DemiOblique":
    				return { face: "AvantGarde,Arial", weight: "bold", style: "italic", decoration: "none" };
    			case "Helvetica-Oblique":
    				return { face: "Helvetica", weight: "normal", style: "italic", decoration: "none" };
    			case "Helvetica-Bold":
    				return { face: "Helvetica", weight: "bold", style: "normal", decoration: "none" };
    			case "Helvetica-BoldOblique":
    				return { face: "Helvetica", weight: "bold", style: "italic", decoration: "none" };
    			case "Helvetica-Narrow":
    				return { face: "\"Helvetica Narrow\",Helvetica", weight: "normal", style: "normal", decoration: "none" };
    			case "Helvetica-Narrow-Oblique":
    				return { face: "\"Helvetica Narrow\",Helvetica", weight: "normal", style: "italic", decoration: "none" };
    			case "Helvetica-Narrow-Bold":
    				return { face: "\"Helvetica Narrow\",Helvetica", weight: "bold", style: "normal", decoration: "none" };
    			case "Helvetica-Narrow-BoldOblique":
    				return { face: "\"Helvetica Narrow\",Helvetica", weight: "bold", style: "italic", decoration: "none" };
    			case "Palatino-Roman":
    				return { face: "Palatino", weight: "normal", style: "normal", decoration: "none" };
    			case "Palatino-Italic":
    				return { face: "Palatino", weight: "normal", style: "italic", decoration: "none" };
    			case "Palatino-Bold":
    				return { face: "Palatino", weight: "bold", style: "normal", decoration: "none" };
    			case "Palatino-BoldItalic":
    				return { face: "Palatino", weight: "bold", style: "italic", decoration: "none" };
    			case "NewCenturySchlbk-Roman":
    				return { face: "\"New Century\",serif", weight: "normal", style: "normal", decoration: "none" };
    			case "NewCenturySchlbk-Italic":
    				return { face: "\"New Century\",serif", weight: "normal", style: "italic", decoration: "none" };
    			case "NewCenturySchlbk-Bold":
    				return { face: "\"New Century\",serif", weight: "bold", style: "normal", decoration: "none" };
    			case "NewCenturySchlbk-BoldItalic":
    				return { face: "\"New Century\",serif", weight: "bold", style: "italic", decoration: "none" };
    			case "Times":
    			case "Times-Roman":
    			case "Times-Narrow":
    			case "Times-Courier":
    			case "Times-New-Roman":
    				return { face: "\"Times New Roman\"", weight: "normal", style: "normal", decoration: "none" };
    			case "Times-Italic":
    			case "Times-Italics":
    				return { face: "\"Times New Roman\"", weight: "normal", style: "italic", decoration: "none" };
    			case "Times-Bold":
    				return { face: "\"Times New Roman\"", weight: "bold", style: "normal", decoration: "none" };
    			case "Times-BoldItalic":
    				return { face: "\"Times New Roman\"", weight: "bold", style: "italic", decoration: "none" };
    			case "ZapfChancery-MediumItalic":
    				return { face: "\"Zapf Chancery\",cursive,serif", weight: "normal", style: "normal", decoration: "none" };
    			default:
    				return null;
    		}
    	};

    	var getFontParameter = function(tokens, currentSetting, str, position, cmd) {
    		// Every font parameter has the following format:
    		// <face> <utf8> <size> <modifiers> <box>
    		// Where:
    		// face: either a standard web font name, or a postscript font, enumerated in fontTranslation. This could also be an * or be missing if the face shouldn't change.
    		// utf8: This is optional, and specifies utf8. That's all that is supported so the field is just silently ignored.
    		// size: The size, in pixels. This may be omitted if the size is not changing.
    		// modifiers: zero or more of "bold", "italic", "underline"
    		// box: Only applies to the measure numbers, gchords, and the parts. If present, then a box is drawn around the characters.
    		// If face is present, then all the modifiers are cleared. If face is absent, then the modifiers are illegal.
    		// The face can be a single word, a set of words separated by hyphens, or a quoted string.
    		//
    		// So, in practicality, there are three types of font definitions: a number only, an asterisk and a number only, or the full definition (with an optional size).
    		function processNumberOnly() {
    			var size = parseInt(tokens[0].token);
    			tokens.shift();
    			if (!currentSetting) {
    				warn("Can't set just the size of the font since there is no default value.", str, position);
    				return { face: "\"Times New Roman\"", weight: "normal", style: "normal", decoration: "none", size: size};
    			}
    			if (tokens.length === 0) {
    				return { face: currentSetting.face, weight: currentSetting.weight, style: currentSetting.style, decoration: currentSetting.decoration, size: size};
    			}
    			if (tokens.length === 1 && tokens[0].token === "box" && fontTypeCanHaveBox[cmd])
    				return { face: currentSetting.face, weight: currentSetting.weight, style: currentSetting.style, decoration: currentSetting.decoration, size: size, box: true};
    			warn("Extra parameters in font definition.", str, position);
    			return { face: currentSetting.face, weight: currentSetting.weight, style: currentSetting.style, decoration: currentSetting.decoration, size: size};
    		}

    		// format 1: asterisk and number only
    		if (tokens[0].token === '*') {
    			tokens.shift();
    			if (tokens[0].type === 'number')
    				return processNumberOnly();
    			else {
    				warn("Expected font size number after *.", str, position);
    			}
    		}

    		// format 2: number only
    		if (tokens[0].type === 'number') {
    			return processNumberOnly();
    		}

    		// format 3: whole definition
    		var face = [];
    		var size;
    		var weight = "normal";
    		var style = "normal";
    		var decoration = "none";
    		var box = false;
    		var state = 'face';
    		var hyphenLast = false;
    		while (tokens.length) {
    			var currToken = tokens.shift();
    			var word = currToken.token.toLowerCase();
    			switch (state) {
    				case 'face':
    					if (hyphenLast || (word !== 'utf' && currToken.type !== 'number' && word !== "bold" && word !== "italic" && word !== "underline" && word !== "box")) {
    						if (face.length > 0 && currToken.token === '-') {
    							hyphenLast = true;
    							face[face.length-1] = face[face.length-1] + currToken.token;
    						}
    						else {
    							if (hyphenLast) {
    								hyphenLast = false;
    								face[face.length-1] = face[face.length-1] + currToken.token;
    							} else
    								face.push(currToken.token);
    						}
    					} else {
    						if (currToken.type === 'number') {
    							if (size) {
    								warn("Font size specified twice in font definition.", str, position);
    							} else {
    								size = currToken.token;
    							}
    							state = 'modifier';
    						} else if (word === "bold")
    							weight = "bold";
    						else if (word === "italic")
    							style = "italic";
    						else if (word === "underline")
    							decoration = "underline";
    						else if (word === "box") {
    							if (fontTypeCanHaveBox[cmd])
    								box = true;
    							else
    								warn("This font style doesn't support \"box\"", str, position);
    							state = "finished";
    						} else if (word === "utf") {
    							currToken = tokens.shift(); // this gets rid of the "8" after "utf"
    							state = "size";
    						} else
    							warn("Unknown parameter " + currToken.token + " in font definition.", str, position);
    					}
    					break;
    				case "size":
    					if (currToken.type === 'number') {
    						if (size) {
    							warn("Font size specified twice in font definition.", str, position);
    						} else {
    							size = currToken.token;
    						}
    					} else {
    						warn("Expected font size in font definition.", str, position);
    					}
    					state = 'modifier';
    					break;
    				case "modifier":
    					if (word === "bold")
    						weight = "bold";
    					else if (word === "italic")
    						style = "italic";
    					else if (word === "underline")
    						decoration = "underline";
    					else if (word === "box") {
    						if (fontTypeCanHaveBox[cmd])
    							box = true;
    						else
    							warn("This font style doesn't support \"box\"", str, position);
    						state = "finished";
    					} else
    						warn("Unknown parameter " + currToken.token + " in font definition.", str, position);
    					break;
    				case "finished":
    					warn("Extra characters found after \"box\" in font definition.", str, position);
    					break;
    			}
    		}

    		if (size === undefined) {
    			if (!currentSetting) {
    				warn("Must specify the size of the font since there is no default value.", str, position);
    				size = 12;
    			} else
    				size = currentSetting.size;
    		} else
    			size = parseFloat(size);

    		face = face.join(' ');
    		var psFont = fontTranslation(face);
    		var font = {};
    		if (psFont) {
    			font.face = psFont.face;
    			font.weight = psFont.weight;
    			font.style = psFont.style;
    			font.decoration = psFont.decoration;
    			font.size = size;
    			if (box)
    				font.box = true;
    			return font;
    		}
    		font.face = face;
    		font.weight = weight;
    		font.style = style;
    		font.decoration = decoration;
    		font.size = size;
    		if (box)
    			font.box = true;
    		return font;
    	};

    	var getChangingFont = function(cmd, tokens, str) {
    		if (tokens.length === 0)
    			return "Directive \"" + cmd + "\" requires a font as a parameter.";
    		multilineVars[cmd] = getFontParameter(tokens, multilineVars[cmd], str, 0, cmd);
    		if (multilineVars.is_in_header) // If the font appears in the header, then it becomes the default font.
    			tune.formatting[cmd] = multilineVars[cmd];
    		return null;
    	};
    	var getGlobalFont = function(cmd, tokens, str) {
    		if (tokens.length === 0)
    			return "Directive \"" + cmd + "\" requires a font as a parameter.";
    		tune.formatting[cmd] = getFontParameter(tokens, tune.formatting[cmd], str, 0, cmd);
    		return null;
    	};

    	var setScale = function(cmd, tokens) {
    		var scratch = "";
    		abc_common.each(tokens, function(tok) {
    			scratch += tok.token;
    		});
    		var num = parseFloat(scratch);
    		if (isNaN(num) || num === 0)
    			return "Directive \"" + cmd + "\" requires a number as a parameter.";
    		tune.formatting.scale = num;

    	};

    	var getRequiredMeasurement = function(cmd, tokens) {
    		var points = tokenizer.getMeasurement(tokens);
    		if (points.used === 0 || tokens.length !== 0)
    			return { error: "Directive \"" + cmd + "\" requires a measurement as a parameter."};
    		return points.value;
    	};
    	var oneParameterMeasurement = function(cmd, tokens) {
    		var points = tokenizer.getMeasurement(tokens);
    		if (points.used === 0 || tokens.length !== 0)
    			return "Directive \"" + cmd + "\" requires a measurement as a parameter.";
    		tune.formatting[cmd] = points.value;
    		return null;
    	};

    	var addMultilineVar = function(key, cmd, tokens, min, max) {
    		if (tokens.length !== 1 || tokens[0].type !== 'number')
    			return "Directive \"" + cmd + "\" requires a number as a parameter.";
    		var i = tokens[0].intt;
    		if (min !== undefined && i < min)
    			return "Directive \"" + cmd + "\" requires a number greater than or equal to " + min + " as a parameter.";
    		if (max !== undefined && i > max)
    			return "Directive \"" + cmd + "\" requires a number less than or equal to " + max + " as a parameter.";
    		multilineVars[key] = i;
    		return null;
    	};

    	var addMultilineVarBool = function(key, cmd, tokens) {
    		if (tokens.length === 1 && (tokens[0].token === 'true' || tokens[0].token === 'false')) {
    			multilineVars[key] = tokens[0].token === 'true';
    			return null;
    		}
    		var str = addMultilineVar(key, cmd, tokens, 0, 1);
    		if (str !== null) return str;
    		multilineVars[key] = (multilineVars[key] === 1);
    		return null;
    	};

    	var addMultilineVarOneParamChoice = function(key, cmd, tokens, choices) {
    		if (tokens.length !== 1)
    			return "Directive \"" + cmd + "\" requires one of [ " + choices.join(", ") + " ] as a parameter.";
    		var choice = tokens[0].token;
    		var found = false;
    		for (var i = 0; !found && i < choices.length; i++) {
    			if (choices[i] === choice)
    				found = true;
    		}
    		if (!found)
    			return "Directive \"" + cmd + "\" requires one of [ " + choices.join(", ") + " ] as a parameter.";
    		multilineVars[key] = choice;
    		return null;
    	};

    	var midiCmdParam0 = [
    		"nobarlines",
    		"barlines",
    		"beataccents",
    		"nobeataccents",
    		"droneon",
    		"droneoff",
    		"drumon",
    		"drumoff",
    		"fermatafixed",
    		"fermataproportional",
    		"gchordon",
    		"gchordoff",
    		"controlcombo",
    		"temperamentnormal",
    		"noportamento"
    	];
    	var midiCmdParam1String = [
    		"gchord",
    		"ptstress",
    		"beatstring"
    	];
    	var midiCmdParam1Integer = [
    		"bassvol",
    		"chordvol",
    		"c",
    		"channel",
    		"beatmod",
    		"deltaloudness",
    		"drumbars",
    		"gracedivider",
    		"makechordchannels",
    		"randomchordattack",
    		"chordattack",
    		"stressmodel",
    		"transpose",
    		"rtranspose",
    		"vol",
    		"volinc"
    	];
    	var midiCmdParam1Integer1OptionalInteger = [
    		"program"
    	];
    	var midiCmdParam2Integer = [
    		"ratio",
    		"snt",
    		"bendvelocity",
    		"pitchbend",
    		"control",
    		"temperamentlinear"
    	];
    	var midiCmdParam4Integer = [
    		"beat"
    	];
    	var midiCmdParam5Integer = [
    		"drone"
    	];
    	var midiCmdParam1String1Integer = [
    		"portamento"
    	];
    	var midiCmdParamFraction = [
    		"expand",
    		"grace",
    		"trim"
    	];
    	var midiCmdParam1StringVariableIntegers = [
    		"drum",
    		"chordname"
    	];

    	var parseMidiCommand = function(midi, tune, restOfString) {
    		var midi_cmd = midi.shift().token;
    		var midi_params = [];
    		if (midiCmdParam0.indexOf(midi_cmd) >= 0) {
    			// NO PARAMETERS
    			if (midi.length !== 0)
    				warn("Unexpected parameter in MIDI " + midi_cmd, restOfString, 0);
    		} else if (midiCmdParam1String.indexOf(midi_cmd) >= 0) {
    			// ONE STRING PARAMETER
    			if (midi.length !== 1)
    				warn("Expected one parameter in MIDI " + midi_cmd, restOfString, 0);
    			else
    				midi_params.push(midi[0].token);
    		} else if (midiCmdParam1Integer.indexOf(midi_cmd) >= 0) {
    			// ONE INT PARAMETER
    			if (midi.length !== 1)
    				warn("Expected one parameter in MIDI " + midi_cmd, restOfString, 0);
    			else if (midi[0].type !== "number")
    				warn("Expected one integer parameter in MIDI " + midi_cmd, restOfString, 0);
    			else
    				midi_params.push(midi[0].intt);
    		} else if (midiCmdParam1Integer1OptionalInteger.indexOf(midi_cmd) >= 0) {
    			// ONE INT PARAMETER, ONE OPTIONAL PARAMETER
    			if (midi.length !== 1 && midi.length !== 2)
    				warn("Expected one or two parameters in MIDI " + midi_cmd, restOfString, 0);
    			else if (midi[0].type !== "number")
    				warn("Expected integer parameter in MIDI " + midi_cmd, restOfString, 0);
    			else if (midi.length === 2 && midi[1].type !== "number")
    				warn("Expected integer parameter in MIDI " + midi_cmd, restOfString, 0);
    			else {
    				midi_params.push(midi[0].intt);
    				if (midi.length === 2)
    					midi_params.push(midi[1].intt);
    			}
    		} else if (midiCmdParam2Integer.indexOf(midi_cmd) >= 0) {
    			// TWO INT PARAMETERS
    			if (midi.length !== 2)
    				warn("Expected two parameters in MIDI " + midi_cmd, restOfString, 0);
    			else if (midi[0].type !== "number" || midi[1].type !== "number")
    				warn("Expected two integer parameters in MIDI " + midi_cmd, restOfString, 0);
    			else {
    				midi_params.push(midi[0].intt);
    				midi_params.push(midi[1].intt);
    			}
    		} else if (midiCmdParam1String1Integer.indexOf(midi_cmd) >= 0) {
    			// ONE STRING PARAMETER, ONE INT PARAMETER
    			if (midi.length !== 2)
    				warn("Expected two parameters in MIDI " + midi_cmd, restOfString, 0);
    			else if (midi[0].type !== "alpha" || midi[1].type !== "number")
    				warn("Expected one string and one integer parameters in MIDI " + midi_cmd, restOfString, 0);
    			else {
    				midi_params.push(midi[0].token);
    				midi_params.push(midi[1].intt);
    			}
    		} else if (midi_cmd === 'drummap') {
    			// BUILD AN OBJECT OF ABC NOTE => MIDI NOTE
    			if (midi.length === 2 && midi[0].type === 'alpha' && midi[1].type === 'number') {
    				if (!tune.formatting) tune.formatting = {};
    				if (!tune.formatting.midi) tune.formatting.midi = {};
    				if (!tune.formatting.midi.drummap) tune.formatting.midi.drummap = {};
    				tune.formatting.midi.drummap[midi[0].token] = midi[1].intt;
    				midi_params = tune.formatting.midi.drummap;
    			} else if (midi.length === 3 && midi[0].type === 'punct' && midi[1].type === 'alpha' && midi[2].type === 'number') {
    				if (!tune.formatting) tune.formatting = {};
    				if (!tune.formatting.midi) tune.formatting.midi = {};
    				if (!tune.formatting.midi.drummap) tune.formatting.midi.drummap = {};
    				tune.formatting.midi.drummap[midi[0].token+midi[1].token] = midi[2].intt;
    				midi_params = tune.formatting.midi.drummap;
    			} else {
    				warn("Expected one note name and one integer parameter in MIDI " + midi_cmd, restOfString, 0);
    			}
    		} else if (midiCmdParamFraction.indexOf(midi_cmd) >= 0) {
    			// ONE FRACTION PARAMETER
    			if (midi.length !== 3)
    				warn("Expected fraction parameter in MIDI " + midi_cmd, restOfString, 0);
    			else if (midi[0].type !== "number" || midi[1].token !== "/" || midi[2].type !== "number")
    				warn("Expected fraction parameter in MIDI " + midi_cmd, restOfString, 0);
    			else {
    				midi_params.push(midi[0].intt);
    				midi_params.push(midi[2].intt);
    			}
    		} else if (midiCmdParam4Integer.indexOf(midi_cmd) >= 0) {
    			// FOUR INT PARAMETERS
    			if (midi.length !== 4)
    				warn("Expected four parameters in MIDI " + midi_cmd, restOfString, 0);
    			else if (midi[0].type !== "number" || midi[1].type !== "number" || midi[2].type !== "number" || midi[3].type !== "number")
    				warn("Expected four integer parameters in MIDI " + midi_cmd, restOfString, 0);
    			else {
    				midi_params.push(midi[0].intt);
    				midi_params.push(midi[1].intt);
    				midi_params.push(midi[2].intt);
    				midi_params.push(midi[3].intt);
    			}
    		} else if (midiCmdParam5Integer.indexOf(midi_cmd) >= 0) {
    			// FIVE INT PARAMETERS
    			if (midi.length !== 5)
    				warn("Expected five parameters in MIDI " + midi_cmd, restOfString, 0);
    			else if (midi[0].type !== "number" || midi[1].type !== "number" || midi[2].type !== "number" || midi[3].type !== "number" || midi[4].type !== "number")
    				warn("Expected five integer parameters in MIDI " + midi_cmd, restOfString, 0);
    			else {
    				midi_params.push(midi[0].intt);
    				midi_params.push(midi[1].intt);
    				midi_params.push(midi[2].intt);
    				midi_params.push(midi[3].intt);
    				midi_params.push(midi[4].intt);
    			}
    		} else if (midiCmdParam1Integer1OptionalInteger.indexOf(midi_cmd) >= 0) {
    			// ONE INT PARAMETER, ONE OPTIONAL OCTAVE PARAMETER
    			if (midi.length !== 1 || midi.length !== 4)
    				warn("Expected one or two parameters in MIDI " + midi_cmd, restOfString, 0);
    			else if (midi[0].type !== "number")
    				warn("Expected integer parameter in MIDI " + midi_cmd, restOfString, 0);
    			else if (midi.length === 4) {
    				if (midi[1].token !== "octave")
    					warn("Expected octave parameter in MIDI " + midi_cmd, restOfString, 0);
    				if (midi[2].token !== "=")
    					warn("Expected octave parameter in MIDI " + midi_cmd, restOfString, 0);
    				if (midi[3].type !== "number")
    					warn("Expected integer parameter for octave in MIDI " + midi_cmd, restOfString, 0);
    			} else {
    				midi_params.push(midi[0].intt);
    				if (midi.length === 4)
    					midi_params.push(midi[3].intt);
    			}
    		} else if (midiCmdParam1StringVariableIntegers.indexOf(midi_cmd) >= 0) {
    			// ONE STRING, VARIABLE INT PARAMETERS
    			if (midi.length < 2)
    				warn("Expected string parameter and at least one integer parameter in MIDI " + midi_cmd, restOfString, 0);
    			else if (midi[0].type !== "alpha")
    				warn("Expected string parameter and at least one integer parameter in MIDI " + midi_cmd, restOfString, 0);
    			else {
    				var p = midi.shift();
    				midi_params.push(p.token);
    				while (midi.length > 0) {
    					p = midi.shift();
    					if (p.type !== "number")
    						warn("Expected integer parameter in MIDI " + midi_cmd, restOfString, 0);
    					midi_params.push(p.intt);
    				}
    			}
    		}

    		if (tune.hasBeginMusic())
    			tune.appendElement('midi', -1, -1, { cmd: midi_cmd, params: midi_params });
    		else {
    			if (tune.formatting['midi'] === undefined)
    				tune.formatting['midi'] = {};
    			tune.formatting['midi'][midi_cmd] = midi_params;
    		}
    	};

    	parseDirective.parseFontChangeLine = function(textstr) {
    		var textParts = textstr.split('$');
    		if (textParts.length > 1 && multilineVars.setfont) {
    			var textarr = [ { text: textParts[0] }];
    			for (var i = 1; i < textParts.length; i++) {
    				if (textParts[i].charAt(0) === '0')
    					textarr.push({ text: textParts[i].substring(1) });
    				else if (textParts[i].charAt(0) === '1' && multilineVars.setfont[1])
    					textarr.push({font: multilineVars.setfont[1], text: textParts[i].substring(1) });
    				else if (textParts[i].charAt(0) === '2' && multilineVars.setfont[2])
    					textarr.push({font: multilineVars.setfont[2], text: textParts[i].substring(1) });
    				else if (textParts[i].charAt(0) === '3' && multilineVars.setfont[3])
    					textarr.push({font: multilineVars.setfont[3], text: textParts[i].substring(1) });
    				else if (textParts[i].charAt(0) === '4' && multilineVars.setfont[4])
    					textarr.push({font: multilineVars.setfont[4], text: textParts[i].substring(1) });
    				else
    					textarr[textarr.length-1].text += '$' + textParts[i];
    			}
    			if (textarr.length > 1)
    				return textarr;
    		}
    		return textstr;
    	};

    	var positionChoices = [ 'auto', 'above', 'below', 'hidden' ];
    	parseDirective.addDirective = function(str) {
    		var tokens = tokenizer.tokenize(str, 0, str.length);	// 3 or more % in a row, or just spaces after %% is just a comment
    		if (tokens.length === 0 || tokens[0].type !== 'alpha') return null;
    		var restOfString = str.substring(str.indexOf(tokens[0].token)+tokens[0].token.length);
    		restOfString = tokenizer.stripComment(restOfString);
    		var cmd = tokens.shift().token.toLowerCase();
    		var scratch = "";
    		switch (cmd)
    		{
    			// The following directives were added to abc_parser_lint, but haven't been implemented here.
    			// Most of them are direct translations from the directives that will be parsed in. See abcm2ps's format.txt for info on each of these.
    			//					alignbars: { type: "number", optional: true },
    			//					aligncomposer: { type: "string", Enum: [ 'left', 'center','right' ], optional: true },
    			//					bstemdown: { type: "boolean", optional: true },
    			//					continueall: { type: "boolean", optional: true },
    			//					dynalign: { type: "boolean", optional: true },
    			//					exprabove: { type: "boolean", optional: true },
    			//					exprbelow: { type: "boolean", optional: true },
    			//					gchordbox: { type: "boolean", optional: true },
    			//					graceslurs: { type: "boolean", optional: true },
    			//					gracespacebefore: { type: "number", optional: true },
    			//					gracespaceinside: { type: "number", optional: true },
    			//					gracespaceafter: { type: "number", optional: true },
    			//					infospace: { type: "number", optional: true },
    			//					lineskipfac: { type: "number", optional: true },
    			//					maxshrink: { type: "number", optional: true },
    			//					maxstaffsep: { type: "number", optional: true },
    			//					maxsysstaffsep: { type: "number", optional: true },
    			//					notespacingfactor: { type: "number", optional: true },
    			//					parskipfac: { type: "number", optional: true },
    			//					slurheight: { type: "number", optional: true },
    			//					splittune: { type: "boolean", optional: true },
    			//					squarebreve: { type: "boolean", optional: true },
    			//					stemheight: { type: "number", optional: true },
    			//					straightflags: { type: "boolean", optional: true },
    			//					stretchstaff: { type: "boolean", optional: true },
    			//					titleformat: { type: "string", optional: true },
    			case "bagpipes":tune.formatting.bagpipes = true;break;
    			case "flatbeams":tune.formatting.flatbeams = true;break;
    			case "landscape":multilineVars.landscape = true;break;
    			case "papersize":multilineVars.papersize = restOfString;break;
    			case "slurgraces":tune.formatting.slurgraces = true;break;
    			case "stretchlast":tune.formatting.stretchlast = true;break;
    			case "titlecaps":multilineVars.titlecaps = true;break;
    			case "titleleft":tune.formatting.titleleft = true;break;
    			case "measurebox":tune.formatting.measurebox = true;break;

    			case "vocal": return addMultilineVarOneParamChoice("vocalPosition", cmd, tokens, positionChoices);
    			case "dynamic": return addMultilineVarOneParamChoice("dynamicPosition", cmd, tokens, positionChoices);
    			case "gchord": return addMultilineVarOneParamChoice("chordPosition", cmd, tokens, positionChoices);
    			case "ornament": return addMultilineVarOneParamChoice("ornamentPosition", cmd, tokens, positionChoices);
    			case "volume": return addMultilineVarOneParamChoice("volumePosition", cmd, tokens, positionChoices);

    			case "botmargin":
    			case "botspace":
    			case "composerspace":
    			case "indent":
    			case "leftmargin":
    			case "linesep":
    			case "musicspace":
    			case "partsspace":
    			case "pageheight":
    			case "pagewidth":
    			case "rightmargin":
    			case "staffsep":
    			case "staffwidth":
    			case "subtitlespace":
    			case "sysstaffsep":
    			case "systemsep":
    			case "textspace":
    			case "titlespace":
    			case "topmargin":
    			case "topspace":
    			case "vocalspace":
    			case "wordsspace":
    				return oneParameterMeasurement(cmd, tokens);
    			case "voicescale":
    				if (tokens.length !== 1 || tokens[0].type !== 'number')
    					return "voicescale requires one float as a parameter";
    				var voiceScale = tokens.shift();
    				if (multilineVars.currentVoice) {
    					multilineVars.currentVoice.scale = voiceScale.floatt;
    					tune.changeVoiceScale(multilineVars.currentVoice.scale);
    				}
    				return null;
    			case "vskip":
    				var vskip = getRequiredMeasurement(cmd, tokens);
    				if (vskip.error)
    					return vskip.error;
    				tune.addSpacing(vskip);
    				return null;
    			case "scale":
    				setScale(cmd, tokens);
    				break;
    			case "sep":
    				if (tokens.length === 0)
    					tune.addSeparator();
    				else {
    					var points = tokenizer.getMeasurement(tokens);
    					if (points.used === 0)
    						return "Directive \"" + cmd + "\" requires 3 numbers: space above, space below, length of line";
    					var spaceAbove = points.value;

    					points = tokenizer.getMeasurement(tokens);
    					if (points.used === 0)
    						return "Directive \"" + cmd + "\" requires 3 numbers: space above, space below, length of line";
    					var spaceBelow = points.value;

    					points = tokenizer.getMeasurement(tokens);
    					if (points.used === 0 || tokens.length !== 0)
    						return "Directive \"" + cmd + "\" requires 3 numbers: space above, space below, length of line";
    					var lenLine = points.value;
    					tune.addSeparator(spaceAbove, spaceBelow, lenLine);
    				}
    				break;
    			case "barsperstaff":
    				scratch = addMultilineVar('barsperstaff', cmd, tokens);
    				if (scratch !== null) return scratch;
    				break;
    			case "staffnonote":
    				// The sense of the boolean is opposite here. "0" means true.
    				if (tokens.length !== 1)
    					return "Directive staffnonote requires one parameter: 0 or 1";
    				if (tokens[0].token === '0')
    					multilineVars.staffnonote = true;
    				else if (tokens[0].token === '1')
    					multilineVars.staffnonote = false;
    				else
    					return "Directive staffnonote requires one parameter: 0 or 1 (received " + tokens[0].token + ')';
    				break;
    			case "printtempo":
    				scratch = addMultilineVarBool('printTempo', cmd, tokens);
    				if (scratch !== null) return scratch;
    				break;
    			case "partsbox":
    				scratch = addMultilineVarBool('partsBox', cmd, tokens);
    				if (scratch !== null) return scratch;
    				multilineVars.partsfont.box = multilineVars.partsBox;
    				break;
    			case "freegchord":
    				scratch = addMultilineVarBool('freegchord', cmd, tokens);
    				if (scratch !== null) return scratch;
    				break;
    			case "measurenb":
    			case "barnumbers":
    				scratch = addMultilineVar('barNumbers', cmd, tokens);
    				if (scratch !== null) return scratch;
    				break;
    			case "setbarnb":
    				if (tokens.length !== 1 || tokens[0].type !== 'number') {
    					return 'Directive setbarnb requires a number as a parameter.';
    				}
    				multilineVars.currBarNumber = tune.setBarNumberImmediate(tokens[0].intt);
    				break;
    			case "begintext":
    				multilineVars.inTextBlock = true;
    				break;
    			case "continueall":
    				multilineVars.continueall = true;
    				break;
    			case "beginps":
    				multilineVars.inPsBlock = true;
    				warn("Postscript ignored", str, 0);
    				break;
    			case "deco":
    				if (restOfString.length > 0)
    					multilineVars.ignoredDecorations.push(restOfString.substring(0, restOfString.indexOf(' ')));
    				warn("Decoration redefinition ignored", str, 0);
    				break;
    			case "text":
    				var textstr = tokenizer.translateString(restOfString);
    				tune.addText(parseDirective.parseFontChangeLine(textstr));
    				break;
    			case "center":
    				var centerstr = tokenizer.translateString(restOfString);
    				tune.addCentered(parseDirective.parseFontChangeLine(centerstr));
    				break;
    			case "font":
    				// don't need to do anything for this; it is a useless directive
    				break;
    			case "setfont":
    				var sfTokens = tokenizer.tokenize(restOfString, 0, restOfString.length);
    //				var sfDone = false;
    				if (sfTokens.length >= 4) {
    					if (sfTokens[0].token === '-' && sfTokens[1].type === 'number') {
    						var sfNum = parseInt(sfTokens[1].token);
    						if (sfNum >= 1 && sfNum <= 4) {
    							if (!multilineVars.setfont)
    								multilineVars.setfont = [];
    							sfTokens.shift();
    							sfTokens.shift();
    							multilineVars.setfont[sfNum] = getFontParameter(sfTokens, multilineVars.setfont[sfNum], str, 0, 'setfont');
    //							var sfSize = sfTokens.pop();
    //							if (sfSize.type === 'number') {
    //								sfSize = parseInt(sfSize.token);
    //								var sfFontName = '';
    //								for (var sfi = 2; sfi < sfTokens.length; sfi++)
    //									sfFontName += sfTokens[sfi].token;
    //								multilineVars.setfont[sfNum] = { face: sfFontName, size: sfSize };
    //								sfDone = true;
    //							}
    						}
    					}
    				}
    //				if (!sfDone)
    //					return "Bad parameters: " + cmd;
    				break;
    			case "gchordfont":
    			case "partsfont":
    			case "tripletfont":
    			case "vocalfont":
    			case "textfont":
    			case "annotationfont":
    			case "historyfont":
    			case "infofont":
    			case "measurefont":
    			case "repeatfont":
    			case "wordsfont":
    				return getChangingFont(cmd, tokens, str);
    			case "composerfont":
    			case "subtitlefont":
    			case "tempofont":
    			case "titlefont":
    			case "voicefont":
    			case "footerfont":
    			case "headerfont":
    				return getGlobalFont(cmd, tokens, str);
    			case "barlabelfont":
    			case "barnumberfont":
    			case "barnumfont":
    				return getChangingFont("measurefont", tokens, str);
    			case "staves":
    			case "score":
    				multilineVars.score_is_present = true;
    				var addVoice = function(id, newStaff, bracket, brace, continueBar) {
    					if (newStaff || multilineVars.staves.length === 0) {
    						multilineVars.staves.push({index: multilineVars.staves.length, numVoices: 0});
    					}
    					var staff = abc_common.last(multilineVars.staves);
    					if (bracket !== undefined) staff.bracket = bracket;
    					if (brace !== undefined) staff.brace = brace;
    					if (continueBar) staff.connectBarLines = 'end';
    					if (multilineVars.voices[id] === undefined) {
    						multilineVars.voices[id] = {staffNum: staff.index, index: staff.numVoices};
    						staff.numVoices++;
    					}
    				};

    				var openParen = false;
    				var openBracket = false;
    				var openBrace = false;
    				var justOpenParen = false;
    				var justOpenBracket = false;
    				var justOpenBrace = false;
    				var continueBar = false;
    				var lastVoice;
    				var addContinueBar = function() {
    					continueBar = true;
    					if (lastVoice) {
    						var ty = 'start';
    						if (lastVoice.staffNum > 0) {
    							if (multilineVars.staves[lastVoice.staffNum-1].connectBarLines === 'start' ||
    								multilineVars.staves[lastVoice.staffNum-1].connectBarLines === 'continue')
    								ty = 'continue';
    						}
    						multilineVars.staves[lastVoice.staffNum].connectBarLines = ty;
    					}
    				};
    				while (tokens.length) {
    					var t = tokens.shift();
    					switch (t.token) {
    						case '(':
    							if (openParen) warn("Can't nest parenthesis in %%score", str, t.start);
    							else {openParen = true;justOpenParen = true;}
    							break;
    						case ')':
    							if (!openParen || justOpenParen) warn("Unexpected close parenthesis in %%score", str, t.start);
    							else openParen = false;
    							break;
    						case '[':
    							if (openBracket) warn("Can't nest brackets in %%score", str, t.start);
    							else {openBracket = true;justOpenBracket = true;}
    							break;
    						case ']':
    							if (!openBracket || justOpenBracket) warn("Unexpected close bracket in %%score", str, t.start);
    							else {openBracket = false;multilineVars.staves[lastVoice.staffNum].bracket = 'end';}
    							break;
    						case '{':
    							if (openBrace ) warn("Can't nest braces in %%score", str, t.start);
    							else {openBrace = true;justOpenBrace = true;}
    							break;
    						case '}':
    							if (!openBrace || justOpenBrace) warn("Unexpected close brace in %%score", str, t.start);
    							else {openBrace = false;multilineVars.staves[lastVoice.staffNum].brace = 'end';}
    							break;
    						case '|':
    							addContinueBar();
    							break;
    						default:
    							var vc = "";
    							while (t.type === 'alpha' || t.type === 'number') {
    								vc += t.token;
    								if (t.continueId)
    									t = tokens.shift();
    								else
    									break;
    							}
    							var newStaff = !openParen || justOpenParen;
    							var bracket = justOpenBracket ? 'start' : openBracket ? 'continue' : undefined;
    							var brace = justOpenBrace ? 'start' : openBrace ? 'continue' : undefined;
    							addVoice(vc, newStaff, bracket, brace, continueBar);
    							justOpenParen = false;
    							justOpenBracket = false;
    							justOpenBrace = false;
    							continueBar = false;
    							lastVoice = multilineVars.voices[vc];
    							if (cmd === 'staves')
    								addContinueBar();
    							break;
    					}
    				}
    				break;

    			case "newpage":
    				var pgNum = tokenizer.getInt(restOfString);
    				tune.addNewPage(pgNum.digits === 0 ? -1 : pgNum.value);
    				break;

    			case "abc":
    				var arr = restOfString.split(' ');
    				switch (arr[0]) {
    					case "-copyright":
    					case "-creator":
    					case "-edited-by":
    					case "-version":
    					case "-charset":
    						var subCmd = arr.shift();
    						tune.addMetaText(cmd+subCmd, arr.join(' '));
    						break;
    					default:
    						return "Unknown directive: " + cmd+arr[0];
    				}
    				break;
    			case "header":
    			case "footer":
    				var footerStr = tokenizer.getMeat(restOfString, 0, restOfString.length);
    				footerStr = restOfString.substring(footerStr.start, footerStr.end);
    				if (footerStr.charAt(0) === '"' && footerStr.charAt(footerStr.length-1) === '"' )
    					footerStr = footerStr.substring(1, footerStr.length-1);
    				var footerArr = footerStr.split('\t');
    				var footer = {};
    				if (footerArr.length === 1)
    					footer = { left: "", center: footerArr[0], right: "" };
    				else if (footerArr.length === 2)
    					footer = { left: footerArr[0], center: footerArr[1], right: "" };
    				else
    					footer = { left: footerArr[0], center: footerArr[1], right: footerArr[2] };
    				if (footerArr.length > 3)
    					warn("Too many tabs in " + cmd + ": " + footerArr.length + " found.", restOfString, 0);

    				tune.addMetaTextObj(cmd, footer);
    				break;

    			case "midi":
    				var midi = tokenizer.tokenize(restOfString, 0, restOfString.length, true);
    				if (midi.length > 0 && midi[0].token === '=')
    					midi.shift();
    				if (midi.length === 0)
    					warn("Expected midi command", restOfString, 0);
    				else
    					parseMidiCommand(midi, tune, restOfString);
    				break;

    			case "map":
    			case "percmap":
    			case "playtempo":
    			case "auquality":
    			case "continuous":
    			case "nobarcheck":
    				// TODO-PER: Actually handle the parameters of these
    				tune.formatting[cmd] = restOfString;
    				break;
    			default:
    				return "Unknown directive: " + cmd;
    		}
    		return null;
    	};
    	parseDirective.globalFormatting = function(formatHash) {
    		for (var cmd in formatHash) {
    			if (formatHash.hasOwnProperty(cmd)) {
    				var value = ''+formatHash[cmd];
    				var tokens = tokenizer.tokenize(value, 0, value.length);
    				var scratch;
    				switch (cmd) {
    					case "titlefont":
    					case "gchordfont":
    					case "composerfont":
    					case "footerfont":
    					case "headerfont":
    					case "historyfont":
    					case "infofont":
    					case "measurefont":
    					case "partsfont":
    					case "repeatfont":
    					case "subtitlefont":
    					case "tempofont":
    					case "textfont":
    					case "voicefont":
    					case "tripletfont":
    					case "vocalfont":
    					case "wordsfont":
    					case "annotationfont":
    						getChangingFont(cmd, tokens, value);
    						break;
    					case "scale":
    						setScale(cmd, tokens);
    						break;
    					case "partsbox":
    						scratch = addMultilineVarBool('partsBox', cmd, tokens);
    						if (scratch !== null) warn(scratch);
    						multilineVars.partsfont.box = multilineVars.partsBox;
    						break;
    					case "freegchord":
    						scratch = addMultilineVarBool('freegchord', cmd, tokens);
    						if (scratch !== null) warn(scratch);
    					default:
    						warn("Formatting directive unrecognized: ", cmd, 0);
    				}
    			}
    		}
    	};
    })();

    var abc_parse_directive = parseDirective;

    //    abc_transpose.js: Handles the automatic transposition of key signatures, chord symbols, and notes.
    //    Copyright (C) 2010-2018 Paul Rosen (paul at paulrosen dot net)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    var transpose = {};

    var keyIndex = {
    	'C': 0,
    	'C#': 1,
    	'Db': 1,
    	'D': 2,
    	'D#': 3,
    	'Eb': 3,
    	'E': 4,
    	'F': 5,
    	'F#': 6,
    	'Gb': 6,
    	'G': 7,
    	'G#': 8,
    	'Ab': 8,
    	'A': 9,
    	'A#': 10,
    	'Bb': 10,
    	'B': 11
    };
    var newKey = ['C', 'Db', 'D', 'Eb', 'E', 'F', 'F#', 'G', 'Ab', 'A', 'Bb', 'B'];
    var newKeyMinor = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'Bb', 'B'];

    transpose.keySignature = function(multilineVars, keys, keyName, root, acc, localTranspose) {
    	if (!localTranspose) localTranspose = 0;
    	multilineVars.localTransposeVerticalMovement = 0;
    	multilineVars.localTransposePreferFlats = false;
    	var k = keys[keyName];
    	if (!k) return multilineVars.key; // If the key isn't in the list, it is non-standard. We won't attempt to transpose it.
    	multilineVars.localTranspose = (multilineVars.globalTranspose ? multilineVars.globalTranspose : 0) + localTranspose;

    	if (!multilineVars.localTranspose)
    		return { accidentals: k, root: root, acc: acc };
    	multilineVars.globalTransposeOrigKeySig = k;
    	if (multilineVars.localTranspose % 12 === 0) {
    		multilineVars.localTransposeVerticalMovement = (multilineVars.localTranspose / 12) * 7;
    		return { accidentals: k, root: root, acc: acc };
    	}

    	var baseKey = keyName[0];
    	if (keyName[1] === 'b' || keyName[1] === '#') {
    		baseKey += keyName[1];
    		keyName = keyName.substr(2);
    	} else
    		keyName = keyName.substr(1);
    	var index = keyIndex[baseKey] + multilineVars.localTranspose;
    	while (index < 0) index += 12;
    	if (index > 11) index = index % 12;
    	var newKeyName = (keyName[0] === 'm' ? newKeyMinor[index] : newKey[index]);
    	var transposedKey = newKeyName + keyName;
    	var newKeySig = keys[transposedKey];
    	if (newKeySig.length > 0 && newKeySig[0].acc === 'flat')
    		multilineVars.localTransposePreferFlats = true;
    	var distance = transposedKey.charCodeAt(0) - baseKey.charCodeAt(0);
    	if (multilineVars.localTranspose > 0) {
    		if (distance < 0)
    			distance += 7;
    		else if (distance === 0) {
    			// There's a funny thing that happens when the key changes only an accidental's distance, for instance, from Ab to A.
    			// If the distance is positive (we are raising pitch), and the change is higher (that is, Ab -> A), then raise an octave.
    			// This test is easier because we know the keys are not equal (or we wouldn't get this far), so if the base key is a flat key, then
    			// the transposed key must be higher. Likewise, if the transposed key is sharp, then the base key must be lower. And one
    			// of those two things must be true because they are not both natural.
    			if (baseKey[1] === '#' ||  transposedKey[1] === 'b')
    				distance += 7;
    		}
    	} else if (multilineVars.localTranspose < 0) {
    		if (distance > 0)
    			distance -= 7;
    		else if (distance === 0) {
    			// There's a funny thing that happens when the key changes only an accidental's distance, for instance, from Ab to A.
    			// If the distance is negative (we are dropping pitch), and the change is lower (that is, A -> Ab), then drop an octave.
    			if (baseKey[1] === 'b' ||  transposedKey[1] === '#')
    				distance -= 7;
    		}
    	}

    	if (multilineVars.localTranspose > 0)
    		multilineVars.localTransposeVerticalMovement = distance + Math.floor(multilineVars.localTranspose / 12) * 7;
    	else
    		multilineVars.localTransposeVerticalMovement = distance + Math.ceil(multilineVars.localTranspose / 12) * 7;
    	return { accidentals: newKeySig, root: newKeyName[0], acc: newKeyName.length > 1 ? newKeyName[1] : "" };
    };

    var sharpChords = [ 'C', 'C♯', 'D', "D♯", 'E', 'F', "F♯", 'G', 'G♯', 'A', 'A♯', 'B'];
    var flatChords = [ 'C', 'D♭', 'D', 'E♭', 'E', 'F', 'G♭', 'G', 'A♭', 'A', 'B♭', 'B'];
    var sharpChordsFree = [ 'C', 'C#', 'D', "D#", 'E', 'F', "F#", 'G', 'G#', 'A', 'A#', 'B'];
    var flatChordsFree = [ 'C', 'Db', 'D', 'Eb', 'E', 'F', 'Gb', 'G', 'Ab', 'A', 'Bb', 'B'];

    transpose.chordName = function(multilineVars, chord) {
    	if (multilineVars.localTranspose && (multilineVars.localTranspose % 12 !== 0)) { // The chords are the same if it is an exact octave change.
    		var transposeFactor = multilineVars.localTranspose;
    		while (transposeFactor < 0) transposeFactor += 12;
    		if (transposeFactor > 11) transposeFactor = transposeFactor % 12;
    		if (multilineVars.freegchord) {
    			chord = chord.replace(/Cb/g, "`~11`");
    			chord = chord.replace(/Db/g, "`~1`");
    			chord = chord.replace(/Eb/g, "`~3`");
    			chord = chord.replace(/Fb/g, "`~4`");
    			chord = chord.replace(/Gb/g, "`~6`");
    			chord = chord.replace(/Ab/g, "`~8`");
    			chord = chord.replace(/Bb/g, "`~10`");
    			chord = chord.replace(/C#/g, "`~1`");
    			chord = chord.replace(/D#/g, "`~3`");
    			chord = chord.replace(/E#/g, "`~5`");
    			chord = chord.replace(/F#/g, "`~6`");
    			chord = chord.replace(/G#/g, "`~8`");
    			chord = chord.replace(/A#/g, "`~10`");
    			chord = chord.replace(/B#/g, "`~0`");
    		} else {
    			chord = chord.replace(/C♭/g, "`~11`");
    			chord = chord.replace(/D♭/g, "`~1`");
    			chord = chord.replace(/E♭/g, "`~3`");
    			chord = chord.replace(/F♭/g, "`~4`");
    			chord = chord.replace(/G♭/g, "`~6`");
    			chord = chord.replace(/A♭/g, "`~8`");
    			chord = chord.replace(/B♭/g, "`~10`");
    			chord = chord.replace(/C♯/g, "`~1`");
    			chord = chord.replace(/D♯/g, "`~3`");
    			chord = chord.replace(/E♯/g, "`~5`");
    			chord = chord.replace(/F♯/g, "`~6`");
    			chord = chord.replace(/G♯/g, "`~8`");
    			chord = chord.replace(/A♯/g, "`~10`");
    			chord = chord.replace(/B♯/g, "`~0`");
    		}
    		chord = chord.replace(/C/g, "`~0`");
    		chord = chord.replace(/D/g, "`~2`");
    		chord = chord.replace(/E/g, "`~4`");
    		chord = chord.replace(/F/g, "`~5`");
    		chord = chord.replace(/G/g, "`~7`");
    		chord = chord.replace(/A/g, "`~9`");
    		chord = chord.replace(/B/g, "`~11`");
    		var arr = chord.split("`");
    		for (var i = 0; i < arr.length; i++) {
    			if (arr[i][0] === '~') {
    				var chordNum = parseInt(arr[i].substr(1),10);
    				chordNum += transposeFactor;
    				if (chordNum > 11) chordNum -= 12;
    				if (multilineVars.freegchord)
    					arr[i] = multilineVars.localTransposePreferFlats ? flatChordsFree[chordNum] : sharpChordsFree[chordNum];
    				else
    					arr[i] = multilineVars.localTransposePreferFlats ? flatChords[chordNum] : sharpChords[chordNum];
    			}
    		}
    		chord = arr.join("");
    	}
    	return chord;
    };

    var pitchToLetter = [ 'c', 'd', 'e', 'f', 'g', 'a', 'b' ];
    function accidentalChange(origPitch, newPitch, accidental, origKeySig, newKeySig) {
    	var origPitchLetter = pitchToLetter[(origPitch + 49) % 7]; // Make sure it is a positive pitch before normalizing.
    	var origAccidental = 0;
    	for (var i = 0; i < origKeySig.length; i++) {
    		if (origKeySig[i].note.toLowerCase() === origPitchLetter)
    			origAccidental = accidentals[origKeySig[i].acc];
    	}

    	var currentAccidental = accidentals[accidental];
    	var delta = currentAccidental - origAccidental;

    	var newPitchLetter = pitchToLetter[(newPitch + 49) % 7]; // Make sure it is a positive pitch before normalizing.
    	var newAccidental = 0;
    	for (var j = 0; j < newKeySig.accidentals.length; j++) {
    		if (newKeySig.accidentals[j].note.toLowerCase() === newPitchLetter)
    			newAccidental = accidentals[newKeySig.accidentals[j].acc];
    	}
    	var calcAccidental = delta + newAccidental;
    	if (calcAccidental < -2) {
    		newPitch--;
    		calcAccidental += (newPitchLetter === 'c' || newPitchLetter === 'f') ? 1 : 2;
    	}
    	if (calcAccidental > 2) {
    		newPitch++;
    		calcAccidental -= (newPitchLetter === 'b' || newPitchLetter === 'e') ? 1 : 2;
    	}
    	return [newPitch, calcAccidental];
    }

    var accidentals = {
    	dblflat: -2,
    	flat: -1,
    	natural: 0,
    	sharp: 1,
    	dblsharp: 2
    };
    var accidentals2 = {
    	"-2": "dblflat",
    	"-1": "flat",
    	"0": "natural",
    	"1": "sharp",
    	"2": "dblsharp"
    };
    transpose.note = function(multilineVars, el) {
    	// the "el" that is passed in has el.accidental, and el.pitch. "pitch" is the vertical position (0=middle C)
    	// localTranspose is the number of half steps
    	// localTransposeVerticalMovement is the vertical distance to move.
    	if (!multilineVars.localTranspose)
    		return;
    	var origPitch = el.pitch;
    	el.pitch = el.pitch + multilineVars.localTransposeVerticalMovement;

    	if (el.accidental) {
    		var ret = accidentalChange(origPitch, el.pitch, el.accidental, multilineVars.globalTransposeOrigKeySig, multilineVars.targetKey);
    		el.pitch = ret[0];
    		el.accidental = accidentals2[ret[1]];
    	}

    };

    var abc_transpose = transpose;

    /*global window */





    var parseKeyVoice = {};

    (function() {
    	var tokenizer;
    	var warn;
    	var multilineVars;
    	var tune;
    	parseKeyVoice.initialize = function(tokenizer_, warn_, multilineVars_, tune_) {
    		tokenizer = tokenizer_;
    		warn = warn_;
    		multilineVars = multilineVars_;
    		tune = tune_;
    	};

    	parseKeyVoice.standardKey = function(keyName, root, acc, localTranspose) {
    		var key1sharp = {acc: 'sharp', note: 'f'};
    		var key2sharp = {acc: 'sharp', note: 'c'};
    		var key3sharp = {acc: 'sharp', note: 'g'};
    		var key4sharp = {acc: 'sharp', note: 'd'};
    		var key5sharp = {acc: 'sharp', note: 'A'};
    		var key6sharp = {acc: 'sharp', note: 'e'};
    		var key7sharp = {acc: 'sharp', note: 'B'};
    		var key1flat = {acc: 'flat', note: 'B'};
    		var key2flat = {acc: 'flat', note: 'e'};
    		var key3flat = {acc: 'flat', note: 'A'};
    		var key4flat = {acc: 'flat', note: 'd'};
    		var key5flat = {acc: 'flat', note: 'G'};
    		var key6flat = {acc: 'flat', note: 'c'};
    		var key7flat = {acc: 'flat', note: 'F'};

    		var keys = {
    			'C#': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp, key7sharp ],
    			'A#m': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp, key7sharp ],
    			'G#Mix': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp, key7sharp ],
    			'D#Dor': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp, key7sharp ],
    			'E#Phr': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp, key7sharp ],
    			'F#Lyd': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp, key7sharp ],
    			'B#Loc': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp, key7sharp ],

    			'F#': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp ],
    			'D#m': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp ],
    			'C#Mix': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp ],
    			'G#Dor': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp ],
    			'A#Phr': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp ],
    			'BLyd': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp ],
    			'E#Loc': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp ],

    			'B': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp ],
    			'G#m': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp ],
    			'F#Mix': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp ],
    			'C#Dor': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp ],
    			'D#Phr': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp ],
    			'ELyd': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp ],
    			'A#Loc': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp ],

    			'E': [ key1sharp, key2sharp, key3sharp, key4sharp ],
    			'C#m': [ key1sharp, key2sharp, key3sharp, key4sharp ],
    			'BMix': [ key1sharp, key2sharp, key3sharp, key4sharp ],
    			'F#Dor': [ key1sharp, key2sharp, key3sharp, key4sharp ],
    			'G#Phr': [ key1sharp, key2sharp, key3sharp, key4sharp ],
    			'ALyd': [ key1sharp, key2sharp, key3sharp, key4sharp ],
    			'D#Loc': [ key1sharp, key2sharp, key3sharp, key4sharp ],

    			'A': [ key1sharp, key2sharp, key3sharp ],
    			'F#m': [ key1sharp, key2sharp, key3sharp ],
    			'EMix': [ key1sharp, key2sharp, key3sharp ],
    			'BDor': [ key1sharp, key2sharp, key3sharp ],
    			'C#Phr': [ key1sharp, key2sharp, key3sharp ],
    			'DLyd': [ key1sharp, key2sharp, key3sharp ],
    			'G#Loc': [ key1sharp, key2sharp, key3sharp ],

    			'D': [ key1sharp, key2sharp ],
    			'Bm': [ key1sharp, key2sharp ],
    			'AMix': [ key1sharp, key2sharp ],
    			'EDor': [ key1sharp, key2sharp ],
    			'F#Phr': [ key1sharp, key2sharp ],
    			'GLyd': [ key1sharp, key2sharp ],
    			'C#Loc': [ key1sharp, key2sharp ],

    			'G': [ key1sharp ],
    			'Em': [ key1sharp ],
    			'DMix': [ key1sharp ],
    			'ADor': [ key1sharp ],
    			'BPhr': [ key1sharp ],
    			'CLyd': [ key1sharp ],
    			'F#Loc': [ key1sharp ],

    			'C': [],
    			'Am': [],
    			'GMix': [],
    			'DDor': [],
    			'EPhr': [],
    			'FLyd': [],
    			'BLoc': [],

    			'F': [ key1flat ],
    			'Dm': [ key1flat ],
    			'CMix': [ key1flat ],
    			'GDor': [ key1flat ],
    			'APhr': [ key1flat ],
    			'BbLyd': [ key1flat ],
    			'ELoc': [ key1flat ],

    			'Bb': [ key1flat, key2flat ],
    			'Gm': [ key1flat, key2flat ],
    			'FMix': [ key1flat, key2flat ],
    			'CDor': [ key1flat, key2flat ],
    			'DPhr': [ key1flat, key2flat ],
    			'EbLyd': [ key1flat, key2flat ],
    			'ALoc': [ key1flat, key2flat ],

    			'Eb': [ key1flat, key2flat, key3flat ],
    			'Cm': [ key1flat, key2flat, key3flat ],
    			'BbMix': [ key1flat, key2flat, key3flat ],
    			'FDor': [ key1flat, key2flat, key3flat ],
    			'GPhr': [ key1flat, key2flat, key3flat ],
    			'AbLyd': [ key1flat, key2flat, key3flat ],
    			'DLoc': [ key1flat, key2flat, key3flat ],

    			'Ab': [ key1flat, key2flat, key3flat, key4flat ],
    			'Fm': [ key1flat, key2flat, key3flat, key4flat ],
    			'EbMix': [ key1flat, key2flat, key3flat, key4flat ],
    			'BbDor': [ key1flat, key2flat, key3flat, key4flat ],
    			'CPhr': [ key1flat, key2flat, key3flat, key4flat ],
    			'DbLyd': [ key1flat, key2flat, key3flat, key4flat ],
    			'GLoc': [ key1flat, key2flat, key3flat, key4flat ],

    			'Db': [ key1flat, key2flat, key3flat, key4flat, key5flat ],
    			'Bbm': [ key1flat, key2flat, key3flat, key4flat, key5flat ],
    			'AbMix': [ key1flat, key2flat, key3flat, key4flat, key5flat ],
    			'EbDor': [ key1flat, key2flat, key3flat, key4flat, key5flat ],
    			'FPhr': [ key1flat, key2flat, key3flat, key4flat, key5flat ],
    			'GbLyd': [ key1flat, key2flat, key3flat, key4flat, key5flat ],
    			'CLoc': [ key1flat, key2flat, key3flat, key4flat, key5flat ],

    			'Gb': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat ],
    			'Ebm': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat ],
    			'DbMix': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat ],
    			'AbDor': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat ],
    			'BbPhr': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat ],
    			'CbLyd': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat ],
    			'FLoc': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat ],

    			'Cb': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat, key7flat ],
    			'Abm': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat, key7flat ],
    			'GbMix': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat, key7flat ],
    			'DbDor': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat, key7flat ],
    			'EbPhr': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat, key7flat ],
    			'FbLyd': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat, key7flat ],
    			'BbLoc': [ key1flat, key2flat, key3flat, key4flat, key5flat, key6flat, key7flat ],

    			// The following are not in the 2.0 spec, but seem normal enough.
    			// TODO-PER: These SOUND the same as what's written, but they aren't right
    			'A#': [ key1flat, key2flat ],
    			'B#': [],
    			'D#': [ key1flat, key2flat, key3flat ],
    			'E#': [ key1flat ],
    			'G#': [ key1flat, key2flat, key3flat, key4flat ],
    			'Gbm': [ key1sharp, key2sharp, key3sharp, key4sharp, key5sharp, key6sharp, key7sharp ]
    		};

    		return abc_transpose.keySignature(multilineVars, keys, keyName, root, acc, localTranspose);
    	};

    	var clefLines = {
    		'treble': { clef: 'treble', pitch: 4, mid: 0 },
    		'treble+8': { clef: 'treble+8', pitch: 4, mid: 0 },
    		'treble-8': { clef: 'treble-8', pitch: 4, mid: 0 },
    		'treble^8': { clef: 'treble+8', pitch: 4, mid: 0 },
    		'treble_8': { clef: 'treble-8', pitch: 4, mid: 0 },
    		'treble1': { clef: 'treble', pitch: 2, mid: 2 },
    		'treble2': { clef: 'treble', pitch: 4, mid: 0 },
    		'treble3': { clef: 'treble', pitch: 6, mid: -2 },
    		'treble4': { clef: 'treble', pitch: 8, mid: -4 },
    		'treble5': { clef: 'treble', pitch: 10, mid: -6 },
    		'perc': { clef: 'perc', pitch: 6, mid: 0 },
    		'none': { clef: 'none', mid: 0 },
    		'bass': { clef: 'bass', pitch: 8, mid: -12 },
    		'bass+8': { clef: 'bass+8', pitch: 8, mid: -12 },
    		'bass-8': { clef: 'bass-8', pitch: 8, mid: -12 },
    		'bass^8': { clef: 'bass+8', pitch: 8, mid: -12 },
    		'bass_8': { clef: 'bass-8', pitch: 8, mid: -12 },
    		'bass+16': { clef: 'bass', pitch: 8, mid: -12 },
    		'bass-16': { clef: 'bass', pitch: 8, mid: -12 },
    		'bass^16': { clef: 'bass', pitch: 8, mid: -12 },
    		'bass_16': { clef: 'bass', pitch: 8, mid: -12 },
    		'bass1': { clef: 'bass', pitch: 2, mid: -6 },
    		'bass2': { clef: 'bass', pitch: 4, mid: -8 },
    		'bass3': { clef: 'bass', pitch: 6, mid: -10 },
    		'bass4': { clef: 'bass', pitch: 8, mid: -12 },
    		'bass5': { clef: 'bass', pitch: 10, mid: -14 },
    		'tenor': { clef: 'alto', pitch: 8, mid: -8 },
    		'tenor1': { clef: 'alto', pitch: 2, mid: -2 },
    		'tenor2': { clef: 'alto', pitch: 4, mid: -4 },
    		'tenor3': { clef: 'alto', pitch: 6, mid: -6 },
    		'tenor4': { clef: 'alto', pitch: 8, mid: -8 },
    		'tenor5': { clef: 'alto', pitch: 10, mid: -10 },
    		'alto': { clef: 'alto', pitch: 6, mid: -6 },
    		'alto1': { clef: 'alto', pitch: 2, mid: -2 },
    		'alto2': { clef: 'alto', pitch: 4, mid: -4 },
    		'alto3': { clef: 'alto', pitch: 6, mid: -6 },
    		'alto4': { clef: 'alto', pitch: 8, mid: -8 },
    		'alto5': { clef: 'alto', pitch: 10, mid: -10 },
    		'alto+8': { clef: 'alto+8', pitch: 6, mid: -6 },
    		'alto-8': { clef: 'alto-8', pitch: 6, mid: -6 },
    		'alto^8': { clef: 'alto+8', pitch: 6, mid: -6 },
    		'alto_8': { clef: 'alto-8', pitch: 6, mid: -6 }
    	};

    	var calcMiddle = function(clef, oct) {
    		var value = clefLines[clef];
    		var mid = value ? value.mid : 0;
    		return mid+oct;
    	};

    	parseKeyVoice.fixClef = function(clef) {
    		var value = clefLines[clef.type];
    		if (value) {
    			clef.clefPos = value.pitch;
    			clef.type = value.clef;
    		}
    	};

    	parseKeyVoice.deepCopyKey = function(key) {
    		var ret = { accidentals: [], root: key.root, acc: key.acc, mode: key.mode };
    		abc_common.each(key.accidentals, function(k) {
    		ret.accidentals.push(abc_common.clone(k));
    		});
    		return ret;
    	};

    	var pitches = {A: 5, B: 6, C: 0, D: 1, E: 2, F: 3, G: 4, a: 12, b: 13, c: 7, d: 8, e: 9, f: 10, g: 11};

    	parseKeyVoice.addPosToKey = function(clef, key) {
    		// Shift the key signature from the treble positions to whatever position is needed for the clef.
    		// This may put the key signature unnaturally high or low, so if it does, then shift it.
    		var mid = clef.verticalPos;
    		abc_common.each(key.accidentals, function(acc) {
    			var pitch = pitches[acc.note];
    			pitch = pitch - mid;
    			acc.verticalPos = pitch;
    		});
    		if (key.impliedNaturals)
    			abc_common.each(key.impliedNaturals, function(acc) {
    				var pitch = pitches[acc.note];
    				pitch = pitch - mid;
    				acc.verticalPos = pitch;
    			});

    		if (mid < -10) {
    			abc_common.each(key.accidentals, function(acc) {
    				acc.verticalPos -= 7;
    				if (acc.verticalPos >= 11 || (acc.verticalPos === 10 && acc.acc === 'flat'))
    					acc.verticalPos -= 7;
    				if (acc.note === 'A' && acc.acc === 'sharp' )
    					acc.verticalPos -=7;
    				if ((acc.note === 'G' || acc.note === 'F') && acc.acc === 'flat' )
    					acc.verticalPos -=7;
    			});
    			if (key.impliedNaturals)
    				abc_common.each(key.impliedNaturals, function(acc) {
    					acc.verticalPos -= 7;
    					if (acc.verticalPos >= 11 || (acc.verticalPos === 10 && acc.acc === 'flat'))
    						acc.verticalPos -= 7;
    					if (acc.note === 'A' && acc.acc === 'sharp' )
    						acc.verticalPos -=7;
    					if ((acc.note === 'G' || acc.note === 'F') && acc.acc === 'flat' )
    						acc.verticalPos -=7;
    				});
    		} else if (mid < -4) {
    			abc_common.each(key.accidentals, function(acc) {
    				acc.verticalPos -= 7;
    				if (mid === -8 && (acc.note === 'f' || acc.note === 'g') && acc.acc === 'sharp' )
    					acc.verticalPos -=7;
    			});
    			if (key.impliedNaturals)
    				abc_common.each(key.impliedNaturals, function(acc) {
    					acc.verticalPos -= 7;
    					if (mid === -8 && (acc.note === 'f' || acc.note === 'g') && acc.acc === 'sharp' )
    						acc.verticalPos -=7;
    				});
    		} else if (mid >= 7) {
    			abc_common.each(key.accidentals, function(acc) {
    				acc.verticalPos += 7;
    			});
    			if (key.impliedNaturals)
    				abc_common.each(key.impliedNaturals, function(acc) {
    					acc.verticalPos += 7;
    				});
    		}
    	};

    	parseKeyVoice.fixKey = function(clef, key) {
    		var fixedKey = abc_common.clone(key);
    		parseKeyVoice.addPosToKey(clef, fixedKey);
    		return fixedKey;
    	};

    	var parseMiddle = function(str) {
    		var i = 0;
    		var p = str.charAt(i++);
    		if (p === '^' || p === '_')
    			p = str.charAt(i++);
    	  var mid = pitches[p];
    		if (mid === undefined)
    			mid = 6; // If a legal middle note wasn't received, just ignore it.
    		for ( ; i < str.length; i++) {
    			if (str.charAt(i) === ',') mid -= 7;
    			else if (str.charAt(i) === "'") mid += 7;
    			else break;
    		}
    		return { mid: mid - 6, str: str.substring(i) };	// We get the note in the middle of the staff. We want the note that appears as the first ledger line below the staff.
    	};

    	var normalizeAccidentals = function(accs) {
    		for (var i = 0; i < accs.length; i++) {
    			if (accs[i].note === 'b')
    				accs[i].note = 'B';
    			else if (accs[i].note === 'a')
    				accs[i].note = 'A';
    			else if (accs[i].note === 'F')
    				accs[i].note = 'f';
    			else if (accs[i].note === 'E')
    				accs[i].note = 'e';
    			else if (accs[i].note === 'D')
    				accs[i].note = 'd';
    			else if (accs[i].note === 'C')
    				accs[i].note = 'c';
    			else if (accs[i].note === 'G' && accs[i].acc === 'sharp')
    				accs[i].note = 'g';
    			else if (accs[i].note === 'g' && accs[i].acc === 'flat')
    				accs[i].note = 'G';
    		}
    	};

    	parseKeyVoice.parseKey = function(str)	// (and clef)
    	{
    		// returns:
    		//		{ foundClef: true, foundKey: true }
    		// Side effects:
    		//		calls warn() when there is a syntax error
    		//		sets these members of multilineVars:
    		//			clef
    		//			key
    		//			style
    		//
    		// The format is:
    		// K: [⟨key⟩] [⟨modifiers⟩*]
    		// modifiers are any of the following in any order:
    		//  [⟨clef⟩] [middle=⟨pitch⟩] [transpose=[-]⟨number⟩] [stafflines=⟨number⟩] [staffscale=⟨number⟩][style=⟨style⟩]
    		// key is none|HP|Hp|⟨specified_key⟩
    		// clef is [clef=] [⟨clef type⟩] [⟨line number⟩] [+8|-8]
    		// specified_key is ⟨pitch⟩[#|b][mode(first three chars are significant)][accidentals*]
    		if (str.length === 0) {
    			// an empty K: field is the same as K:none
    			str = 'none';
    		}
    		var tokens = tokenizer.tokenize(str, 0, str.length);
    		var ret = {};

    		// first the key
    		switch (tokens[0].token) {
    			case 'HP':
    				abc_parse_directive.addDirective("bagpipes");
    				multilineVars.key = { root: "HP", accidentals: [], acc: "", mode: "" };
    				ret.foundKey = true;
    				tokens.shift();
    				break;
    			case 'Hp':
    				abc_parse_directive.addDirective("bagpipes");
    				multilineVars.key = { root: "Hp", accidentals: [{acc: 'natural', note: 'g'}, {acc: 'sharp', note: 'f'}, {acc: 'sharp', note: 'c'}], acc: "", mode: "" };
    				ret.foundKey = true;
    				tokens.shift();
    				break;
    			case 'none':
    				// we got the none key - that's the same as C to us
    				multilineVars.key = { root: "none", accidentals: [], acc: "", mode: "" };
    				ret.foundKey = true;
    				tokens.shift();
    				break;
    			default:
    				var retPitch = tokenizer.getKeyPitch(tokens[0].token);
    				if (retPitch.len > 0) {
    					ret.foundKey = true;
    					var acc = "";
    					var mode = "";
    					// The accidental and mode might be attached to the pitch, so we might want to just remove the first character.
    					if (tokens[0].token.length > 1)
    						tokens[0].token = tokens[0].token.substring(1);
    					else
    						tokens.shift();
    					var key = retPitch.token;
    					// We got a pitch to start with, so we might also have an accidental and a mode
    					if (tokens.length > 0) {
    						var retAcc = tokenizer.getSharpFlat(tokens[0].token);
    						if (retAcc.len > 0) {
    							if (tokens[0].token.length > 1)
    								tokens[0].token = tokens[0].token.substring(1);
    							else
    								tokens.shift();
    							key += retAcc.token;
    							acc = retAcc.token;
    						}
    						if (tokens.length > 0) {
    							var retMode = tokenizer.getMode(tokens[0].token);
    							if (retMode.len > 0) {
    								tokens.shift();
    								key += retMode.token;
    								mode = retMode.token;
    							}
    						}
    						// Be sure that the key specified is in the list: not all keys are physically possible, like Cbmin.
    						if (parseKeyVoice.standardKey(key, retPitch.token, acc, 0) === undefined) {
    							warn("Unsupported key signature: " + key, str, 0);
    							return ret;
    						}
    					}
    					// We need to do a deep copy because we are going to modify it
    					var oldKey = parseKeyVoice.deepCopyKey(multilineVars.key);
    					//TODO-PER: HACK! To get the local transpose to work, the transposition is done for each line. This caused the global transposition variable to be factored in twice, so, instead of rewriting that right now, I'm just subtracting one of them here.
    					var keyCompensate = multilineVars.globalTranspose ? -multilineVars.globalTranspose : 0;
    					multilineVars.key = parseKeyVoice.deepCopyKey(parseKeyVoice.standardKey(key, retPitch.token, acc, keyCompensate));
    					multilineVars.key.mode = mode;
    					if (oldKey) {
    						// Add natural in all places that the old key had an accidental.
    						var kk;
    						for (var k = 0; k < multilineVars.key.accidentals.length; k++) {
    							for (kk = 0; kk < oldKey.accidentals.length; kk++) {
    								if (oldKey.accidentals[kk].note && multilineVars.key.accidentals[k].note.toLowerCase() === oldKey.accidentals[kk].note.toLowerCase())
    									oldKey.accidentals[kk].note = null;
    							}
    						}
    						for (kk = 0; kk < oldKey.accidentals.length; kk++) {
    							if (oldKey.accidentals[kk].note) {
    								if (!multilineVars.key.impliedNaturals)
    									multilineVars.key.impliedNaturals = [];
    								multilineVars.key.impliedNaturals.push({ acc: 'natural', note: oldKey.accidentals[kk].note });
    							}
    						}
    					}
    				}
    				break;
    		}

    		// There are two special cases of deprecated syntax. Ignore them if they occur
    		if (tokens.length === 0) return ret;
    		if (tokens[0].token === 'exp') tokens.shift();
    		if (tokens.length === 0) return ret;
    		if (tokens[0].token === 'oct') tokens.shift();

    		// now see if there are extra accidentals
    		if (tokens.length === 0) return ret;
    		var accs = tokenizer.getKeyAccidentals2(tokens);
    		if (accs.warn)
    			warn(accs.warn, str, 0);
    		// If we have extra accidentals, first replace ones that are of the same pitch before adding them to the end.
    		if (accs.accs) {
    			if (!ret.foundKey) {		// if there are only extra accidentals, make sure this is set.
    				ret.foundKey = true;
    				multilineVars.key = { root: "none", acc: "", mode: "", accidentals: [] };
    			}
    			normalizeAccidentals(accs.accs);
    			for (var i = 0; i < accs.accs.length; i++) {
    				var found = false;
    				for (var j = 0; j < multilineVars.key.accidentals.length && !found; j++) {
    					if (multilineVars.key.accidentals[j].note === accs.accs[i].note) {
    						found = true;
    						if (multilineVars.key.accidentals[j].acc !== accs.accs[i].acc) {
    							// If the accidental is different, then replace it. If it is the same, then the declaration was redundant, so just ignore it.
    							multilineVars.key.accidentals[j].acc = accs.accs[i].acc;
    							if (!multilineVars.key.explicitAccidentals)
    								multilineVars.key.explicitAccidentals = [];
    							multilineVars.key.explicitAccidentals.push(accs.accs[i]);
    						}
    					}
    				}
    				if (!found) {
    					if (!multilineVars.key.explicitAccidentals)
    						multilineVars.key.explicitAccidentals = [];
    					multilineVars.key.explicitAccidentals.push(accs.accs[i]);
    					multilineVars.key.accidentals.push(accs.accs[i]);
    					if (multilineVars.key.impliedNaturals) {
    						for (var kkk = 0; kkk < multilineVars.key.impliedNaturals.length; kkk++) {
    							if (multilineVars.key.impliedNaturals[kkk].note === accs.accs[i].note)
    								multilineVars.key.impliedNaturals.splice(kkk, 1);
    						}
    					}
    				}
    			}
    		}

    		// Now see if any optional parameters are present. They have the form "key=value", except that "clef=" is optional
    		var token;
    		while (tokens.length > 0) {
    			switch (tokens[0].token) {
    				case "m":
    				case "middle":
    					tokens.shift();
    					if (tokens.length === 0) { warn("Expected = after middle", str, 0); return ret; }
    					token = tokens.shift();
    					if (token.token !== "=") { warn("Expected = after middle", str, token.start); break; }
    					if (tokens.length === 0) { warn("Expected parameter after middle=", str, 0); return ret; }
    					var pitch = tokenizer.getPitchFromTokens(tokens);
    					if (pitch.warn)
    						warn(pitch.warn, str, 0);
    					if (pitch.position)
    						multilineVars.clef.verticalPos = pitch.position - 6;	// we get the position from the middle line, but want to offset it to the first ledger line.
    					break;
    				case "transpose":
    					tokens.shift();
    					if (tokens.length === 0) { warn("Expected = after transpose", str, 0); return ret; }
    					token = tokens.shift();
    					if (token.token !== "=") { warn("Expected = after transpose", str, token.start); break; }
    					if (tokens.length === 0) { warn("Expected parameter after transpose=", str, 0); return ret; }
    					if (tokens[0].type !== 'number') { warn("Expected number after transpose", str, tokens[0].start); break; }
    					multilineVars.clef.transpose = tokens[0].intt;
    					tokens.shift();
    					break;
    				case "stafflines":
    					tokens.shift();
    					if (tokens.length === 0) { warn("Expected = after stafflines", str, 0); return ret; }
    					token = tokens.shift();
    					if (token.token !== "=") { warn("Expected = after stafflines", str, token.start); break; }
    					if (tokens.length === 0) { warn("Expected parameter after stafflines=", str, 0); return ret; }
    					if (tokens[0].type !== 'number') { warn("Expected number after stafflines", str, tokens[0].start); break; }
    					multilineVars.clef.stafflines = tokens[0].intt;
    					tokens.shift();
    					break;
    				case "staffscale":
    					tokens.shift();
    					if (tokens.length === 0) { warn("Expected = after staffscale", str, 0); return ret; }
    					token = tokens.shift();
    					if (token.token !== "=") { warn("Expected = after staffscale", str, token.start); break; }
    					if (tokens.length === 0) { warn("Expected parameter after staffscale=", str, 0); return ret; }
    					if (tokens[0].type !== 'number') { warn("Expected number after staffscale", str, tokens[0].start); break; }
    					multilineVars.clef.staffscale = tokens[0].floatt;
    					tokens.shift();
    					break;
    				case "style":
    					tokens.shift();
    					if (tokens.length === 0) { warn("Expected = after style", str, 0); return ret; }
    					token = tokens.shift();
    					if (token.token !== "=") { warn("Expected = after style", str, token.start); break; }
    					if (tokens.length === 0) { warn("Expected parameter after style=", str, 0); return ret; }
    					switch (tokens[0].token) {
    						case "normal":
    						case "harmonic":
    						case "rhythm":
    						case "x":
    							multilineVars.style = tokens[0].token;
    							tokens.shift();
    							break;
    						default:
    							warn("error parsing style element: " + tokens[0].token, str, tokens[0].start);
    							break;
    					}
    					break;
    				case "clef":
    					tokens.shift();
    					if (tokens.length === 0) { warn("Expected = after clef", str, 0); return ret; }
    					token = tokens.shift();
    					if (token.token !== "=") { warn("Expected = after clef", str, token.start); break; }
    					if (tokens.length === 0) { warn("Expected parameter after clef=", str, 0); return ret; }
    					//break; yes, we want to fall through. That allows "clef=" to be optional.
    				case "treble":
    				case "bass":
    				case "alto":
    				case "tenor":
    				case "perc":
    					// clef is [clef=] [⟨clef type⟩] [⟨line number⟩] [+8|-8]
    					var clef = tokens.shift();
    					switch (clef.token) {
    						case 'treble':
    						case 'tenor':
    						case 'alto':
    						case 'bass':
    						case 'perc':
    						case 'none':
    							break;
    						case 'C': clef.token = 'alto'; break;
    						case 'F': clef.token = 'bass'; break;
    						case 'G': clef.token = 'treble'; break;
    						case 'c': clef.token = 'alto'; break;
    						case 'f': clef.token = 'bass'; break;
    						case 'g': clef.token = 'treble'; break;
    						default:
    							warn("Expected clef name. Found " + clef.token, str, clef.start);
    							break;
    					}
    					if (tokens.length > 0 && tokens[0].type === 'number') {
    						clef.token += tokens[0].token;
    						tokens.shift();
    					}
    					if (tokens.length > 1 && (tokens[0].token === '-' || tokens[0].token === '+' || tokens[0].token === '^' || tokens[0].token === '_') && tokens[1].token === '8') {
    						clef.token += tokens[0].token + tokens[1].token;
    						tokens.shift();
    						tokens.shift();
    					}
    					multilineVars.clef = {type: clef.token, verticalPos: calcMiddle(clef.token, 0)};
    					if (multilineVars.currentVoice && multilineVars.currentVoice.transpose !== undefined)
    						multilineVars.clef.transpose = multilineVars.currentVoice.transpose;
    					ret.foundClef = true;
    					break;
    				default:
    					warn("Unknown parameter: " + tokens[0].token, str, tokens[0].start);
    					tokens.shift();
    			}
    		}
    		return ret;
    	};

    	var setCurrentVoice = function(id) {
    		multilineVars.currentVoice = multilineVars.voices[id];
    		tune.setCurrentVoice(multilineVars.currentVoice.staffNum, multilineVars.currentVoice.index);
    	};

    	parseKeyVoice.parseVoice = function(line, i, e) {
    		//First truncate the string to the first non-space character after V: through either the
    		//end of the line or a % character. Then remove trailing spaces, too.
    		var ret = tokenizer.getMeat(line, i, e);
    		var start = ret.start;
    		var end = ret.end;
    		//The first thing on the line is the ID. It can be any non-space string and terminates at the
    		//first space.
    		var id = tokenizer.getToken(line, start, end);
    		if (id.length === 0) {
    			warn("Expected a voice id", line, start);
    			return;
    		}
    		var isNew = false;
    		if (multilineVars.voices[id] === undefined) {
    			multilineVars.voices[id] = {};
    			isNew = true;
    			if (multilineVars.score_is_present)
    				warn("Can't have an unknown V: id when the %score directive is present", line, start);
    		}
    		start += id.length;
    		start += tokenizer.eatWhiteSpace(line, start);

    		var staffInfo = {startStaff: isNew};
    		var addNextTokenToStaffInfo = function(name) {
    			var attr = tokenizer.getVoiceToken(line, start, end);
    			if (attr.warn !== undefined)
    				warn("Expected value for " + name + " in voice: " + attr.warn, line, start);
    			else if (attr.token.length === 0 && line.charAt(start) !== '"')
    				warn("Expected value for " + name + " in voice", line, start);
    			else
    				staffInfo[name] = attr.token;
    			start += attr.len;
    		};
    		var addNextTokenToVoiceInfo = function(id, name, type) {
    			var attr = tokenizer.getVoiceToken(line, start, end);
    			if (attr.warn !== undefined)
    				warn("Expected value for " + name + " in voice: " + attr.warn, line, start);
    			else if (attr.token.length === 0 && line.charAt(start) !== '"')
    				warn("Expected value for " + name + " in voice", line, start);
    			else {
    				if (type === 'number')
    					attr.token = parseFloat(attr.token);
    				multilineVars.voices[id][name] = attr.token;
    			}
    			start += attr.len;
    		};
    		var getNextToken = function(name, type) {
    			var attr = tokenizer.getVoiceToken(line, start, end);
    			if (attr.warn !== undefined)
    				warn("Expected value for " + name + " in voice: " + attr.warn, line, start);
    			else if (attr.token.length === 0 && line.charAt(start) !== '"')
    				warn("Expected value for " + name + " in voice", line, start);
    			else {
    				if (type === 'number')
    					attr.token = parseFloat(attr.token);
    				return attr.token;
    			}
    			start += attr.len;
    		};
    		var addNextNoteTokenToVoiceInfo = function(id, name) {
    			var noteToTransposition = {
    				"_B": 2,
    				"_E": 9,
    				"_b": -10,
    				"_e": -3
    			};
    			var attr = tokenizer.getVoiceToken(line, start, end);
    			if (attr.warn !== undefined)
    				warn("Expected one of (_B, _E, _b, _e) for " + name + " in voice: " + attr.warn, line, start);
    			else if (attr.token.length === 0 && line.charAt(start) !== '"')
    				warn("Expected one of (_B, _E, _b, _e) for " + name + " in voice", line, start);
    			else {
    				var t = noteToTransposition[attr.token];
    				if (!t)
    					warn("Expected one of (_B, _E, _b, _e) for " + name + " in voice", line, start);
    				else
    					multilineVars.voices[id][name] = t;
    			}
    			start += attr.len;
    		};

    		//Then the following items can occur in any order:
    		while (start < end) {
    			var token = tokenizer.getVoiceToken(line, start, end);
    			start += token.len;

    			if (token.warn) {
    				warn("Error parsing voice: " + token.warn, line, start);
    			} else {
    				var attr = null;
    				switch (token.token) {
    					case 'clef':
    					case 'cl':
    						addNextTokenToStaffInfo('clef');
    						// TODO-PER: check for a legal clef; do octavizing
    						var oct = 0;
    	//							for (var ii = 0; ii < staffInfo.clef.length; ii++) {
    	//								if (staffInfo.clef[ii] === ',') oct -= 7;
    	//								else if (staffInfo.clef[ii] === "'") oct += 7;
    	//							}
    						if (staffInfo.clef !== undefined) {
    						  staffInfo.clef = staffInfo.clef.replace(/[',]/g, ""); //'//comment for emacs formatting of regexp
    							if (staffInfo.clef.indexOf('+16') !== -1) {
    								oct += 14;
    								staffInfo.clef = staffInfo.clef.replace('+16', '');
    							}
    							staffInfo.verticalPos = calcMiddle(staffInfo.clef, oct);
    						}
    						break;
    					case 'treble':
    					case 'bass':
    					case 'tenor':
    					case 'alto':
    					case 'perc':
    					case 'none':
    					case 'treble\'':
    					case 'bass\'':
    					case 'tenor\'':
    					case 'alto\'':
    					case 'none\'':
    					case 'treble\'\'':
    					case 'bass\'\'':
    					case 'tenor\'\'':
    					case 'alto\'\'':
    					case 'none\'\'':
    					case 'treble,':
    					case 'bass,':
    					case 'tenor,':
    					case 'alto,':
    					case 'none,':
    					case 'treble,,':
    					case 'bass,,':
    					case 'tenor,,':
    					case 'alto,,':
    					case 'none,,':
    						// TODO-PER: handle the octave indicators on the clef by changing the middle property
    						var oct2 = 0;
    	//							for (var iii = 0; iii < token.token.length; iii++) {
    	//								if (token.token[iii] === ',') oct2 -= 7;
    	//								else if (token.token[iii] === "'") oct2 += 7;
    	//							}
    											  staffInfo.clef = token.token.replace(/[',]/g, ""); //'//comment for emacs formatting of regexp
    						staffInfo.verticalPos = calcMiddle(staffInfo.clef, oct2);
    						multilineVars.voices[id].clef = token.token;
    						break;
    					case 'staves':
    					case 'stave':
    					case 'stv':
    						addNextTokenToStaffInfo('staves');
    						break;
    					case 'brace':
    					case 'brc':
    						addNextTokenToStaffInfo('brace');
    						break;
    					case 'bracket':
    					case 'brk':
    						addNextTokenToStaffInfo('bracket');
    						break;
    					case 'name':
    					case 'nm':
    						addNextTokenToStaffInfo('name');
    						break;
    					case 'subname':
    					case 'sname':
    					case 'snm':
    						addNextTokenToStaffInfo('subname');
    						break;
    					case 'merge':
    						staffInfo.startStaff = false;
    						break;
    					case 'stem':
    					case 'stems':
    						attr = tokenizer.getVoiceToken(line, start, end);
    						if (attr.warn !== undefined)
    							warn("Expected value for stems in voice: " + attr.warn, line, start);
    						else if (attr.token === 'up' || attr.token === 'down')
    							multilineVars.voices[id].stem = attr.token;
    						else
    							warn("Expected up or down for voice stem", line, start);
    						start += attr.len;
    						break;
    					case 'up':
    					case 'down':
    						multilineVars.voices[id].stem = token.token;
    						break;
    					case 'middle':
    					case 'm':
    						addNextTokenToStaffInfo('verticalPos');
    						staffInfo.verticalPos = parseMiddle(staffInfo.verticalPos).mid;
    						break;
    					case 'gchords':
    					case 'gch':
    						multilineVars.voices[id].suppressChords = true;
    						// gchords can stand on its own, or it could be gchords=0.
    						attr = tokenizer.getVoiceToken(line, start, end);
    						if (attr.token === "0")
    							start = start + attr.len;
    						break;
    					case 'space':
    					case 'spc':
    						addNextTokenToStaffInfo('spacing');
    						break;
    					case 'scale':
    						addNextTokenToVoiceInfo(id, 'scale', 'number');
    						break;
    					case 'score':
    						addNextNoteTokenToVoiceInfo(id, 'scoreTranspose');
    						break;
    					case 'transpose':
    						addNextTokenToVoiceInfo(id, 'transpose', 'number');
    						break;
    					case 'stafflines':
    						addNextTokenToVoiceInfo(id, 'stafflines', 'number');
    						break;
    					case 'staffscale':
    						// TODO-PER: This is passed to the engraver, but the engraver ignores it.
    						addNextTokenToVoiceInfo(id, 'staffscale', 'number');
    						break;
    					case 'octave':
    						// TODO-PER: This is accepted, but not implemented, yet.
    						addNextTokenToVoiceInfo(id, 'octave', 'number');
    						break;
    					case 'volume':
    						// TODO-PER: This is accepted, but not implemented, yet.
    						addNextTokenToVoiceInfo(id, 'volume', 'number');
    						break;
    					case 'cue':
    						// TODO-PER: This is accepted, but not implemented, yet.
    						var cue = getNextToken('cue', 'string');
    						if (cue === 'on')
    							multilineVars.voices[id].scale = 0.6;
    						else multilineVars.voices[id].scale = 1;
    						break;
    					case "style":
    						attr = tokenizer.getVoiceToken(line, start, end);
    						if (attr.warn !== undefined)
    							warn("Expected value for style in voice: " + attr.warn, line, start);
    						else if (attr.token === 'normal' || attr.token === 'harmonic' || attr.token === 'rhythm' || attr.token === 'x')
    							multilineVars.voices[id].style = attr.token;
    						else
    							warn("Expected one of [normal, harmonic, rhythm, x] for voice style", line, start);
    						start += attr.len;
    						break;
    					// default:
    					// Use this to find V: usages that aren't handled.
    					// 	console.log("parse voice", token, tune.metaText.title);
    				}
    			}
    			start += tokenizer.eatWhiteSpace(line, start);
    		}

    		// now we've filled up staffInfo, figure out what to do with this voice
    		// TODO-PER: It is unclear from the standard and the examples what to do with brace, bracket, and staves, so they are ignored for now.
    		if (staffInfo.startStaff || multilineVars.staves.length === 0) {
    			multilineVars.staves.push({index: multilineVars.staves.length, meter: multilineVars.origMeter});
    			if (!multilineVars.score_is_present)
    				multilineVars.staves[multilineVars.staves.length-1].numVoices = 0;
    		}
    		if (multilineVars.voices[id].staffNum === undefined) {
    			// store where to write this for quick access later.
    			multilineVars.voices[id].staffNum = multilineVars.staves.length-1;
    			var vi = 0;
    			for(var v in multilineVars.voices) {
    				if(multilineVars.voices.hasOwnProperty(v)) {
    					if (multilineVars.voices[v].staffNum === multilineVars.voices[id].staffNum)
    						vi++;
    				}
    			}
    			multilineVars.voices[id].index = vi-1;
    		}
    		var s = multilineVars.staves[multilineVars.voices[id].staffNum];
    		if (!multilineVars.score_is_present)
    			s.numVoices++;
    		if (staffInfo.clef) s.clef = {type: staffInfo.clef, verticalPos: staffInfo.verticalPos};
    		if (staffInfo.spacing) s.spacing_below_offset = staffInfo.spacing;
    		if (staffInfo.verticalPos) s.verticalPos = staffInfo.verticalPos;

    		if (staffInfo.name) {if (s.name) s.name.push(staffInfo.name); else s.name = [ staffInfo.name ];}
    		if (staffInfo.subname) {if (s.subname) s.subname.push(staffInfo.subname); else s.subname = [ staffInfo.subname ];}

    		setCurrentVoice(id);
    	};

    })();

    var abc_parse_key_voice = parseKeyVoice;

    //    abc_parse_header.js: parses a the header fields from a string representing ABC Music Notation into a usable internal structure.
    //    Copyright (C) 2010-2018 Paul Rosen (paul at paulrosen dot net)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    /*global window */





    var ParseHeader = function(tokenizer, warn, multilineVars, tune) {
    	this.reset = function(tokenizer, warn, multilineVars, tune) {
    		abc_parse_key_voice.initialize(tokenizer, warn, multilineVars, tune);
    		abc_parse_directive.initialize(tokenizer, warn, multilineVars, tune);
    	};
    	this.reset(tokenizer, warn, multilineVars, tune);

    	this.setTitle = function(title) {
    		if (multilineVars.hasMainTitle)
    			tune.addSubtitle(tokenizer.translateString(tokenizer.stripComment(title)));	// display secondary title
    		else
    		{
    			var titleStr = tokenizer.translateString(tokenizer.theReverser(tokenizer.stripComment(title)));
    			if (multilineVars.titlecaps)
    				titleStr = titleStr.toUpperCase();
    			tune.addMetaText("title", titleStr);
    			multilineVars.hasMainTitle = true;
    		}
    	};

    	this.setMeter = function(line) {
    		line = tokenizer.stripComment(line);
    		if (line === 'C') {
    			if (multilineVars.havent_set_length === true) {
    				multilineVars.default_length = 0.125;
    				multilineVars.havent_set_length = false;
    			}
    			return {type: 'common_time'};
    		} else if (line === 'C|') {
    			if (multilineVars.havent_set_length === true) {
    				multilineVars.default_length = 0.125;
    				multilineVars.havent_set_length = false;
    			}
    			return {type: 'cut_time'};
    		} else if (line === 'o') {
    			if (multilineVars.havent_set_length === true) {
    				multilineVars.default_length = 0.125;
    				multilineVars.havent_set_length = false;
    			}
    			return {type: 'tempus_perfectum'};
    		} else if (line === 'c') {
    			if (multilineVars.havent_set_length === true) {
    				multilineVars.default_length = 0.125;
    				multilineVars.havent_set_length = false;
    			}
    			return {type: 'tempus_imperfectum'};
    		} else if (line === 'o.') {
    			if (multilineVars.havent_set_length === true) {
    				multilineVars.default_length = 0.125;
    				multilineVars.havent_set_length = false;
    			}
    			return {type: 'tempus_perfectum_prolatio'};
    		} else if (line === 'c.') {
    			if (multilineVars.havent_set_length === true) {
    				multilineVars.default_length = 0.125;
    				multilineVars.havent_set_length = false;
    			}
    			return {type: 'tempus_imperfectum_prolatio'};
    		} else if (line.length === 0 || line.toLowerCase() === 'none') {
    			if (multilineVars.havent_set_length === true) {
    				multilineVars.default_length = 0.125;
    				multilineVars.havent_set_length = false;
    			}
    			return null;
    		}
    		else
    		{
    			var tokens = tokenizer.tokenize(line, 0, line.length);
    			// the form is [open_paren] decimal [ plus|dot decimal ]... [close_paren] slash decimal [plus same_as_before]
    			try {
    				var parseNum = function() {
    					// handles this much: [open_paren] decimal [ plus|dot decimal ]... [close_paren]
    					var ret = {value: 0, num: ""};

    					var tok = tokens.shift();
    					if (tok.token === '(')
    						tok = tokens.shift();
    					while (1) {
    						if (tok.type !== 'number') throw "Expected top number of meter";
    						ret.value += parseInt(tok.token);
    						ret.num += tok.token;
    						if (tokens.length === 0 || tokens[0].token === '/') return ret;
    						tok = tokens.shift();
    						if (tok.token === ')') {
    							if (tokens.length === 0 || tokens[0].token === '/') return ret;
    							throw "Unexpected paren in meter";
    						}
    						if (tok.token !== '.' && tok.token !== '+') throw "Expected top number of meter";
    						ret.num += tok.token;
    						if (tokens.length === 0) throw "Expected top number of meter";
    						tok = tokens.shift();
    					}
    					return ret;	// just to suppress warning
    				};

    				var parseFraction = function() {
    					// handles this much: parseNum slash decimal
    					var ret = parseNum();
    					if (tokens.length === 0) return ret;
    					var tok = tokens.shift();
    					if (tok.token !== '/') throw "Expected slash in meter";
    					tok = tokens.shift();
    					if (tok.type !== 'number') throw "Expected bottom number of meter";
    					ret.den = tok.token;
    					ret.value = ret.value / parseInt(ret.den);
    					return ret;
    				};

    				if (tokens.length === 0) throw "Expected meter definition in M: line";
    				var meter = {type: 'specified', value: [ ]};
    				var totalLength = 0;
    				while (1) {
    					var ret = parseFraction();
    					totalLength += ret.value;
    					var mv = { num: ret.num };
    					if (ret.den !== undefined)
    						mv.den = ret.den;
    					meter.value.push(mv);
    					if (tokens.length === 0) break;
    					//var tok = tokens.shift();
    					//if (tok.token !== '+') throw "Extra characters in M: line";
    				}

    				if (multilineVars.havent_set_length === true) {
    					multilineVars.default_length = totalLength < 0.75 ? 0.0625 : 0.125;
    					multilineVars.havent_set_length = false;
    				}
    				return meter;
    			} catch (e) {
    				warn(e, line, 0);
    			}
    		}
    		return null;
    	};

    	this.calcTempo = function(relTempo) {
    		var dur = 1/4;
    		if (multilineVars.meter && multilineVars.meter.type === 'specified') {
    			dur = 1 / parseInt(multilineVars.meter.value[0].den);
    		} else if (multilineVars.origMeter && multilineVars.origMeter.type === 'specified') {
    			dur = 1 / parseInt(multilineVars.origMeter.value[0].den);
    		}
    		//var dur = multilineVars.default_length ? multilineVars.default_length : 1;
    		for (var i = 0; i < relTempo.duration; i++)
    			relTempo.duration[i] = dur * relTempo.duration[i];
    		return relTempo;
    	};

    	this.resolveTempo = function() {
    		if (multilineVars.tempo) {	// If there's a tempo waiting to be resolved
    			this.calcTempo(multilineVars.tempo);
    			tune.metaText.tempo = multilineVars.tempo;
    			delete multilineVars.tempo;
    		}
    	};

    	this.addUserDefinition = function(line, start, end) {
    		var equals = line.indexOf('=', start);
    		if (equals === -1) {
    			warn("Need an = in a macro definition", line, start);
    			return;
    		}

    		var before = abc_common.strip(line.substring(start, equals));
    		var after = abc_common.strip(line.substring(equals+1));

    		if (before.length !== 1) {
    			warn("Macro definitions can only be one character", line, start);
    			return;
    		}
    		var legalChars = "HIJKLMNOPQRSTUVWXYhijklmnopqrstuvw~";
    		if (legalChars.indexOf(before) === -1) {
    			warn("Macro definitions must be H-Y, h-w, or tilde", line, start);
    			return;
    		}
    		if (after.length === 0) {
    			warn("Missing macro definition", line, start);
    			return;
    		}
    		if (multilineVars.macros === undefined)
    			multilineVars.macros = {};
    		multilineVars.macros[before] = after;
    	};

    	this.setDefaultLength = function(line, start, end) {
    		var len = abc_common.gsub(line.substring(start, end), " ", "");
    		var len_arr = len.split('/');
    		if (len_arr.length === 2) {
    			var n = parseInt(len_arr[0]);
    			var d = parseInt(len_arr[1]);
    			if (d > 0) {
    				multilineVars.default_length = n / d;	// a whole note is 1
    				multilineVars.havent_set_length = false;
    			}
    		} else if (len_arr.length === 1 && len_arr[0] === '1') {
    			multilineVars.default_length = 1;
    			multilineVars.havent_set_length = false;
    		}
    	};


    	var tempoString = {

    		larghissimo: 20,
    		adagissimo: 24,
    		sostenuto: 28,
    		grave: 32,
    		largo: 40,
    		lento: 50,
    		larghetto: 60,
    		adagio: 68,
    		adagietto: 74,
    		andante: 80,
    		andantino: 88,
    		"marcia moderato": 84,
    		"andante moderato": 100,
    		moderato: 112,
    		allegretto: 116,
    		"allegro moderato": 120,
    		allegro: 126,
    		animato: 132,
    		agitato: 140,
    		veloce: 148,
    		"mosso vivo": 156,
    		vivace: 164,
    		vivacissimo: 172,
    		allegrissimo: 176,
    		presto: 184,
    		prestissimo: 210,
    	};

    	this.setTempo = function(line, start, end) {
    		//Q - tempo; can be used to specify the notes per minute, e.g. If
    		//the meter denominator is a 4 note then Q:120 or Q:C=120
    		//is 120 quarter notes per minute. Similarly  Q:C3=40 would be 40
    		//dotted half notes per minute. An absolute tempo may also be
    		//set, e.g. Q:1/8=120 is 120 eighth notes per minute,
    		//irrespective of the meter's denominator.
    		//
    		// This is either a number, "C=number", "Cnumber=number", or fraction [fraction...]=number
    		// It depends on the M: field, which may either not be present, or may appear after this.
    		// If M: is not present, an eighth note is used.
    		// That means that this field can't be calculated until the end, if it is the first three types, since we don't know if we'll see an M: field.
    		// So, if it is the fourth type, set it here, otherwise, save the info in the multilineVars.
    		// The temporary variables we keep are the duration and the bpm. In the first two forms, the duration is 1.
    		// In addition, a quoted string may both precede and follow. If a quoted string is present, then the duration part is optional.
    		try {
    			var tokens = tokenizer.tokenize(line, start, end);

    			if (tokens.length === 0) throw "Missing parameter in Q: field";

    			var tempo = {};
    			var delaySet = true;
    			var token = tokens.shift();
    			if (token.type === 'quote') {
    				tempo.preString = token.token;
    				token = tokens.shift();
    				if (tokens.length === 0) {	// It's ok to just get a string for the tempo
    					// If the string is a well-known tempo, put in the bpm
    					if (tempoString[tempo.preString.toLowerCase()]) {
    						tempo.bpm = tempoString[tempo.preString.toLowerCase()];
    						tempo.suppressBpm = true;
    					}
    					return {type: 'immediate', tempo: tempo};
    				}
    			}
    			if (token.type === 'alpha' && token.token === 'C')	 { // either type 2 or type 3
    				if (tokens.length === 0) throw "Missing tempo after C in Q: field";
    				token = tokens.shift();
    				if (token.type === 'punct' && token.token === '=') {
    					// This is a type 2 format. The duration is an implied 1
    					if (tokens.length === 0) throw "Missing tempo after = in Q: field";
    					token = tokens.shift();
    					if (token.type !== 'number') throw "Expected number after = in Q: field";
    					tempo.duration = [1];
    					tempo.bpm = parseInt(token.token);
    				} else if (token.type === 'number') {
    					// This is a type 3 format.
    					tempo.duration = [parseInt(token.token)];
    					if (tokens.length === 0) throw "Missing = after duration in Q: field";
    					token = tokens.shift();
    					if (token.type !== 'punct' || token.token !== '=') throw "Expected = after duration in Q: field";
    					if (tokens.length === 0) throw "Missing tempo after = in Q: field";
    					token = tokens.shift();
    					if (token.type !== 'number') throw "Expected number after = in Q: field";
    					tempo.bpm = parseInt(token.token);
    				} else throw "Expected number or equal after C in Q: field";

    			} else if (token.type === 'number') {	// either type 1 or type 4
    				var num = parseInt(token.token);
    				if (tokens.length === 0 || tokens[0].type === 'quote') {
    					// This is type 1
    					tempo.duration = [1];
    					tempo.bpm = num;
    				} else {	// This is type 4
    					delaySet = false;
    					token = tokens.shift();
    					if (token.type !== 'punct' && token.token !== '/') throw "Expected fraction in Q: field";
    					token = tokens.shift();
    					if (token.type !== 'number') throw "Expected fraction in Q: field";
    					var den = parseInt(token.token);
    					tempo.duration = [num/den];
    					// We got the first fraction, keep getting more as long as we find them.
    					while (tokens.length > 0  && tokens[0].token !== '=' && tokens[0].type !== 'quote') {
    						token = tokens.shift();
    						if (token.type !== 'number') throw "Expected fraction in Q: field";
    						num = parseInt(token.token);
    						token = tokens.shift();
    						if (token.type !== 'punct' && token.token !== '/') throw "Expected fraction in Q: field";
    						token = tokens.shift();
    						if (token.type !== 'number') throw "Expected fraction in Q: field";
    						den = parseInt(token.token);
    						tempo.duration.push(num/den);
    					}
    					token = tokens.shift();
    					if (token.type !== 'punct' && token.token !== '=') throw "Expected = in Q: field";
    					token = tokens.shift();
    					if (token.type !== 'number') throw "Expected tempo in Q: field";
    					tempo.bpm = parseInt(token.token);
    				}
    			} else throw "Unknown value in Q: field";
    			if (tokens.length !== 0) {
    				token = tokens.shift();
    				if (token.type === 'quote') {
    					tempo.postString = token.token;
    					token = tokens.shift();
    				}
    				if (tokens.length !== 0) throw "Unexpected string at end of Q: field";
    			}
    			if (multilineVars.printTempo === false)
    				tempo.suppress = true;
    			return {type: delaySet?'delaySet':'immediate', tempo: tempo};
    		} catch (msg) {
    			warn(msg, line, start);
    			return {type: 'none'};
    		}
    	};

    	this.letter_to_inline_header = function(line, i)
    	{
    		var ws = tokenizer.eatWhiteSpace(line, i);
    		i +=ws;
    		if (line.length >= i+5 && line.charAt(i) === '[' && line.charAt(i+2) === ':') {
    			var e = line.indexOf(']', i);
    			var startChar = multilineVars.iChar + i;
    			var endChar = multilineVars.iChar + e + 1;
    			switch(line.substring(i, i+3))
    			{
    				case "[I:":
    					var err = abc_parse_directive.addDirective(line.substring(i+3, e));
    					if (err) warn(err, line, i);
    					return [ e-i+1+ws ];
    				case "[M:":
    					var meter = this.setMeter(line.substring(i+3, e));
    					if (tune.hasBeginMusic() && meter)
    						tune.appendStartingElement('meter', startChar, endChar, meter);
    					else
    						multilineVars.meter = meter;
    					return [ e-i+1+ws ];
    				case "[K:":
    					var result = abc_parse_key_voice.parseKey(line.substring(i+3, e));
    					if (result.foundClef && tune.hasBeginMusic())
    						tune.appendStartingElement('clef', startChar, endChar, multilineVars.clef);
    					if (result.foundKey && tune.hasBeginMusic())
    						tune.appendStartingElement('key', startChar, endChar, abc_parse_key_voice.fixKey(multilineVars.clef, multilineVars.key));
    					return [ e-i+1+ws ];
    				case "[P:":
    					if (tune.lines.length <= tune.lineNum)
    						multilineVars.partForNextLine = { title: line.substring(i+3, e), startChar: startChar, endChar: endChar };
    					else
    						tune.appendElement('part', startChar, endChar, {title: line.substring(i+3, e)});
    					return [ e-i+1+ws ];
    				case "[L:":
    					this.setDefaultLength(line, i+3, e);
    					return [ e-i+1+ws ];
    				case "[Q:":
    					if (e > 0) {
    						var tempo = this.setTempo(line, i+3, e);
    						if (tempo.type === 'delaySet') tune.appendElement('tempo', startChar, endChar, this.calcTempo(tempo.tempo));
    						else if (tempo.type === 'immediate') tune.appendElement('tempo', startChar, endChar, tempo.tempo);
    						return [ e-i+1+ws, line.charAt(i+1), line.substring(i+3, e)];
    					}
    					break;
    				case "[V:":
    					if (e > 0) {
    						abc_parse_key_voice.parseVoice(line, i+3, e);
    						//startNewLine();
    						return [ e-i+1+ws, line.charAt(i+1), line.substring(i+3, e)];
    					}
    					break;
    					// TODO: complain about unhandled header
    			}
    		}
    		return [ 0 ];
    	};

    	this.letter_to_body_header = function(line, i)
    	{
    		if (line.length >= i+3) {
    			switch(line.substring(i, i+2))
    			{
    				case "I:":
    					var err = abc_parse_directive.addDirective(line.substring(i+2));
    					if (err) warn(err, line, i);
    					return [ line.length ];
    				case "M:":
    					var meter = this.setMeter(line.substring(i+2));
    					if (tune.hasBeginMusic() && meter)
    						tune.appendStartingElement('meter', multilineVars.iChar + i, multilineVars.iChar + line.length, meter);
    					return [ line.length ];
    				case "K:":
    					var result = abc_parse_key_voice.parseKey(line.substring(i+2));
    					if (result.foundClef && tune.hasBeginMusic())
    						tune.appendStartingElement('clef', multilineVars.iChar + i, multilineVars.iChar + line.length, multilineVars.clef);
    					if (result.foundKey && tune.hasBeginMusic())
    						tune.appendStartingElement('key', multilineVars.iChar + i, multilineVars.iChar + line.length, abc_parse_key_voice.fixKey(multilineVars.clef, multilineVars.key));
    					return [ line.length ];
    				case "P:":
    					if (tune.hasBeginMusic())
    						tune.appendElement('part', multilineVars.iChar + i, multilineVars.iChar + line.length, {title: line.substring(i+2)});
    					return [ line.length ];
    				case "L:":
    					this.setDefaultLength(line, i+2, line.length);
    					return [ line.length ];
    				case "Q:":
    					var e = line.indexOf('\x12', i+2);
    					if (e === -1) e = line.length;
    					var tempo = this.setTempo(line, i+2, e);
    					if (tempo.type === 'delaySet') tune.appendElement('tempo', multilineVars.iChar + i, multilineVars.iChar + line.length, this.calcTempo(tempo.tempo));
    					else if (tempo.type === 'immediate') tune.appendElement('tempo', multilineVars.iChar + i, multilineVars.iChar + line.length, tempo.tempo);
    				return [ e, line.charAt(i), abc_common.strip(line.substring(i+2))];
    				case "V:":
    					abc_parse_key_voice.parseVoice(line, i+2, line.length);
    //						startNewLine();
    					return [ line.length, line.charAt(i), abc_common.strip(line.substring(i+2))];
    					// TODO: complain about unhandled header
    			}
    		}
    		return [ 0 ];
    	};

    	var metaTextHeaders = {
    		A: 'author',
    		B: 'book',
    		C: 'composer',
    		D: 'discography',
    		F: 'url',
    		G: 'group',
    		I: 'instruction',
    		N: 'notes',
    		O: 'origin',
    		R: 'rhythm',
    		S: 'source',
    		W: 'unalignedWords',
    		Z: 'transcription'
    	};

    	this.parseHeader = function(line) {
    		if (abc_common.startsWith(line, '%%')) {
    			var err = abc_parse_directive.addDirective(line.substring(2));
    			if (err) warn(err, line, 2);
    			return {};
    		}
    		var i = line.indexOf('%');
    		if (i >= 0)
    			line = line.substring(0, i);
    		line = line.replace(/\s+$/, '');

    		if (line.length === 0)
    			return {};

    		if (line.length >= 2) {
    			if (line.charAt(1) === ':') {
    				var nextLine = "";
    				if (line.indexOf('\x12') >= 0 && line.charAt(0) !== 'w') {	// w: is the only header field that can have a continuation.
    					nextLine = line.substring(line.indexOf('\x12')+1);
    					line = line.substring(0, line.indexOf('\x12'));	//This handles a continuation mark on a header field
    				}
    				var field = metaTextHeaders[line.charAt(0)];
    				if (field !== undefined) {
    					if (field === 'unalignedWords')
    						tune.addMetaTextArray(field, abc_parse_directive.parseFontChangeLine(tokenizer.translateString(tokenizer.stripComment(line.substring(2)))));
    					else
    						tune.addMetaText(field, tokenizer.translateString(tokenizer.stripComment(line.substring(2))));
    					return {};
    				} else {
    					var startChar = multilineVars.iChar;
    					var endChar = startChar + line.length;
    					switch(line.charAt(0))
    					{
    						case  'H':
    							tune.addMetaText("history", tokenizer.translateString(tokenizer.stripComment(line.substring(2))));
    							multilineVars.is_in_history = true;
    							break;
    						case  'K':
    							// since the key is the last thing that can happen in the header, we can resolve the tempo now
    							this.resolveTempo();
    							var result = abc_parse_key_voice.parseKey(line.substring(2));
    							if (!multilineVars.is_in_header && tune.hasBeginMusic()) {
    								if (result.foundClef)
    									tune.appendStartingElement('clef', startChar, endChar, multilineVars.clef);
    								if (result.foundKey)
    									tune.appendStartingElement('key', startChar, endChar, abc_parse_key_voice.fixKey(multilineVars.clef, multilineVars.key));
    							}
    							multilineVars.is_in_header = false;	// The first key signifies the end of the header.
    							break;
    						case  'L':
    							this.setDefaultLength(line, 2, line.length);
    							break;
    						case  'M':
    							multilineVars.origMeter = multilineVars.meter = this.setMeter(line.substring(2));
    							break;
    						case  'P':
    							// TODO-PER: There is more to do with parts, but the writer doesn't care.
    							if (multilineVars.is_in_header)
    								tune.addMetaText("partOrder", tokenizer.translateString(tokenizer.stripComment(line.substring(2))));
    							else
    								multilineVars.partForNextLine = { title: tokenizer.translateString(tokenizer.stripComment(line.substring(2))), startChar: startChar, endChar: endChar};
    							break;
    						case  'Q':
    							var tempo = this.setTempo(line, 2, line.length);
    							if (tempo.type === 'delaySet') multilineVars.tempo = tempo.tempo;
    							else if (tempo.type === 'immediate') tune.metaText.tempo = tempo.tempo;
    							break;
    						case  'T':
    							this.setTitle(line.substring(2));
    							break;
    						case 'U':
    							this.addUserDefinition(line, 2, line.length);
    							break;
    						case  'V':
    							abc_parse_key_voice.parseVoice(line, 2, line.length);
    							if (!multilineVars.is_in_header)
    								return {newline: true};
    							break;
    						case  's':
    							return {symbols: true};
    						case  'w':
    							return {words: true};
    						case 'X':
    							break;
    						case 'E':
    						case 'm':
    							warn("Ignored header", line, 0);
    							break;
    						default:
    							// It wasn't a recognized header value, so parse it as music.
    							if (nextLine.length)
    								nextLine = "\x12" + nextLine;
    							//parseRegularMusicLine(line+nextLine);
    							//nextLine = "";
    							return {regular: true, str: line+nextLine};
    					}
    				}
    				if (nextLine.length > 0)
    					return {recurse: true, str: nextLine};
    				return {};
    			}
    		}

    		// If we got this far, we have a regular line of mulsic
    		return {regular: true, str: line};
    	};
    };

    var abc_parse_header = ParseHeader;

    //    abc_tokenizer.js: tokenizes an ABC Music Notation string to support abc_parse.
    //    Copyright (C) 2010-2018 Paul Rosen (paul at paulrosen dot net)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



    // this is a series of functions that get a particular element out of the passed stream.
    // the return is the number of characters consumed, so 0 means that the element wasn't found.
    // also returned is the element found. This may be a different length because spaces may be consumed that aren't part of the string.
    // The return structure for most calls is { len: num_chars_consumed, token: str }
    var Tokenizer = function() {
    	this.skipWhiteSpace = function(str) {
    		for (var i = 0; i < str.length; i++) {
    		  if (!this.isWhiteSpace(str.charAt(i)))
    				return i;
    		}
    		return str.length;	// It must have been all white space
    	};
    	var finished = function(str, i) {
    		return i >= str.length;
    	};
    	this.eatWhiteSpace = function(line, index) {
    		for (var i = index; i < line.length; i++) {
    		  if (!this.isWhiteSpace(line.charAt(i)))
    				return i-index;
    		}
    		return i-index;
    	};

    	// This just gets the basic pitch letter, ignoring leading spaces, and normalizing it to a capital
    	this.getKeyPitch = function(str) {
    		var i = this.skipWhiteSpace(str);
    		if (finished(str, i))
    			return {len: 0};
    		switch (str.charAt(i)) {
    			case 'A':return {len: i+1, token: 'A'};
    			case 'B':return {len: i+1, token: 'B'};
    			case 'C':return {len: i+1, token: 'C'};
    			case 'D':return {len: i+1, token: 'D'};
    			case 'E':return {len: i+1, token: 'E'};
    			case 'F':return {len: i+1, token: 'F'};
    			case 'G':return {len: i+1, token: 'G'};
    //			case 'a':return {len: i+1, token: 'A'};
    //			case 'b':return {len: i+1, token: 'B'};
    //			case 'c':return {len: i+1, token: 'C'};
    //			case 'd':return {len: i+1, token: 'D'};
    //			case 'e':return {len: i+1, token: 'E'};
    //			case 'f':return {len: i+1, token: 'F'};
    //			case 'g':return {len: i+1, token: 'G'};
    		}
    		return {len: 0};
    	};

    	// This just gets the basic accidental, ignoring leading spaces, and only the ones that appear in a key
    	this.getSharpFlat = function(str) {
    		if (str === 'bass')
    			return {len: 0};
    		switch (str.charAt(0)) {
    			case '#':return {len: 1, token: '#'};
    			case 'b':return {len: 1, token: 'b'};
    		}
    		return {len: 0};
    	};

    	this.getMode = function(str) {
    		var skipAlpha = function(str, start) {
    			// This returns the index of the next non-alphabetic char, or the entire length of the string if not found.
    		  while (start < str.length && ((str.charAt(start) >= 'a' && str.charAt(start) <= 'z') || (str.charAt(start) >= 'A' && str.charAt(start) <= 'Z')))
    				start++;
    			return start;
    		};

    		var i = this.skipWhiteSpace(str);
    		if (finished(str, i))
    			return {len: 0};
    		var firstThree = str.substring(i,i+3).toLowerCase();
    		if (firstThree.length > 1 && firstThree.charAt(1) === ' ' || firstThree.charAt(1) === '^' || firstThree.charAt(1) === '_' || firstThree.charAt(1) === '=') firstThree = firstThree.charAt(0);	// This will handle the case of 'm'
    		switch (firstThree) {
    			case 'mix':return {len: skipAlpha(str, i), token: 'Mix'};
    			case 'dor':return {len: skipAlpha(str, i), token: 'Dor'};
    			case 'phr':return {len: skipAlpha(str, i), token: 'Phr'};
    			case 'lyd':return {len: skipAlpha(str, i), token: 'Lyd'};
    			case 'loc':return {len: skipAlpha(str, i), token: 'Loc'};
    			case 'aeo':return {len: skipAlpha(str, i), token: 'm'};
    			case 'maj':return {len: skipAlpha(str, i), token: ''};
    			case 'ion':return {len: skipAlpha(str, i), token: ''};
    			case 'min':return {len: skipAlpha(str, i), token: 'm'};
    			case 'm':return {len: skipAlpha(str, i), token: 'm'};
    		}
    		return {len: 0};
    	};

    	this.getClef = function(str, bExplicitOnly) {
    		var strOrig = str;
    		var i = this.skipWhiteSpace(str);
    		if (finished(str, i))
    			return {len: 0};
    		// The word 'clef' is optional, but if it appears, a clef MUST appear
    		var needsClef = false;
    		var strClef = str.substring(i);
    		if (abc_common.startsWith(strClef, 'clef=')) {
    			needsClef = true;
    			strClef = strClef.substring(5);
    			i += 5;
    		}
    		if (strClef.length === 0 && needsClef)
    			return {len: i+5, warn: "No clef specified: " + strOrig};

    		var j = this.skipWhiteSpace(strClef);
    		if (finished(strClef, j))
    			return {len: 0};
    		if (j > 0) {
    			i += j;
    			strClef = strClef.substring(j);
    		}
    		var name = null;
    		if (abc_common.startsWith(strClef, 'treble'))
    			name = 'treble';
    		else if (abc_common.startsWith(strClef, 'bass3'))
    			name = 'bass3';
    		else if (abc_common.startsWith(strClef, 'bass'))
    			name = 'bass';
    		else if (abc_common.startsWith(strClef, 'tenor'))
    			name = 'tenor';
    		else if (abc_common.startsWith(strClef, 'alto2'))
    			name = 'alto2';
    		else if (abc_common.startsWith(strClef, 'alto1'))
    			name = 'alto1';
    		else if (abc_common.startsWith(strClef, 'alto'))
    			name = 'alto';
    		else if (!bExplicitOnly && (needsClef && abc_common.startsWith(strClef, 'none')))
    			name = 'none';
    		else if (abc_common.startsWith(strClef, 'perc'))
    			name = 'perc';
    		else if (!bExplicitOnly && (needsClef && abc_common.startsWith(strClef, 'C')))
    			name = 'tenor';
    		else if (!bExplicitOnly && (needsClef && abc_common.startsWith(strClef, 'F')))
    			name = 'bass';
    		else if (!bExplicitOnly && (needsClef && abc_common.startsWith(strClef, 'G')))
    			name = 'treble';
    		else
    			return {len: i+5, warn: "Unknown clef specified: " + strOrig};

    		strClef = strClef.substring(name.length);
    		j = this.isMatch(strClef, '+8');
    		if (j > 0)
    			name += "+8";
    		else {
    			j = this.isMatch(strClef, '-8');
    			if (j > 0)
    				name += "-8";
    		}
    		return {len: i+name.length, token: name, explicit: needsClef};
    	};

    	// This returns one of the legal bar lines
    	// This is called alot and there is no obvious tokenable items, so this is broken apart.
    	this.getBarLine = function(line, i) {
    		switch (line.charAt(i)) {
    			case ']':
    				++i;
    				switch (line.charAt(i)) {
    					case '|': return {len: 2, token: "bar_thick_thin"};
    					case '[':
    						++i;
    						if ((line.charAt(i) >= '1' && line.charAt(i) <= '9') || line.charAt(i) === '"')
    							return {len: 2, token: "bar_invisible"};
    						return {len: 1, warn: "Unknown bar symbol"};
    					default:
    						return {len: 1, token: "bar_invisible"};
    				}
    			case ':':
    				++i;
    				switch (line.charAt(i)) {
    					case ':': return {len: 2, token: "bar_dbl_repeat"};
    					case '|':	// :|
    						++i;
    						switch (line.charAt(i)) {
    							case ']':	// :|]
    								++i;
    								switch (line.charAt(i)) {
    									case '|':	// :|]|
    										++i;
    										if (line.charAt(i) === ':')  return {len: 5, token: "bar_dbl_repeat"};
    										return {len: 3, token: "bar_right_repeat"};
    									default:
    										return {len: 3, token: "bar_right_repeat"};
    								}
    							case '|':	// :||
    								++i;
    								if (line.charAt(i) === ':')  return {len: 4, token: "bar_dbl_repeat"};
    								return {len: 3, token: "bar_right_repeat"};
    							default:
    								return {len: 2, token: "bar_right_repeat"};
    						}
    					default:
    						return {len: 1, warn: "Unknown bar symbol"};
    				}
    			case '[':	// [
    				++i;
    				if (line.charAt(i) === '|') {	// [|
    					++i;
    					switch (line.charAt(i)) {
    						case ':': return {len: 3, token: "bar_left_repeat"};
    						case ']': return {len: 3, token: "bar_invisible"};
    						default: return {len: 2, token: "bar_thick_thin"};
    					}
    				} else {
    					if ((line.charAt(i) >= '1' && line.charAt(i) <= '9') || line.charAt(i) === '"')
    						return {len: 1, token: "bar_invisible"};
    					return {len: 0};
    				}
    			case '|':	// |
    				++i;
    				switch (line.charAt(i)) {
    					case ']': return {len: 2, token: "bar_thin_thick"};
    					case '|': // ||
    						++i;
    						if (line.charAt(i) === ':') return {len: 3, token: "bar_left_repeat"};
    						return {len: 2, token: "bar_thin_thin"};
    					case ':':	// |:
    						var colons = 0;
    						while (line.charAt(i+colons) === ':') colons++;
    						return { len: 1+colons, token: "bar_left_repeat"};
    					default: return {len: 1, token: "bar_thin"};
    				}
    		}
    		return {len: 0};
    	};

    	// this returns all the characters in the string that match one of the characters in the legalChars string
    	this.getTokenOf = function(str, legalChars) {
    		for (var i = 0; i < str.length; i++) {
    			if (legalChars.indexOf(str.charAt(i)) < 0)
    				return {len: i, token: str.substring(0, i)};
    		}
    		return {len: i, token: str};
    	};

    	this.getToken = function(str, start, end) {
    		// This returns the next set of chars that doesn't contain spaces
    		var i = start;
    		while (i < end && !this.isWhiteSpace(str.charAt(i)))
    			i++;
    		return str.substring(start, i);
    	};

    	// This just sees if the next token is the word passed in, with possible leading spaces
    	this.isMatch = function(str, match) {
    		var i = this.skipWhiteSpace(str);
    		if (finished(str, i))
    			return 0;
    		if (abc_common.startsWith(str.substring(i), match))
    			return i+match.length;
    		return 0;
    	};

    	this.getPitchFromTokens = function(tokens) {
    		var ret = { };
    		var pitches = {A: 5, B: 6, C: 0, D: 1, E: 2, F: 3, G: 4, a: 12, b: 13, c: 7, d: 8, e: 9, f: 10, g: 11};
    		ret.position = pitches[tokens[0].token];
    		if (ret.position === undefined)
    			return { warn: "Pitch expected. Found: " + tokens[0].token };
    		tokens.shift();
    		while (tokens.length) {
    			switch (tokens[0].token) {
    				case ',': ret.position -= 7; tokens.shift(); break;
    				case '\'': ret.position += 7; tokens.shift(); break;
    				default: return ret;
    			}
    		}
    		return ret;
    	};

    	this.getKeyAccidentals2 = function(tokens) {
    		var accs;
    		// find and strip off all accidentals in the token list
    		while (tokens.length > 0) {
    			var acc;
    			if (tokens[0].token === '^') {
    				acc = 'sharp';
    				tokens.shift();
    				if (tokens.length === 0) return {accs: accs, warn: 'Expected note name after ' + acc};
    				switch (tokens[0].token) {
    					case '^': acc = 'dblsharp'; tokens.shift(); break;
    					case '/': acc = 'quartersharp'; tokens.shift(); break;
    				}
    			} else if (tokens[0].token === '=') {
    				acc = 'natural';
    				tokens.shift();
    			} else if (tokens[0].token === '_') {
    				acc = 'flat';
    				tokens.shift();
    				if (tokens.length === 0) return {accs: accs, warn: 'Expected note name after ' + acc};
    				switch (tokens[0].token) {
    					case '_': acc = 'dblflat'; tokens.shift(); break;
    					case '/': acc = 'quarterflat'; tokens.shift(); break;
    				}
    			} else {
    				// Not an accidental, we'll assume that a later parse will recognize it.
    				return { accs: accs };
    			}
    			if (tokens.length === 0) return {accs: accs, warn: 'Expected note name after ' + acc};
    			switch (tokens[0].token.charAt(0))
    			{
    				case 'a':
    				case 'b':
    				case 'c':
    				case 'd':
    				case 'e':
    				case 'f':
    				case 'g':
    				case 'A':
    				case 'B':
    				case 'C':
    				case 'D':
    				case 'E':
    				case 'F':
    				case 'G':
    					if (accs === undefined)
    						accs = [];
    					accs.push({ acc: acc, note: tokens[0].token.charAt(0) });
    					if (tokens[0].token.length === 1)
    						tokens.shift();
    					else
    						tokens[0].token = tokens[0].token.substring(1);
    					break;
    				default:
    					return {accs: accs, warn: 'Expected note name after ' + acc + ' Found: ' + tokens[0].token };
    			}
    		}
    		return { accs: accs };
    	};

    	// This gets an accidental marking for the key signature. It has the accidental then the pitch letter.
    	this.getKeyAccidental = function(str) {
    		var accTranslation = {
    			'^': 'sharp',
    			'^^': 'dblsharp',
    			'=': 'natural',
    			'_': 'flat',
    			'__': 'dblflat',
    			'_/': 'quarterflat',
    			'^/': 'quartersharp'
    		};
    		var i = this.skipWhiteSpace(str);
    		if (finished(str, i))
    			return {len: 0};
    		var acc = null;
    		switch (str.charAt(i))
    		{
    			case '^':
    			case '_':
    			case '=':
    				acc = str.charAt(i);
    				break;
    			default:return {len: 0};
    		}
    		i++;
    		if (finished(str, i))
    			return {len: 1, warn: 'Expected note name after accidental'};
    		switch (str.charAt(i))
    		{
    			case 'a':
    			case 'b':
    			case 'c':
    			case 'd':
    			case 'e':
    			case 'f':
    			case 'g':
    			case 'A':
    			case 'B':
    			case 'C':
    			case 'D':
    			case 'E':
    			case 'F':
    			case 'G':
    				return {len: i+1, token: {acc: accTranslation[acc], note: str.charAt(i)}};
    			case '^':
    			case '_':
    			case '/':
    				acc += str.charAt(i);
    				i++;
    				if (finished(str, i))
    					return {len: 2, warn: 'Expected note name after accidental'};
    				switch (str.charAt(i))
    				{
    					case 'a':
    					case 'b':
    					case 'c':
    					case 'd':
    					case 'e':
    					case 'f':
    					case 'g':
    					case 'A':
    					case 'B':
    					case 'C':
    					case 'D':
    					case 'E':
    					case 'F':
    					case 'G':
    						return {len: i+1, token: {acc: accTranslation[acc], note: str.charAt(i)}};
    					default:
    						return {len: 2, warn: 'Expected note name after accidental'};
    				}
    				break;
    			default:
    				return {len: 1, warn: 'Expected note name after accidental'};
    		}
    	};

    	this.isWhiteSpace = function(ch) {
    		return ch === ' ' || ch === '\t' || ch === '\x12';
    	};

    	this.getMeat = function(line, start, end) {
    		// This removes any comments starting with '%' and trims the ends of the string so that there are no leading or trailing spaces.
    		// it returns just the start and end characters that contain the meat.
    		var comment = line.indexOf('%', start);
    		if (comment >= 0 && comment < end)
    			end = comment;
    		while (start < end && (line.charAt(start) === ' ' || line.charAt(start) === '\t' || line.charAt(start) === '\x12'))
    			start++;
    		while (start < end && (line.charAt(end-1) === ' ' || line.charAt(end-1) === '\t' || line.charAt(end-1) === '\x12'))
    			end--;
    		return {start: start, end: end};
    	};

    	var isLetter = function(ch) {
    		return (ch >= 'A' && ch <= 'Z') || (ch >= 'a' && ch <= 'z');
    	};

    	var isNumber = function(ch) {
    		return (ch >= '0' && ch <= '9');
    	};

    	this.tokenize = function(line, start, end, alphaUntilWhiteSpace) {
    		// this returns all the tokens inside the passed string. A token is a punctuation mark, a string of digits, a string of letters.
    		//  Quoted strings are one token.
    		//  If there is a minus sign next to a number, then it is included in the number.
    		// If there is a period immediately after a number, with a number immediately following, then a float is returned.
    		// The type of token is returned: quote, alpha, number, punct
    		// If alphaUntilWhiteSpace is true, then the behavior of the alpha token changes.

    		var ret = this.getMeat(line, start, end);
    		start = ret.start;
    		end = ret.end;
    		var tokens = [];
    		var i;
    		while (start < end) {
    			if (line.charAt(start) === '"') {
    				i = start+1;
    				while (i < end && line.charAt(i) !== '"') i++;
    				tokens.push({ type: 'quote', token: line.substring(start+1, i), start: start+1, end: i});
    				i++;
    			} else if (isLetter(line.charAt(start))) {
    				i = start+1;
    				if (alphaUntilWhiteSpace)
    					while (i < end && !this.isWhiteSpace(line.charAt(i))) i++;
    				else
    					while (i < end && isLetter(line.charAt(i))) i++;
    				tokens.push({ type: 'alpha', token: line.substring(start, i), continueId: isNumber(line.charAt(i)), start: start, end: i});
    				start = i + 1;
    			} else if (line.charAt(start) === '.' && isNumber(line.charAt(i+1))) {
    				i = start+1;
    				var int2 = null;
    				var float2 = null;
    				while (i < end && isNumber(line.charAt(i))) i++;

    				float2 = parseFloat(line.substring(start, i));
    				tokens.push({ type: 'number', token: line.substring(start, i), intt: int2, floatt: float2, continueId: isLetter(line.charAt(i)), start: start, end: i});
    				start = i + 1;
    			} else if (isNumber(line.charAt(start)) || (line.charAt(start) === '-' && isNumber(line.charAt(i+1)))) {
    				i = start+1;
    				var intt = null;
    				var floatt = null;
    				while (i < end && isNumber(line.charAt(i))) i++;
    				if (line.charAt(i) === '.' && isNumber(line.charAt(i+1))) {
    					i++;
    					while (i < end && isNumber(line.charAt(i))) i++;
    				} else
    					intt = parseInt(line.substring(start, i));

    				floatt = parseFloat(line.substring(start, i));
    				tokens.push({ type: 'number', token: line.substring(start, i), intt: intt, floatt: floatt, continueId: isLetter(line.charAt(i)), start: start, end: i});
    				start = i + 1;
    			} else if (line.charAt(start) === ' ' || line.charAt(start) === '\t') {
    				i = start+1;
    			} else {
    				tokens.push({ type: 'punct', token: line.charAt(start), start: start, end: start+1});
    				i = start+1;
    			}
    			start = i;
    		}
    		return tokens;
    	};

    	this.getVoiceToken = function(line, start, end) {
    		// This finds the next token. A token is delimited by a space or an equal sign. If it starts with a quote, then the portion between the quotes is returned.
    		var i = start;
    		while (i < end && this.isWhiteSpace(line.charAt(i)) || line.charAt(i) === '=')
    			i++;

    		if (line.charAt(i) === '"') {
    			var close = line.indexOf('"', i+1);
    			if (close === -1 || close >= end)
    				return {len: 1, err: "Missing close quote"};
    			return {len: close-start+1, token: this.translateString(line.substring(i+1, close))};
    		} else {
    			var ii = i;
    			while (ii < end && !this.isWhiteSpace(line.charAt(ii)) && line.charAt(ii) !== '=')
    				ii++;
    			return {len: ii-start+1, token: line.substring(i, ii)};
    		}
    	};

    	var charMap = {
    		"`a": 'à', "'a": "á", "^a": "â", "~a": "ã", "\"a": "ä", "oa": "å", "aa": "å", "=a": "ā", "ua": "ă", ";a": "ą",
    		"`e": 'è', "'e": "é", "^e": "ê", "\"e": "ë", "=e": "ē", "ue": "ĕ", ";e": "ę", ".e": "ė",
    		"`i": 'ì', "'i": "í", "^i": "î", "\"i": "ï", "=i": "ī", "ui": "ĭ", ";i": "į",
    		"`o": 'ò', "'o": "ó", "^o": "ô", "~o": "õ", "\"o": "ö", "=o": "ō", "uo": "ŏ", "/o": "ø",
    		"`u": 'ù', "'u": "ú", "^u": "û", "~u": "ũ", "\"u": "ü", "ou": "ů", "=u": "ū", "uu": "ŭ", ";u": "ų",
    		"`A": 'À', "'A": "Á", "^A": "Â", "~A": "Ã", "\"A": "Ä", "oA": "Å", "AA": "Å", "=A": "Ā", "uA": "Ă", ";A": "Ą",
    		"`E": 'È', "'E": "É", "^E": "Ê", "\"E": "Ë", "=E": "Ē", "uE": "Ĕ", ";E": "Ę", ".E": "Ė",
    		"`I": 'Ì', "'I": "Í", "^I": "Î", "~I": "Ĩ", "\"I": "Ï", "=I": "Ī", "uI": "Ĭ", ";I": "Į", ".I": "İ",
    		"`O": 'Ò', "'O": "Ó", "^O": "Ô", "~O": "Õ", "\"O": "Ö", "=O": "Ō", "uO": "Ŏ", "/O": "Ø",
    		"`U": 'Ù', "'U": "Ú", "^U": "Û", "~U": "Ũ", "\"U": "Ü", "oU": "Ů", "=U": "Ū", "uU": "Ŭ", ";U": "Ų",
    		"ae": "æ", "AE": "Æ", "oe": "œ", "OE": "Œ", "ss": "ß",
    		"'c": "ć", "^c": "ĉ", "uc": "č", "cc": "ç", ".c": "ċ", "cC": "Ç", "'C": "Ć", "^C": "Ĉ", "uC": "Č", ".C": "Ċ",
    		"~N": "Ñ", "~n": "ñ",
    		"=s": "š", "vs": "š",
    		"DH": "Ð", "dh": "ð",
    		"HO": "Ő", "Ho": "ő", "HU": "Ű", "Hu": "ű",
    		"'Y": "Ý", "'y": "ý", "^Y": "Ŷ", "^y": "ŷ", "\"Y": "Ÿ", "\"y": "ÿ",
    		"vS": "Š", "vZ": "Ž", "vz": 'ž'

    // More chars: Ĳ ĳ Ď ď Đ đ Ĝ ĝ Ğ ğ Ġ ġ Ģ ģ Ĥ ĥ Ħ ħ Ĵ ĵ Ķ ķ ĸ Ĺ ĺ Ļ ļ Ľ ľ Ŀ ŀ Ł ł Ń ń Ņ ņ Ň ň ŉ Ŋ ŋ Ŕ ŕ Ŗ ŗ Ř ř Ś ś Ŝ ŝ Ş ş Š Ţ ţ Ť ť Ŧ ŧ Ŵ ŵ Ź ź Ż ż Ž
    	};
    	var charMap1 = {
    		"#": "♯",
    		"b": "♭",
    		"=": "♮"
    	};
    	var charMap2 = {
    		"201": "♯",
    		"202": "♭",
    		"203": "♮",
    		"241": "¡",
    		"242": "¢", "252": "a", "262": "2", "272": "o", "302": "Â", "312": "Ê", "322": "Ò", "332": "Ú", "342": "â", "352": "ê", "362": "ò", "372": "ú",
    		"243": "£", "253": "«", "263": "3", "273": "»", "303": "Ã", "313": "Ë", "323": "Ó", "333": "Û", "343": "ã", "353": "ë", "363": "ó", "373": "û",
    		"244": "¤", "254": "¬", "264": "  ́", "274": "1⁄4", "304": "Ä", "314": "Ì", "324": "Ô", "334": "Ü", "344": "ä", "354": "ì", "364": "ô", "374": "ü",
    		"245": "¥", "255": "-", "265": "μ", "275": "1⁄2", "305": "Å", "315": "Í", "325": "Õ", "335": "Ý",  "345": "å", "355": "í", "365": "õ", "375": "ý",
    		"246": "¦", "256": "®", "266": "¶", "276": "3⁄4", "306": "Æ", "316": "Î", "326": "Ö", "336": "Þ", "346": "æ", "356": "î", "366": "ö", "376": "þ",
    		"247": "§", "257": " ̄", "267": "·", "277": "¿", "307": "Ç", "317": "Ï", "327": "×", "337": "ß", "347": "ç", "357": "ï", "367": "÷", "377": "ÿ",
    		"250": " ̈", "260": "°", "270": " ̧", "300": "À", "310": "È", "320": "Ð", "330": "Ø", "340": "à", "350": "è", "360": "ð", "370": "ø",
    		"251": "©", "261": "±", "271": "1", "301": "Á", "311": "É", "321": "Ñ", "331": "Ù", "341": "á", "351": "é", "361": "ñ", "371": "ù" };
    	this.translateString = function(str) {
    		var arr = str.split('\\');
    		if (arr.length === 1) return str;
    		var out = null;
    		abc_common.each(arr, function(s) {
    			if (out === null)
    				out = s;
    			else {
    				var c = charMap[s.substring(0, 2)];
    				if (c !== undefined)
    					out += c + s.substring(2);
    				else {
    					c = charMap2[s.substring(0, 3)];
    					if (c !== undefined)
    						out += c + s.substring(3);
    					else {
    						c = charMap1[s.substring(0, 1)];
    						if (c !== undefined)
    							out += c + s.substring(1);
    						else
    							out += "\\" + s;
    					}
    				}
    			}
    		});
    		return out;
    	};
    	this.getNumber = function(line, index) {
    		var num = 0;
    		while (index < line.length) {
    			switch (line.charAt(index)) {
    				case '0':num = num*10;index++;break;
    				case '1':num = num*10+1;index++;break;
    				case '2':num = num*10+2;index++;break;
    				case '3':num = num*10+3;index++;break;
    				case '4':num = num*10+4;index++;break;
    				case '5':num = num*10+5;index++;break;
    				case '6':num = num*10+6;index++;break;
    				case '7':num = num*10+7;index++;break;
    				case '8':num = num*10+8;index++;break;
    				case '9':num = num*10+9;index++;break;
    				default:
    					return {num: num, index: index};
    			}
    		}
    		return {num: num, index: index};
    	};

    	this.getFraction = function(line, index) {
    		var num = 1;
    		var den = 1;
    		if (line.charAt(index) !== '/') {
    			var ret = this.getNumber(line, index);
    			num = ret.num;
    			index = ret.index;
    		}
    		if (line.charAt(index) === '/') {
    			index++;
    			if (line.charAt(index) === '/') {
    				var div = 0.5;
    				while (line.charAt(index++) === '/')
    					div = div /2;
    				return {value: num * div, index: index-1};
    			} else {
    				var iSave = index;
    				var ret2 = this.getNumber(line, index);
    				if (ret2.num === 0 && iSave === index)	// If we didn't use any characters, it is an implied 2
    					ret2.num = 2;
    				if (ret2.num !== 0)
    					den = ret2.num;
    				index = ret2.index;
    			}
    		}

    		return {value: num/den, index: index};
    	};

    	this.theReverser = function(str) {
    		if (abc_common.endsWith(str, ", The"))
    			return "The " + str.substring(0, str.length-5);
    		if (abc_common.endsWith(str, ", A"))
    			return "A " + str.substring(0, str.length-3);
    		return str;
    	};

    	this.stripComment = function(str) {
    		var i = str.indexOf('%');
    		if (i >= 0)
    			return abc_common.strip(str.substring(0, i));
    		return abc_common.strip(str);
    	};

    	this.getInt = function(str) {
    		// This parses the beginning of the string for a number and returns { value: num, digits: num }
    		// If digits is 0, then the string didn't point to a number.
    		var x = parseInt(str);
    		if (isNaN(x))
    			return {digits: 0};
    		var s = "" + x;
    		var i = str.indexOf(s);	// This is to account for leading spaces
    		return {value: x, digits: i+s.length};
    	};

    	this.getFloat = function(str) {
    		// This parses the beginning of the string for a number and returns { value: num, digits: num }
    		// If digits is 0, then the string didn't point to a number.
    		var x = parseFloat(str);
    		if (isNaN(x))
    			return {digits: 0};
    		var s = "" + x;
    		var i = str.indexOf(s);	// This is to account for leading spaces
    		return {value: x, digits: i+s.length};
    	};

    	this.getMeasurement = function(tokens) {
    		if (tokens.length === 0) return { used: 0 };
    		var used = 1;
    		var num = '';
    		if (tokens[0].token === '-') {
    			tokens.shift();
    			num = '-';
    			used++;
    		}
    		else if (tokens[0].type !== 'number') return { used: 0 };
    		num += tokens.shift().token;
    		if (tokens.length === 0) return { used: 1, value: parseInt(num) };
    		var x = tokens.shift();
    		if (x.token === '.') {
    			used++;
    			if (tokens.length === 0) return { used: used, value: parseInt(num) };
    			if (tokens[0].type === 'number') {
    				x = tokens.shift();
    				num = num + '.' + x.token;
    				used++;
    				if (tokens.length === 0) return { used: used, value: parseFloat(num) };
    			}
    			x = tokens.shift();
    		}
    		switch (x.token) {
    			case 'pt': return { used: used+1, value: parseFloat(num) };
    			case 'cm': return { used: used+1, value: parseFloat(num)/2.54*72 };
    			case 'in': return { used: used+1, value: parseFloat(num)*72 };
    			default: tokens.unshift(x); return { used: used, value: parseFloat(num) };
    		}
    	};
    	var substInChord = function(str)
    	{
    		while ( str.indexOf("\\n") !== -1)
    		{
    			str = str.replace("\\n", "\n");
    		}
    		return str;
    	};
    	this.getBrackettedSubstring = function(line, i, maxErrorChars, _matchChar)
    	{
    		// This extracts the sub string by looking at the first character and searching for that
    		// character later in the line (or search for the optional _matchChar).
    		// For instance, if the first character is a quote it will look for
    		// the end quote. If the end of the line is reached, then only up to the default number
    		// of characters are returned, so that a missing end quote won't eat up the entire line.
    		// It returns the substring and the number of characters consumed.
    		// The number of characters consumed is normally two more than the size of the substring,
    		// but in the error case it might not be.
    		var matchChar = _matchChar || line.charAt(i);
    		var pos = i+1;
    		while ((pos < line.length) && (line.charAt(pos) !== matchChar))
    			++pos;
    		if (line.charAt(pos) === matchChar)
    			return [pos-i+1,substInChord(line.substring(i+1, pos)), true];
    		else	// we hit the end of line, so we'll just pick an arbitrary num of chars so the line doesn't disappear.
    		{
    			pos = i+maxErrorChars;
    			if (pos > line.length-1)
    				pos = line.length-1;
    			return [pos-i+1, substInChord(line.substring(i+1, pos)), false];
    		}
    	};
    };

    var abc_tokenizer = Tokenizer;

    //    wrap_lines.js: does line wrap on an already parsed tune.
    //    Copyright (C) 2018 Paul Rosen (paul at paulrosen dot net)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    function wrapLines(tune, lineBreaks) {
    	if (!lineBreaks || tune.lines.length === 0)
    		return;

    	// tune.lines contains nested arrays: there is an array of lines (that's the part this function rewrites),
    	// there is an array of staffs per line (for instance, piano will have 2, orchestra will have many)
    	// there is an array of voices per staff (for instance, 4-part harmony might have bass and tenor on a single staff)
    	// The measure numbers start at zero for each staff, but on the succeeding lines, the measure numbers are reset to the beginning of the line.
    	var newLines = [];
    	// keep track of our counters for each staff and voice
    	var startNewLine = [];
    	var currentLine = [];
    	var measureNumber = [];
    	var measureMarker = [];
    	var lastMeter = '';
    	var voiceStart = {};
    	var linesWithoutStaff = 0;

    	for (var i = 0; i < tune.lines.length; i++) {
    		var line = tune.lines[i];
    		if (line.staff) {
    			var staffs = line.staff;
    			for (var j = 0; j < staffs.length; j++) {
    				if (startNewLine[j] === undefined) {
    					startNewLine[j] = [];
    					currentLine[j] = [];
    					measureNumber[j] = [];
    					measureMarker[j] = [];
    				}
    				var staff = staffs[j];
    				var voices = staff.voices;
    				for (var k = 0; k < voices.length; k++) {
    					if (startNewLine[j][k] === undefined) {
    						startNewLine[j][k] = true;
    						currentLine[j][k] = 0;
    						measureNumber[j][k] = 0;
    						measureMarker[j][k] = 0;
    					}
    					if (linesWithoutStaff > 0) currentLine[j][k] += linesWithoutStaff;
    					var voice = voices[k];
    					for (var e = 0; e < voice.length; e++) {
    						if (startNewLine[j][k]) {
    							if (!newLines[currentLine[j][k]])
    								newLines[currentLine[j][k]] = { staff: [] };
    							if (!newLines[currentLine[j][k]].staff[j]) {
    								newLines[currentLine[j][k]].staff[j] = {voices: []};
    								for (var key in staff) {
    									if (staff.hasOwnProperty(key)) {
    										if (key === 'meter') {
    											if (newLines.length === 1 || lastMeter !== JSON.stringify(staff[key])) {
    												lastMeter = JSON.stringify(staff[key]);
    												newLines[currentLine[j][k]].staff[j][key] = staff[key];
    											}
    										} else if (key !== 'voices') {
    											newLines[currentLine[j][k]].staff[j][key] = staff[key];
    										}
    									}
    								}
    							}
    							if (measureMarker[j][k])
    								newLines[currentLine[j][k]].staff[j].barNumber = measureMarker[j][k];
    							startNewLine[j][k] = false;
    						}
    						var element = voice[e];
    						if (!newLines[currentLine[j][k]].staff[j].voices[k]) {
    							newLines[currentLine[j][k]].staff[j].voices[k] = [];
    							for (var startItem in voiceStart) {
    								if (voiceStart.hasOwnProperty(startItem)) {
    									newLines[currentLine[j][k]].staff[j].voices[k].push(voiceStart[startItem]);
    								}
    							}
    						}
    						newLines[currentLine[j][k]].staff[j].voices[k].push(element);
    						if (element.el_type === 'stem') {
    							// This is a nice trick to just pay attention to the last setting of each type.
    							voiceStart[element.el_type] = element;
    						}

    						if (element.el_type === 'bar') {
    							measureNumber[j][k]++;
    							if (lineBreaks[measureNumber[j][k]]) {
    								startNewLine[j][k] = true;
    								currentLine[j][k]++;
    								measureMarker[j][k] = element.barNumber;
    								delete element.barNumber;
    							}
    						}
    					}

    				}
    			}
    			linesWithoutStaff = 0;
    		} else {
    			newLines.push(line);
    			linesWithoutStaff++;
    		}
    	}
    	tune.lines = newLines;
    }

    function freeFormLineBreaks(widths, lineBreakPoint) {
    	var lineBreaks = [];
    	var totals = [];
    	var totalThisLine = 0;
    	// run through each measure and see if the accumulation is less than the ideal.
    	// if it passes the ideal, then see whether the last or this one is closer to the ideal.
    	for (var i = 0; i < widths.length; i++) {
    		var width = widths[i];
    		var attemptedWidth = totalThisLine + width;
    		if (attemptedWidth < lineBreakPoint)
    			totalThisLine = attemptedWidth;
    		else {
    			// This just passed the ideal, so see whether the previous or the current number of measures is closer.
    			var oldDistance = lineBreakPoint - totalThisLine;
    			var newDistance = attemptedWidth - lineBreakPoint;
    			if (oldDistance < newDistance && totalThisLine > 0) {
    				lineBreaks.push(i - 1);
    				totals.push(Math.round(totalThisLine - width));
    				totalThisLine = width;
    			} else {
    				if (i < widths.length-1) {
    					lineBreaks.push(i);
    					totals.push(Math.round(totalThisLine));
    					totalThisLine = 0;
    				}
    			}
    		}
    	}
    	totals.push(Math.round(totalThisLine));
    	return { lineBreaks: lineBreaks, totals: totals };
    }

    function clone(arr) {
    	var newArr = [];
    	for (var i = 0; i < arr.length; i++)
    		newArr.push(arr[i]);
    	return newArr;
    }

    function oneTry(measureWidths, idealWidths, accumulator, lineAccumulator, lineWidths, lastVariance, highestVariance, currLine, lineBreaks, startIndex, otherTries) {
    	for (var i = startIndex; i < measureWidths.length; i++) {
    		var measureWidth = measureWidths[i];
    		accumulator += measureWidth;
    		lineAccumulator += measureWidth;
    		var thisVariance = Math.abs(accumulator - idealWidths[currLine]);
    		var varianceIsClose = Math.abs(thisVariance - lastVariance) < idealWidths[0] / 10; // see if the difference is less than 10%, if so, run the test both ways.
    		if (varianceIsClose) {
    			if (thisVariance < lastVariance) {
    				// Also attempt one less measure on the current line - sometimes that works out better.
    				var newWidths = clone(lineWidths);
    				var newBreaks = clone(lineBreaks);
    				newBreaks.push(i-1);
    				newWidths.push(lineAccumulator - measureWidth);
    				otherTries.push({
    					accumulator: accumulator,
    					lineAccumulator: measureWidth,
    					lineWidths: newWidths,
    					lastVariance: Math.abs(accumulator - idealWidths[currLine+1]),
    					highestVariance: Math.max(highestVariance, lastVariance),
    					currLine: currLine+1,
    					lineBreaks: newBreaks,
    					startIndex: i+1});
    			} else if (thisVariance > lastVariance && i < measureWidths.length-1) {
    				// Also attempt one extra measure on this line.
    				newWidths = clone(lineWidths);
    				newBreaks = clone(lineBreaks);
    				// newBreaks[newBreaks.length-1] = i;
    				// newWidths[newWidths.length-1] = lineAccumulator;
    				otherTries.push({
    					accumulator: accumulator,
    					lineAccumulator: lineAccumulator,
    					lineWidths: newWidths,
    					lastVariance: thisVariance,
    					highestVariance: Math.max(highestVariance, thisVariance),
    					currLine: currLine,
    					lineBreaks: newBreaks,
    					startIndex: i+1});
    			}
    		}
    		if (thisVariance > lastVariance) {
    			lineBreaks.push(i - 1);
    			currLine++;
    			highestVariance = Math.max(highestVariance, lastVariance);
    			lastVariance = Math.abs(accumulator - idealWidths[currLine]);
    			lineWidths.push(lineAccumulator - measureWidth);
    			lineAccumulator = measureWidth;
    		} else {
    			lastVariance = thisVariance;
    		}
    	}
    	lineWidths.push(lineAccumulator);
    }

    function optimizeLineWidths(widths, lineBreakPoint, lineBreaks, explanation) {
    	//	figure out how many lines - That's one more than was tried before.
    	var numLines = Math.ceil(widths.total / lineBreakPoint) + 1;

    	//	get the ideal width for a line (cumulative width / num lines) - approx the same as lineBreakPoint except for rounding
    	var idealWidth = Math.floor(widths.total / numLines);

    	//	get each ideal line width (1*ideal, 2*ideal, 3*ideal, etc)
    	var idealWidths = [];
    	for (var i = 0; i < numLines; i++)
    		idealWidths.push(idealWidth*(i+1));

    	//	from first measure, step through accum. Widths until the abs of the ideal is greater than the last one.
    	// This can sometimes look funny in edge cases, so when the length is within 10%, try one more or one less to see which is better.
    	// This is better than trying all the possibilities because that would get to be a huge number for even a medium size piece.
    	// This method seems to never generate more than about 16 tries and it is usually 4 or less.
    	var otherTries = [];
    	otherTries.push({
    		accumulator: 0,
    		lineAccumulator: 0,
    		lineWidths: [],
    		lastVariance: 999999,
    		highestVariance: 0,
    		currLine: 0,
    		lineBreaks: [], // These are the zero-based last measure on each line
    		startIndex: 0});
    	var index = 0;
    	while (index < otherTries.length) {
    		oneTry(widths.measureWidths,
    			idealWidths,
    			otherTries[index].accumulator,
    			otherTries[index].lineAccumulator,
    			otherTries[index].lineWidths,
    			otherTries[index].lastVariance,
    			otherTries[index].highestVariance,
    			otherTries[index].currLine,
    			otherTries[index].lineBreaks,
    			otherTries[index].startIndex,
    			otherTries);
    		index++;
    	}
    	for (i = 0; i < otherTries.length; i++) {
    		var otherTry = otherTries[i];
    		otherTry.variances = [];
    		otherTry.aveVariance = 0;
    		for (var j = 0; j < otherTry.lineWidths.length; j++) {
    			var lineWidth = otherTry.lineWidths[j];
    			otherTry.variances.push(lineWidth - idealWidths[0]);
    			otherTry.aveVariance += Math.abs(lineWidth - idealWidths[0]);
    		}
    		otherTry.aveVariance =  otherTry.aveVariance / otherTry.lineWidths.length;
    		explanation.attempts.push({ type: "optimizeLineWidths", lineBreaks: otherTry.lineBreaks, variances: otherTry.variances, aveVariance: otherTry.aveVariance, widths: widths.measureWidths });
    	}
    	var smallest = 9999999;
    	var smallestIndex = -1;
    	for (i = 0; i < otherTries.length; i++) {
    		otherTry = otherTries[i];
    		if (otherTry.aveVariance < smallest) {
    			smallest = otherTry.aveVariance;
    			smallestIndex = i;
    		}
    	}
    	return { failed: false, lineBreaks: otherTries[smallestIndex].lineBreaks, variance: otherTries[smallestIndex].highestVariance };
    }
    // 	// Instead of having to try all the different combinations to find the best, we start with an important piece of knowledge about the lineBreaks we are given:
    // 	// If there is a line too short, it is the last one.
    // 	// So, let's just do a couple of tweaks to see how it works to add one or two measures to the last line.
    // 	var avg = widths.total / (lineBreaks.length + 1);
    // 	var variance = getVariance(widths, lineBreaks);
    // 	var variancePct = variance/lineBreakPoint*100;
    //
    // 	if (lineBreaks.length === 0)
    // 		return { failed: true, reason: "Only one line." };
    //
    // 	var lastLineStart = lineBreaks[lineBreaks.length-1]+1;
    // 	var lastLineVariance = lineVariance(widths.measureWidths, lastLineStart, widths.measureWidths.length, avg);
    // 	if (variance > lastLineVariance)
    // 		return { failed: true, reason: "Last line is not too short." };
    //
    // 	// Let's get a list of all combinations that have a possibility of working. That is, all combinations where no line has a variance larger than "variance".
    // 	var lastLines = lastLinePossibilities(widths.measureWidths, lastLineStart, avg - variance, avg + variance);
    // 	var attempts = getAttempts(widths.measureWidths, 0, lineBreaks.length, avg - variance, avg + variance, lastLines);
    // 	//console.log(attempts, avg - variance, avg + variance);
    //
    // 	var failed = true;
    // 	for (var i = 0; i < attempts.length; i++) {
    // 		var newVariance = getVariance(widths, attempts[i]);
    // 		if (newVariance < variance) {
    // 			explanation.attempts.push({
    // 				type: "Optimize try", lineBreaks: attempts[i],
    // 				variance: Math.round(variance), newVariance: Math.round(newVariance),
    // 				totalAttempts: attempts.length
    // 			});
    // 			variance = newVariance;
    // 			lineBreaks = attempts[i];
    // 			failed = false;
    // 		}
    // 	}
    // 	if (failed) {
    // 		explanation.attempts.push({ type: "Optimize try", lineBreaks: lineBreaks, variance: variance, reason: "None of the " + attempts.length + " attempts were better." });
    // 		// TODO-PER: This shouldn't be necessary, but just try to move one measure down and see if it helps.
    // 		if (lineBreaks.length > 0) {
    // 			var attempt = [].concat(lineBreaks);
    // 			attempt[attempt.length - 1]--;
    // 			newVariance = getVariance(widths, attempt);
    // 			explanation.attempts.push({
    // 				type: "Optimize last try", lineBreaks: attempts[i],
    // 				variance: Math.round(variance), newVariance: Math.round(newVariance),
    // 				totalAttempts: attempts.length
    // 			});
    // 			if (newVariance < variance) {
    // 				variance = newVariance;
    // 				lineBreaks = attempt;
    // 				failed = false;
    // 			}
    // 		}
    // 	}
    // 	// Let's squeeze the line successively until it spills onto an extra line, then take the option with the lowest variance
    // 	// var targetNumLines = lineBreaks.length;
    // 	// var newNumLines = targetNumLines;
    // 	// var TRY_INCREMENT = 1;
    // 	// var tryBreakPoint = lineBreakPoint - TRY_INCREMENT;
    // 	// var failed = true;
    // 	// while (targetNumLines === newNumLines && tryBreakPoint > 50) {
    // 	// 	var ff = freeFormLineBreaks(widths.measureWidths, tryBreakPoint);
    // 	// 	newNumLines = ff.lineBreaks.length;
    // 	// 	if (newNumLines === targetNumLines) {
    // 	// 		var newVariance = getVariance(widths, ff.lineBreaks);
    // 	// 		var newVariancePct = newVariance/tryBreakPoint*100;
    // 	// 		explanation.attempts.push({type: "Optimize try", tryBreakPoint: Math.round(tryBreakPoint), lineBreaks: ff.lineBreaks, totals: ff.totals,
    // 	// 			variance: Math.round(variance), newVariance: Math.round(newVariance), variancePct: Math.round(variancePct), newVariancePct: Math.round(newVariancePct)
    // 	// 		});
    // 	// 		if (newVariancePct < variancePct) {
    // 	// 			variancePct = newVariancePct;
    // 	// 			lineBreaks = ff.lineBreaks;
    // 	// 			failed = false;
    // 	// 		}
    // 	// 	} else {
    // 	// 		explanation.attempts.push({type: "Optimize try", explanation: "Exceeded number of lines." , tryBreakPoint: Math.round(tryBreakPoint), lineBreaks: ff.lineBreaks, totals: ff.totals, variance: variance, avg: avg, variancePct: variancePct});
    // 	// 	}
    // 	// 	tryBreakPoint -= TRY_INCREMENT;
    // 	// }
    //
    // 	return { failed: failed, lineBreaks: lineBreaks, variance: variance };
    // }

    // function fixedNumLinesBreaks(widths, numLines, allowOver, allowableVariance) {
    // 	var idealLineBreak = widths.total / numLines;
    // 	// If all the measures had the same amount of stuff, then the ave would be correct.
    // 	// We will test all the combinations from one less to one more than the average.
    // 	var averageMeasuresPerLine = Math.round(widths.measureWidths.length / numLines);
    // 	var minMeasuresPerLine = Math.max(averageMeasuresPerLine - 1, 1);
    // 	var maxMeasuresPerLine = averageMeasuresPerLine + 1;
    // 	var tries = createLineTestArray(numLines, widths.measureWidths.length, maxMeasuresPerLine, minMeasuresPerLine);
    // 	console.log("fixedNumLinesBreaks tests ("+minMeasuresPerLine+'-'+maxMeasuresPerLine+")", numLines, tries.length)
    //
    // 	// For each possible number of measures per line, see which has the closest spacing to the ideal.
    // 	var bestCase = -1;
    // 	var bestCaseVariance = 1000000;
    // 	for (var i = 0 ; i < tries.length; i++) {
    // 		var attempt = tries[i];
    // 		var variance = getVariance(attempt, idealLineBreak, widths.measureWidths, allowOver ? allowableVariance : 0);
    // 		if (variance !== null) {
    // 			if (variance < bestCaseVariance) {
    // 				bestCaseVariance = variance;
    // 				bestCase = i;
    // 			}
    // 		}
    // 	}
    // 	var failed = true;
    // 	// For debugging, recreate the line widths
    // 	var totals = [];
    // 	if (bestCase >= 0) {
    // 		failed = false;
    // 		var index = 0;
    // 		for (i = 0; i < tries[bestCase].length; i++) {
    // 			var total = 0;
    // 			for (var j = 0; j < tries[bestCase][i]; j++) {
    // 				total += widths.measureWidths[index++];
    // 			}
    // 			totals.push(Math.round(total));
    // 		}
    // 		// We now have an array that contains the number of measures per line, but we want to return the absolute measure number to break on.
    // 		if (tries[bestCase].length > 0) {
    // 			tries[bestCase][0]--; // The results should contain the last measure number on the line, zero-based.
    // 			for (i = 1; i < tries[bestCase].length; i++)
    // 				tries[bestCase][i] += tries[bestCase][i - 1]; // This sets the zero-based measure number
    // 			// The last line is implied and we don't need to return it
    // 			tries[bestCase].pop();
    // 		}
    // 	}
    // 	return { failed: failed, lineBreaks: tries[bestCase], bestCaseVariance: Math.round(bestCaseVariance), totals: totals };
    // }

    function fixedMeasureLineBreaks(widths, lineBreakPoint, preferredMeasuresPerLine) {
    	var lineBreaks = [];
    	var totals = [];
    	var thisWidth = 0;
    	var failed = false;
    	for (var i = 0; i < widths.length; i++) {
    		thisWidth += widths[i];
    		if (thisWidth > lineBreakPoint) {
    			failed = true;
    		}
    		if (i % preferredMeasuresPerLine === (preferredMeasuresPerLine-1)) {
    			if (i !== widths.length-1) // Don't bother putting a line break for the last line - it's already a break.
    				lineBreaks.push(i);
    			totals.push(Math.round(thisWidth));
    			thisWidth = 0;
    		}
    	}
    	return { failed: failed, totals: totals, lineBreaks: lineBreaks };
    }

    function getRevisedTune(lineBreaks, staffWidth, abcString, params, Parse) {
    	var abcParser = new Parse();
    	var revisedParams = {
    		lineBreaks: lineBreaks,
    		staffwidth: staffWidth
    	};
    	for (var key in params) {
    		if (params.hasOwnProperty(key) && key !== 'wrap' && key !== 'staffwidth') {
    			revisedParams[key] = params[key];
    		}
    	}

    	abcParser.parse(abcString, revisedParams);
    	return { tune: abcParser.getTune(), revisedParams: revisedParams };
    }

    function calcLineWraps(tune, widths, abcString, params, Parse, engraver_controller) {
    	// For calculating how much can go on the line, it depends on the width of the line. It is a convenience to just divide it here
    	// by the minimum spacing instead of multiplying the min spacing later.
    	// The scaling works differently: this is done by changing the scaling of the outer SVG, so the scaling needs to be compensated
    	// for here, because the actual width will be different from the calculated numbers.

    	// If the desired width is less than the margin, just punt and return the original tune
    	if (params.staffwidth < widths.left) {
    		return {
    			explanation: "Staffwidth is narrower than the margin",
    			tune: tune,
    			revisedParams: params
    		};
    	}
    	var scale = params.scale ? Math.max(params.scale, 0.1) : 1;
    	var minSpacing = params.wrap.minSpacing ? Math.max(parseFloat(params.wrap.minSpacing), 1) : 1;
    	var minSpacingLimit = params.wrap.minSpacingLimit ? Math.max(parseFloat(params.wrap.minSpacingLimit), 1) : minSpacing - 0.1;
    	var maxSpacing = params.wrap.maxSpacing ? Math.max(parseFloat(params.wrap.maxSpacing), 1) : undefined;
    	if (params.wrap.lastLineLimit && !maxSpacing)
    		maxSpacing = Math.max(parseFloat(params.wrap.lastLineLimit), 1);
    	var targetHeight = params.wrap.targetHeight ? Math.max(parseInt(params.wrap.targetHeight, 10), 100) : undefined;
    	var preferredMeasuresPerLine = params.wrap.preferredMeasuresPerLine ? Math.max(parseInt(params.wrap.preferredMeasuresPerLine, 10), 1) : undefined;

    	var lineBreakPoint = (params.staffwidth - widths.left) / minSpacing / scale;
    	var minLineSize = (params.staffwidth - widths.left) / maxSpacing / scale;
    	var allowableVariance = (params.staffwidth - widths.left) / minSpacingLimit / scale;
    	var explanation = { widths: widths, lineBreakPoint: lineBreakPoint, minLineSize: minLineSize, attempts: [], staffWidth: params.staffwidth, minWidth: Math.round(allowableVariance) };

    	// If there is a preferred number of measures per line, test that first. If none of the lines is too long, then we're finished.
    	var lineBreaks = null;
    	if (preferredMeasuresPerLine) {
    		var f = fixedMeasureLineBreaks(widths.measureWidths, lineBreakPoint, preferredMeasuresPerLine);
    		explanation.attempts.push({ type: "Fixed Measures Per Line", preferredMeasuresPerLine: preferredMeasuresPerLine, lineBreaks: f.lineBreaks, failed: f.failed, totals: f.totals });
    		if (!f.failed)
    			lineBreaks = f.lineBreaks;
    	}

    	// If we don't have lineBreaks yet, use the free form method of line breaks.
    	// This will be called either if Preferred Measures is not used, or if the music is just weird - like a single measure is way too crowded.
    	if (!lineBreaks) {
    		var ff = freeFormLineBreaks(widths.measureWidths, lineBreakPoint);
    		explanation.attempts.push({ type: "Free Form", lineBreaks: ff.lineBreaks, totals: ff.totals });
    		lineBreaks = ff.lineBreaks;

    		// We now have an acceptable number of lines, but the measures may not be optimally distributed. See if there is a better distribution.
    		ff = optimizeLineWidths(widths, lineBreakPoint, lineBreaks, explanation);
    		explanation.attempts.push({ type: "Optimize", failed: ff.failed, reason: ff.reason, lineBreaks: ff.lineBreaks, totals: ff.totals });
    		if (!ff.failed)
    			lineBreaks = ff.lineBreaks;
    	}

    	// If the vertical space exceeds targetHeight, remove a line and try again. If that is too crowded, then don't use it.
    	var staffWidth = params.staffwidth;
    	var ret = getRevisedTune(lineBreaks, staffWidth, abcString, params, Parse);
    	var newWidths = engraver_controller.getMeasureWidths(ret.tune);
    	var gotTune = true; // If we adjust the num lines, set this to false
    	explanation.attempts.push({type: "heightCheck", height: newWidths.height });

    	// 	if all of the lines are too sparse, make the width narrower.
    	// TODO-PER: implement this case.

    	// If one line and the spacing is > maxSpacing, make the width narrower.
    	if (lineBreaks.length === 0 && minLineSize > widths.total) {
    		staffWidth = (widths.total * maxSpacing * scale) + widths.left;
    		explanation.attempts.push({type: "too sparse", newWidth: Math.round(staffWidth)});
    		gotTune = false;
    	}

    	// if (ret.lineBreaks.length === 0) {
    	// 	// Everything fits on one line, so see if there is TOO much space and the staff width needs to be shortened.
    	// 	if (minLineSize > 0 && ret.totalThisLine > 0 && ret.totalThisLine < minLineSize)
    	// 		staffWidth = staffWidth / (minLineSize / ret.totalThisLine);
    	// } else if (ret.totalThisLine < minLineSize) {
    	// 	// the last line is too short, so attempt to redistribute by changing the min.
    	// 	// We will try more and less space alternatively. The space can't be less than 1.0, and we'll try in 0.1 increments.
    	// 	var minTrys = [];
    	// 	if (minSpacing > 1.1)
    	// 		minTrys.push(minSpacing - 0.1);
    	// 	minTrys.push(minSpacing + 0.1);
    	// 	if (minSpacing > 1.2)
    	// 		minTrys.push(minSpacing - 0.2);
    	// 	minTrys.push(minSpacing + 0.2);
    	// 	if (minSpacing > 1.3)
    	// 		minTrys.push(minSpacing - 0.3);
    	// 	minTrys.push(minSpacing + 0.3);
    	// 	for (var i = 0; i < minTrys.length && ret.totalThisLine < minLineSize; i++) {
    	// 		lineBreakPoint = (params.staffwidth - widths.left) / minTrys[i] / scale;
    	// 		ret = calcLineBreaks(widths.measureWidths, lineBreakPoint);
    	// 	}
    	// }

    	if (!gotTune)
    		ret = getRevisedTune(lineBreaks, staffWidth, abcString, params, Parse);
    	ret.explanation = explanation;
    	return ret;
    }

    var wrap_lines = { wrapLines: wrapLines, calcLineWraps: calcLineWraps };

    //    abc_tune.js: a computer usable internal structure representing one tune.
    //    Copyright (C) 2010-2018 Paul Rosen (paul at paulrosen dot net)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.





    /**
     * This is the data for a single ABC tune. It is created and populated by the window.ABCJS.parse.Parse class.
     * Also known as the ABCJS Abstract Syntax Tree
     * @alternateClassName ABCJS.Tune
     */
    var Tune = function() {
    	// The structure consists of a hash with the following two items:
    	// metaText: a hash of {key, value}, where key is one of: title, author, rhythm, source, transcription, unalignedWords, etc...
    	// tempo: { noteLength: number (e.g. .125), bpm: number }
    	// lines: an array of elements, or one of the following:
    	//
    	// STAFF: array of elements
    	// SUBTITLE: string
    	//
    	// TODO: actually, the start and end char should modify each part of the note type
    	// The elements all have a type field and a start and end char
    	// field. The rest of the fields depend on the type and are listed below:
    	// REST: duration=1,2,4,8; chord: string
    	// NOTE: accidental=none,dbl_flat,flat,natural,sharp,dbl_sharp
    	//		pitch: "C" is 0. The numbers refer to the pitch letter.
    	//		duration: .5 (sixteenth), .75 (dotted sixteenth), 1 (eighth), 1.5 (dotted eighth)
    	//			2 (quarter), 3 (dotted quarter), 4 (half), 6 (dotted half) 8 (whole)
    	//		chord: { name:chord, position: one of 'default', 'above', 'below' }
    	//		end_beam = true or undefined if this is the last note in a beam.
    	//		lyric: array of { syllable: xxx, divider: one of " -_" }
    	//		startTie = true|undefined
    	//		endTie = true|undefined
    	//		startTriplet = num <- that is the number to print
    	//		endTriplet = true|undefined (the last note of the triplet)
    	// TODO: actually, decoration should be an array.
    	//		decoration: upbow, downbow, accent
    	// BAR: type=bar_thin, bar_thin_thick, bar_thin_thin, bar_thick_thin, bar_right_repeat, bar_left_repeat, bar_double_repeat
    	//	number: 1 or 2: if it is the start of a first or second ending
    	// CLEF: type=treble,bass
    	// KEY-SIG:
    	//		accidentals[]: { acc:sharp|dblsharp|natural|flat|dblflat,  note:a|b|c|d|e|f|g }
    	// METER: type: common_time,cut_time,specified
    	//		if specified, { num: 99, den: 99 }

    	this.getBeatLength = function() {
    		for (var i = 0; i < this.lines.length; i++) {
    			if (this.lines[i].staff) {
    				for (var j = 0; j < this.lines[i].staff.length; j++) {
    					if (this.lines[i].staff[j].meter) {
    						var meter = this.lines[i].staff[j].meter;
    						if (meter.type === "specified") {
    							if (meter.value.length > 0) {
    								var num = parseInt(meter.value[0].num, 10);
    								var den = parseInt(meter.value[0].den, 10);
    								if (num === 3 && den === 8) return 3/8;
    								if (num === 6 && den === 8) return 3/8;
    								if (num === 6 && den === 4) return 3/4;
    								if (num === 9 && den === 8) return 3/8;
    								if (num === 12 && den === 8) return 3/8;
    								return 1/den;
    							}
    							else
    								return 1/4; // No meter was specified, so use this default
    						} else if (meter.type === 'cut_time') {
    							return 1/2;
    						} else {
    							return 1/4; // TODO-PER: this works for common time, but not for the ancient meters.
    						}
    					}
    				}
    			}
    		}
    		return 1/4; // No meter was specified, so use this default
    	};

    	this.getPickupLength = function() {
    		var pickupLength = 0;
    		var barLength = this.getBarLength();
    		for (var i = 0; i < this.lines.length; i++) {
    			if (this.lines[i].staff) {
    				for (var j = 0; j < this.lines[i].staff.length; j++) {
    					for (var v = 0; v < this.lines[i].staff[j].voices.length; v++) {
    						var voice = this.lines[i].staff[j].voices[v];
    						var tripletMultiplier = 1;
    						for (var el = 0; el < voice.length; el++) {
    							var isSpacer = voice[el].rest && voice[el].rest.type === "spacer";
    							if (voice[el].startTriplet)
    								tripletMultiplier = voice[el].tripletMultiplier;
    							if (voice[el].duration && !isSpacer)
    								pickupLength += voice[el].duration * tripletMultiplier;
    							if (voice[el].endTriplet)
    								tripletMultiplier = 1;
    							if (pickupLength >= barLength)
    								pickupLength -= barLength;
    							if (voice[el].el_type === 'bar')
    								return pickupLength;
    						}
    					}
    				}
    			}
    		}
    		return pickupLength;
    	};

    	this.getBarLength = function() {
    		var meter = this.getMeterFraction();
    		return meter.num / meter.den;
    	};

    	this.millisecondsPerMeasure = function(bpmOverride) {
    		var bpm;
    		if (bpmOverride) {
    			bpm = bpmOverride;
    		} else {
    			var tempo = this.metaText ? this.metaText.tempo : null;
    			bpm = this.getBpm(tempo);
    		}
    		if (bpm <= 0)
    			bpm = 1; // I don't think this can happen, but we don't want a possibility of dividing by zero.

    		var beatsPerMeasure = this.getBeatsPerMeasure();

    		var minutesPerMeasure = beatsPerMeasure / bpm;
    		return minutesPerMeasure * 60000;
    	};

    	this.getBeatsPerMeasure = function() {
    		var beatsPerMeasure;
    		var meter = this.getMeterFraction();
    		if (meter.den === 8) {
    			beatsPerMeasure = meter.num / 3;
    		} else {
    			beatsPerMeasure = meter.num;
    		}
    		if (beatsPerMeasure <= 0) // This probably won't happen in any normal case - but it is possible that the meter could be set to something nonsensical.
    			beatsPerMeasure = 1;
    		return beatsPerMeasure;
    	};

    	this.reset = function () {
    		this.version = "1.0.1";
    		this.media = "screen";
    		this.metaText = {};
    		this.formatting = {};
    		this.lines = [];
    		this.staffNum = 0;
    		this.voiceNum = 0;
    		this.lineNum = 0;
    	};

    	this.resolveOverlays = function() {
    		var madeChanges = false;
    		for (var i = 0; i < this.lines.length; i++) {
    			var line = this.lines[i];
    			if (line.staff) {
    				for (var j = 0; j < line.staff.length; j++) {
    					var staff = line.staff[j];
    					var overlayVoice = [];
    					for (var k = 0; k < staff.voices.length; k++) {
    						var voice = staff.voices[k];
    						overlayVoice.push({ hasOverlay: false, voice: [], snip: []});
    						var durationThisBar = 0;
    						var inOverlay = false;
    						var snipStart = -1;
    						for (var kk = 0; kk < voice.length; kk++) {
    							var event = voice[kk];
    							if (event.el_type === "overlay" && !inOverlay) {
    								madeChanges = true;
    								inOverlay = true;
    								snipStart = kk;
    								overlayVoice[k].hasOverlay = true;
    							} else if (event.el_type === "bar") {
    								if (inOverlay) {
    									// delete the overlay events from this array without messing up this loop.
    									inOverlay = false;
    									overlayVoice[k].snip.push({ start: snipStart, len: kk - snipStart});
    									overlayVoice[k].voice.push(event); // Also end the overlay with the barline.
    								} else {
    									// This keeps the voices lined up: if the overlay isn't in the first measure then we need a bunch of invisible rests.
    									if (durationThisBar > 0)
    										overlayVoice[k].voice.push({ el_type: "note", duration: durationThisBar, rest: {type: "invisible"}, startChar: event.startChar, endChar: event.endChar });
    									overlayVoice[k].voice.push(event);
    								}
    								durationThisBar = 0;
    							} else if (event.el_type === "note") {
    								if (inOverlay) {
    									overlayVoice[k].voice.push(event);
    								} else {
    									durationThisBar += event.duration;
    								}
    							} else if (event.el_type === "scale" || event.el_type === "stem" || event.el_type === "overlay" || event.el_type === "style" || event.el_type === "transpose") {
    								// These types of events are duplicated on the overlay layer.
    								overlayVoice[k].voice.push(event);
    							}
    						}
    						if (overlayVoice[k].hasOverlay && overlayVoice[k].snip.length === 0) {
    							// there was no closing bar, so we didn't set the snip amount.
    							overlayVoice[k].snip.push({ start: snipStart, len: voice.length - snipStart});
    						}
    					}
    					for (k = 0; k < overlayVoice.length; k++) {
    						var ov = overlayVoice[k];
    						if (ov.hasOverlay) {
    							staff.voices.push(ov.voice);
    							for (var kkk = ov.snip.length-1; kkk >= 0; kkk--) {
    								var snip = ov.snip[kkk];
    								staff.voices[k].splice(snip.start, snip.len);
    							}
    							// remove ending marks from the overlay voice so they are not repeated
    							for (kkk = 0; kkk < staff.voices[staff.voices.length-1].length; kkk++) {
    								staff.voices[staff.voices.length-1][kkk] = abc_common.clone(staff.voices[staff.voices.length-1][kkk]);
    								var el = staff.voices[staff.voices.length-1][kkk];
    								if (el.el_type === 'bar' && el.startEnding) {
    									delete el.startEnding;
    								}
    								if (el.el_type === 'bar' && el.endEnding)
    									delete el.endEnding;
    							}
    						}
    					}
    				}
    			}
    		}
    		return madeChanges;
    	};

    	function fixTitles(lines) {
    		// We might have name and subname defined. We now know what line everything is on, so we can determine which to use.
    		var firstMusicLine = true;
    		for (var i = 0; i < lines.length; i++) {
    			var line = lines[i];
    			if (line.staff) {
    				for (var j = 0; j < line.staff.length; j++) {
    					var staff = line.staff[j];
    					if (staff.title) {
    						var hasATitle = false;
    						for (var k = 0; k < staff.title.length; k++) {
    							if (staff.title[k]) {
    							staff.title[k] = (firstMusicLine) ? staff.title[k].name : staff.title[k].subname;
    							if (staff.title[k])
    								hasATitle = true;
    							else
    									staff.title[k] = '';
    							} else
    								staff.title[k] = '';
    						}
    						if (!hasATitle)
    							delete staff.title;
    					}
    				}
    				firstMusicLine = false;
    			}
    		}
    	}

    	this.cleanUp = function(defWidth, defLength, barsperstaff, staffnonote, currSlur) {
    		this.closeLine();	// Close the last line.

    		// If the tempo was created with a string like "Allegro", then the duration of a beat needs to be set at the last moment, when it is most likely known.
    		if (this.metaText.tempo && this.metaText.tempo.bpm && !this.metaText.tempo.duration)
    			this.metaText.tempo.duration = [ this.getBeatLength() ];

    		// Remove any blank lines
    		var anyDeleted = false;
    		var i, s, v;
    		for (i = 0; i < this.lines.length; i++) {
    			if (this.lines[i].staff !== undefined) {
    				var hasAny = false;
    				for (s = 0; s < this.lines[i].staff.length; s++) {
    					if (this.lines[i].staff[s] === undefined) {
    						anyDeleted = true;
    						this.lines[i].staff[s] = null;
    						//this.lines[i].staff[s] = { voices: []};	// TODO-PER: There was a part missing in the abc music. How should we recover?
    					} else {
    						for (v = 0; v < this.lines[i].staff[s].voices.length; v++) {
    							if (this.lines[i].staff[s].voices[v] === undefined)
    								this.lines[i].staff[s].voices[v] = [];	// TODO-PER: There was a part missing in the abc music. How should we recover?
    							else
    								if (this.containsNotes(this.lines[i].staff[s].voices[v])) hasAny = true;
    						}
    					}
    				}
    				if (!hasAny) {
    					this.lines[i] = null;
    					anyDeleted = true;
    				}
    			}
    		}
    		if (anyDeleted) {
    			this.lines = abc_common.compact(this.lines);
    			abc_common.each(this.lines, function(line) {
    				if (line.staff)
    					line.staff = abc_common.compact(line.staff);
    			});
    		}

    		// if we exceeded the number of bars allowed on a line, then force a new line
    		if (barsperstaff) {
    			while (wrapMusicLines(this.lines, barsperstaff)) {
    				// This will keep wrapping until the end of the piece.
    			}
    		}

    		// If we were passed staffnonote, then we want to get rid of all staffs that contain only rests.
    		if (staffnonote) {
    			anyDeleted = false;
    			for (i = 0; i < this.lines.length; i++) {
    				if (this.lines[i].staff !== undefined) {
    					for (s = 0; s < this.lines[i].staff.length; s++) {
    						var keepThis = false;
    						for (v = 0; v < this.lines[i].staff[s].voices.length; v++) {
    							if (this.containsNotesStrict(this.lines[i].staff[s].voices[v])) {
    								keepThis = true;
    							}
    						}
    						if (!keepThis) {
    							anyDeleted = true;
    							this.lines[i].staff[s] = null;
    						}
    					}
    				}
    			}
    			if (anyDeleted) {
    				abc_common.each(this.lines, function(line) {
    					if (line.staff)
    						line.staff = abc_common.compact(line.staff);
    				});
    			}
    		}

    		fixTitles(this.lines);

    		// Remove the temporary working variables
    		for (i = 0; i < this.lines.length; i++) {
    			if (this.lines[i].staff) {
    				for (s = 0; s < this.lines[i].staff.length; s++)
    						delete this.lines[i].staff[s].workingClef;
    			}
    		}

    		// If there are overlays, create new voices for them.
    		while (this.resolveOverlays()) {
    			// keep resolving overlays as long as any are found.
    		}

    		function cleanUpSlursInLine(line) {
    			var x;
    //			var lyr = null;	// TODO-PER: debugging.

    			var addEndSlur = function(obj, num, chordPos) {
    				if (currSlur[chordPos] === undefined) {
    					// There isn't an exact match for note position, but we'll take any other open slur.
    					for (x = 0; x < currSlur.length; x++) {
    						if (currSlur[x] !== undefined) {
    							chordPos = x;
    							break;
    						}
    					}
    					if (currSlur[chordPos] === undefined) {
    						var offNum = chordPos*100+1;
    						abc_common.each(obj.endSlur, function(x) { if (offNum === x) --offNum; });
    						currSlur[chordPos] = [offNum];
    					}
    				}
    				var slurNum;
    				for (var i = 0; i < num; i++) {
    					slurNum = currSlur[chordPos].pop();
    					obj.endSlur.push(slurNum);
    //					lyr.syllable += '<' + slurNum;	// TODO-PER: debugging
    				}
    				if (currSlur[chordPos].length === 0)
    					delete currSlur[chordPos];
    				return slurNum;
    			};

    			var addStartSlur = function(obj, num, chordPos, usedNums) {
    				obj.startSlur = [];
    				if (currSlur[chordPos] === undefined) {
    					currSlur[chordPos] = [];
    				}
    				var nextNum = chordPos*100+1;
    				for (var i = 0; i < num; i++) {
    					if (usedNums) {
    						abc_common.each(usedNums, function(x) { if (nextNum === x) ++nextNum; });
    						abc_common.each(usedNums, function(x) { if (nextNum === x) ++nextNum; });
    						abc_common.each(usedNums, function(x) { if (nextNum === x) ++nextNum; });
    					}
    					abc_common.each(currSlur[chordPos], function(x) { if (nextNum === x) ++nextNum; });
    					abc_common.each(currSlur[chordPos], function(x) { if (nextNum === x) ++nextNum; });

    					currSlur[chordPos].push(nextNum);
    					obj.startSlur.push({ label: nextNum });
    //					lyr.syllable += ' ' + nextNum + '>';	// TODO-PER:debugging
    					nextNum++;
    				}
    			};

    			for (var i = 0; i < line.length; i++) {
    				var el = line[i];
    //				if (el.lyric === undefined)	// TODO-PER: debugging
    //					el.lyric = [{ divider: '-' }];	// TODO-PER: debugging
    //				lyr = el.lyric[0];	// TODO-PER: debugging
    //				lyr.syllable = '';	// TODO-PER: debugging
    				if (el.el_type === 'note') {
    					if (el.gracenotes) {
    						for (var g = 0; g < el.gracenotes.length; g++) {
    							if (el.gracenotes[g].endSlur) {
    								var gg = el.gracenotes[g].endSlur;
    								el.gracenotes[g].endSlur = [];
    								for (var ggg = 0; ggg < gg; ggg++)
    									addEndSlur(el.gracenotes[g], 1, 20);
    							}
    							if (el.gracenotes[g].startSlur) {
    								x = el.gracenotes[g].startSlur;
    								addStartSlur(el.gracenotes[g], x, 20);
    							}
    						}
    					}
    					if (el.endSlur) {
    						x = el.endSlur;
    						el.endSlur = [];
    						addEndSlur(el, x, 0);
    					}
    					if (el.startSlur) {
    						x = el.startSlur;
    						addStartSlur(el, x, 0);
    					}
    					if (el.pitches) {
    						var usedNums = [];
    						for (var p = 0; p < el.pitches.length; p++) {
    							if (el.pitches[p].endSlur) {
    								var k = el.pitches[p].endSlur;
    								el.pitches[p].endSlur = [];
    								for (var j = 0; j < k; j++) {
    									var slurNum = addEndSlur(el.pitches[p], 1, p+1);
    									usedNums.push(slurNum);
    								}
    							}
    						}
    						for (p = 0; p < el.pitches.length; p++) {
    							if (el.pitches[p].startSlur) {
    								x = el.pitches[p].startSlur;
    								addStartSlur(el.pitches[p], x, p+1, usedNums);
    							}
    						}
    						// Correct for the weird gracenote case where ({g}a) should match.
    						// The end slur was already assigned to the note, and needs to be moved to the first note of the graces.
    						if (el.gracenotes && el.pitches[0].endSlur && el.pitches[0].endSlur[0] === 100 && el.pitches[0].startSlur) {
    							if (el.gracenotes[0].endSlur)
    								el.gracenotes[0].endSlur.push(el.pitches[0].startSlur[0].label);
    							else
    								el.gracenotes[0].endSlur = [el.pitches[0].startSlur[0].label];
    							if (el.pitches[0].endSlur.length === 1)
    								delete el.pitches[0].endSlur;
    							else if (el.pitches[0].endSlur[0] === 100)
    								el.pitches[0].endSlur.shift();
    							else if (el.pitches[0].endSlur[el.pitches[0].endSlur.length-1] === 100)
    								el.pitches[0].endSlur.pop();
    							if (currSlur[1].length === 1)
    								delete currSlur[1];
    							else
    								currSlur[1].pop();
    						}
    					}
    				}
    			}
    		}

    		// TODO-PER: This could be done faster as we go instead of as the last step.
    		function fixClefPlacement(el) {
    			abc_parse_key_voice.fixClef(el);
    			//if (el.el_type === 'clef') {
    //				var min = -2;
    //				var max = 5;
    //				switch(el.type) {
    //					case 'treble+8':
    //					case 'treble-8':
    //						break;
    //					case 'bass':
    //					case 'bass+8':
    //					case 'bass-8':
    //						el.verticalPos = 20 + el.verticalPos; min += 6; max += 6;
    //						break;
    //					case 'tenor':
    //					case 'tenor+8':
    //					case 'tenor-8':
    //						el.verticalPos = - el.verticalPos; min = -40; max = 40;
    ////						el.verticalPos+=2; min += 6; max += 6;
    //						break;
    //					case 'alto':
    //					case 'alto+8':
    //					case 'alto-8':
    //						el.verticalPos = - el.verticalPos; min = -40; max = 40;
    ////						el.verticalPos-=2; min += 4; max += 4;
    //						break;
    //				}
    //				if (el.verticalPos < min) {
    //					while (el.verticalPos < min)
    //						el.verticalPos += 7;
    //				} else if (el.verticalPos > max) {
    //					while (el.verticalPos > max)
    //						el.verticalPos -= 7;
    //				}
    			//}
    		}

    		function wrapMusicLines(lines, barsperstaff) {
    			for (i = 0; i < lines.length; i++) {
    				if (lines[i].staff !== undefined) {
    					for (s = 0; s < lines[i].staff.length; s++) {
    						var permanentItems = [];
    						for (v = 0; v < lines[i].staff[s].voices.length; v++) {
    							var voice = lines[i].staff[s].voices[v];
    							var barNumThisLine = 0;
    							for (var n = 0; n < voice.length; n++) {
    								if (voice[n].el_type === 'bar') {
    									barNumThisLine++;
    									if (barNumThisLine >= barsperstaff) {
    										// push everything else to the next line, if there is anything else,
    										// and there is a next line. If there isn't a next line, create one.
    										if (n < voice.length - 1) {
    											var nextLine = getNextMusicLine(lines, i);
    											if (!nextLine) {
    												var cp = JSON.parse(JSON.stringify(lines[i]));
    												lines.push(abc_common.clone(cp));
    												nextLine = lines[lines.length - 1];
    												for (var ss = 0; ss < nextLine.staff.length; ss++) {
    													for (var vv = 0; vv < nextLine.staff[ss].voices.length; vv++)
    														nextLine.staff[ss].voices[vv] = [];
    												}
    											}
    											var startElement = n + 1;
    											var section = lines[i].staff[s].voices[v].slice(startElement);
    											lines[i].staff[s].voices[v] = lines[i].staff[s].voices[v].slice(0, startElement);
    											nextLine.staff[s].voices[v] = permanentItems.concat(section.concat(nextLine.staff[s].voices[v]));
    											return true;
    										}
    									}
    								} else if (!voice[n].duration) {
    									permanentItems.push(voice[n]);
    								}
    							}
    						}
    					}
    				}
    			}
    			return false;
    		}

    		function getNextMusicLine(lines, currentLine) {
    			currentLine++;
    			while (lines.length > currentLine) {
    				if (lines[currentLine].staff)
    					return lines[currentLine];
    				currentLine++;
    			}
    			return null;
    		}

    		for (this.lineNum = 0; this.lineNum < this.lines.length; this.lineNum++) {
    			var staff = this.lines[this.lineNum].staff;
    			if (staff) {
    				for (this.staffNum = 0; this.staffNum < staff.length; this.staffNum++) {
    					if (staff[this.staffNum].clef)
    						fixClefPlacement(staff[this.staffNum].clef);
    					for (this.voiceNum = 0; this.voiceNum < staff[this.staffNum].voices.length; this.voiceNum++) {
    						var voice = staff[this.staffNum].voices[this.voiceNum];
    						cleanUpSlursInLine(voice);
    						for (var j = 0; j < voice.length; j++) {
    							if (voice[j].el_type === 'clef')
    								fixClefPlacement(voice[j]);
    						}
    						if (voice.length > 0 && voice[voice.length-1].barNumber) {
    							// Don't hang a bar number on the last bar line: it should go on the next line.
    							var nextLine = getNextMusicLine(this.lines, this.lineNum);
    							if (nextLine)
    								nextLine.staff[0].barNumber = voice[voice.length-1].barNumber;
    							delete voice[voice.length-1].barNumber;
    						}
    					}
    				}
    			}
    		}

    		if (!this.formatting.pagewidth)
    			this.formatting.pagewidth = defWidth;
    		if (!this.formatting.pageheight)
    			this.formatting.pageheight = defLength;

    		// Remove temporary variables that the outside doesn't need to know about
    		delete this.staffNum;
    		delete this.voiceNum;
    		delete this.lineNum;
    		delete this.potentialStartBeam;
    		delete this.potentialEndBeam;
    		delete this.vskipPending;

    		return currSlur;
    	};

    	this.reset();

    	this.getLastNote = function() {
    		if (this.lines[this.lineNum] && this.lines[this.lineNum].staff && this.lines[this.lineNum].staff[this.staffNum] &&
    			this.lines[this.lineNum].staff[this.staffNum].voices[this.voiceNum]) {
    			for (var i = this.lines[this.lineNum].staff[this.staffNum].voices[this.voiceNum].length-1; i >= 0; i--) {
    				var el = this.lines[this.lineNum].staff[this.staffNum].voices[this.voiceNum][i];
    				if (el.el_type === 'note') {
    					return el;
    				}
    			}
    		}
    		return null;
    	};

    	this.addTieToLastNote = function() {
    		// TODO-PER: if this is a chord, which note?
    		var el = this.getLastNote();
    		if (el && el.pitches && el.pitches.length > 0) {
    			el.pitches[0].startTie = {};
    			return true;
    		}
    		return false;
    	};

    	this.getDuration = function(el) {
    		if (el.duration) return el.duration;
    		//if (el.pitches && el.pitches.length > 0) return el.pitches[0].duration;
    		return 0;
    	};

    	this.closeLine = function() {
    		if (this.potentialStartBeam && this.potentialEndBeam) {
    			this.potentialStartBeam.startBeam = true;
    			this.potentialEndBeam.endBeam = true;
    		}
    		delete this.potentialStartBeam;
    		delete this.potentialEndBeam;
    	};

    	this.appendElement = function(type, startChar, endChar, hashParams)
    	{
    		var This = this;
    		var pushNote = function(hp) {
    			var currStaff = This.lines[This.lineNum].staff[This.staffNum];
    			if (!currStaff) {
    				// TODO-PER: This prevents a crash, but it drops the element. Need to figure out how to start a new line, or delay adding this.
    				return;
    			}
    			if (hp.pitches !== undefined) {
    				var mid = currStaff.workingClef.verticalPos;
    				abc_common.each(hp.pitches, function(p) { p.verticalPos = p.pitch - mid; });
    			}
    			if (hp.gracenotes !== undefined) {
    				var mid2 = currStaff.workingClef.verticalPos;
    				abc_common.each(hp.gracenotes, function(p) { p.verticalPos = p.pitch - mid2; });
    			}
    			currStaff.voices[This.voiceNum].push(hp);
    		};
    		hashParams.el_type = type;
    		if (startChar !== null)
    			hashParams.startChar = startChar;
    		if (endChar !== null)
    			hashParams.endChar = endChar;
    		var endBeamHere = function() {
    			This.potentialStartBeam.startBeam = true;
    			hashParams.endBeam = true;
    			delete This.potentialStartBeam;
    			delete This.potentialEndBeam;
    		};
    		var endBeamLast = function() {
    			if (This.potentialStartBeam !== undefined && This.potentialEndBeam !== undefined) {	// Do we have a set of notes to beam?
    				This.potentialStartBeam.startBeam = true;
    				This.potentialEndBeam.endBeam = true;
    			}
    			delete This.potentialStartBeam;
    			delete This.potentialEndBeam;
    		};
    		if (type === 'note') { // && (hashParams.rest !== undefined || hashParams.end_beam === undefined)) {
    			// Now, add the startBeam and endBeam where it is needed.
    			// end_beam is already set on the places where there is a forced end_beam. We'll remove that here after using that info.
    			// this.potentialStartBeam either points to null or the start beam.
    			// this.potentialEndBeam either points to null or the start beam.
    			// If we have a beam break (note is longer than a quarter, or an end_beam is on this element), then set the beam if we have one.
    			// reset the variables for the next notes.
    			var dur = This.getDuration(hashParams);
    			if (dur >= 0.25) {	// The beam ends on the note before this.
    				endBeamLast();
    			} else if (hashParams.force_end_beam_last && This.potentialStartBeam !== undefined) {
    				endBeamLast();
    			} else if (hashParams.end_beam && This.potentialStartBeam !== undefined) {	// the beam is forced to end on this note, probably because of a space in the ABC
    				if (hashParams.rest === undefined)
    					endBeamHere();
    				else
    					endBeamLast();
    			} else if (hashParams.rest === undefined) {	// this a short note and we aren't about to end the beam
    				if (This.potentialStartBeam === undefined) {	// We aren't collecting notes for a beam, so start here.
    					if (!hashParams.end_beam) {
    						This.potentialStartBeam = hashParams;
    						delete This.potentialEndBeam;
    					}
    				} else {
    					This.potentialEndBeam = hashParams;	// Continue the beaming, look for the end next note.
    				}
    			}

    			//  end_beam goes on rests and notes which precede rests _except_ when a rest (or set of adjacent rests) has normal notes on both sides (no spaces)
    //			if (hashParams.rest !== undefined)
    //			{
    //				hashParams.end_beam = true;
    //				var el2 = this.getLastNote();
    //				if (el2) el2.end_beam = true;
    //				// TODO-PER: implement exception mentioned in the comment.
    //			}
    		} else {	// It's not a note, so there definitely isn't beaming after it.
    			endBeamLast();
    		}
    		delete hashParams.end_beam;	// We don't want this temporary variable hanging around.
    		delete hashParams.force_end_beam_last;	// We don't want this temporary variable hanging around.
    		pushNote(hashParams);
    	};

    	this.appendStartingElement = function(type, startChar, endChar, hashParams2)
    	{
    		// If we're in the middle of beaming, then end the beam.
    		this.closeLine();

    		// We only ever want implied naturals the first time.
    		var impliedNaturals;
    		if (type === 'key') {
    			impliedNaturals = hashParams2.impliedNaturals;
    			delete hashParams2.impliedNaturals;
    			delete hashParams2.explicitAccidentals;
    		}

    		// Clone the object because it will be sticking around for the next line and we don't want the extra fields in it.
    		var hashParams = abc_common.clone(hashParams2);

    		if (this.lines[this.lineNum].staff) { // be sure that we are on a music type line before doing the following.
    			// If this is the first item in this staff, then we might have to initialize the staff, first.
    			if (this.lines[this.lineNum].staff.length <= this.staffNum) {
    				this.lines[this.lineNum].staff[this.staffNum] = {};
    				this.lines[this.lineNum].staff[this.staffNum].clef = abc_common.clone(this.lines[this.lineNum].staff[0].clef);
    				this.lines[this.lineNum].staff[this.staffNum].key = abc_common.clone(this.lines[this.lineNum].staff[0].key);
    				if (this.lines[this.lineNum].staff[0].meter)
    					this.lines[this.lineNum].staff[this.staffNum].meter = abc_common.clone(this.lines[this.lineNum].staff[0].meter);
    				this.lines[this.lineNum].staff[this.staffNum].workingClef = abc_common.clone(this.lines[this.lineNum].staff[0].workingClef);
    				this.lines[this.lineNum].staff[this.staffNum].voices = [[]];
    			}
    			// If this is a clef type, then we replace the working clef on the line. This is kept separate from
    			// the clef in case there is an inline clef field. We need to know what the current position for
    			// the note is.
    			if (type === 'clef') {
    				this.lines[this.lineNum].staff[this.staffNum].workingClef = hashParams;
    			}

    			// These elements should not be added twice, so if the element exists on this line without a note or bar before it, just replace the staff version.
    			var voice = this.lines[this.lineNum].staff[this.staffNum].voices[this.voiceNum];
    			for (var i = 0; i < voice.length; i++) {
    				if (voice[i].el_type === 'note' || voice[i].el_type === 'bar') {
    					hashParams.el_type = type;
    					hashParams.startChar = startChar;
    					hashParams.endChar = endChar;
    					if (impliedNaturals)
    						hashParams.accidentals = impliedNaturals.concat(hashParams.accidentals);
    					voice.push(hashParams);
    					return;
    				}
    				if (voice[i].el_type === type) {
    					hashParams.el_type = type;
    					hashParams.startChar = startChar;
    					hashParams.endChar = endChar;
    					if (impliedNaturals)
    						hashParams.accidentals = impliedNaturals.concat(hashParams.accidentals);
    					voice[i] = hashParams;
    					return;
    				}
    			}
    			// We didn't see either that type or a note, so replace the element to the staff.
    			this.lines[this.lineNum].staff[this.staffNum][type] = hashParams2;
    		}
    	};

    	this.getNumLines = function() {
    		return this.lines.length;
    	};

    	this.pushLine = function(hash) {
    		if (this.vskipPending) {
    			hash.vskip = this.vskipPending;
    			delete this.vskipPending;
    		}
    		this.lines.push(hash);
    	};

    	this.addSubtitle = function(str) {
    		this.pushLine({subtitle: str});
    	};

    	this.addSpacing = function(num) {
    		this.vskipPending = num;
    	};

    	this.addNewPage = function(num) {
    		this.pushLine({newpage: num});
    	};

    	this.addSeparator = function(spaceAbove, spaceBelow, lineLength) {
    		this.pushLine({separator: {spaceAbove: spaceAbove, spaceBelow: spaceBelow, lineLength: lineLength}});
    	};

    	this.addText = function(str) {
    		this.pushLine({text: str});
    	};

    	this.addCentered = function(str) {
    		this.pushLine({text: [{text: str, center: true }]});
    	};

    	this.containsNotes = function(voice) {
    		for (var i = 0; i < voice.length; i++) {
    			if (voice[i].el_type === 'note' || voice[i].el_type === 'bar')
    				return true;
    		}
    		return false;
    	};

    	this.containsNotesStrict = function(voice) {
    		for (var i = 0; i < voice.length; i++) {
    			if (voice[i].el_type === 'note' && voice[i].rest === undefined)
    				return true;
    		}
    		return false;
    	};

    //	anyVoiceContainsNotes: function(line) {
    //		for (var i = 0; i < line.staff.voices.length; i++) {
    //			if (this.containsNotes(line.staff.voices[i]))
    //				return true;
    //		}
    //		return false;
    //	},
    	this.changeVoiceScale = function(scale) {
    		var This = this;
    		This.appendElement('scale', null, null, { size: scale} );
    	};

    	this.startNewLine = function(params) {
    		// If the pointed to line doesn't exist, just create that. If the line does exist, but doesn't have any music on it, just use it.
    		// If it does exist and has music, then increment the line number. If the new element doesn't exist, create it.
    		var This = this;
    		this.closeLine();	// Close the previous line.
    		var createVoice = function(params) {
    			var thisStaff = This.lines[This.lineNum].staff[This.staffNum];
    			thisStaff.voices[This.voiceNum] = [];
    			if (!thisStaff.title)
    				thisStaff.title = [];
    			thisStaff.title[This.voiceNum] = { name: params.name, subname: params.subname };
    			if (params.style)
    				This.appendElement('style', null, null, {head: params.style});
    			if (params.stem)
    				This.appendElement('stem', null, null, {direction: params.stem});
    			else if (This.voiceNum > 0) {
    				if (thisStaff.voices[0]!== undefined) {
    					var found = false;
    					for (var i = 0; i < thisStaff.voices[0].length; i++) {
    						if (thisStaff.voices[0].el_type === 'stem')
    							found = true;
    					}
    					if (!found) {
    						var stem = { el_type: 'stem', direction: 'up' };
    						thisStaff.voices[0].splice(0,0,stem);
    					}
    				}
    				This.appendElement('stem', null, null, {direction: 'down'});
    			}
    			if (params.scale)
    				This.appendElement('scale', null, null, { size: params.scale} );
    		};
    		var createStaff = function(params) {
    			if (params.key && params.key.impliedNaturals) {
    				params.key.accidentals = params.key.accidentals.concat(params.key.impliedNaturals);
    				delete params.key.impliedNaturals;
    			}

    			This.lines[This.lineNum].staff[This.staffNum] = {voices: [ ], clef: params.clef, key: params.key, workingClef: params.clef };
    			if (params.stafflines !== undefined) {
    				This.lines[This.lineNum].staff[This.staffNum].clef.stafflines = params.stafflines;
    				This.lines[This.lineNum].staff[This.staffNum].workingClef.stafflines = params.stafflines;
    			}
    			if (params.staffscale) {
    				This.lines[This.lineNum].staff[This.staffNum].staffscale = params.staffscale;
    			}
    			if (params.tripletfont) This.lines[This.lineNum].staff[This.staffNum].tripletfont = params.tripletfont;
    			if (params.vocalfont) This.lines[This.lineNum].staff[This.staffNum].vocalfont = params.vocalfont;
    			if (params.bracket) This.lines[This.lineNum].staff[This.staffNum].bracket = params.bracket;
    			if (params.brace) This.lines[This.lineNum].staff[This.staffNum].brace = params.brace;
    			if (params.connectBarLines) This.lines[This.lineNum].staff[This.staffNum].connectBarLines = params.connectBarLines;
    			if (params.barNumber) This.lines[This.lineNum].staff[This.staffNum].barNumber = params.barNumber;
    			createVoice(params);
    			// Some stuff just happens for the first voice
    			if (params.part)
    				This.appendElement('part', params.part.startChar, params.part.endChar, {title: params.part.title});
    			if (params.meter !== undefined) This.lines[This.lineNum].staff[This.staffNum].meter = params.meter;
    		};
    		var createLine = function(params) {
    			This.lines[This.lineNum] = {staff: []};
    			createStaff(params);
    		};
    		if (this.lines[this.lineNum] === undefined) createLine(params);
    		else if (this.lines[this.lineNum].staff === undefined) {
    			this.lineNum++;
    			this.startNewLine(params);
    		} else if (this.lines[this.lineNum].staff[this.staffNum] === undefined) createStaff(params);
    		else if (this.lines[this.lineNum].staff[this.staffNum].voices[this.voiceNum] === undefined) createVoice(params);
    		else if (!this.containsNotes(this.lines[this.lineNum].staff[this.staffNum].voices[this.voiceNum])) return;
    		else {
    			this.lineNum++;
    			this.startNewLine(params);
    		}
    	};

    	this.setBarNumberImmediate = function(barNumber) {
    		// If this is called right at the beginning of a line, then correct the measure number that is already written.
    		// If this is called at the beginning of a measure, then correct the measure number that was just created.
    		// If this is called in the middle of a measure, then subtract one from it, because it will be incremented before applied.
    		var currentVoice = this.getCurrentVoice();
    		if (currentVoice && currentVoice.length > 0) {
    			var lastElement = currentVoice[currentVoice.length-1];
    			if (lastElement.el_type === 'bar') {
    				if (lastElement.barNumber !== undefined) // the measure number might not be written for this bar, don't override that.
    					lastElement.barNumber = barNumber;
    			} else
    				return barNumber-1;
    		}
    		return barNumber;
    	};

    	this.hasBeginMusic = function() {
    		// return true if there exists at least one line that contains "staff"
    		for (var i = 0; i < this.lines.length; i++) {
    			if (this.lines[i].staff)
    				return true;
    		}
    		return false;
    	};

    	this.isFirstLine = function(index) {
    		for (var i = index-1; i >= 0; i--) {
    			if (this.lines[i].staff !== undefined) return false;
    		}
    		return true;
    	};

    	this.getMeter = function() {
    		for (var i = 0; i < this.lines.length; i++) {
    			var line = this.lines[i];
    			if (line.staff) {
    				for (var j = 0; j < line.staff.length; j++) {
    					var meter = line.staff[j].meter;
    					if (meter) {
    						return meter;
    					}
    				}
    			}
    		}
    		return { type: "common_time" };
    	};

    	this.getMeterFraction = function() {
    		var meter = this.getMeter();
    		var num = 4;
    		var den = 4;
    		if (meter) {
    			if (meter.type === 'specified') {
    				num = parseInt(meter.value[0].num, 10);
    				den = parseInt(meter.value[0].den,10);
    			} else if (meter.type === 'cut_time') {
    				num = 2;
    				den = 2;
    			} else if (meter.type === 'common_time') {
    				num = 4;
    				den = 4;
    			}
    		}
    		this.meter = { num: num, den: den };
    		return this.meter; // TODO-PER: is this saved value used anywhere? A get function shouldn't change state.
    	};

    	this.getKeySignature = function() {
    		for (var i = 0; i < this.lines.length; i++) {
    			var line = this.lines[i];
    			if (line.staff) {
    				for (var j = 0; j < line.staff.length; j++) {
    					if (line.staff[j].key)
    						return line.staff[j].key;
    				}
    			}
    		}
    		return {  };
    	};

    	this.getCurrentVoice = function() {
    		if (this.lines[this.lineNum] !== undefined && this.lines[this.lineNum].staff[this.staffNum] !== undefined && this.lines[this.lineNum].staff[this.staffNum].voices[this.voiceNum] !== undefined)
    			return this.lines[this.lineNum].staff[this.staffNum].voices[this.voiceNum];
    		else return null;
    	};

    	this.setCurrentVoice = function(staffNum, voiceNum) {
    		this.staffNum = staffNum;
    		this.voiceNum = voiceNum;
    		for (var i = 0; i < this.lines.length; i++) {
    			if (this.lines[i].staff) {
    				if (this.lines[i].staff[staffNum] === undefined || this.lines[i].staff[staffNum].voices[voiceNum] === undefined ||
    					!this.containsNotes(this.lines[i].staff[staffNum].voices[voiceNum] )) {
    					this.lineNum =  i;
    					return;
    				}
    			}
    		}
    		this.lineNum =  i;
    	};

    	this.addMetaText = function(key, value) {
    		if (this.metaText[key] === undefined)
    			this.metaText[key] = value;
    		else
    			this.metaText[key] += "\n" + value;
    	};

    	this.addMetaTextArray = function(key, value) {
    		if (this.metaText[key] === undefined)
    			this.metaText[key] = [value];
    		else
    			this.metaText[key].push(value);
    	};
    	this.addMetaTextObj = function(key, value) {
    		this.metaText[key] = value;
    	};

    	function addVerticalInfo(timingEvents) {
    		// Add vertical info to the bar events: put the next event's top, and the event after the next measure's top.
    		var lastBarTop;
    		var lastBarBottom;
    		var lastEventTop;
    		var lastEventBottom;
    		for (var e = timingEvents.length - 1; e >= 0; e--) {
    			var ev = timingEvents[e];
    			if (ev.type === 'bar') {
    				ev.top = lastEventTop;
    				ev.nextTop = lastBarTop;
    				lastBarTop = lastEventTop;

    				ev.bottom = lastEventBottom;
    				ev.nextBottom = lastBarBottom;
    				lastBarBottom = lastEventBottom;
    			} else if (ev.type === 'event') {
    				lastEventTop = ev.top;
    				lastEventBottom = ev.top + ev.height;
    			}
    		}
    	}

    	function makeSortedArray(hash) {
    		var arr = [];
    		for (var k in hash) {
    			if (hash.hasOwnProperty(k))
    				arr.push(hash[k]);
    		}
    		arr = arr.sort(function (a, b) {
    			var diff = a.milliseconds - b.milliseconds;
    			// if the events have the same time, make sure a bar comes before a note
    			if (diff !== 0) {
    				return diff;
    			}
    			else {
    				return a.type === "bar" ? -1 : 1;
    			}
    		});
    		return arr;
    	}

    	this.addElementToEvents = function(eventHash, element, voiceTimeMilliseconds, top, height, line, measureNumber, timeDivider, isTiedState, nextIsBar) {
    		if (element.hint)
    			return { isTiedState: undefined, duration: 0 };
    		var realDuration = element.durationClass ? element.durationClass : element.duration;
    		if (element.abcelem.rest && element.abcelem.rest.type === "spacer")
    			realDuration = 0;
    		if (realDuration > 0) {
    			var es = [];
    			// If there is an invisible rest, then there are not elements, so don't push a null one.
    			for (var i = 0; i < element.elemset.length; i++) {
    				if (element.elemset[i] !== null)
    					es.push(element.elemset[i]);
    			}
    			var isTiedToNext = element.startTie;
    			if (isTiedState !== undefined) {
    				eventHash["event" + isTiedState].elements.push(es); // Add the tied note to the first note that it is tied to
    				if (nextIsBar) {
    					if (!eventHash["event" + voiceTimeMilliseconds]) {
    						eventHash["event" + voiceTimeMilliseconds] = {
    							type: "event",
    							milliseconds: voiceTimeMilliseconds,
    							line: line,
    							measureNumber: measureNumber,
    							top: top,
    							height: height,
    							left: null,
    							width: 0,
    							elements: [],
    							startChar: null,
    							endChar: null,
    							startCharArray: [],
    							endCharArray: []
    						};
    					}
    					eventHash["event" + voiceTimeMilliseconds].measureStart = true;
    					nextIsBar = false;
    				}
    				if (!isTiedToNext)
    					isTiedState = undefined;
    			} else {
    				// the last note wasn't tied.
    				if (!eventHash["event" + voiceTimeMilliseconds]) {
    					eventHash["event" + voiceTimeMilliseconds] = {
    						type: "event",
    						milliseconds: voiceTimeMilliseconds,
    						line: line,
    						measureNumber: measureNumber,
    						top: top,
    						height: height,
    						left: element.x,
    						width: element.w,
    						elements: [es],
    						startChar: element.abcelem.startChar,
    						endChar: element.abcelem.endChar,
    						startCharArray: [element.abcelem.startChar],
    						endCharArray: [element.abcelem.endChar],
    						midiPitches: element.abcelem.midiPitches ? abc_common.cloneArray(element.abcelem.midiPitches) : []
    					};
    					if (element.abcelem.midiGraceNotePitches)
    						eventHash["event" + voiceTimeMilliseconds].midiGraceNotePitches = abc_common.cloneArray(element.abcelem.midiGraceNotePitches);
    				} else {
    					// If there is more than one voice then two notes can fall at the same time. Usually they would be lined up in the same place, but if it is a whole rest, then it is placed funny. In any case, the left most element wins.
    					if (eventHash["event" + voiceTimeMilliseconds].left)
    						eventHash["event" + voiceTimeMilliseconds].left = Math.min(eventHash["event" + voiceTimeMilliseconds].left, element.x);
    					else
    						eventHash["event" + voiceTimeMilliseconds].left = element.x;
    					eventHash["event" + voiceTimeMilliseconds].elements.push(es);
    					eventHash["event" + voiceTimeMilliseconds].startCharArray.push(element.abcelem.startChar);
    					eventHash["event" + voiceTimeMilliseconds].endCharArray.push(element.abcelem.endChar);
    					if (eventHash["event" + voiceTimeMilliseconds].startChar === null)
    						eventHash["event" + voiceTimeMilliseconds].startChar =element.abcelem.startChar;
    					if (eventHash["event" + voiceTimeMilliseconds].endChar === null)
    						eventHash["event" + voiceTimeMilliseconds].endChar =element.abcelem.endChar;
    					if (element.abcelem.midiPitches && element.abcelem.midiPitches.length) {
    						if (!eventHash["event" + voiceTimeMilliseconds].midiPitches)
    							eventHash["event" + voiceTimeMilliseconds].midiPitches = [];
    						for (var i = 0; i < element.abcelem.midiPitches.length; i++)
    							eventHash["event" + voiceTimeMilliseconds].midiPitches.push(element.abcelem.midiPitches[i]);
    					}
    					if (element.abcelem.midiGraceNotePitches && element.abcelem.midiGraceNotePitches.length) {
    						if (!eventHash["event" + voiceTimeMilliseconds].midiGraceNotePitches)
    							eventHash["event" + voiceTimeMilliseconds].midiGraceNotePitches = [];
    						for (var j = 0; j < element.abcelem.midiGraceNotePitches.length; j++)
    							eventHash["event" + voiceTimeMilliseconds].midiGraceNotePitches.push(element.abcelem.midiGraceNotePitches[j]);
    					}
    				}
    				if (nextIsBar) {
    					eventHash["event" + voiceTimeMilliseconds].measureStart = true;
    					nextIsBar = false;
    				}
    				if (isTiedToNext)
    					isTiedState = voiceTimeMilliseconds;
    			}
    		}
    		return { isTiedState: isTiedState, duration: realDuration / timeDivider, nextIsBar: nextIsBar || element.type === 'bar' };
    	};

    	this.makeVoicesArray = function() {
    		// First make a new array that is arranged by voice so that the repeats that span different lines are handled correctly.
    		var voicesArr = [];
    		for (var line = 0; line < this.engraver.staffgroups.length; line++) {
    			var group = this.engraver.staffgroups[line];
    			var firstStaff = group.staffs[0];
    			var middleC = firstStaff.absoluteY;
    			var top = middleC - firstStaff.top * abc_spacing.STEP;
    			var lastStaff = group.staffs[group.staffs.length - 1];
    			middleC = lastStaff.absoluteY;
    			var bottom = middleC - lastStaff.bottom * abc_spacing.STEP;
    			var height = bottom - top;

    			var voices = group.voices;
    			for (var v = 0; v < voices.length; v++) {
    				var measureNumber = 0;
    				var noteFound = false;
    				if (!voicesArr[v])
    					voicesArr[v] = [];
    				var elements = voices[v].children;
    				for (var elem = 0; elem < elements.length; elem++) {
    					voicesArr[v].push({top: top, height: height, line: line, measureNumber: measureNumber, elem: elements[elem]});
    					if (elements[elem].type === 'bar' && noteFound) // Count the measures by counting the bar lines, but skip a bar line that appears at the left of the music, before any notes.
    						measureNumber++;
    					if (elements[elem].type === 'note' || elements[elem].type === 'rest')
    						noteFound = true;
    				}
    			}
    		}
    		return voicesArr;
    	};

    	this.setupEvents = function(startingDelay, timeDivider, bpm) {
    		var timingEvents = [];

    		var eventHash = {};
    		// The time is the number of seconds from the beginning of the piece.
    		// The units we are scanning are in notation units (i.e. 0.25 is a quarter note)
    		var time = startingDelay;
    		var isTiedState;
    		var nextIsBar = true;
    		var voices = this.makeVoicesArray();
    		for (var v = 0; v < voices.length; v++) {
    			var voiceTime = time;
    			var voiceTimeMilliseconds = Math.round(voiceTime * 1000);
    			var startingRepeatElem = 0;
    			var endingRepeatElem = -1;
    			var elements = voices[v];
    			for (var elem = 0; elem < elements.length; elem++) {
    				var element = elements[elem].elem;
    				if (element.abcelem.el_type === "tempo") {
    					var bpm = this.getBpm(element.abcelem);
    					var beatLength = this.getBeatLength();
    					var beatsPerSecond = bpm / 60;
    					timeDivider = beatLength * beatsPerSecond;
    				}
    				var ret = this.addElementToEvents(eventHash, element, voiceTimeMilliseconds, elements[elem].top, elements[elem].height, elements[elem].line, elements[elem].measureNumber, timeDivider, isTiedState, nextIsBar);
    				isTiedState = ret.isTiedState;
    				nextIsBar = ret.nextIsBar;
    				voiceTime += ret.duration;
    				voiceTimeMilliseconds = Math.round(voiceTime * 1000);
    				if (element.type === 'bar') {
    					var barType = element.abcelem.type;
    					var endRepeat = (barType === "bar_right_repeat" || barType === "bar_dbl_repeat");
    					var startEnding = (element.abcelem.startEnding === '1');
    					var startRepeat = (barType === "bar_left_repeat" || barType === "bar_dbl_repeat" || barType === "bar_right_repeat");
    					if (endRepeat) {
    						if (endingRepeatElem === -1)
    							endingRepeatElem = elem;
    						for (var el2 = startingRepeatElem; el2 < endingRepeatElem; el2++) {
    							var element2 = elements[el2].elem;
    							ret = this.addElementToEvents(eventHash, element2, voiceTimeMilliseconds, elements[el2].top, elements[el2].height, elements[el2].line, elements[el2].measureNumber, timeDivider, isTiedState, nextIsBar);
    							isTiedState = ret.isTiedState;
    							nextIsBar = ret.nextIsBar;
    							voiceTime += ret.duration;
    							voiceTimeMilliseconds = Math.round(voiceTime * 1000);
    						}
    						nextIsBar = true;
    						endingRepeatElem = -1;
    					}
    					if (startEnding)
    						endingRepeatElem = elem;
    					if (startRepeat)
    						startingRepeatElem = elem;
    				}
    			}
    		}
    		// now we have all the events, but if there are multiple voices then there may be events out of order or duplicated, so normalize it.
    		timingEvents = makeSortedArray(eventHash);
    		addVerticalInfo(timingEvents);
    		timingEvents.push({ type: "end", milliseconds: voiceTimeMilliseconds });
    		this.addUsefulCallbackInfo(timingEvents, bpm);
    		return timingEvents;
    	};

    	this.addUsefulCallbackInfo = function(timingEvents, bpm) {
    		var millisecondsPerMeasure = this.millisecondsPerMeasure(bpm);
    		for (var i = 0; i < timingEvents.length; i++) {
    			var ev = timingEvents[i];
    			ev.millisecondsPerMeasure = millisecondsPerMeasure;
    		}
    	};

    	this.getBpm = function(tempo) {
    		var bpm;
    		if (tempo) {
    			bpm = tempo.bpm;
    			var beatLength = this.getBeatLength();
    			var statedBeatLength = tempo.duration && tempo.duration.length > 0 ? tempo.duration[0] : beatLength;
    			bpm = bpm * statedBeatLength / beatLength;
    		}
    		if (!bpm) {
    			bpm = 180;
    			// Compensate for compound meter, where the beat isn't a beat.
    			var meter = this.getMeterFraction();
    			if (meter && meter.den === 8) {
    				bpm = 120;
    			}
    		}
    		return bpm;
    	};

    	this.setTiming = function (bpm, measuresOfDelay) {
    		if (!bpm) {
    			var tempo = this.metaText ? this.metaText.tempo : null;
    			bpm = this.getBpm(tempo);
    		}

    		var beatLength = this.getBeatLength();
    		var beatsPerSecond = bpm / 60;

    		var measureLength = this.getBarLength();

    		var startingDelay = measureLength / beatLength * measuresOfDelay / beatsPerSecond;
    		if (startingDelay)
    			startingDelay -= this.getPickupLength() / beatLength / beatsPerSecond;
    		var timeDivider = beatLength * beatsPerSecond;

    		this.noteTimings = this.setupEvents(startingDelay, timeDivider, bpm);
    	};
    };

    var abc_tune = Tune;

    //    abc_parse.js: parses a string representing ABC Music Notation into a usable internal structure.
    //    Copyright (C) 2010-2018 Paul Rosen (paul at paulrosen dot net)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    /*global window */











    var Parse = function() {
    	var tune = new abc_tune();
    	var tokenizer = new abc_tokenizer();

    	this.getTune = function() {
    		return {
    			formatting: tune.formatting,
    			lines: tune.lines,
    			media: tune.media,
    			metaText: tune.metaText,
    			version: tune.version,

    			addElementToEvents: tune.addElementToEvents,
    			addUsefulCallbackInfo: tune.addUsefulCallbackInfo,
    			getBarLength: tune.getBarLength,
    			getBeatLength: tune.getBeatLength,
    			getBeatsPerMeasure: tune.getBeatsPerMeasure,
    			getBpm: tune.getBpm,
    			getMeter: tune.getMeter,
    			getMeterFraction: tune.getMeterFraction,
    			getPickupLength: tune.getPickupLength,
    			getKeySignature: tune.getKeySignature,
    			makeVoicesArray: tune.makeVoicesArray,
    			millisecondsPerMeasure: tune.millisecondsPerMeasure,
    			setupEvents: tune.setupEvents,
    			setTiming: tune.setTiming
    		};
    	};

    	function addPositioning(el, type, value) {
    		if (!el.positioning) el.positioning = {};
    		el.positioning[type] = value;
    	}

    	function addFont(el, type, value) {
    		if (!el.fonts) el.fonts = {};
    		el.fonts[type] = value;
    	}

    	var multilineVars = {
    		reset: function() {
    			for (var property in this) {
    				if (this.hasOwnProperty(property) && typeof this[property] !== "function") {
    					delete this[property];
    				}
    			}
    			this.iChar = 0;
    			this.key = {accidentals: [], root: 'none', acc: '', mode: '' };
    			this.meter = null; // if no meter is specified, free meter is assumed
    			this.origMeter = null;	// this is for new voices that are created after we set the meter.
    			this.hasMainTitle = false;
    			this.default_length = 0.125;
    			this.clef = { type: 'treble', verticalPos: 0 };
    			this.next_note_duration = 0;
    			this.start_new_line = true;
    			this.is_in_header = true;
    			this.is_in_history = false;
    			this.partForNextLine = {};
    			this.havent_set_length = true;
    			this.voices = {};
    			this.staves = [];
    			this.macros = {};
    			this.currBarNumber = 1;
    			this.barCounter = {};
    			this.inTextBlock = false;
    			this.inPsBlock = false;
    			this.ignoredDecorations = [];
    			this.textBlock = "";
    			this.score_is_present = false;	// Can't have original V: lines when there is the score directive
    			this.inEnding = false;
    			this.inTie = [];
    			this.inTieChord = {};
    			this.vocalPosition = "auto";
    			this.dynamicPosition = "auto";
    			this.chordPosition = "auto";
    			this.ornamentPosition = "auto";
    			this.volumePosition = "auto";
    			this.openSlurs = [];
    			this.freegchord = false;
    		},
    		differentFont: function(type, defaultFonts) {
    			if (this[type].decoration !== defaultFonts[type].decoration) return true;
    			if (this[type].face !== defaultFonts[type].face) return true;
    			if (this[type].size !== defaultFonts[type].size) return true;
    			if (this[type].style !== defaultFonts[type].style) return true;
    			if (this[type].weight !== defaultFonts[type].weight) return true;
    			return false;
    		},
    		addFormattingOptions: function(el, defaultFonts, elType) {
    			if (elType === 'note') {
    				if (this.vocalPosition !== 'auto') addPositioning(el, 'vocalPosition', this.vocalPosition);
    				if (this.dynamicPosition !== 'auto') addPositioning(el, 'dynamicPosition', this.dynamicPosition);
    				if (this.chordPosition !== 'auto') addPositioning(el, 'chordPosition', this.chordPosition);
    				if (this.ornamentPosition !== 'auto') addPositioning(el, 'ornamentPosition', this.ornamentPosition);
    				if (this.volumePosition !== 'auto') addPositioning(el, 'volumePosition', this.volumePosition);
    				if (this.differentFont("annotationfont", defaultFonts)) addFont(el, 'annotationfont', this.annotationfont);
    				if (this.differentFont("gchordfont", defaultFonts)) addFont(el, 'gchordfont', this.gchordfont);
    				if (this.differentFont("vocalfont", defaultFonts)) addFont(el, 'vocalfont', this.vocalfont);
    				if (this.differentFont("tripletfont", defaultFonts)) addFont(el, 'tripletfont', this.tripletfont);
    			} else if (elType === 'bar') {
    				if (this.dynamicPosition !== 'auto') addPositioning(el, 'dynamicPosition', this.dynamicPosition);
    				if (this.chordPosition !== 'auto') addPositioning(el, 'chordPosition', this.chordPosition);
    				if (this.ornamentPosition !== 'auto') addPositioning(el, 'ornamentPosition', this.ornamentPosition);
    				if (this.volumePosition !== 'auto') addPositioning(el, 'volumePosition', this.volumePosition);
    				if (this.differentFont("measurefont", defaultFonts)) addFont(el, 'measurefont', this.measurefont);
    				if (this.differentFont("repeatfont", defaultFonts)) addFont(el, 'repeatfont', this.repeatfont);
    			}
    		}
    	};

    	var addWarning = function(str) {
    		if (!multilineVars.warnings)
    			multilineVars.warnings = [];
    		multilineVars.warnings.push(str);
    	};

    	var addWarningObject = function(warningObject) {
    		if (!multilineVars.warningObjects)
    			multilineVars.warningObjects = [];
    		multilineVars.warningObjects.push(warningObject);
    	};

    	var encode = function(str) {
    		var ret = abc_common.gsub(str, '\x12', ' ');
    		ret = abc_common.gsub(ret, '&', '&amp;');
    		ret = abc_common.gsub(ret, '<', '&lt;');
    		return abc_common.gsub(ret, '>', '&gt;');
    	};

    	var warn = function(str, line, col_num) {
    		if (!line) line = " ";
    		var bad_char = line.charAt(col_num);
    		if (bad_char === ' ')
    			bad_char = "SPACE";
    		var clean_line = encode(line.substring(0, col_num)) +
    			'<span style="text-decoration:underline;font-size:1.3em;font-weight:bold;">' + bad_char + '</span>' +
    			encode(line.substring(col_num+1));
    		addWarning("Music Line:" + tune.getNumLines() + ":" + (col_num+1) + ': ' + str + ":  " + clean_line);
    		addWarningObject({message:str, line:line, startChar: multilineVars.iChar + col_num, column: col_num});
    	};
    	var header = new abc_parse_header(tokenizer, warn, multilineVars, tune);

    	this.getWarnings = function() {
    		return multilineVars.warnings;
    	};
    	this.getWarningObjects = function() {
    		return multilineVars.warningObjects;
    	};

    	var letter_to_chord = function(line, i)
    	{
    		if (line.charAt(i) === '"')
    		{
    			var chord = tokenizer.getBrackettedSubstring(line, i, 5);
    			if (!chord[2])
    				warn("Missing the closing quote while parsing the chord symbol", line , i);
    			// If it starts with ^, then the chord appears above.
    			// If it starts with _ then the chord appears below.
    			// (note that the 2.0 draft standard defines them as not chords, but annotations and also defines @.)
    			if (chord[0] > 0 && chord[1].length > 0 && chord[1].charAt(0) === '^') {
    				chord[1] = chord[1].substring(1);
    				chord[2] = 'above';
    			} else if (chord[0] > 0 && chord[1].length > 0 && chord[1].charAt(0) === '_') {
    				chord[1] = chord[1].substring(1);
    				chord[2] = 'below';
    			} else if (chord[0] > 0 && chord[1].length > 0 && chord[1].charAt(0) === '<') {
    				chord[1] = chord[1].substring(1);
    				chord[2] = 'left';
    			} else if (chord[0] > 0 && chord[1].length > 0 && chord[1].charAt(0) === '>') {
    				chord[1] = chord[1].substring(1);
    				chord[2] = 'right';
    			} else if (chord[0] > 0 && chord[1].length > 0 && chord[1].charAt(0) === '@') {
    				// @-15,5.7
    				chord[1] = chord[1].substring(1);
    				var x = tokenizer.getFloat(chord[1]);
    				if (x.digits === 0)
    					warn("Missing first position in absolutely positioned annotation.", line , i);
    				chord[1] = chord[1].substring(x.digits);
    				if (chord[1][0] !== ',')
    					warn("Missing comma absolutely positioned annotation.", line , i);
    				chord[1] = chord[1].substring(1);
    				var y = tokenizer.getFloat(chord[1]);
    				if (y.digits === 0)
    					warn("Missing second position in absolutely positioned annotation.", line , i);
    				chord[1] = chord[1].substring(y.digits);
    				var ws = tokenizer.skipWhiteSpace(chord[1]);
    				chord[1] = chord[1].substring(ws);
    				chord[2] = null;
    				chord[3] = { x: x.value, y: y.value };
    			} else {
    				if (multilineVars.freegchord !== true) {
    					chord[1] = chord[1].replace(/([ABCDEFG0-9])b/g, "$1♭");
    					chord[1] = chord[1].replace(/([ABCDEFG0-9])#/g, "$1♯");
    				}
    				chord[2] = 'default';
    				chord[1] = abc_transpose.chordName(multilineVars, chord[1]);
    			}
    			return chord;
    		}
    		return [0, ""];
    	};

    	var legalAccents = [ "trill", "lowermordent", "uppermordent", "mordent", "pralltriller", "accent",
    		"fermata", "invertedfermata", "tenuto", "0", "1", "2", "3", "4", "5", "+", "wedge",
    		"open", "thumb", "snap", "turn", "roll", "breath", "shortphrase", "mediumphrase", "longphrase",
    		"segno", "coda", "D.S.", "D.C.", "fine",
    		"slide", "^", "marcato",
    		"upbow", "downbow", "/", "//", "///", "////", "trem1", "trem2", "trem3", "trem4",
    		"turnx", "invertedturn", "invertedturnx", "trill(", "trill)", "arpeggio", "xstem", "mark", "umarcato",
    		"style=normal", "style=harmonic", "style=rhythm", "style=x"
    	];
    	var volumeDecorations = [ "p", "pp", "f", "ff", "mf", "mp", "ppp", "pppp",  "fff", "ffff", "sfz" ];
    	var dynamicDecorations = ["crescendo(", "crescendo)", "diminuendo(", "diminuendo)"];

    	var accentPseudonyms = [ ["<", "accent"], [">", "accent"], ["tr", "trill"],
    		["plus", "+"], [ "emphasis", "accent"],
    		[ "^", "umarcato" ], [ "marcato", "umarcato" ] ];
    	var accentDynamicPseudonyms = [ ["<(", "crescendo("], ["<)", "crescendo)"],
    		[">(", "diminuendo("], [">)", "diminuendo)"] ];
    	var letter_to_accent = function(line, i)
    	{
    		var macro = multilineVars.macros[line.charAt(i)];

    		if (macro !== undefined) {
    			if (macro.charAt(0) === '!' || macro.charAt(0) === '+')
    				macro = macro.substring(1);
    			if (macro.charAt(macro.length-1) === '!' || macro.charAt(macro.length-1) === '+')
    				macro = macro.substring(0, macro.length-1);
    			if (abc_common.detect(legalAccents, function(acc) {
    					return (macro === acc);
    				}))
    				return [ 1, macro ];
    			else if (abc_common.detect(volumeDecorations, function(acc) {
    					return (macro === acc);
    				})) {
    				if (multilineVars.volumePosition === 'hidden')
    					macro = "";
    				return [1, macro];
    			} else if (abc_common.detect(dynamicDecorations, function(acc) {
    					if (multilineVars.dynamicPosition === 'hidden')
    						macro = "";
    					return (macro === acc);
    				})) {
    				return [1, macro];
    			} else {
    				if (!abc_common.detect(multilineVars.ignoredDecorations, function(dec) {
    					return (macro === dec);
    				}))
    					warn("Unknown macro: " + macro, line, i);
    				return [1, '' ];
    			}
    		}
    		switch (line.charAt(i))
    		{
    			case '.':return [1, 'staccato'];
    			case 'u':return [1, 'upbow'];
    			case 'v':return [1, 'downbow'];
    			case '~':return [1, 'irishroll'];
    			case '!':
    			case '+':
    				var ret = tokenizer.getBrackettedSubstring(line, i, 5);
    				// Be sure that the accent is recognizable.
    			if (ret[1].length > 0 && (ret[1].charAt(0) === '^' || ret[1].charAt(0) ==='_'))
    					ret[1] = ret[1].substring(1);	// TODO-PER: The test files have indicators forcing the ornament to the top or bottom, but that isn't in the standard. We'll just ignore them.
    				if (abc_common.detect(legalAccents, function(acc) {
    					return (ret[1] === acc);
    				}))
    					return ret;
    				if (abc_common.detect(volumeDecorations, function(acc) {
    						return (ret[1] === acc);
    					})) {
    					if (multilineVars.volumePosition === 'hidden' )
    						ret[1] = '';
    						return ret;
    				}
    				if (abc_common.detect(dynamicDecorations, function(acc) {
    						return (ret[1] === acc);
    					})) {
    					if (multilineVars.dynamicPosition === 'hidden' )
    						ret[1] = '';
    						return ret;
    				}

    				if (abc_common.detect(accentPseudonyms, function(acc) {
    					if (ret[1] === acc[0]) {
    						ret[1] = acc[1];
    						return true;
    					} else
    						return false;
    				}))
    					return ret;

    				if (abc_common.detect(accentDynamicPseudonyms, function(acc) {
    					if (ret[1] === acc[0]) {
    						ret[1] = acc[1];
    						return true;
    					} else
    						return false;
    				})) {
    					if (multilineVars.dynamicPosition === 'hidden' )
    						ret[1] = '';
    						return ret;
    				}
    				// We didn't find the accent in the list, so consume the space, but don't return an accent.
    				// Although it is possible that ! was used as a line break, so accept that.
    			if (line.charAt(i) === '!' && (ret[0] === 1 || line.charAt(i+ret[0]-1) !== '!'))
    					return [1, null ];
    				warn("Unknown decoration: " + ret[1], line, i);
    				ret[1] = "";
    				return ret;
    			case 'H':return [1, 'fermata'];
    			case 'J':return [1, 'slide'];
    			case 'L':return [1, 'accent'];
    			case 'M':return [1, 'mordent'];
    			case 'O':return [1, 'coda'];
    			case 'P':return [1, 'pralltriller'];
    			case 'R':return [1, 'roll'];
    			case 'S':return [1, 'segno'];
    			case 'T':return [1, 'trill'];
    		}
    		return [0, 0];
    	};

    	var letter_to_spacer = function(line, i)
    	{
    		var start = i;
    		while (tokenizer.isWhiteSpace(line.charAt(i)))
    			i++;
    		return [ i-start ];
    	};

    	// returns the class of the bar line
    	// the number of the repeat
    	// and the number of characters used up
    	// if 0 is returned, then the next element was not a bar line
    	var letter_to_bar = function(line, curr_pos)
    	{
    		var ret = tokenizer.getBarLine(line, curr_pos);
    		if (ret.len === 0)
    			return [0,""];
    		if (ret.warn) {
    			warn(ret.warn, line, curr_pos);
    			return [ret.len,""];
    		}

    		// Now see if this is a repeated ending
    		// A repeated ending is all of the characters 1,2,3,4,5,6,7,8,9,0,-, and comma
    		// It can also optionally start with '[', which is ignored.
    		// Also, it can have white space before the '['.
    		for (var ws = 0; ws < line.length; ws++)
    			if (line.charAt(curr_pos + ret.len + ws) !== ' ')
    				break;
    		var orig_bar_len = ret.len;
    		if (line.charAt(curr_pos+ret.len+ws) === '[') {
    			ret.len += ws + 1;
    		}

    		// It can also be a quoted string. It is unclear whether that construct requires '[', but it seems like it would. otherwise it would be confused with a regular chord.
    		if (line.charAt(curr_pos+ret.len) === '"' && line.charAt(curr_pos+ret.len-1) === '[') {
    			var ending = tokenizer.getBrackettedSubstring(line, curr_pos+ret.len, 5);
    			return [ret.len+ending[0], ret.token, ending[1]];
    		}
    		var retRep = tokenizer.getTokenOf(line.substring(curr_pos+ret.len), "1234567890-,");
    		if (retRep.len === 0 || retRep.token[0] === '-')
    			return [orig_bar_len, ret.token];

    		return [ret.len+retRep.len, ret.token, retRep.token];
    	};

    	var tripletQ = {
    		2: 3,
    		3: 2,
    		4: 3,
    		5: 2, // TODO-PER: not handling 6/8 rhythm yet
    		6: 2,
    		7: 2, // TODO-PER: not handling 6/8 rhythm yet
    		8: 3,
    		9: 2 // TODO-PER: not handling 6/8 rhythm yet
    	};
    	var letter_to_open_slurs_and_triplets =  function(line, i) {
    		// consume spaces, and look for all the open parens. If there is a number after the open paren,
    		// that is a triplet. Otherwise that is a slur. Collect all the slurs and the first triplet.
    		var ret = {};
    		var start = i;
    		while (line.charAt(i) === '(' || tokenizer.isWhiteSpace(line.charAt(i))) {
    			if (line.charAt(i) === '(') {
    				if (i+1 < line.length && (line.charAt(i+1) >= '2' && line.charAt(i+1) <= '9')) {
    					if (ret.triplet !== undefined)
    						warn("Can't nest triplets", line, i);
    					else {
    						ret.triplet = line.charAt(i+1) - '0';
    						ret.tripletQ = tripletQ[ret.triplet];
    						ret.num_notes = ret.triplet;
    						if (i+2 < line.length && line.charAt(i+2) === ':') {
    							// We are expecting "(p:q:r" or "(p:q" or "(p::r"
    							// That is: "put p notes into the time of q for the next r notes"
    							// if r is missing, then it is equal to p.
    							// if q is missing, it is determined from this table:
    							// (2 notes in the time of 3
    							// (3 notes in the time of 2
    							// (4 notes in the time of 3
    							// (5 notes in the time of n | if time sig is (6/8, 9/8, 12/8), n=3, else n=2
    							// (6 notes in the time of 2
    							// (7 notes in the time of n
    							// (8 notes in the time of 3
    							// (9 notes in the time of n
    							if (i+3 < line.length && line.charAt(i+3) === ':') {
    								// The second number, 'q', is not present.
    								if (i+4 < line.length && (line.charAt(i+4) >= '1' && line.charAt(i+4) <= '9')) {
    									ret.num_notes = line.charAt(i+4) - '0';
    									i += 3;
    								} else
    									warn("expected number after the two colons after the triplet to mark the duration", line, i);
    							} else if (i+3 < line.length && (line.charAt(i+3) >= '1' && line.charAt(i+3) <= '9')) {
    								ret.tripletQ = line.charAt(i+3) - '0';
    								if (i+4 < line.length && line.charAt(i+4) === ':') {
    									if (i+5 < line.length && (line.charAt(i+5) >= '1' && line.charAt(i+5) <= '9')) {
    										ret.num_notes = line.charAt(i+5) - '0';
    										i += 4;
    									}
    								} else {
    									i += 2;
    								}
    							} else
    								warn("expected number after the triplet to mark the duration", line, i);
    						}
    					}
    					i++;
    				}
    				else {
    					if (ret.startSlur === undefined)
    						ret.startSlur = 1;
    					else
    						ret.startSlur++;
    				}
    			}
    			i++;
    		}
    		ret.consumed = i-start;
    		return ret;
    	};

    	var addWords = function(line, words) {
    		if (!line) { warn("Can't add words before the first line of music", line, 0); return; }
    		words = abc_common.strip(words);
    		if (words.charAt(words.length-1) !== '-')
    			words = words + ' ';	// Just makes it easier to parse below, since every word has a divider after it.
    		var word_list = [];
    		// first make a list of words from the string we are passed. A word is divided on either a space or dash.
    		var last_divider = 0;
    		var replace = false;
    		var addWord = function(i) {
    			var word = abc_common.strip(words.substring(last_divider, i));
    			last_divider = i+1;
    			if (word.length > 0) {
    				if (replace)
    					word = abc_common.gsub(word,'~', ' ');
    				var div = words.charAt(i);
    				if (div !== '_' && div !== '-')
    					div = ' ';
    				word_list.push({syllable: tokenizer.translateString(word), divider: div});
    				replace = false;
    				return true;
    			}
    			return false;
    		};
    		for (var i = 0; i < words.length; i++) {
    			switch (words.charAt(i)) {
    				case ' ':
    				case '\x12':
    					addWord(i);
    					break;
    				case '-':
    					if (!addWord(i) && word_list.length > 0) {
    						abc_common.last(word_list).divider = '-';
    						word_list.push({skip: true, to: 'next'});
    					}
    					break;
    				case '_':
    					addWord(i);
    					word_list.push({skip: true, to: 'slur'});
    					break;
    				case '*':
    					addWord(i);
    					word_list.push({skip: true, to: 'next'});
    					break;
    				case '|':
    					addWord(i);
    					word_list.push({skip: true, to: 'bar'});
    					break;
    				case '~':
    					replace = true;
    					break;
    			}
    		}

    		var inSlur = false;
    		abc_common.each(line, function(el) {
    			if (word_list.length !== 0) {
    				if (word_list[0].skip) {
    					switch (word_list[0].to) {
    						case 'next': if (el.el_type === 'note' && el.pitches !== null && !inSlur) word_list.shift(); break;
    						case 'slur': if (el.el_type === 'note' && el.pitches !== null) word_list.shift(); break;
    						case 'bar': if (el.el_type === 'bar') word_list.shift(); break;
    					}
    					if (el.el_type !== 'bar') {
    						if (el.lyric === undefined)
    							el.lyric = [{syllable: "", divider: " "}];
    						else
    							el.lyric.push({syllable: "", divider: " "});
    					}
    				} else {
    					if (el.el_type === 'note' && el.rest === undefined && !inSlur) {
    						var lyric = word_list.shift();
    						if (lyric.syllable)
    							lyric.syllable = lyric.syllable.replace(/ +/g,'\xA0');
    						if (el.lyric === undefined)
    							el.lyric = [ lyric ];
    						else
    							el.lyric.push(lyric);
    					}
    				}
    			}
    		});
    	};

    	var addSymbols = function(line, words) {
    		// TODO-PER: Currently copied from w: line. This needs to be read as symbols instead.
    		if (!line) { warn("Can't add symbols before the first line of music", line, 0); return; }
    		words = abc_common.strip(words);
    		if (words.charAt(words.length-1) !== '-')
    			words = words + ' ';	// Just makes it easier to parse below, since every word has a divider after it.
    		var word_list = [];
    		// first make a list of words from the string we are passed. A word is divided on either a space or dash.
    		var last_divider = 0;
    		var replace = false;
    		var addWord = function(i) {
    			var word = abc_common.strip(words.substring(last_divider, i));
    			last_divider = i+1;
    			if (word.length > 0) {
    				if (replace)
    					word = abc_common.gsub(word, '~', ' ');
    				var div = words.charAt(i);
    				if (div !== '_' && div !== '-')
    					div = ' ';
    				word_list.push({syllable: tokenizer.translateString(word), divider: div});
    				replace = false;
    				return true;
    			}
    			return false;
    		};
    		for (var i = 0; i < words.length; i++) {
    			switch (words.charAt(i)) {
    				case ' ':
    				case '\x12':
    					addWord(i);
    					break;
    				case '-':
    					if (!addWord(i) && word_list.length > 0) {
    						abc_common.last(word_list).divider = '-';
    						word_list.push({skip: true, to: 'next'});
    					}
    					break;
    				case '_':
    					addWord(i);
    					word_list.push({skip: true, to: 'slur'});
    					break;
    				case '*':
    					addWord(i);
    					word_list.push({skip: true, to: 'next'});
    					break;
    				case '|':
    					addWord(i);
    					word_list.push({skip: true, to: 'bar'});
    					break;
    				case '~':
    					replace = true;
    					break;
    			}
    		}

    		var inSlur = false;
    		abc_common.each(line, function(el) {
    			if (word_list.length !== 0) {
    				if (word_list[0].skip) {
    					switch (word_list[0].to) {
    						case 'next': if (el.el_type === 'note' && el.pitches !== null && !inSlur) word_list.shift(); break;
    						case 'slur': if (el.el_type === 'note' && el.pitches !== null) word_list.shift(); break;
    						case 'bar': if (el.el_type === 'bar') word_list.shift(); break;
    					}
    				} else {
    					if (el.el_type === 'note' && el.rest === undefined && !inSlur) {
    						var lyric = word_list.shift();
    						if (el.lyric === undefined)
    							el.lyric = [ lyric ];
    						else
    							el.lyric.push(lyric);
    					}
    				}
    			}
    		});
    	};

    	var getBrokenRhythm = function(line, index) {
    		switch (line.charAt(index)) {
    			case '>':
    			if (index < line.length - 1 && line.charAt(index+1) === '>')	// double >>
    					return [2, 1.75, 0.25];
    				else
    					return [1, 1.5, 0.5];
    			case '<':
    			if (index < line.length - 1 && line.charAt(index+1) === '<')	// double <<
    					return [2, 0.25, 1.75];
    				else
    					return [1, 0.5, 1.5];
    		}
    		return null;
    	};

    	// TODO-PER: make this a method in el.
    	var addEndBeam = function(el) {
    		if (el.duration !== undefined && el.duration < 0.25)
    			el.end_beam = true;
    		return el;
    	};

    	var pitches = {A: 5, B: 6, C: 0, D: 1, E: 2, F: 3, G: 4, a: 12, b: 13, c: 7, d: 8, e: 9, f: 10, g: 11};
    	var rests = {x: 'invisible', y: 'spacer', z: 'rest', Z: 'multimeasure' };
    	var getCoreNote = function(line, index, el, canHaveBrokenRhythm) {
    		//var el = { startChar: index };
    		var isComplete = function(state) {
    			return (state === 'octave' || state === 'duration' || state === 'Zduration' || state === 'broken_rhythm' || state === 'end_slur');
    		};
    		var state = 'startSlur';
    		var durationSetByPreviousNote = false;
    		while (1) {
    			switch(line.charAt(index)) {
    				case '(':
    					if (state === 'startSlur') {
    						if (el.startSlur === undefined) el.startSlur = 1; else el.startSlur++;
    					} else if (isComplete(state)) {el.endChar = index;return el;}
    					else return null;
    					break;
    				case ')':
    					if (isComplete(state)) {
    						if (el.endSlur === undefined) el.endSlur = 1; else el.endSlur++;
    					} else return null;
    					break;
    				case '^':
    					if (state === 'startSlur') {el.accidental = 'sharp';state = 'sharp2';}
    					else if (state === 'sharp2') {el.accidental = 'dblsharp';state = 'pitch';}
    					else if (isComplete(state)) {el.endChar = index;return el;}
    					else return null;
    					break;
    				case '_':
    					if (state === 'startSlur') {el.accidental = 'flat';state = 'flat2';}
    					else if (state === 'flat2') {el.accidental = 'dblflat';state = 'pitch';}
    					else if (isComplete(state)) {el.endChar = index;return el;}
    					else return null;
    					break;
    				case '=':
    					if (state === 'startSlur') {el.accidental = 'natural';state = 'pitch';}
    					else if (isComplete(state)) {el.endChar = index;return el;}
    					else return null;
    					break;
    				case 'A':
    				case 'B':
    				case 'C':
    				case 'D':
    				case 'E':
    				case 'F':
    				case 'G':
    				case 'a':
    				case 'b':
    				case 'c':
    				case 'd':
    				case 'e':
    				case 'f':
    				case 'g':
    					if (state === 'startSlur' || state === 'sharp2' || state === 'flat2' || state === 'pitch') {
    						el.pitch = pitches[line.charAt(index)];
    						abc_transpose.note(multilineVars, el);
    						state = 'octave';
    						// At this point we have a valid note. The rest is optional. Set the duration in case we don't get one below
    						if (canHaveBrokenRhythm && multilineVars.next_note_duration !== 0) {
    							el.duration = multilineVars.default_length * multilineVars.next_note_duration;
    							multilineVars.next_note_duration = 0;
    							durationSetByPreviousNote = true;
    						} else
    							el.duration = multilineVars.default_length;
    						// If the clef is percussion, there is probably some translation of the pitch to a particular drum kit item.
    						if ((multilineVars.clef && multilineVars.clef.type === "perc") ||
    							(multilineVars.currentVoice && multilineVars.currentVoice.clef === "perc")) {
    							var key = line.charAt(index);
    							if (el.accidental) {
    								var accMap = { 'dblflat': '__', 'flat': '_', 'natural': '=', 'sharp': '^', 'dblsharp': '^^'};
    								key = accMap[el.accidental] + key;
    							}
    							if (tune.formatting && tune.formatting.midi && tune.formatting.midi.drummap)
    								el.midipitch = tune.formatting.midi.drummap[key];
    						}
    					} else if (isComplete(state)) {el.endChar = index;return el;}
    					else return null;
    					break;
    				case ',':
    					if (state === 'octave') {el.pitch -= 7;}
    					else if (isComplete(state)) {el.endChar = index;return el;}
    					else return null;
    					break;
    				case '\'':
    					if (state === 'octave') {el.pitch += 7;}
    					else if (isComplete(state)) {el.endChar = index;return el;}
    					else return null;
    					break;
    				case 'x':
    				case 'y':
    				case 'z':
    				case 'Z':
    					if (state === 'startSlur') {
    						el.rest = { type: rests[line.charAt(index)] };
    						// There shouldn't be some of the properties that notes have. If some sneak in due to bad syntax in the abc file,
    						// just nix them here.
    						delete el.accidental;
    						delete el.startSlur;
    						delete el.startTie;
    						delete el.endSlur;
    						delete el.endTie;
    						delete el.end_beam;
    						delete el.grace_notes;
    						// At this point we have a valid note. The rest is optional. Set the duration in case we don't get one below
    						if (el.rest.type === 'multimeasure') {
    							el.duration = 1;
    							state = 'Zduration';
    						} else {
    							if (canHaveBrokenRhythm && multilineVars.next_note_duration !== 0) {
    								el.duration = multilineVars.default_length * multilineVars.next_note_duration;
    								multilineVars.next_note_duration = 0;
    								durationSetByPreviousNote = true;
    							} else
    								el.duration = multilineVars.default_length;
    							state = 'duration';
    						}
    					} else if (isComplete(state)) {el.endChar = index;return el;}
    					else return null;
    					break;
    				case '1':
    				case '2':
    				case '3':
    				case '4':
    				case '5':
    				case '6':
    				case '7':
    				case '8':
    				case '9':
    				case '0':
    				case '/':
    					if (state === 'octave' || state === 'duration') {
    						var fraction = tokenizer.getFraction(line, index);
    						//if (!durationSetByPreviousNote)
    							el.duration = el.duration * fraction.value;
    						// TODO-PER: We can test the returned duration here and give a warning if it isn't the one expected.
    						el.endChar = fraction.index;
    						while (fraction.index < line.length && (tokenizer.isWhiteSpace(line.charAt(fraction.index)) || line.charAt(fraction.index) === '-')) {
    							if (line.charAt(fraction.index) === '-')
    								el.startTie = {};
    							else
    								el = addEndBeam(el);
    							fraction.index++;
    						}
    						index = fraction.index-1;
    						state = 'broken_rhythm';
    					} else if (state === 'sharp2') {
    						el.accidental = 'quartersharp';state = 'pitch';
    					} else if (state === 'flat2') {
    						el.accidental = 'quarterflat';state = 'pitch';
    					} else if (state === 'Zduration') {
    						var num = tokenizer.getNumber(line, index);
    						el.duration = num.num;
    						el.endChar = num.index;
    						return el;
    					} else return null;
    					break;
    				case '-':
    					if (state === 'startSlur') {
    						// This is the first character, so it must have been meant for the previous note. Correct that here.
    						tune.addTieToLastNote();
    						el.endTie = true;
    					} else if (state === 'octave' || state === 'duration' || state === 'end_slur') {
    						el.startTie = {};
    						if (!durationSetByPreviousNote && canHaveBrokenRhythm)
    							state = 'broken_rhythm';
    						else {
    							// Peek ahead to the next character. If it is a space, then we have an end beam.
    							if (tokenizer.isWhiteSpace(line.charAt(index + 1)))
    								addEndBeam(el);
    							el.endChar = index+1;
    							return el;
    						}
    					} else if (state === 'broken_rhythm') {el.endChar = index;return el;}
    					else return null;
    					break;
    				case ' ':
    				case '\t':
    					if (isComplete(state)) {
    						el.end_beam = true;
    						// look ahead to see if there is a tie
    						do {
    							if (line.charAt(index) === '-')
    								el.startTie = {};
    							index++;
    						} while (index < line.length && (tokenizer.isWhiteSpace(line.charAt(index)) || line.charAt(index) === '-'));
    						el.endChar = index;
    						if (!durationSetByPreviousNote && canHaveBrokenRhythm && (line.charAt(index) === '<' || line.charAt(index) === '>')) {	// TODO-PER: Don't need the test for < and >, but that makes the endChar work out for the regression test.
    							index--;
    							state = 'broken_rhythm';
    						} else
    							return el;
    					}
    					else return null;
    					break;
    				case '>':
    				case '<':
    					if (isComplete(state)) {
    						if (canHaveBrokenRhythm) {
    							var br2 = getBrokenRhythm(line, index);
    							index += br2[0] - 1;	// index gets incremented below, so we'll let that happen
    							multilineVars.next_note_duration = br2[2];
    							el.duration = br2[1]*el.duration;
    							state = 'end_slur';
    						} else {
    							el.endChar = index;
    							return el;
    						}
    					} else
    						return null;
    					break;
    				default:
    					if (isComplete(state)) {
    						el.endChar = index;
    						return el;
    					}
    					return null;
    			}
    			index++;
    			if (index === line.length) {
    				if (isComplete(state)) {el.endChar = index;return el;}
    				else return null;
    			}
    		}
    		return null;
    	};

    	function startNewLine() {
    		var params = { startChar: -1, endChar: -1};
    		if (multilineVars.partForNextLine.title)
    			params.part = multilineVars.partForNextLine;
    		params.clef = multilineVars.currentVoice && multilineVars.staves[multilineVars.currentVoice.staffNum].clef !== undefined ? abc_common.clone(multilineVars.staves[multilineVars.currentVoice.staffNum].clef) : abc_common.clone(multilineVars.clef);
    		var scoreTranspose = multilineVars.currentVoice ? multilineVars.currentVoice.scoreTranspose : 0;
    		params.key = abc_parse_key_voice.standardKey(multilineVars.key.root+multilineVars.key.acc+multilineVars.key.mode, multilineVars.key.root, multilineVars.key.acc, scoreTranspose);
    		params.key.mode = multilineVars.key.mode;
    		if (multilineVars.key.impliedNaturals)
    			params.key.impliedNaturals = multilineVars.key.impliedNaturals;
    		if (multilineVars.key.explicitAccidentals) {
    			for (var i = 0; i < multilineVars.key.explicitAccidentals.length; i++) {
    				var found = false;
    				for (var j = 0; j < params.key.accidentals.length; j++) {
    					if (params.key.accidentals[j].note === multilineVars.key.explicitAccidentals[i].note) {
    						// If the note is already in the list, override it with the new value
    						params.key.accidentals[j].acc = multilineVars.key.explicitAccidentals[i].acc;
    						found = true;
    					}
    				}
    				if (!found)
    					params.key.accidentals.push(multilineVars.key.explicitAccidentals[i]);
    			}
    		}
    		multilineVars.targetKey = params.key;
    		if (params.key.explicitAccidentals)
    			delete params.key.explicitAccidentals;
    		abc_parse_key_voice.addPosToKey(params.clef, params.key);
    		if (multilineVars.meter !== null) {
    			if (multilineVars.currentVoice) {
    				abc_common.each(multilineVars.staves, function(st) {
    					st.meter = multilineVars.meter;
    				});
    				params.meter = multilineVars.staves[multilineVars.currentVoice.staffNum].meter;
    				multilineVars.staves[multilineVars.currentVoice.staffNum].meter = null;
    			} else
    				params.meter = multilineVars.meter;
    			multilineVars.meter = null;
    		} else if (multilineVars.currentVoice && multilineVars.staves[multilineVars.currentVoice.staffNum].meter) {
    			// Make sure that each voice gets the meter marking.
    			params.meter = multilineVars.staves[multilineVars.currentVoice.staffNum].meter;
    			multilineVars.staves[multilineVars.currentVoice.staffNum].meter = null;
    		}
    		if (multilineVars.currentVoice && multilineVars.currentVoice.name)
    			params.name = multilineVars.currentVoice.name;
    		if (multilineVars.vocalfont)
    			params.vocalfont = multilineVars.vocalfont;
    		if (multilineVars.tripletfont)
    			params.tripletfont = multilineVars.tripletfont;
    		if (multilineVars.style)
    			params.style = multilineVars.style;
    		if (multilineVars.currentVoice) {
    			var staff = multilineVars.staves[multilineVars.currentVoice.staffNum];
    			if (staff.brace) params.brace = staff.brace;
    			if (staff.bracket) params.bracket = staff.bracket;
    			if (staff.connectBarLines) params.connectBarLines = staff.connectBarLines;
    			if (staff.name) params.name = staff.name[multilineVars.currentVoice.index];
    			if (staff.subname) params.subname = staff.subname[multilineVars.currentVoice.index];
    			if (multilineVars.currentVoice.stem)
    				params.stem = multilineVars.currentVoice.stem;
    			if (multilineVars.currentVoice.stafflines)
    				params.stafflines = multilineVars.currentVoice.stafflines;
    			if (multilineVars.currentVoice.staffscale)
    				params.staffscale = multilineVars.currentVoice.staffscale;
    			if (multilineVars.currentVoice.scale)
    				params.scale = multilineVars.currentVoice.scale;
    			if (multilineVars.currentVoice.style)
    				params.style = multilineVars.currentVoice.style;
    			if (multilineVars.currentVoice.transpose)
    				params.clef.transpose = multilineVars.currentVoice.transpose;
    		}
    		var isFirstVoice = multilineVars.currentVoice === undefined || (multilineVars.currentVoice.staffNum ===  0 && multilineVars.currentVoice.index ===  0);
    		if (multilineVars.barNumbers === 0 && isFirstVoice && multilineVars.currBarNumber !== 1)
    			params.barNumber = multilineVars.currBarNumber;
    		tune.startNewLine(params);
    		if (multilineVars.key.impliedNaturals)
    			delete multilineVars.key.impliedNaturals;

    		multilineVars.partForNextLine = {};
    	}

    	var letter_to_grace =  function(line, i) {
    		// Grace notes are an array of: startslur, note, endslur, space; where note is accidental, pitch, duration
    		if (line.charAt(i) === '{') {
    			// fetch the gracenotes string and consume that into the array
    			var gra = tokenizer.getBrackettedSubstring(line, i, 1, '}');
    			if (!gra[2])
    				warn("Missing the closing '}' while parsing grace note", line, i);
    			// If there is a slur after the grace construction, then move it to the last note inside the grace construction
    			if (line[i+gra[0]] === ')') {
    				gra[0]++;
    				gra[1] += ')';
    			}

    			var gracenotes = [];
    			var ii = 0;
    			var inTie = false;
    			while (ii < gra[1].length) {
    				var acciaccatura = false;
    				if (gra[1].charAt(ii) === '/') {
    					acciaccatura = true;
    					ii++;
    				}
    				var note = getCoreNote(gra[1], ii, {}, false);
    				if (note !== null) {
    					// The grace note durations should not be affected by the default length: they should be based on 1/16, so if that isn't the default, then multiply here.
    					note.duration = note.duration / (multilineVars.default_length * 8);
    					if (acciaccatura)
    						note.acciaccatura = true;
    					gracenotes.push(note);

    					if (inTie) {
    						note.endTie = true;
    						inTie = false;
    					}
    					if (note.startTie)
    						inTie = true;

    					ii  = note.endChar;
    					delete note.endChar;
    				}
    				else {
    					// We shouldn't get anything but notes or a space here, so report an error
    					if (gra[1].charAt(ii) === ' ') {
    						if (gracenotes.length > 0)
    							gracenotes[gracenotes.length-1].end_beam = true;
    					} else
    						warn("Unknown character '" + gra[1].charAt(ii) + "' while parsing grace note", line, i);
    					ii++;
    				}
    			}
    			if (gracenotes.length)
    				return [gra[0], gracenotes];
    		}
    		return [ 0 ];
    	};

    	function letter_to_overlay(line, i) {
    		if (line.charAt(i) === '&') {
    			var start = i;
    			while (line.charAt(i) && line.charAt(i) !== ':' && line.charAt(i) !== '|')
    				i++;
    			return [ i-start, line.substring(start+1, i) ];
    		}
    		return [ 0 ];
    	}

    	function durationOfMeasure(multilineVars) {
    		// TODO-PER: This could be more complicated if one of the unusual measures is used.
    		var meter = multilineVars.origMeter;
    		if (!meter || meter.type !== 'specified')
    			return 1;
    		if (!meter.value || meter.value.length === 0)
    			return 1;
    		return parseInt(meter.value[0].num, 10) / parseInt(meter.value[0].den, 10);
    	}

    	//
    	// Parse line of music
    	//
    	// This is a stream of <(bar-marking|header|note-group)...> in any order, with optional spaces between each element
    	// core-note is <open-slur, accidental, pitch:required, octave, duration, close-slur&|tie> with no spaces within that
    	// chord is <open-bracket:required, core-note:required... close-bracket:required duration> with no spaces within that
    	// grace-notes is <open-brace:required, (open-slur|core-note:required|close-slur)..., close-brace:required> spaces are allowed
    	// note-group is <grace-notes, chord symbols&|decorations..., grace-notes, slur&|triplet, chord|core-note, end-slur|tie> spaces are allowed between items
    	// bar-marking is <ampersand> or <chord symbols&|decorations..., bar:required> spaces allowed
    	// header is <open-bracket:required, K|M|L|V:required, colon:required, field:required, close-bracket:required> spaces can occur between the colon, in the field, and before the close bracket
    	// header can also be the only thing on a line. This is true even if it is a continuation line. In this case the brackets are not required.
    	// a space is a back-tick, a space, or a tab. If it is a back-tick, then there is no end-beam.

    	// Line preprocessing: anything after a % is ignored (the double %% should have been taken care of before this)
    	// Then, all leading and trailing spaces are ignored.
    	// If there was a line continuation, the \n was replaced by a \r and the \ was replaced by a space. This allows the construct
    	// of having a header mid-line conceptually, but actually be at the start of the line. This is equivolent to putting the header in [ ].

    	// TODO-PER: How to handle ! for line break?
    	// TODO-PER: dots before bar, dots before slur
    	// TODO-PER: U: redefinable symbols.

    	// Ambiguous symbols:
    	// "[" can be the start of a chord, the start of a header element or part of a bar line.
    	// --- if it is immediately followed by "|", it is a bar line
    	// --- if it is immediately followed by K: L: M: V: it is a header (note: there are other headers mentioned in the standard, but I'm not sure how they would be used.)
    	// --- otherwise it is the beginning of a chord
    	// "(" can be the start of a slur or a triplet
    	// --- if it is followed by a number from 2-9, then it is a triplet
    	// --- otherwise it is a slur
    	// "]"
    	// --- if there is a chord open, then this is the close
    	// --- if it is after a [|, then it is an invisible bar line
    	// --- otherwise, it is par of a bar
    	// "." can be a bar modifier or a slur modifier, or a decoration
    	// --- if it comes immediately before a bar, it is a bar modifier
    	// --- if it comes immediately before a slur, it is a slur modifier
    	// --- otherwise it is a decoration for the next note.
    	// number:
    	// --- if it is after a bar, with no space, it is an ending marker
    	// --- if it is after a ( with no space, it is a triplet count
    	// --- if it is after a pitch or octave or slash, then it is a duration

    	// Unambiguous symbols (except inside quoted strings):
    	// vertical-bar, colon: part of a bar
    	// ABCDEFGabcdefg: pitch
    	// xyzZ: rest
    	// comma, prime: octave
    	// close-paren: end-slur
    	// hyphen: tie
    	// tilde, v, u, bang, plus, THLMPSO: decoration
    	// carat, underscore, equal: accidental
    	// ampersand: time reset
    	// open-curly, close-curly: grace notes
    	// double-quote: chord symbol
    	// less-than, greater-than, slash: duration
    	// back-tick, space, tab: space
    	var nonDecorations = "ABCDEFGabcdefgxyzZ[]|^_{";	// use this to prescreen so we don't have to look for a decoration at every note.

    	var parseRegularMusicLine = function(line) {
    		header.resolveTempo();
    		//multilineVars.havent_set_length = false;	// To late to set this now.
    		multilineVars.is_in_header = false;	// We should have gotten a key header by now, but just in case, this is definitely out of the header.
    		var i = 0;
    		var startOfLine = multilineVars.iChar;
    		// see if there is nothing but a comment on this line. If so, just ignore it. A full line comment is optional white space followed by %
    		while (tokenizer.isWhiteSpace(line.charAt(i)) && i < line.length)
    			i++;
    		if (i === line.length || line.charAt(i) === '%')
    			return;

    		// Start with the standard staff, clef and key symbols on each line
    		var delayStartNewLine = multilineVars.start_new_line;
    		if (multilineVars.continueall === undefined)
    			multilineVars.start_new_line = true;
    		else
    			multilineVars.start_new_line = false;
    		var tripletNotesLeft = 0;

    		// See if the line starts with a header field
    		var retHeader = header.letter_to_body_header(line, i);
    		if (retHeader[0] > 0) {
    			i += retHeader[0];
    			if (retHeader[1] === 'V')
    				delayStartNewLine = true; // fixes bug on this: c[V:2]d
    			// TODO-PER: Handle inline headers
    		}
    		var el = { };

    		var overlayLevel = 0;
    		while (i < line.length)
    		{
    			var startI = i;
    			if (line.charAt(i) === '%')
    				break;

    			var retInlineHeader = header.letter_to_inline_header(line, i);
    			if (retInlineHeader[0] > 0) {
    					i += retInlineHeader[0];
    					if (retInlineHeader[1] === 'V')
    						delayStartNewLine = true; // fixes bug on this: c[V:2]d
    					// TODO-PER: Handle inline headers
    					//multilineVars.start_new_line = false;
    			} else {
    				// Wait until here to actually start the line because we know we're past the inline statements.
    				if (delayStartNewLine) {
    					startNewLine();
    					delayStartNewLine = false;
    				}

    				// We need to decide if the following characters are a bar-marking or a note-group.
    				// Unfortunately, that is ambiguous. Both can contain chord symbols and decorations.
    				// If there is a grace note either before or after the chord symbols and decorations, then it is definitely a note-group.
    				// If there is a bar marker, it is definitely a bar-marking.
    				// If there is either a core-note or chord, it is definitely a note-group.
    				// So, loop while we find grace-notes, chords-symbols, or decorations. [It is an error to have more than one grace-note group in a row; the others can be multiple]
    				// Then, if there is a grace-note, we know where to go.
    				// Else see if we have a chord, core-note, slur, triplet, or bar.

    				var ret;
    				while (1) {
    					ret = tokenizer.eatWhiteSpace(line, i);
    					if (ret > 0) {
    						i += ret;
    					}
    					if (i > 0 && line.charAt(i-1) === '\x12') {
    						// there is one case where a line continuation isn't the same as being on the same line, and that is if the next character after it is a header.
    						ret = header.letter_to_body_header(line, i);
    						if (ret[0] > 0) {
    							if (ret[1] === 'V')
    								startNewLine(); // fixes bug on this: c\\nV:2]\\nd
    							// TODO: insert header here
    							i = ret[0];
    							multilineVars.start_new_line = false;
    						}
    					}
    					// gather all the grace notes, chord symbols and decorations
    					ret = letter_to_spacer(line, i);
    					if (ret[0] > 0) {
    						i += ret[0];
    					}

    					ret = letter_to_chord(line, i);
    					if (ret[0] > 0) {
    						// There could be more than one chord here if they have different positions.
    						// If two chords have the same position, then connect them with newline.
    						if (!el.chord)
    							el.chord = [];
    						var chordName = tokenizer.translateString(ret[1]);
    						chordName = chordName.replace(/;/g, "\n");
    						var addedChord = false;
    						for (var ci = 0; ci < el.chord.length; ci++) {
    							if (el.chord[ci].position === ret[2]) {
    								addedChord = true;
    								el.chord[ci].name += "\n" + chordName;
    							}
    						}
    						if (addedChord === false) {
    							if (ret[2] === null && ret[3])
    								el.chord.push({name: chordName, rel_position: ret[3]});
    							else
    								el.chord.push({name: chordName, position: ret[2]});
    						}

    						i += ret[0];
    						var ii = tokenizer.skipWhiteSpace(line.substring(i));
    						if (ii > 0)
    							el.force_end_beam_last = true;
    						i += ii;
    					} else {
    						if (nonDecorations.indexOf(line.charAt(i)) === -1)
    							ret = letter_to_accent(line, i);
    						else ret = [ 0 ];
    						if (ret[0] > 0) {
    							if (ret[1] === null) {
    								if (i + 1 < line.length)
    									startNewLine();	// There was a ! in the middle of the line. Start a new line if there is anything after it.
    							} else if (ret[1].length > 0) {
    								if (ret[1].indexOf("style=") === 0) {
    									el.style = ret[1].substr(6);
    								} else {
    									if (el.decoration === undefined)
    										el.decoration = [];
    									el.decoration.push(ret[1]);
    								}
    							}
    							i += ret[0];
    						} else {
    							ret = letter_to_grace(line, i);
    							// TODO-PER: Be sure there aren't already grace notes defined. That is an error.
    							if (ret[0] > 0) {
    								el.gracenotes = ret[1];
    								i += ret[0];
    							} else
    								break;
    						}
    					}
    				}

    				ret = letter_to_bar(line, i);
    				if (ret[0] > 0) {
    					// This is definitely a bar
    					overlayLevel = 0;
    					if (el.gracenotes !== undefined) {
    						// Attach the grace note to an invisible note
    						el.rest = { type: 'spacer' };
    						el.duration = 0.125; // TODO-PER: I don't think the duration of this matters much, but figure out if it does.
    						multilineVars.addFormattingOptions(el, tune.formatting, 'note');
    						tune.appendElement('note', startOfLine+i, startOfLine+i+ret[0], el);
    						multilineVars.measureNotEmpty = true;
    						el = {};
    					}
    					var bar = {type: ret[1]};
    					if (bar.type.length === 0)
    						warn("Unknown bar type", line, i);
    					else {
    						if (multilineVars.inEnding && bar.type !== 'bar_thin') {
    							bar.endEnding = true;
    							multilineVars.inEnding = false;
    						}
    						if (ret[2]) {
    							bar.startEnding = ret[2];
    							if (multilineVars.inEnding)
    								bar.endEnding = true;
    							multilineVars.inEnding = true;
    						}
    						if (el.decoration !== undefined)
    							bar.decoration = el.decoration;
    						if (el.chord !== undefined)
    							bar.chord = el.chord;
    						if (bar.startEnding && multilineVars.barFirstEndingNum === undefined)
    							multilineVars.barFirstEndingNum = multilineVars.currBarNumber;
    						else if (bar.startEnding && bar.endEnding && multilineVars.barFirstEndingNum)
    							multilineVars.currBarNumber = multilineVars.barFirstEndingNum;
    						else if (bar.endEnding)
    							multilineVars.barFirstEndingNum = undefined;
    						if (bar.type !== 'bar_invisible' && multilineVars.measureNotEmpty) {
    							var isFirstVoice = multilineVars.currentVoice === undefined || (multilineVars.currentVoice.staffNum ===  0 && multilineVars.currentVoice.index ===  0);
    							if (isFirstVoice) {
    								multilineVars.currBarNumber++;
    								if (multilineVars.barNumbers && multilineVars.currBarNumber % multilineVars.barNumbers === 0)
    									bar.barNumber = multilineVars.currBarNumber;
    							}
    						}
    						multilineVars.addFormattingOptions(el, tune.formatting, 'bar');
    						tune.appendElement('bar', startOfLine+i, startOfLine+i+ret[0], bar);
    						multilineVars.measureNotEmpty = false;
    						el = {};
    					}
    					i += ret[0];
    					var cv = multilineVars.currentVoice ? multilineVars.currentVoice.staffNum + '-' + multilineVars.currentVoice.index : 'ONLY';
    					// if (multilineVars.lineBreaks) {
    					// 	if (!multilineVars.barCounter[cv])
    					// 		multilineVars.barCounter[cv] = 0;
    					// 	var breakNow = multilineVars.lineBreaks[''+multilineVars.barCounter[cv]];
    					// 	multilineVars.barCounter[cv]++;
    					// 	if (breakNow)
    					// 		startNewLine();
    					// }
    				} else if (line[i] === '&') {	// backtrack to beginning of measure
    					ret = letter_to_overlay(line, i);
    					if (ret[0] > 0) {
    						tune.appendElement('overlay', startOfLine, startOfLine+1, {});
    						i += 1;
    						overlayLevel++;
    					}

    				} else {
    					// This is definitely a note group
    					//
    					// Look for as many open slurs and triplets as there are. (Note: only the first triplet is valid.)
    					ret = letter_to_open_slurs_and_triplets(line, i);
    					if (ret.consumed > 0) {
    						if (ret.startSlur !== undefined)
    							el.startSlur = ret.startSlur;
    						if (ret.triplet !== undefined) {
    							if (tripletNotesLeft > 0)
    								warn("Can't nest triplets", line, i);
    							else {
    								el.startTriplet = ret.triplet;
    								el.tripletMultiplier = ret.tripletQ / ret.triplet;
    								tripletNotesLeft = ret.num_notes === undefined ? ret.triplet : ret.num_notes;
    							}
    						}
    						i += ret.consumed;
    					}

    					// handle chords.
    					if (line.charAt(i) === '[') {
    						var chordStartChar = i;
    						i++;
    						var chordDuration = null;
    						var rememberEndBeam = false;

    						var done = false;
    						while (!done) {
    							var accent = letter_to_accent(line, i);
    							if (accent[0] > 0) {
    								i += accent[0];
    							}

    							var chordNote = getCoreNote(line, i, {}, false);
    							if (chordNote !== null) {
    								if (accent[0] > 0) { // If we found a decoration above, it modifies the entire chord. "style" is handled below.
    									if (accent[1].indexOf("style=") !== 0) {
    										if (el.decoration === undefined)
    											el.decoration = [];
    										el.decoration.push(accent[1]);
    									}
    								}
    								if (chordNote.end_beam) {
    									el.end_beam = true;
    									delete chordNote.end_beam;
    								}
    								if (el.pitches === undefined) {
    									el.duration = chordNote.duration;
    									el.pitches = [ chordNote ];
    								} else	// Just ignore the note lengths of all but the first note. The standard isn't clear here, but this seems less confusing.
    									el.pitches.push(chordNote);
    								delete chordNote.duration;
    								if (accent[0] > 0) { // If we found a style above, it modifies the individual pitch, not the entire chord.
    									if (accent[1].indexOf("style=") === 0) {
    										el.pitches[el.pitches.length-1].style = accent[1].substr(6);
    									}
    								}

    								if (multilineVars.inTieChord[el.pitches.length]) {
    									chordNote.endTie = true;
    									multilineVars.inTieChord[el.pitches.length] = undefined;
    								}
    								if (chordNote.startTie)
    									multilineVars.inTieChord[el.pitches.length] = true;

    								i  = chordNote.endChar;
    								delete chordNote.endChar;
    							} else if (line.charAt(i) === ' ') {
    								// Spaces are not allowed in chords, but we can recover from it by ignoring it.
    								warn("Spaces are not allowed in chords", line, i);
    								i++;
    							} else {
    								if (i < line.length && line.charAt(i) === ']') {
    									// consume the close bracket
    									i++;

    									if (multilineVars.next_note_duration !== 0) {
    										el.duration = el.duration * multilineVars.next_note_duration;
    										multilineVars.next_note_duration = 0;
    									}

    									if (isInTie(multilineVars,  overlayLevel, el)) {
    										abc_common.each(el.pitches, function(pitch) { pitch.endTie = true; });
    										setIsInTie(multilineVars,  overlayLevel, false);
    									}

    									if (tripletNotesLeft > 0) {
    										tripletNotesLeft--;
    										if (tripletNotesLeft === 0) {
    											el.endTriplet = true;
    										}
    									}

    									var postChordDone = false;
    									while (i < line.length && !postChordDone) {
    										switch (line.charAt(i)) {
    											case ' ':
    											case '\t':
    												addEndBeam(el);
    												break;
    											case ')':
    												if (el.endSlur === undefined) el.endSlur = 1; else el.endSlur++;
    												break;
    											case '-':
    												abc_common.each(el.pitches, function(pitch) { pitch.startTie = {}; });
    												setIsInTie(multilineVars,  overlayLevel, true);
    												break;
    											case '>':
    											case '<':
    												var br2 = getBrokenRhythm(line, i);
    												i += br2[0] - 1;	// index gets incremented below, so we'll let that happen
    												multilineVars.next_note_duration = br2[2];
    												if (chordDuration)
    													chordDuration = chordDuration * br2[1];
    												else
    													chordDuration = br2[1];
    												break;
    											case '1':
    											case '2':
    											case '3':
    											case '4':
    											case '5':
    											case '6':
    											case '7':
    											case '8':
    											case '9':
    											case '/':
    												var fraction = tokenizer.getFraction(line, i);
    												chordDuration = fraction.value;
    												i = fraction.index;
    												if (line.charAt(i) === ' ')
    													rememberEndBeam = true;
    												if (line.charAt(i) === '-' || line.charAt(i) === ')' || line.charAt(i) === ' ' || line.charAt(i) === '<' || line.charAt(i) === '>')
    													i--; // Subtracting one because one is automatically added below
    												else
    													postChordDone = true;
    												break;
    											default:
    												postChordDone = true;
    												break;
    										}
    										if (!postChordDone) {
    											i++;
    										}
    									}
    								} else
    									warn("Expected ']' to end the chords", line, i);

    								if (el.pitches !== undefined) {
    									if (chordDuration !== null) {
    										el.duration = el.duration * chordDuration;
    										if (rememberEndBeam)
    											addEndBeam(el);
    									}

    									multilineVars.addFormattingOptions(el, tune.formatting, 'note');
    									tune.appendElement('note', startOfLine+chordStartChar, startOfLine+i, el);
    									multilineVars.measureNotEmpty = true;
    									el = {};
    								}
    								done = true;
    							}
    						}

    					} else {
    						// Single pitch
    						var el2 = {};
    						var core = getCoreNote(line, i, el2, true);
    						if (el2.endTie !== undefined) setIsInTie(multilineVars,  overlayLevel, true);
    						if (core !== null) {
    							if (core.pitch !== undefined) {
    								el.pitches = [ { } ];
    								// TODO-PER: straighten this out so there is not so much copying: getCoreNote shouldn't change e'
    								if (core.accidental !== undefined) el.pitches[0].accidental = core.accidental;
    								el.pitches[0].pitch = core.pitch;
    								if (core.midipitch)
    									el.pitches[0].midipitch = core.midipitch;
    								if (core.endSlur !== undefined) el.pitches[0].endSlur = core.endSlur;
    								if (core.endTie !== undefined) el.pitches[0].endTie = core.endTie;
    								if (core.startSlur !== undefined) el.pitches[0].startSlur = core.startSlur;
    								if (el.startSlur !== undefined) el.pitches[0].startSlur = el.startSlur;
    								if (core.startTie !== undefined) el.pitches[0].startTie = core.startTie;
    								if (el.startTie !== undefined) el.pitches[0].startTie = el.startTie;
    							} else {
    								el.rest = core.rest;
    								if (core.endSlur !== undefined) el.endSlur = core.endSlur;
    								if (core.endTie !== undefined) el.rest.endTie = core.endTie;
    								if (core.startSlur !== undefined) el.startSlur = core.startSlur;
    								if (core.startTie !== undefined) el.rest.startTie = core.startTie;
    								if (el.startTie !== undefined) el.rest.startTie = el.startTie;
    							}

    							if (core.chord !== undefined) el.chord = core.chord;
    							if (core.duration !== undefined) el.duration = core.duration;
    							if (core.decoration !== undefined) el.decoration = core.decoration;
    							if (core.graceNotes !== undefined) el.graceNotes = core.graceNotes;
    							delete el.startSlur;
    							if (isInTie(multilineVars,  overlayLevel, el)) {
    								if (el.pitches !== undefined) {
    									el.pitches[0].endTie = true;
    								} else if (el.rest.type !== 'spacer') {
    									el.rest.endTie = true;
    								}
    								setIsInTie(multilineVars,  overlayLevel, false);
    							}
    							if (core.startTie || el.startTie)
    								setIsInTie(multilineVars,  overlayLevel, true);
    							i  = core.endChar;

    							if (tripletNotesLeft > 0) {
    								tripletNotesLeft--;
    								if (tripletNotesLeft === 0) {
    									el.endTriplet = true;
    								}
    							}

    							if (core.end_beam)
    								addEndBeam(el);

    							// If there is a whole rest, then it should be the duration of the measure, not it's own duration. We need to special case it.
    							// If the time signature length is greater than 4/4, though, then a whole rest has no special treatment.
    							if (el.rest && el.rest.type === 'rest' && el.duration === 1 && durationOfMeasure(multilineVars) <= 1) {
    								el.rest.type = 'whole';

    								el.duration = durationOfMeasure(multilineVars);
    							}

    							multilineVars.addFormattingOptions(el, tune.formatting, 'note');
    							tune.appendElement('note', startOfLine+startI, startOfLine+i, el);
    							multilineVars.measureNotEmpty = true;
    							el = {};
    						}
    					}

    					if (i === startI) {	// don't know what this is, so ignore it.
    						if (line.charAt(i) !== ' ' && line.charAt(i) !== '`')
    							warn("Unknown character ignored", line, i);
    						i++;
    					}
    				}
    			}
    		}
    	};

    	var isInTie = function(multilineVars, overlayLevel, el) {
    		if (multilineVars.inTie[overlayLevel] === undefined)
    			return false;
    		// If this is single voice music then the voice index isn't set, so we use the first voice.
    		var voiceIndex = multilineVars.currentVoice ? multilineVars.currentVoice.index : 0;
    		if (multilineVars.inTie[overlayLevel][voiceIndex]) {
    			if (el.pitches !== undefined || el.rest.type !== 'spacer')
    				return true;
    		}
    		return false;
    	};

    	var setIsInTie =function(multilineVars, overlayLevel, value) {
    		// If this is single voice music then the voice index isn't set, so we use the first voice.
    		var voiceIndex = multilineVars.currentVoice ? multilineVars.currentVoice.index : 0;
    		if (multilineVars.inTie[overlayLevel] === undefined)
    			multilineVars.inTie[overlayLevel] = [];
    		multilineVars.inTie[overlayLevel][voiceIndex] = value;
    	};

    	var parseLine = function(line) {
    		var ret = header.parseHeader(line);
    		if (ret.regular)
    			parseRegularMusicLine(ret.str);
    		if (ret.newline)
    			startNewLine();
    		if (ret.words)
    			addWords(tune.getCurrentVoice(), line.substring(2));
    		if (ret.symbols)
    			addSymbols(tune.getCurrentVoice(), line.substring(2));
    		if (ret.recurse)
    			parseLine(ret.str);
    	};

    	function appendLastMeasure(voice, nextVoice) {
    		voice.push({
    			el_type: 'hint'
    		});
    		for (var i = 0; i < nextVoice.length; i++) {
    			var element = nextVoice[i];
    			var hint = abc_common.clone(element);
    			voice.push(hint);
    			if (element.el_type === 'bar')
    					return;
    		}
    	}

    	function addHintMeasure(staff, nextStaff) {
    		for (var i = 0; i < staff.length; i++) {
    			var stave = staff[i];
    			var nextStave = nextStaff[i];
    			if (nextStave) { // Be sure there is the same number of staves on the next line.
    				for (var j = 0; j < nextStave.voices.length; j++) {
    					var nextVoice = nextStave.voices[j];
    					var voice = stave.voices[j];
    					if (voice) { // Be sure there are the same number of voices on the previous line.
    						appendLastMeasure(voice, nextVoice);
    					}
    				}
    			}
    		}
    	}

    	function addHintMeasures() {
    		for (var i = 0; i < tune.lines.length; i++) {
    			var line = tune.lines[i].staff;
    			if (line) {
    				var j = i+1;
    				while (j < tune.lines.length && tune.lines[j].staff === undefined)
    					j++;
    				if (j < tune.lines.length) {
    					var nextLine = tune.lines[j].staff;
    					addHintMeasure(line, nextLine);
    				}
    			}
    		}
    	}

    	this.parse = function(strTune, switches, startPos) {
    		// the switches are optional and cause a difference in the way the tune is parsed.
    		// switches.header_only : stop parsing when the header is finished
    		// switches.stop_on_warning : stop at the first warning encountered.
    		// switches.print: format for the page instead of the browser.
    		// switches.format: a hash of the desired formatting commands.
    		// switches.hint_measures: put the next measure at the end of the current line.
    		// switches.transpose: change the key signature, chords, and notes by a number of half-steps.
    		if (!switches) switches = {};
    		if (!startPos) startPos = 0;
    		tune.reset();
    		if (switches.print)
    			tune.media = 'print';
    		multilineVars.reset();
    		multilineVars.iChar = startPos;
    		if (switches.visualTranspose) {
    			multilineVars.globalTranspose = parseInt(switches.visualTranspose);
    			if (multilineVars.globalTranspose === 0)
    				multilineVars.globalTranspose = undefined;
    		} else
    			multilineVars.globalTranspose = undefined;
    		if (switches.lineBreaks) {
    			// change the format of the the line breaks for easy testing.
    			// The line break numbers are 0-based and they reflect the last measure of the current line.
    			multilineVars.lineBreaks = {};
    			//multilineVars.continueall = true;
    			for (var i = 0; i < switches.lineBreaks.length; i++)
    				multilineVars.lineBreaks[''+(switches.lineBreaks[i]+1)] = true; // Add 1 so that the line break is the first measure of the next line.
    		}
    		header.reset(tokenizer, warn, multilineVars, tune);

    		// Take care of whatever line endings come our way
    		strTune = abc_common.gsub(strTune, '\r\n', '\n');
    		strTune = abc_common.gsub(strTune, '\r', '\n');
    		strTune += '\n';	// Tacked on temporarily to make the last line continuation work
    		strTune = strTune.replace(/\n\\.*\n/g, "\n");	// get rid of latex commands.
    		var continuationReplacement = function(all, backslash, comment){
    			var spaces = "                                                                                                                                                                                                     ";
    			var padding = comment ? spaces.substring(0, comment.length) : "";
    			return backslash + " \x12" + padding;
    		};
    		strTune = strTune.replace(/\\([ \t]*)(%.*)*\n/g, continuationReplacement);	// take care of line continuations right away, but keep the same number of characters
    		var lines = strTune.split('\n');
    		if (abc_common.last(lines).length === 0)	// remove the blank line we added above.
    			lines.pop();
    		try {
    			if (switches.format) {
    				abc_parse_directive.globalFormatting(switches.format);
    			}
    			abc_common.each(lines,  function(line) {
    				if (switches.header_only && multilineVars.is_in_header === false)
    					throw "normal_abort";
    				if (switches.stop_on_warning && multilineVars.warnings)
    					throw "normal_abort";
    				if (multilineVars.is_in_history) {
    					if (line.charAt(1) === ':') {
    						multilineVars.is_in_history = false;
    						parseLine(line);
    					} else
    						tune.addMetaText("history", tokenizer.translateString(tokenizer.stripComment(line)));
    				} else if (multilineVars.inTextBlock) {
    					if (abc_common.startsWith(line, "%%endtext")) {
    						//tune.addMetaText("textBlock", multilineVars.textBlock);
    						tune.addText(multilineVars.textBlock);
    						multilineVars.inTextBlock = false;
    					}
    					else {
    						if (abc_common.startsWith(line, "%%"))
    							multilineVars.textBlock += ' ' + line.substring(2);
    						else
    							multilineVars.textBlock += ' ' + line;
    					}
    				} else if (multilineVars.inPsBlock) {
    					if (abc_common.startsWith(line, "%%endps")) {
    						// Just ignore postscript
    						multilineVars.inPsBlock = false;
    					}
    					else
    						multilineVars.textBlock += ' ' + line;
    				} else
    					parseLine(line);
    				multilineVars.iChar += line.length + 1;
    			});
    			var ph = 11*72;
    			var pl = 8.5*72;
    			switch (multilineVars.papersize) {
    				//case "letter": ph = 11*72; pl = 8.5*72; break;
    				case "legal": ph = 14*72; pl = 8.5*72; break;
    				case "A4": ph = 11.7*72; pl = 8.3*72; break;
    			}
    			if (multilineVars.landscape) {
    				var x = ph;
    				ph = pl;
    				pl = x;
    			}
    			multilineVars.openSlurs = tune.cleanUp(pl, ph, multilineVars.barsperstaff, multilineVars.staffnonote, multilineVars.openSlurs);
    		} catch (err) {
    			if (err !== "normal_abort")
    				throw err;
    		}
    		if (switches.hint_measures) {
    			addHintMeasures();
    		}

    		wrap_lines.wrapLines(tune, multilineVars.lineBreaks);
    	};
    };

    var abc_parse = Parse;

    //    abc_tunebook.js: splits a string representing ABC Music Notation into individual tunes.
    //    Copyright (C) 2010-2018 Paul Rosen (paul at paulrosen dot net)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    /*global document */
    /*global window, ABCJS, console */




    var tunebook = {};

    (function() {

    	tunebook.numberOfTunes = function(abc) {
    		var tunes = abc.split("\nX:");
    		var num = tunes.length;
    		if (num === 0) num = 1;
    		return num;
    	};

    	var TuneBook = tunebook.TuneBook = function(book) {
    		var This = this;
    		var directives = "";
    		book = abc_common.strip(book);
    		var tunes = book.split("\nX:");
    		for (var i = 1; i < tunes.length; i++)	// Put back the X: that we lost when splitting the tunes.
    			tunes[i] = "X:" + tunes[i];
    		// Keep track of the character position each tune starts with.
    		var pos = 0;
    		This.tunes = [];
    		abc_common.each(tunes, function(tune) {
    			This.tunes.push({ abc: tune, startPos: pos});
    			pos += tune.length + 1; // We also lost a newline when splitting, so count that.
    		});
    		if (This.tunes.length > 1 && !abc_common.startsWith(This.tunes[0].abc, 'X:')) {	// If there is only one tune, the X: might be missing, otherwise assume the top of the file is "intertune"
    			// There could be file-wide directives in this, if so, we need to insert it into each tune. We can probably get away with
    			// just looking for file-wide directives here (before the first tune) and inserting them at the bottom of each tune, since
    			// the tune is parsed all at once. The directives will be seen before the engraver begins processing.
    			var dir = This.tunes.shift();
    			var arrDir = dir.abc.split('\n');
    			abc_common.each(arrDir, function(line) {
    				if (abc_common.startsWith(line, '%%'))
    					directives += line + '\n';
    			});
    		}
    		This.header = directives;

    		// Now, the tune ends at a blank line, so truncate it if needed. There may be "intertune" stuff.
    		abc_common.each(This.tunes, function(tune) {
    			var end = tune.abc.indexOf('\n\n');
    			if (end > 0)
    				tune.abc = tune.abc.substring(0, end);
    			tune.pure = tune.abc;
    			tune.abc = directives + tune.abc;

    			// for the user's convenience, parse and store the title separately. The title is between the first T: and the next \n
    			var title = tune.pure.split("T:");
    			if (title.length > 1) {
    				title = title[1].split("\n");
    				tune.title = title[0].replace(/^\s+|\s+$/g, '');
    			} else
    				tune.title = "";

    			// for the user's convenience, parse and store the id separately. The id is between the first X: and the next \n
    			var id = tune.pure.substring(2, tune.pure.indexOf("\n"));
    			tune.id = id.replace(/^\s+|\s+$/g, '');
    		});
    	};

    	TuneBook.prototype.getTuneById = function(id) {
    		for (var i = 0; i < this.tunes.length; i++) {
    			if (this.tunes[i].id === ''+id)
    				return this.tunes[i];
    		}
    		return null;
    	};

    	TuneBook.prototype.getTuneByTitle = function(title) {
    		for (var i = 0; i < this.tunes.length; i++) {
    			if (this.tunes[i].title === title)
    				return this.tunes[i];
    		}
    		return null;
    	};

    	tunebook.parseOnly = function(abc, params) {
    		var numTunes = tunebook.numberOfTunes(abc);

    		// this just needs to be passed in because this tells the engine how many tunes to process.
    		var output = [];
    		for (var i = 0; i < numTunes; i++) {
    			output.push(1);
    		}
    		function callback() {
    			// Don't need to do anything with the parsed tunes.
    		}
    		return tunebook.renderEngine(callback, output, abc, params);
    	};

    	tunebook.renderEngine = function (callback, output, abc, params) {
    		var ret = [];
    		var isArray = function(testObject) {
    			return testObject && !(testObject.propertyIsEnumerable('length')) && typeof testObject === 'object' && typeof testObject.length === 'number';
    		};

    		// check and normalize input parameters
    		if (output === undefined || abc === undefined)
    			return;
    		if (!isArray(output))
    			output = [ output ];
    		if (params === undefined)
    			params = {};
    		var currentTune = params.startingTune ? parseInt(params.startingTune, 10) : 0;

    		// parse the abc string
    		var book = new TuneBook(abc);
    		var abcParser = new abc_parse();

    		// output each tune, if it exists. Otherwise clear the div.
    		for (var i = 0; i < output.length; i++) {
    			var div = output[i];
    			if (div === "*") ; else if (typeof(div) === "string")
    				div = document.getElementById(div);
    			if (div) {
    				if (currentTune >= 0 && currentTune < book.tunes.length) {
    					abcParser.parse(book.tunes[currentTune].abc, params, book.tunes[currentTune].startPos - book.header.length);
    					var tune = abcParser.getTune();
    					var override = callback(div, tune, i, book.tunes[currentTune].abc);
    					ret.push(override ? override : tune);
    				} else {
    					if (div.hasOwnProperty('innerHTML'))
    						div.innerHTML = "";
    				}
    			}
    			currentTune++;
    		}
    		return ret;
    	};

    	tunebook.extractMeasures = function(abc) {
    		var tunes = [];
    		var book = new TuneBook(abc);
    		for (var i = 0; i < book.tunes.length; i++) {
    			var tune = book.tunes[i];
    			var arr = tune.abc.split("K:");
    			var arr2 = arr[1].split("\n");
    			var header = arr[0] + "K:" + arr2[0] + "\n";
    			var lastChord = null;
    			var measureStartChord = null;
    			var fragStart = null;
    			var measures = [];
    			var hasNotes = false;
    			var tuneObj = tunebook.parseOnly(tune.abc)[0];
    			var hasPickup = tuneObj.getPickupLength() > 0;
    			// var staves = flattenTune(tuneObj);
    			// for (var s = 0; s < staves.length; s++) {
    			// 	var voices = measuresParser(staves[s], tune);
    			// 	if (s === 0)
    			// 		measures = voices;
    			// 	else {
    			// 		for (var ss = 0; ss < voices.length; ss++) {
    			// 			var voice = voices[ss];
    			// 			if (measures.length <= ss)
    			// 				measures.push([]);
    			// 			var measureVoice = measures[ss];
    			// 			for (var sss = 0; sss < voice.length; sss++) {
    			// 				if (measureVoice.length > sss)
    			// 					measureVoice[sss].abc += "\n" + voice[sss].abc;
    			// 				else
    			// 					measures.push(voice[sss]);
    			// 			}
    			// 		}
    			// 	}
    			// 	console.log(voices);
    			// }
    			// measures = measures[0];

    			for (var j = 0; j < tuneObj.lines.length; j++) {
    				var line = tuneObj.lines[j];
    				if (line.staff) {
    					for (var k = 0; k < 1 /*line.staff.length*/; k++) {
    						var staff = line.staff[k];
    						for (var kk = 0; kk < 1 /*staff.voices.length*/; kk++) {
    							var voice = staff.voices[kk];
    							for (var kkk = 0; kkk < voice.length; kkk++) {
    								var elem = voice[kkk];
    								if (fragStart === null && elem.startChar >= 0) {
    									fragStart = elem.startChar;
    									if (elem.chord === undefined)
    										measureStartChord = lastChord;
    									else
    										measureStartChord = null;
    								}
    								if (elem.chord)
    									lastChord = elem;
    								if (elem.el_type === 'bar') {
    									if (hasNotes) {
    										var frag = tune.abc.substring(fragStart, elem.endChar);
    										var measure = {abc: frag};
    										lastChord = measureStartChord && measureStartChord.chord && measureStartChord.chord.length > 0 ? measureStartChord.chord[0].name : null;
    										if (lastChord)
    											measure.lastChord = lastChord;
    										if (elem.startEnding)
    											measure.startEnding = elem.startEnding;
    										if (elem.endEnding)
    											measure.endEnding = elem.endEnding;
    										measures.push(measure);
    										fragStart = null;
    										hasNotes = false;
    									}
    								} else if (elem.el_type === 'note') {
    									hasNotes = true;
    								}
    							}
    						}
    					}
    				}
    			}
    			tunes.push({
    				header: header,
    				measures: measures,
    				hasPickup: hasPickup
    			});
    		}
    		return tunes;
    	};
    })();

    var abc_tunebook = tunebook;

    //    abc_absolute_element.js: Definition of the AbsoluteElement class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



    // duration - actual musical duration - different from notehead duration in triplets. refer to abcelem to get the notehead duration
    // minspacing - spacing which must be taken on top of the width defined by the duration
    // type is a meta-type for the element. It is not necessary for drawing, but it is useful to make semantic sense of the element. For instance, it can be used in the element's class name.
    var AbsoluteElement = function AbsoluteElement(abcelem, duration, minspacing, type, tuneNumber, options) {
    	//console.log("Absolute:",abcelem, type);
    	if (!options)
    		options = {};
    	this.tuneNumber = tuneNumber;
    	this.abcelem = abcelem;
    	this.duration = duration;
    	this.durationClass = options.durationClassOveride ? options.durationClassOveride : this.duration;
    	this.minspacing = minspacing || 0;
    	this.x = 0;
    	this.children = [];
    	this.heads = [];
    	this.extra = [];
    	this.extraw = 0;
    	//this.decs = [];
    	this.w = 0;
    	this.right = [];
    	this.invisible = false;
    	this.bottom = undefined;
    	this.top = undefined;
    	this.type = type;
    	// these are the heights of all of the vertical elements that can't be placed until the end of the line.
    	// the vertical order of elements that are above is: tempo, part, volume/dynamic, ending/chord, lyric
    	// the vertical order of elements that are below is: lyric, chord, volume/dynamic
    	this.specialY = {
    		tempoHeightAbove: 0,
    		partHeightAbove: 0,
    		volumeHeightAbove: 0,
    		dynamicHeightAbove: 0,
    		endingHeightAbove: 0,
    		chordHeightAbove: 0,
    		lyricHeightAbove: 0,

    		lyricHeightBelow: 0,
    		chordHeightBelow: 0,
    		volumeHeightBelow: 0,
    		dynamicHeightBelow: 0
    	};
    };

    // For each of the relative elements that can't be placed in advance (because their vertical placement depends on everything
    // else on the line), this iterates through them and sets their pitch. By the time this is called, specialYResolved contains a
    // hash with the vertical placement (in pitch units) for each type.
    // TODO-PER: I think this needs to be separated by "above" and "below". How do we know that for dynamics at the point where they are being defined, though? We need a pass through all the relative elements to set "above" and "below".
    AbsoluteElement.prototype.setUpperAndLowerElements = function(specialYResolved) {
    	// specialYResolved contains the actual pitch for each of the classes of elements.
    	for (var i = 0; i < this.children.length; i++) {
    		var child = this.children[i];
    		for (var key in this.specialY) { // for each class of element that needs to be placed vertically
    			if (this.specialY.hasOwnProperty(key)) {
    				if (child[key]) { // If this relative element has defined a height for this class of element
    					child.pitch = specialYResolved[key];
    					if (child.top === undefined) { // TODO-PER: HACK! Not sure this is the right place to do this.
    						child.setUpperAndLowerElements(specialYResolved);
    						this.pushTop(child.top);
    						this.pushBottom(child.bottom);
    					}
    				}
    			}
    		}
    	}
    };

    AbsoluteElement.prototype.getMinWidth = function () { // absolute space taken to the right of the note
    	return this.w;
    };

    AbsoluteElement.prototype.getExtraWidth = function () { // space needed to the left of the note
    	return -this.extraw;
    };

    AbsoluteElement.prototype.addExtra = function (extra) {
    	if (extra.dx<this.extraw) this.extraw = extra.dx;
    	this.extra[this.extra.length] = extra;
    	this.addChild(extra);
    };

    AbsoluteElement.prototype.addHead = function (head) {
    	if (head.dx<this.extraw) this.extraw = head.dx;
    	this.heads[this.heads.length] = head;
    	this.addRight(head);
    };

    AbsoluteElement.prototype.addRight = function (right) {
    	if (right.dx+right.w>this.w) this.w = right.dx+right.w;
    	this.right[this.right.length] = right;
    	this.addChild(right);
    };

    AbsoluteElement.prototype.addCentered = function (elem) {
    	var half = elem.w/2;
    	if (-half<this.extraw) this.extraw = -half;
    	this.extra[this.extra.length] = elem;
    	if (elem.dx+half>this.w) this.w = elem.dx+half;
    	this.right[this.right.length] = elem;
    	this.addChild(elem);
    };

    AbsoluteElement.prototype.setLimit = function(member, child) {
    	if (!child[member]) return;
    	if (!this.specialY[member])
    		this.specialY[member] = child[member];
    	else
    		this.specialY[member] = Math.max(this.specialY[member], child[member]);
    };

    AbsoluteElement.prototype.addChild = function (child) {
    	//console.log("Relative:",child);
    	child.parent = this;
    	this.children[this.children.length] = child;
    	this.pushTop(child.top);
    	this.pushBottom(child.bottom);
    	this.setLimit('tempoHeightAbove', child);
    	this.setLimit('partHeightAbove', child);
    	this.setLimit('volumeHeightAbove', child);
    	this.setLimit('dynamicHeightAbove', child);
    	this.setLimit('endingHeightAbove', child);
    	this.setLimit('chordHeightAbove', child);
    	this.setLimit('lyricHeightAbove', child);
    	this.setLimit('lyricHeightBelow', child);
    	this.setLimit('chordHeightBelow', child);
    	this.setLimit('volumeHeightBelow', child);
    	this.setLimit('dynamicHeightBelow', child);
    };

    AbsoluteElement.prototype.pushTop = function (top) {
    	if (top !== undefined) {
    		if (this.top === undefined)
    			this.top = top;
    		else
    			this.top = Math.max(top, this.top);
    	}
    };

    AbsoluteElement.prototype.pushBottom = function (bottom) {
    	if (bottom !== undefined) {
    		if (this.bottom === undefined)
    			this.bottom = bottom;
    		else
    			this.bottom = Math.min(bottom, this.bottom);
    	}
    };

    AbsoluteElement.prototype.setX = function (x) {
    	this.x = x;
    	for (var i=0; i<this.children.length; i++)
    		this.children[i].setX(x);
    };

    AbsoluteElement.prototype.setHint = function () {
    	this.hint = true;
    };

    AbsoluteElement.prototype.draw = function (renderer, bartop) {
    	if (this.invisible) return;
    	this.elemset = [];
    	renderer.beginGroup();
    	for (var i=0; i<this.children.length; i++) {
    		var el = this.children[i].draw(renderer,bartop);
    		if (el)
    			this.elemset.push(el);
    	}
    	var klass = this.type;
    	if (this.type === 'note' || this.type === 'rest') {
    		klass += ' d' + this.durationClass;
    		klass = klass.replace(/\./g, '-');
    		if (this.abcelem.pitches) {
    			for (var j = 0; j < this.abcelem.pitches.length; j++) {
    				klass += ' p' + this.abcelem.pitches[j].pitch;
    			}
    		}
    	}
    	var g = renderer.endGroup(klass);
    	if (g)
    		this.elemset.push(g);
    	if (this.klass)
    		this.setClass("mark", "", "#00ff00");
    	if (this.hint)
    		this.setClass("abcjs-hint", "", null);
    	var opacity = /*ABCJS.write.debugPlacement*/ 0; // Create transparent box that encompasses the element, and not so transparent to debug it.
    	var target = renderer.printShadedBox(this.x, renderer.calcY(this.top), this.w, renderer.calcY(this.bottom)-renderer.calcY(this.top), "#000000", opacity);
    	var self = this;
    	var controller = renderer.controller;
    	target.addEventListener('mouseup', function () {
    		var classes = [];
    		if (self.elemset) {
    			for (var j = 0; j < self.elemset.length; j++) {
    				var es = self.elemset[j];
    				if (es)
    					classes.push(es.getAttribute("class"));
    			}
    		}
    		controller.notifySelect(self, self.tuneNumber, classes);
    	});
    	this.abcelem.abselem = this;
    };

    AbsoluteElement.prototype.isIE=/*@cc_on!@*/false;//IE detector

    AbsoluteElement.prototype.setClass = function (addClass, removeClass, color) {
    	for (var i = 0; i < this.elemset.length; i++) {
    		var el = this.elemset[i];
    		el.setAttribute("fill", color);
    		var kls = el.getAttribute("class");
    		if (!kls) kls = "";
    		kls = kls.replace(removeClass, "");
    		kls = kls.replace(addClass, "");
    		if (addClass.length > 0) {
    			if (kls.length > 0 && kls.charAt(kls.length - 1) !== ' ') kls += " ";
    			kls += addClass;
    		}
    		el.setAttribute("class", kls);
    	}
    };

    AbsoluteElement.prototype.highlight = function (klass, color) {
    	if (klass === undefined)
    		klass = "abcjs-note_selected";
    	if (color === undefined)
    		color = "#ff0000";
    	this.setClass(klass, "", color);
    };

    AbsoluteElement.prototype.unhighlight = function (klass, color) {
    	if (klass === undefined)
    		klass = "abcjs-note_selected";
    	if (color === undefined)
    		color = "#000000";
    	this.setClass("", klass, color);
    };

    var abc_absolute_element = AbsoluteElement;

    //    abc_relative_element.js: Definition of the RelativeElement class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    var RelativeElement = function RelativeElement(c, dx, w, pitch, opt) {
    	opt = opt || {};
    	this.x = 0;
    	this.c = c;      // character or path or string
    	this.dx = dx;    // relative x position
    	this.w = w;      // minimum width taken up by this element (can include gratuitous space)
    	this.pitch = pitch; // relative y position by pitch
    	this.scalex = opt.scalex || 1; // should the character/path be scaled?
    	this.scaley = opt.scaley || 1; // should the character/path be scaled?
    	this.type = opt.type || "symbol"; // cheap types.
    	this.pitch2 = opt.pitch2;
    	this.linewidth = opt.linewidth;
    	this.klass = opt.klass;
    	this.top = pitch;
    	if (this.pitch2 !== undefined && this.pitch2 > this.top) this.top = this.pitch2;
    	this.bottom = pitch;
    	if (this.pitch2 !== undefined && this.pitch2 < this.bottom) this.bottom = this.pitch2;
    	if (opt.thickness) {
    		this.top += opt.thickness/2;
    		this.bottom -= opt.thickness/2;
    	}
    	if (opt.stemHeight) {
    		if (opt.stemHeight > 0)
    			this.top += opt.stemHeight;
    		else
    			this.bottom += opt.stemHeight;
    	}
    	//if (this.type === "symbol") {
    	//	var offset = glyphs.getYCorr(this.c);
    	//	this.top += offset;
    	//	this.bottom += offset;
    	//}
    	this.height = opt.height ? opt.height : 4; // The +1 is to give a little bit of padding.
    	this.centerVertically = false;
    	switch (this.type) {
    		case "debug":
    			this.chordHeightAbove = this.height;
    			break;
    		case "lyric":
    			if (opt.position && opt.position === 'below')
    				this.lyricHeightBelow = this.height;
    			else
    				this.lyricHeightAbove = this.height;
    			break;
    		case "chord":
    			if (opt.position && opt.position === 'below')
    				this.chordHeightBelow = this.height;
    			else
    				this.chordHeightAbove = this.height;
    			break;
    		case "text":
    			if (this.pitch === undefined) {
    				if (opt.position && opt.position === 'below')
    					this.chordHeightBelow = this.height;
    				else
    					this.chordHeightAbove = this.height;
    			} else
    				this.centerVertically = true;
    			break;
    		case "part": this.partHeightAbove = this.height; break;
    	}
    };

    RelativeElement.prototype.setX = function (x) {
    	this.x = x+this.dx;
    };

    RelativeElement.prototype.setUpperAndLowerElements = function(positionY) {
    	switch(this.type) {
    		case "part":
    			this.top = positionY.partHeightAbove + this.height;
    			this.bottom = positionY.partHeightAbove;
    			break;
    		case "text":
    		case "chord":
    			if (this.chordHeightAbove) {
    				this.top = positionY.chordHeightAbove;
    				this.bottom = positionY.chordHeightAbove;
    			} else {
    				this.top = positionY.chordHeightBelow;
    				this.bottom = positionY.chordHeightBelow;
    			}
    			break;
    		case "lyric":
    			if (this.lyricHeightAbove) {
    				this.top = positionY.lyricHeightAbove;
    				this.bottom = positionY.lyricHeightAbove;
    			} else {
    				this.top = positionY.lyricHeightBelow;
    				this.bottom = positionY.lyricHeightBelow;
    			}
    			break;
    		case "debug":
    			this.top = positionY.chordHeightAbove;
    			this.bottom = positionY.chordHeightAbove;
    			break;
    	}
    	if (this.pitch === undefined || this.top === undefined)
    		window.console.error("RelativeElement position not set.", this.type, this.pitch, this.top, positionY);
    };

    RelativeElement.prototype.draw = function (renderer, bartop) {
    	if (this.pitch === undefined)
    		window.console.error(this.type + " Relative Element y-coordinate not set.");
    	var y = renderer.calcY(this.pitch);
    	switch(this.type) {
    		case "symbol":
    			if (this.c===null) return null;
    			var klass = "symbol";
    			if (this.klass) klass += " " + this.klass;
    			this.graphelem = renderer.printSymbol(this.x, this.pitch, this.c, this.scalex, this.scaley, renderer.addClasses(klass)); break;
    		case "debug":
    			this.graphelem = renderer.renderText(this.x, renderer.calcY(15), ""+this.c, "debugfont", 'debug-msg', 'start'); break;
    		case "barNumber":
    			this.graphelem = renderer.renderText(this.x, y, ""+this.c, "measurefont", 'bar-number', "middle");
    			break;
    		case "lyric":
    			this.graphelem = renderer.renderText(this.x, y, this.c, "vocalfont", 'lyric', "middle");
    			break;
    		case "chord":
    			this.graphelem = renderer.renderText(this.x, y, this.c, 'gchordfont', "chord", "middle");
    			break;
    		case "decoration":
    			this.graphelem = renderer.renderText(this.x, y, this.c, 'annotationfont', "annotation", "middle", true);
    			break;
    		case "text":
    			this.graphelem = renderer.renderText(this.x, y, this.c, 'annotationfont', "annotation", "start", this.centerVertically);
    			break;
    		case "multimeasure-text":
    			this.graphelem = renderer.renderText(this.x+this.w/2, y, this.c, 'tempofont', "rest", "middle", false);
    			break;
    		case "part":
    			this.graphelem = renderer.renderText(this.x, y, this.c, 'partsfont', "part", "start");
    			break;
    		case "bar":
    			this.graphelem = renderer.printStem(this.x, this.linewidth, y, (bartop)?bartop:renderer.calcY(this.pitch2)); break; // bartop can't be 0
    		case "stem":
    			this.graphelem = renderer.printStem(this.x, this.linewidth, y, renderer.calcY(this.pitch2)); break;
    		case "ledger":
    			this.graphelem = renderer.printStaveLine(this.x, this.x+this.w, this.pitch); break;
    	}
    	if (this.scalex!==1 && this.graphelem) {
    		renderer.scaleExistingElem(this.graphelem, this.scalex, this.scaley, this.x, y);
    	}
    	return this.graphelem;
    };

    var abc_relative_element = RelativeElement;

    //    abc_beam_element.js: Definition of the BeamElem class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.





    var getDurlog = function(duration) {
            // TODO-PER: This is a hack to prevent a Chrome lockup. Duration should have been defined already,
            // but there's definitely a case where it isn't. [Probably something to do with triplets.]
            if (duration === undefined) {
                    return 0;
            }
    //        console.log("getDurlog: " + duration);
      return Math.floor(Math.log(duration)/Math.log(2));
    };


    // Most elements on the page are related to a particular absolute element -- notes, rests, bars, etc. Beams, however, span multiple elements.
    // This means that beams can't be laid out until the absolute elements are placed. There is the further complication that the stems for beamed
    // notes can't be laid out until the beams are because we don't know how long they will be until we know the slope of the beam and the horizontal
    // spacing of the absolute elements.
    //
    // So, when a beam is detected, a BeamElem is created, then all notes belonging to that beam are added to it. These notes are not given stems at that time.
    // Then, after the horizontal layout is complete, all of the BeamElem are iterated to set the beam position, then all of the notes that are beamed are given
    // stems. After that, we are ready for the drawing step.

    // There are three phases: the setup phase, when new elements are being discovered, the layout phase, when everything is calculated, and the drawing phase,
    // when the object is not changed, but is used to put the elements on the page.

    var BeamElem;

    (function() {

    	//
    	// Setup phase
    	//
    	BeamElem = function BeamElem(stemHeight, type, flat) {
    		// type is "grace", "up", "down", or undefined. flat is used to force flat beams, as it commonly found in the grace notes of bagpipe music.
    		this.isflat = flat;
    		this.isgrace = (type && type === "grace");
    		this.forceup = this.isgrace || (type && type === "up");
    		this.forcedown = (type && type === "down");
    		this.elems = []; // all the AbsoluteElements that this beam touches. It may include embedded rests.
    		this.total = 0;
    		this.allrests = true;
    		this.stemHeight = stemHeight;
    		this.beams = []; // During the layout phase, this will become a list of the beams that need to be drawn.
    	};

    	BeamElem.prototype.setHint = function () {
    		this.hint = true;
    	};

    	BeamElem.prototype.add = function(abselem) {
    		var pitch = abselem.abcelem.averagepitch;
    		if (pitch === undefined) return; // don't include elements like spacers in beams
    		this.allrests = this.allrests && abselem.abcelem.rest;
    		abselem.beam = this;
    		this.elems.push(abselem);
    		//var pitch = abselem.abcelem.averagepitch;
    		this.total += pitch; // TODO CHORD (get pitches from abselem.heads)
    		if (this.min === undefined || abselem.abcelem.minpitch < this.min) {
    			this.min = abselem.abcelem.minpitch;
    		}
    		if (this.max === undefined || abselem.abcelem.maxpitch > this.max) {
    			this.max = abselem.abcelem.maxpitch;
    		}
    	};

    	var middleLine = 6;	// hardcoded 6 is B

    	BeamElem.prototype.calcDir = function() {
    		if (this.forceup) return true;
    		if (this.forcedown) return false;
    		var average = calcAverage(this.total, this.elems.length);
    		return average < middleLine;
    	};

    	//
    	// layout phase
    	//
    	BeamElem.prototype.layout = function() {
    		if (this.elems.length === 0 || this.allrests) return;

    		this.stemsUp = this.calcDir(); // True means the stems are facing up.
    		var dy = calcDy(this.stemsUp, this.isgrace); // This is the width of the beam line.

    		// create the main beam
    		var firstElement = this.elems[0];
    		var lastElement = this.elems[this.elems.length - 1];
    		var minStemHeight = 0; // The following is to leave space for "!///!" marks.
    		var referencePitch = this.stemsUp ? firstElement.abcelem.maxpitch : firstElement.abcelem.minpitch;
    		minStemHeight = minStem(firstElement, this.stemsUp, referencePitch, minStemHeight);
    		minStemHeight = minStem(lastElement, this.stemsUp, referencePitch, minStemHeight);
    		minStemHeight = Math.max(this.stemHeight, minStemHeight + 3); // TODO-PER: The 3 is the width of a 16th beam. The actual height of the beam should be used instead.
    		var yPos = calcYPos(this.total, this.elems.length, minStemHeight, this.stemsUp, firstElement.abcelem.averagepitch, lastElement.abcelem.averagepitch, this.isflat, this.min, this.max, this.isgrace);
    		var xPos = calcXPos(this.stemsUp, firstElement, lastElement);
    		this.beams.push({ startX: xPos[0], endX: xPos[1], startY: yPos[0], endY: yPos[1], dy: dy });

    		// create the rest of the beams (in the case of 1/16th notes, etc.
    		var beams = createAdditionalBeams(this.elems, this.stemsUp, this.beams[0], this.isgrace, dy);
    		for (var i = 0; i < beams.length; i++)
    			this.beams.push(beams[i]);

    		// Now that the main beam is defined, we know how tall the stems should be, so create them and attach them to the original notes.
    		createStems(this.elems, this.stemsUp, this.beams[0], dy, this.mainNote);
    	};

    	BeamElem.prototype.isAbove = function() {
    		return this.stemsUp;
    	};

    	// We can't just use the entire beam for the calculation. The range has to be passed in, because the beam might extend into some unrelated notes. for instance, (3_a'f'e'f'2 when L:16
    	BeamElem.prototype.heightAtMidpoint = function(startX, endX) {
    		if (this.beams.length === 0)
    			return 0;
    		var beam = this.beams[0];
    		var midPoint = startX + (endX - startX) / 2;
    		return getBarYAt(beam.startX, beam.startY, beam.endX, beam.endY, midPoint);
    	};

    	BeamElem.prototype.yAtNote = function(element) {
    		var beam = this.beams[0];
    		return getBarYAt(beam.startX, beam.startY, beam.endX, beam.endY, element.x);
    	};

    	BeamElem.prototype.xAtMidpoint = function(startX, endX) {
    		return startX + (endX - startX)/2;
    	};

    	//
    	// Drawing phase
    	//
    	BeamElem.prototype.draw = function(renderer) {
    		if (this.beams.length === 0) return;

    		renderer.beginGroup();
    		for (var i = 0; i < this.beams.length; i++) {
    			var beam = this.beams[i];
    			drawBeam(renderer, beam.startX, beam.startY, beam.endX, beam.endY, beam.dy, this.hint);
    		}
    		renderer.endGroup('beam-elem');
    	};

    	//
    	// private functions
    	//
    	function minStem(element, stemsUp, referencePitch, minStemHeight) {
    		if (!element.children)
    			return minStemHeight;
    		for (var i = 0; i < element.children.length; i++) {
    			var elem = element.children[i];
    			if (stemsUp && elem.top !== undefined && elem.c === "flags.ugrace")
    				minStemHeight = Math.max(minStemHeight, elem.top - referencePitch);
    			else if (!stemsUp && elem.bottom !== undefined && elem.c === "flags.ugrace")
    				minStemHeight = Math.max(minStemHeight, referencePitch - elem.bottom + 7); // The extra 7 is because we are measuring the slash from the top.
    		}
    		return minStemHeight;
    	}

    	function calcSlant(leftAveragePitch, rightAveragePitch, numStems, isFlat) {
    		if (isFlat)
    			return 0;
    		var slant = leftAveragePitch - rightAveragePitch;
    		var maxSlant = numStems / 2;

    		if (slant > maxSlant) slant = maxSlant;
    		if (slant < -maxSlant) slant = -maxSlant;
    		return slant;
    	}

    	function calcAverage(total, numElements) {
    		if (!numElements)
    			return 0;
    		return total / numElements;
    	}

    	function getBarYAt(startx, starty, endx, endy, x) {
    		return starty + (endy - starty) / (endx - startx) * (x - startx);
    	}

    	function calcDy(asc, isGrace) {
    		var dy = (asc) ? abc_spacing.STEP : -abc_spacing.STEP;
    		if (isGrace) dy = dy * 0.4;
    		return dy;
    	}

    	function drawBeam(renderer, startX, startY, endX, endY, dy, isHint) {
    		var klass = 'beam-elem';
    		if (isHint)
    			klass += " abcjs-hint";

    		// the X coordinates are actual coordinates, but the Y coordinates are in pitches.
    		startY = renderer.calcY(startY);
    		endY = renderer.calcY(endY);
    		var pathString = "M" + startX + " " + startY + " L" + endX + " " + endY +
    			"L" + endX + " " + (endY + dy) + " L" + startX + " " + (startY + dy) + "z";
    		renderer.printPath({
    			path: pathString,
    			stroke: "none",
    			fill: "#000000",
    			'class': renderer.addClasses(klass)
    		});
    	}

    	function calcXPos(asc, firstElement, lastElement) {
    		var starthead = firstElement.heads[asc ? 0 : firstElement.heads.length - 1];
    		var endhead = lastElement.heads[asc ? 0 : lastElement.heads.length - 1];
    		var startX = starthead.x;
    		if (asc) startX += starthead.w - 0.6;
    		var endX = endhead.x;
    		if (asc) endX += endhead.w;
    		return [ startX, endX ];
    	}

    	function calcYPos(total, numElements, stemHeight, asc, firstAveragePitch, lastAveragePitch, isFlat, minPitch, maxPitch, isGrace) {
    		var average = calcAverage(total, numElements); // This is the average pitch for the all the notes that will be beamed.
    		var barpos = stemHeight - 2; // (isGrace)? 5:7;
    		var barminpos = stemHeight - 2;
    		var pos = Math.round(asc ? Math.max(average + barpos, maxPitch + barminpos) : Math.min(average - barpos, minPitch - barminpos));

    		var slant = calcSlant(firstAveragePitch, lastAveragePitch, numElements, isFlat);
    		var startY = pos + Math.floor(slant / 2);
    		var endY = pos + Math.floor(-slant / 2);

    		// If the notes are too high or too low, make the beam go down to the middle
    		if (!isGrace) {
    			if (asc && pos < 6) {
    				startY = 6;
    				endY = 6;
    			} else if (!asc && pos > 6) {
    				startY = 6;
    				endY = 6;
    			}
    		}

    		return [ startY, endY];
    	}

    	function createStems(elems, asc, beam, dy, mainNote) {
    		for (var i = 0; i < elems.length; i++) {
    			var elem = elems[i];
    			if (elem.abcelem.rest)
    				continue;
    			// TODO-PER: This is odd. If it is a regular beam then elems is an array of AbsoluteElements, if it is a grace beam then it is an array of objects , so we directly attach the element to the parent. We tell it if is a grace note because they are passed in as a generic object instead of an AbsoluteElement.
    			var isGrace = elem.addExtra ? false : true;
    			var parent = isGrace ? mainNote : elem;
    			var furthestHead = elem.heads[(asc) ? 0 : elem.heads.length - 1];
    			var ovalDelta = 1 / 5;//(isGrace)?1/3:1/5;
    			var pitch = furthestHead.pitch + ((asc) ? ovalDelta : -ovalDelta);
    			var dx = asc ? furthestHead.w : 0; // down-pointing stems start on the left side of the note, up-pointing stems start on the right side, so we offset by the note width.
    			var x = furthestHead.x + dx; // this is now the actual x location in pixels.
    			var bary = getBarYAt(beam.startX, beam.startY, beam.endX, beam.endY, x);
    			var lineWidth = (asc) ? -0.6 : 0.6;
    			if (!asc)
    				bary -= (dy / 2) / abc_spacing.STEP;	// TODO-PER: This is just a fudge factor so the down-pointing stems don't overlap.
    			if (isGrace)
    				dx += elem.heads[0].dx;
    			// TODO-PER-HACK: One type of note head has a different placement of the stem. This should be more generically calculated:
    			if (furthestHead.c === 'noteheads.slash.quarter') {
    				if (asc)
    					pitch += 1;
    				else
    					pitch -= 1;
    			}
    			var stem = new abc_relative_element(null, dx, 0, pitch, {
    				"type": "stem",
    				"pitch2": bary,
    				linewidth: lineWidth
    			});
    			stem.setX(parent.x); // This is after the x coordinates were set, so we have to set it directly.
    			parent.addExtra(stem);
    		}

    	}

    	function createAdditionalBeams(elems, asc, beam, isGrace, dy) {
    		var beams = [];
    		var auxBeams = [];  // auxbeam will be {x, y, durlog, single} auxbeam[0] should match with durlog=-4 (16th) (j=-4-durlog)
    		for (var i = 0; i < elems.length; i++) {
    			var elem = elems[i];
    			if (elem.abcelem.rest)
    				continue;
    			var furthestHead = elem.heads[(asc) ? 0 : elem.heads.length - 1];
    			var x = furthestHead.x + ((asc) ? furthestHead.w : 0);
    			var bary = getBarYAt(beam.startX, beam.startY, beam.endX, beam.endY, x);

    			var sy = (asc) ? -1.5 : 1.5;
    			if (isGrace) sy = sy * 2 / 3; // This makes the second beam on grace notes closer to the first one.
    			var duration = elem.abcelem.duration; // get the duration via abcelem because of triplets
    			if (duration === 0) duration = 0.25; // if this is stemless, then we use quarter note as the duration.
    			for (var durlog = getDurlog(duration); durlog < -3; durlog++) {
    				if (auxBeams[-4 - durlog]) {
    					auxBeams[-4 - durlog].single = false;
    				} else {
    					auxBeams[-4 - durlog] = {
    						x: x + ((asc) ? -0.6 : 0), y: bary + sy * (-4 - durlog + 1),
    						durlog: durlog, single: true
    					};
    				}
    			}

    			for (var j = auxBeams.length - 1; j >= 0; j--) {
    				if (i === elems.length - 1 || getDurlog(elems[i + 1].abcelem.duration) > (-j - 4)) {

    					var auxBeamEndX = x;
    					var auxBeamEndY = bary + sy * (j + 1);


    					if (auxBeams[j].single) {
    						auxBeamEndX = (i === 0) ? x + 5 : x - 5;
    						auxBeamEndY = getBarYAt(beam.startX, beam.startY, beam.endX, beam.endY, auxBeamEndX) + sy * (j + 1);
    					}
    					beams.push({ startX: auxBeams[j].x, endX: auxBeamEndX, startY: auxBeams[j].y, endY: auxBeamEndY, dy: dy });
    					auxBeams = auxBeams.slice(0, j);
    				}
    			}
    		}
    		return beams;
    	}
    })();

    var abc_beam_element = BeamElem;

    //    abc_brace_element.js: Definition of the BraceElement class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    var BraceElem = function BraceElem() {
        this.length = 1;
    };

    BraceElem.prototype.increaseStavesIncluded = function() {
        this.length++;
    };

    BraceElem.prototype.setLocation = function(x) {
    	this.x = x;
    };

    BraceElem.prototype.getWidth = function() {
    	return 10; // TODO-PER: right now the drawing function doesn't vary the width at all. If it does in the future then this will change.
    };

    BraceElem.prototype.layout = function (renderer, top, bottom) {
        this.startY = top;
        this.endY = bottom;
    };

    BraceElem.prototype.draw = function (renderer, top, bottom) {
        this.layout(renderer, top, bottom);
        renderer.drawBrace(this.x,this.startY, this.endY);

    };

    var abc_brace_element = BraceElem;

    /**
     * Glyphs and some methods to adjust for their x and y baseline
     */
    	var glyphs =
    	{'0':{d:[['M',4.83,-14.97],['c',0.33,-0.03,1.11,0.00,1.47,0.06],['c',1.68,0.36,2.97,1.59,3.78,3.60],['c',1.20,2.97,0.81,6.96,-0.90,9.27],['c',-0.78,1.08,-1.71,1.71,-2.91,1.95],['c',-0.45,0.09,-1.32,0.09,-1.77,0.00],['c',-0.81,-0.18,-1.47,-0.51,-2.07,-1.02],['c',-2.34,-2.07,-3.15,-6.72,-1.74,-10.20],['c',0.87,-2.16,2.28,-3.42,4.14,-3.66],['z'],['m',1.11,0.87],['c',-0.21,-0.06,-0.69,-0.09,-0.87,-0.06],['c',-0.54,0.12,-0.87,0.42,-1.17,0.99],['c',-0.36,0.66,-0.51,1.56,-0.60,3.00],['c',-0.03,0.75,-0.03,4.59,0.00,5.31],['c',0.09,1.50,0.27,2.40,0.60,3.06],['c',0.24,0.48,0.57,0.78,0.96,0.90],['c',0.27,0.09,0.78,0.09,1.05,0.00],['c',0.39,-0.12,0.72,-0.42,0.96,-0.90],['c',0.33,-0.66,0.51,-1.56,0.60,-3.06],['c',0.03,-0.72,0.03,-4.56,0.00,-5.31],['c',-0.09,-1.47,-0.27,-2.37,-0.60,-3.03],['c',-0.24,-0.48,-0.54,-0.78,-0.93,-0.90],['z']],w:10.78,h:14.959},
    		'1':{d:[['M',3.30,-15.06],['c',0.06,-0.06,0.21,-0.03,0.66,0.15],['c',0.81,0.39,1.08,0.39,1.83,0.03],['c',0.21,-0.09,0.39,-0.15,0.42,-0.15],['c',0.12,0.00,0.21,0.09,0.27,0.21],['c',0.06,0.12,0.06,0.33,0.06,5.94],['c',0.00,3.93,0.00,5.85,0.03,6.03],['c',0.06,0.36,0.15,0.69,0.27,0.96],['c',0.36,0.75,0.93,1.17,1.68,1.26],['c',0.30,0.03,0.39,0.09,0.39,0.30],['c',0.00,0.15,-0.03,0.18,-0.09,0.24],['c',-0.06,0.06,-0.09,0.06,-0.48,0.06],['c',-0.42,0.00,-0.69,-0.03,-2.10,-0.24],['c',-0.90,-0.15,-1.77,-0.15,-2.67,0.00],['c',-1.41,0.21,-1.68,0.24,-2.10,0.24],['c',-0.39,0.00,-0.42,0.00,-0.48,-0.06],['c',-0.06,-0.06,-0.06,-0.09,-0.06,-0.24],['c',0.00,-0.21,0.06,-0.27,0.36,-0.30],['c',0.75,-0.09,1.32,-0.51,1.68,-1.26],['c',0.12,-0.27,0.21,-0.60,0.27,-0.96],['c',0.03,-0.18,0.03,-1.59,0.03,-4.29],['c',0.00,-3.87,0.00,-4.05,-0.06,-4.14],['c',-0.09,-0.15,-0.18,-0.24,-0.39,-0.24],['c',-0.12,0.00,-0.15,0.03,-0.21,0.06],['c',-0.03,0.06,-0.45,0.99,-0.96,2.13],['c',-0.48,1.14,-0.90,2.10,-0.93,2.16],['c',-0.06,0.15,-0.21,0.24,-0.33,0.24],['c',-0.24,0.00,-0.42,-0.18,-0.42,-0.39],['c',0.00,-0.06,3.27,-7.62,3.33,-7.74],['z']],w:8.94,h:15.058},
    		'2':{d:[['M',4.23,-14.97],['c',0.57,-0.06,1.68,0.00,2.34,0.18],['c',0.69,0.18,1.50,0.54,2.01,0.90],['c',1.35,0.96,1.95,2.25,1.77,3.81],['c',-0.15,1.35,-0.66,2.34,-1.68,3.15],['c',-0.60,0.48,-1.44,0.93,-3.12,1.65],['c',-1.32,0.57,-1.80,0.81,-2.37,1.14],['c',-0.57,0.33,-0.57,0.33,-0.24,0.27],['c',0.39,-0.09,1.26,-0.09,1.68,0.00],['c',0.72,0.15,1.41,0.45,2.10,0.90],['c',0.99,0.63,1.86,0.87,2.55,0.75],['c',0.24,-0.06,0.42,-0.15,0.57,-0.30],['c',0.12,-0.09,0.30,-0.42,0.30,-0.51],['c',0.00,-0.09,0.12,-0.21,0.24,-0.24],['c',0.18,-0.03,0.39,0.12,0.39,0.30],['c',0.00,0.12,-0.15,0.57,-0.30,0.87],['c',-0.54,1.02,-1.56,1.74,-2.79,2.01],['c',-0.42,0.09,-1.23,0.09,-1.62,0.03],['c',-0.81,-0.18,-1.32,-0.45,-2.01,-1.11],['c',-0.45,-0.45,-0.63,-0.57,-0.96,-0.69],['c',-0.84,-0.27,-1.89,0.12,-2.25,0.90],['c',-0.12,0.21,-0.21,0.54,-0.21,0.72],['c',0.00,0.12,-0.12,0.21,-0.27,0.24],['c',-0.15,0.00,-0.27,-0.03,-0.33,-0.15],['c',-0.09,-0.21,0.09,-1.08,0.33,-1.71],['c',0.24,-0.66,0.66,-1.26,1.29,-1.89],['c',0.45,-0.45,0.90,-0.81,1.92,-1.56],['c',1.29,-0.93,1.89,-1.44,2.34,-1.98],['c',0.87,-1.05,1.26,-2.19,1.20,-3.63],['c',-0.06,-1.29,-0.39,-2.31,-0.96,-2.91],['c',-0.36,-0.33,-0.72,-0.51,-1.17,-0.54],['c',-0.84,-0.03,-1.53,0.42,-1.59,1.05],['c',-0.03,0.33,0.12,0.60,0.57,1.14],['c',0.45,0.54,0.54,0.87,0.42,1.41],['c',-0.15,0.63,-0.54,1.11,-1.08,1.38],['c',-0.63,0.33,-1.20,0.33,-1.83,0.00],['c',-0.24,-0.12,-0.33,-0.18,-0.54,-0.39],['c',-0.18,-0.18,-0.27,-0.30,-0.36,-0.51],['c',-0.24,-0.45,-0.27,-0.84,-0.21,-1.38],['c',0.12,-0.75,0.45,-1.41,1.02,-1.98],['c',0.72,-0.72,1.74,-1.17,2.85,-1.32],['z']],w:10.764,h:14.97},
    		'3':{d:[['M',3.78,-14.97],['c',0.30,-0.03,1.41,0.00,1.83,0.06],['c',2.22,0.30,3.51,1.32,3.72,2.91],['c',0.03,0.33,0.03,1.26,-0.03,1.65],['c',-0.12,0.84,-0.48,1.47,-1.05,1.77],['c',-0.27,0.15,-0.36,0.24,-0.45,0.39],['c',-0.09,0.21,-0.09,0.36,0.00,0.57],['c',0.09,0.15,0.18,0.24,0.51,0.39],['c',0.75,0.42,1.23,1.14,1.41,2.13],['c',0.06,0.42,0.06,1.35,0.00,1.71],['c',-0.18,0.81,-0.48,1.38,-1.02,1.95],['c',-0.75,0.72,-1.80,1.20,-3.18,1.38],['c',-0.42,0.06,-1.56,0.06,-1.95,0.00],['c',-1.89,-0.33,-3.18,-1.29,-3.51,-2.64],['c',-0.03,-0.12,-0.03,-0.33,-0.03,-0.60],['c',0.00,-0.36,0.00,-0.42,0.06,-0.63],['c',0.12,-0.30,0.27,-0.51,0.51,-0.75],['c',0.24,-0.24,0.45,-0.39,0.75,-0.51],['c',0.21,-0.06,0.27,-0.06,0.60,-0.06],['c',0.33,0.00,0.39,0.00,0.60,0.06],['c',0.30,0.12,0.51,0.27,0.75,0.51],['c',0.36,0.33,0.57,0.75,0.60,1.20],['c',0.00,0.21,0.00,0.27,-0.06,0.42],['c',-0.09,0.18,-0.12,0.24,-0.54,0.54],['c',-0.51,0.36,-0.63,0.54,-0.60,0.87],['c',0.06,0.54,0.54,0.90,1.38,0.99],['c',0.36,0.06,0.72,0.03,0.96,-0.06],['c',0.81,-0.27,1.29,-1.23,1.44,-2.79],['c',0.03,-0.45,0.03,-1.95,-0.03,-2.37],['c',-0.09,-0.75,-0.33,-1.23,-0.75,-1.44],['c',-0.33,-0.18,-0.45,-0.18,-1.98,-0.18],['c',-1.35,0.00,-1.41,0.00,-1.50,-0.06],['c',-0.18,-0.12,-0.24,-0.39,-0.12,-0.60],['c',0.12,-0.15,0.15,-0.15,1.68,-0.15],['c',1.50,0.00,1.62,0.00,1.89,-0.15],['c',0.18,-0.09,0.42,-0.36,0.54,-0.57],['c',0.18,-0.42,0.27,-0.90,0.30,-1.95],['c',0.03,-1.20,-0.06,-1.80,-0.36,-2.37],['c',-0.24,-0.48,-0.63,-0.81,-1.14,-0.96],['c',-0.30,-0.06,-1.08,-0.06,-1.38,0.03],['c',-0.60,0.15,-0.90,0.42,-0.96,0.84],['c',-0.03,0.30,0.06,0.45,0.63,0.84],['c',0.33,0.24,0.42,0.39,0.45,0.63],['c',0.03,0.72,-0.57,1.50,-1.32,1.65],['c',-1.05,0.27,-2.10,-0.57,-2.10,-1.65],['c',0.00,-0.45,0.15,-0.96,0.39,-1.38],['c',0.12,-0.21,0.54,-0.63,0.81,-0.81],['c',0.57,-0.42,1.38,-0.69,2.25,-0.81],['z']],w:9.735,h:14.967},
    		'4':{d:[['M',8.64,-14.94],['c',0.27,-0.09,0.42,-0.12,0.54,-0.03],['c',0.09,0.06,0.15,0.21,0.15,0.30],['c',-0.03,0.06,-1.92,2.31,-4.23,5.04],['c',-2.31,2.73,-4.23,4.98,-4.26,5.01],['c',-0.03,0.06,0.12,0.06,2.55,0.06],['l',2.61,0.00],['l',0.00,-2.37],['c',0.00,-2.19,0.03,-2.37,0.06,-2.46],['c',0.03,-0.06,0.21,-0.18,0.57,-0.42],['c',1.08,-0.72,1.38,-1.08,1.86,-2.16],['c',0.12,-0.30,0.24,-0.54,0.27,-0.57],['c',0.12,-0.12,0.39,-0.06,0.45,0.12],['c',0.06,0.09,0.06,0.57,0.06,3.96],['l',0.00,3.90],['l',1.08,0.00],['c',1.05,0.00,1.11,0.00,1.20,0.06],['c',0.24,0.15,0.24,0.54,0.00,0.69],['c',-0.09,0.06,-0.15,0.06,-1.20,0.06],['l',-1.08,0.00],['l',0.00,0.33],['c',0.00,0.57,0.09,1.11,0.30,1.53],['c',0.36,0.75,0.93,1.17,1.68,1.26],['c',0.30,0.03,0.39,0.09,0.39,0.30],['c',0.00,0.15,-0.03,0.18,-0.09,0.24],['c',-0.06,0.06,-0.09,0.06,-0.48,0.06],['c',-0.42,0.00,-0.69,-0.03,-2.10,-0.24],['c',-0.90,-0.15,-1.77,-0.15,-2.67,0.00],['c',-1.41,0.21,-1.68,0.24,-2.10,0.24],['c',-0.39,0.00,-0.42,0.00,-0.48,-0.06],['c',-0.06,-0.06,-0.06,-0.09,-0.06,-0.24],['c',0.00,-0.21,0.06,-0.27,0.36,-0.30],['c',0.75,-0.09,1.32,-0.51,1.68,-1.26],['c',0.21,-0.42,0.30,-0.96,0.30,-1.53],['l',0.00,-0.33],['l',-2.70,0.00],['c',-2.91,0.00,-2.85,0.00,-3.09,-0.15],['c',-0.18,-0.12,-0.30,-0.39,-0.27,-0.54],['c',0.03,-0.06,0.18,-0.24,0.33,-0.45],['c',0.75,-0.90,1.59,-2.07,2.13,-3.03],['c',0.33,-0.54,0.84,-1.62,1.05,-2.16],['c',0.57,-1.41,0.84,-2.64,0.90,-4.05],['c',0.03,-0.63,0.06,-0.72,0.24,-0.81],['l',0.12,-0.06],['l',0.45,0.12],['c',0.66,0.18,1.02,0.24,1.47,0.27],['c',0.60,0.03,1.23,-0.09,2.01,-0.33],['z']],w:11.795,h:14.994},
    		'5':{d:[['M',1.02,-14.94],['c',0.12,-0.09,0.03,-0.09,1.08,0.06],['c',2.49,0.36,4.35,0.36,6.96,-0.06],['c',0.57,-0.09,0.66,-0.06,0.81,0.06],['c',0.15,0.18,0.12,0.24,-0.15,0.51],['c',-1.29,1.26,-3.24,2.04,-5.58,2.31],['c',-0.60,0.09,-1.20,0.12,-1.71,0.12],['c',-0.39,0.00,-0.45,0.00,-0.57,0.06],['c',-0.09,0.06,-0.15,0.12,-0.21,0.21],['l',-0.06,0.12],['l',0.00,1.65],['l',0.00,1.65],['l',0.21,-0.21],['c',0.66,-0.57,1.41,-0.96,2.19,-1.14],['c',0.33,-0.06,1.41,-0.06,1.95,0.00],['c',2.61,0.36,4.02,1.74,4.26,4.14],['c',0.03,0.45,0.03,1.08,-0.03,1.44],['c',-0.18,1.02,-0.78,2.01,-1.59,2.70],['c',-0.72,0.57,-1.62,1.02,-2.49,1.20],['c',-1.38,0.27,-3.03,0.06,-4.20,-0.54],['c',-1.08,-0.54,-1.71,-1.32,-1.86,-2.28],['c',-0.09,-0.69,0.09,-1.29,0.57,-1.74],['c',0.24,-0.24,0.45,-0.39,0.75,-0.51],['c',0.21,-0.06,0.27,-0.06,0.60,-0.06],['c',0.33,0.00,0.39,0.00,0.60,0.06],['c',0.30,0.12,0.51,0.27,0.75,0.51],['c',0.36,0.33,0.57,0.75,0.60,1.20],['c',0.00,0.21,0.00,0.27,-0.06,0.42],['c',-0.09,0.18,-0.12,0.24,-0.54,0.54],['c',-0.18,0.12,-0.36,0.30,-0.42,0.33],['c',-0.36,0.42,-0.18,0.99,0.36,1.26],['c',0.51,0.27,1.47,0.36,2.01,0.27],['c',0.93,-0.21,1.47,-1.17,1.65,-2.91],['c',0.06,-0.45,0.06,-1.89,0.00,-2.31],['c',-0.15,-1.20,-0.51,-2.10,-1.05,-2.55],['c',-0.21,-0.18,-0.54,-0.36,-0.81,-0.39],['c',-0.30,-0.06,-0.84,-0.03,-1.26,0.06],['c',-0.93,0.18,-1.65,0.60,-2.16,1.20],['c',-0.15,0.21,-0.27,0.30,-0.39,0.30],['c',-0.15,0.00,-0.30,-0.09,-0.36,-0.18],['c',-0.06,-0.09,-0.06,-0.15,-0.06,-3.66],['c',0.00,-3.39,0.00,-3.57,0.06,-3.66],['c',0.03,-0.06,0.09,-0.15,0.15,-0.18],['z']],w:10.212,h:14.997},
    		'6':{d:[['M',4.98,-14.97],['c',0.36,-0.03,1.20,0.00,1.59,0.06],['c',0.90,0.15,1.68,0.51,2.25,1.05],['c',0.57,0.51,0.87,1.23,0.84,1.98],['c',-0.03,0.51,-0.21,0.90,-0.60,1.26],['c',-0.24,0.24,-0.45,0.39,-0.75,0.51],['c',-0.21,0.06,-0.27,0.06,-0.60,0.06],['c',-0.33,0.00,-0.39,0.00,-0.60,-0.06],['c',-0.30,-0.12,-0.51,-0.27,-0.75,-0.51],['c',-0.39,-0.36,-0.57,-0.78,-0.57,-1.26],['c',0.00,-0.27,0.00,-0.30,0.09,-0.42],['c',0.03,-0.09,0.18,-0.21,0.30,-0.30],['c',0.12,-0.09,0.30,-0.21,0.39,-0.27],['c',0.09,-0.06,0.21,-0.18,0.27,-0.24],['c',0.06,-0.12,0.09,-0.15,0.09,-0.33],['c',0.00,-0.18,-0.03,-0.24,-0.09,-0.36],['c',-0.24,-0.39,-0.75,-0.60,-1.38,-0.57],['c',-0.54,0.03,-0.90,0.18,-1.23,0.48],['c',-0.81,0.72,-1.08,2.16,-0.96,5.37],['l',0.00,0.63],['l',0.30,-0.12],['c',0.78,-0.27,1.29,-0.33,2.10,-0.27],['c',1.47,0.12,2.49,0.54,3.27,1.29],['c',0.48,0.51,0.81,1.11,0.96,1.89],['c',0.06,0.27,0.06,0.42,0.06,0.93],['c',0.00,0.54,0.00,0.69,-0.06,0.96],['c',-0.15,0.78,-0.48,1.38,-0.96,1.89],['c',-0.54,0.51,-1.17,0.87,-1.98,1.08],['c',-1.14,0.30,-2.40,0.33,-3.24,0.03],['c',-1.50,-0.48,-2.64,-1.89,-3.27,-4.02],['c',-0.36,-1.23,-0.51,-2.82,-0.42,-4.08],['c',0.30,-3.66,2.28,-6.30,4.95,-6.66],['z'],['m',0.66,7.41],['c',-0.27,-0.09,-0.81,-0.12,-1.08,-0.06],['c',-0.72,0.18,-1.08,0.69,-1.23,1.71],['c',-0.06,0.54,-0.06,3.00,0.00,3.54],['c',0.18,1.26,0.72,1.77,1.80,1.74],['c',0.39,-0.03,0.63,-0.09,0.90,-0.27],['c',0.66,-0.42,0.90,-1.32,0.90,-3.24],['c',0.00,-2.22,-0.36,-3.12,-1.29,-3.42],['z']],w:9.956,h:14.982},
    		'7':{d:[['M',0.21,-14.97],['c',0.21,-0.06,0.45,0.00,0.54,0.15],['c',0.06,0.09,0.06,0.15,0.06,0.39],['c',0.00,0.24,0.00,0.33,0.06,0.42],['c',0.06,0.12,0.21,0.24,0.27,0.24],['c',0.03,0.00,0.12,-0.12,0.24,-0.21],['c',0.96,-1.20,2.58,-1.35,3.99,-0.42],['c',0.15,0.12,0.42,0.30,0.54,0.45],['c',0.48,0.39,0.81,0.57,1.29,0.60],['c',0.69,0.03,1.50,-0.30,2.13,-0.87],['c',0.09,-0.09,0.27,-0.30,0.39,-0.45],['c',0.12,-0.15,0.24,-0.27,0.30,-0.30],['c',0.18,-0.06,0.39,0.03,0.51,0.21],['c',0.06,0.18,0.06,0.24,-0.27,0.72],['c',-0.18,0.24,-0.54,0.78,-0.78,1.17],['c',-2.37,3.54,-3.54,6.27,-3.87,9.00],['c',-0.03,0.33,-0.03,0.66,-0.03,1.26],['c',0.00,0.90,0.00,1.08,0.15,1.89],['c',0.06,0.45,0.06,0.48,0.03,0.60],['c',-0.06,0.09,-0.21,0.21,-0.30,0.21],['c',-0.03,0.00,-0.27,-0.06,-0.54,-0.15],['c',-0.84,-0.27,-1.11,-0.30,-1.65,-0.30],['c',-0.57,0.00,-0.84,0.03,-1.56,0.27],['c',-0.60,0.18,-0.69,0.21,-0.81,0.15],['c',-0.12,-0.06,-0.21,-0.18,-0.21,-0.30],['c',0.00,-0.15,0.60,-1.44,1.20,-2.61],['c',1.14,-2.22,2.73,-4.68,5.10,-8.01],['c',0.21,-0.27,0.36,-0.48,0.33,-0.48],['c',0.00,0.00,-0.12,0.06,-0.27,0.12],['c',-0.54,0.30,-0.99,0.39,-1.56,0.39],['c',-0.75,0.03,-1.20,-0.18,-1.83,-0.75],['c',-0.99,-0.90,-1.83,-1.17,-2.31,-0.72],['c',-0.18,0.15,-0.36,0.51,-0.45,0.84],['c',-0.06,0.24,-0.06,0.33,-0.09,1.98],['c',0.00,1.62,-0.03,1.74,-0.06,1.80],['c',-0.15,0.24,-0.54,0.24,-0.69,0.00],['c',-0.06,-0.09,-0.06,-0.15,-0.06,-3.57],['c',0.00,-3.42,0.00,-3.48,0.06,-3.57],['c',0.03,-0.06,0.09,-0.12,0.15,-0.15],['z']],w:10.561,h:15.093},
    		'8':{d:[['M',4.98,-14.97],['c',0.33,-0.03,1.02,-0.03,1.32,0.00],['c',1.32,0.12,2.49,0.60,3.21,1.32],['c',0.39,0.39,0.66,0.81,0.78,1.29],['c',0.09,0.36,0.09,1.08,0.00,1.44],['c',-0.21,0.84,-0.66,1.59,-1.59,2.55],['l',-0.30,0.30],['l',0.27,0.18],['c',1.47,0.93,2.31,2.31,2.25,3.75],['c',-0.03,0.75,-0.24,1.35,-0.63,1.95],['c',-0.45,0.66,-1.02,1.14,-1.83,1.53],['c',-1.80,0.87,-4.20,0.87,-6.00,0.03],['c',-1.62,-0.78,-2.52,-2.16,-2.46,-3.66],['c',0.06,-0.99,0.54,-1.77,1.80,-2.97],['c',0.54,-0.51,0.54,-0.54,0.48,-0.57],['c',-0.39,-0.27,-0.96,-0.78,-1.20,-1.14],['c',-0.75,-1.11,-0.87,-2.40,-0.30,-3.60],['c',0.69,-1.35,2.25,-2.25,4.20,-2.40],['z'],['m',1.53,0.69],['c',-0.42,-0.09,-1.11,-0.12,-1.38,-0.06],['c',-0.30,0.06,-0.60,0.18,-0.81,0.30],['c',-0.21,0.12,-0.60,0.51,-0.72,0.72],['c',-0.51,0.87,-0.42,1.89,0.21,2.52],['c',0.21,0.21,0.36,0.30,1.95,1.23],['c',0.96,0.54,1.74,0.99,1.77,1.02],['c',0.09,0.00,0.63,-0.60,0.99,-1.11],['c',0.21,-0.36,0.48,-0.87,0.57,-1.23],['c',0.06,-0.24,0.06,-0.36,0.06,-0.72],['c',0.00,-0.45,-0.03,-0.66,-0.15,-0.99],['c',-0.39,-0.81,-1.29,-1.44,-2.49,-1.68],['z'],['m',-1.44,8.07],['l',-1.89,-1.08],['c',-0.03,0.00,-0.18,0.15,-0.39,0.33],['c',-1.20,1.08,-1.65,1.95,-1.59,3.00],['c',0.09,1.59,1.35,2.85,3.21,3.24],['c',0.33,0.06,0.45,0.06,0.93,0.06],['c',0.63,0.00,0.81,-0.03,1.29,-0.27],['c',0.90,-0.42,1.47,-1.41,1.41,-2.40],['c',-0.06,-0.66,-0.39,-1.29,-0.90,-1.65],['c',-0.12,-0.09,-1.05,-0.63,-2.07,-1.23],['z']],w:10.926,h:14.989},
    		'9':{d:[['M',4.23,-14.97],['c',0.42,-0.03,1.29,0.00,1.62,0.06],['c',0.51,0.12,0.93,0.30,1.38,0.57],['c',1.53,1.02,2.52,3.24,2.73,5.94],['c',0.18,2.55,-0.48,4.98,-1.83,6.57],['c',-1.05,1.26,-2.40,1.89,-3.93,1.83],['c',-1.23,-0.06,-2.31,-0.45,-3.03,-1.14],['c',-0.57,-0.51,-0.87,-1.23,-0.84,-1.98],['c',0.03,-0.51,0.21,-0.90,0.60,-1.26],['c',0.24,-0.24,0.45,-0.39,0.75,-0.51],['c',0.21,-0.06,0.27,-0.06,0.60,-0.06],['c',0.33,0.00,0.39,0.00,0.60,0.06],['c',0.30,0.12,0.51,0.27,0.75,0.51],['c',0.39,0.36,0.57,0.78,0.57,1.26],['c',0.00,0.27,0.00,0.30,-0.09,0.42],['c',-0.03,0.09,-0.18,0.21,-0.30,0.30],['c',-0.12,0.09,-0.30,0.21,-0.39,0.27],['c',-0.09,0.06,-0.21,0.18,-0.27,0.24],['c',-0.06,0.12,-0.06,0.15,-0.06,0.33],['c',0.00,0.18,0.00,0.24,0.06,0.36],['c',0.24,0.39,0.75,0.60,1.38,0.57],['c',0.54,-0.03,0.90,-0.18,1.23,-0.48],['c',0.81,-0.72,1.08,-2.16,0.96,-5.37],['l',0.00,-0.63],['l',-0.30,0.12],['c',-0.78,0.27,-1.29,0.33,-2.10,0.27],['c',-1.47,-0.12,-2.49,-0.54,-3.27,-1.29],['c',-0.48,-0.51,-0.81,-1.11,-0.96,-1.89],['c',-0.06,-0.27,-0.06,-0.42,-0.06,-0.96],['c',0.00,-0.51,0.00,-0.66,0.06,-0.93],['c',0.15,-0.78,0.48,-1.38,0.96,-1.89],['c',0.15,-0.12,0.33,-0.27,0.42,-0.36],['c',0.69,-0.51,1.62,-0.81,2.76,-0.93],['z'],['m',1.17,0.66],['c',-0.21,-0.06,-0.57,-0.06,-0.81,-0.03],['c',-0.78,0.12,-1.26,0.69,-1.41,1.74],['c',-0.12,0.63,-0.15,1.95,-0.09,2.79],['c',0.12,1.71,0.63,2.40,1.77,2.46],['c',1.08,0.03,1.62,-0.48,1.80,-1.74],['c',0.06,-0.54,0.06,-3.00,0.00,-3.54],['c',-0.15,-1.05,-0.51,-1.53,-1.26,-1.68],['z']],w:9.959,h:14.986},
    		'rests.multimeasure':{d:[['M',0,-4],['l',0,16],['l',1,0],['l',0,-5],['l',40,0],['l',0,5],['l',1,0],['l',0,-16],['l',-1,0],['l',0,5],['l',-40,0],['l',0,-5],['z']],w:42,h:18},
    		'rests.whole':{d:[['M',0.06,0.03],['l',0.09,-0.06],['l',5.46,0.00],['l',5.49,0.00],['l',0.09,0.06],['l',0.06,0.09],['l',0.00,2.19],['l',0.00,2.19],['l',-0.06,0.09],['l',-0.09,0.06],['l',-5.49,0.00],['l',-5.46,0.00],['l',-0.09,-0.06],['l',-0.06,-0.09],['l',0.00,-2.19],['l',0.00,-2.19],['z']],w:11.25,h:4.68},
    		'rests.half':{d:[['M',0.06,-4.62],['l',0.09,-0.06],['l',5.46,0.00],['l',5.49,0.00],['l',0.09,0.06],['l',0.06,0.09],['l',0.00,2.19],['l',0.00,2.19],['l',-0.06,0.09],['l',-0.09,0.06],['l',-5.49,0.00],['l',-5.46,0.00],['l',-0.09,-0.06],['l',-0.06,-0.09],['l',0.00,-2.19],['l',0.00,-2.19],['z']],w:11.25,h:4.68},
    		'rests.quarter':{d:[['M',1.89,-11.82],['c',0.12,-0.06,0.24,-0.06,0.36,-0.03],['c',0.09,0.06,4.74,5.58,4.86,5.82],['c',0.21,0.39,0.15,0.78,-0.15,1.26],['c',-0.24,0.33,-0.72,0.81,-1.62,1.56],['c',-0.45,0.36,-0.87,0.75,-0.96,0.84],['c',-0.93,0.99,-1.14,2.49,-0.60,3.63],['c',0.18,0.39,0.27,0.48,1.32,1.68],['c',1.92,2.25,1.83,2.16,1.83,2.34],['c',0.00,0.18,-0.18,0.36,-0.36,0.39],['c',-0.15,0.00,-0.27,-0.06,-0.48,-0.27],['c',-0.75,-0.75,-2.46,-1.29,-3.39,-1.08],['c',-0.45,0.09,-0.69,0.27,-0.90,0.69],['c',-0.12,0.30,-0.21,0.66,-0.24,1.14],['c',-0.03,0.66,0.09,1.35,0.30,2.01],['c',0.15,0.42,0.24,0.66,0.45,0.96],['c',0.18,0.24,0.18,0.33,0.03,0.42],['c',-0.12,0.06,-0.18,0.03,-0.45,-0.30],['c',-1.08,-1.38,-2.07,-3.36,-2.40,-4.83],['c',-0.27,-1.05,-0.15,-1.77,0.27,-2.07],['c',0.21,-0.12,0.42,-0.15,0.87,-0.15],['c',0.87,0.06,2.10,0.39,3.30,0.90],['l',0.39,0.18],['l',-1.65,-1.95],['c',-2.52,-2.97,-2.61,-3.09,-2.70,-3.27],['c',-0.09,-0.24,-0.12,-0.48,-0.03,-0.75],['c',0.15,-0.48,0.57,-0.96,1.83,-2.01],['c',0.45,-0.36,0.84,-0.72,0.93,-0.78],['c',0.69,-0.75,1.02,-1.80,0.90,-2.79],['c',-0.06,-0.33,-0.21,-0.84,-0.39,-1.11],['c',-0.09,-0.15,-0.45,-0.60,-0.81,-1.05],['c',-0.36,-0.42,-0.69,-0.81,-0.72,-0.87],['c',-0.09,-0.18,0.00,-0.42,0.21,-0.51],['z']],w:7.888,h:21.435},
    		'rests.8th':{d:[['M',1.68,-6.12],['c',0.66,-0.09,1.23,0.09,1.68,0.51],['c',0.27,0.30,0.39,0.54,0.57,1.26],['c',0.09,0.33,0.18,0.66,0.21,0.72],['c',0.12,0.27,0.33,0.45,0.60,0.48],['c',0.12,0.00,0.18,0.00,0.33,-0.09],['c',0.39,-0.18,1.32,-1.29,1.68,-1.98],['c',0.09,-0.21,0.24,-0.30,0.39,-0.30],['c',0.12,0.00,0.27,0.09,0.33,0.18],['c',0.03,0.06,-0.27,1.11,-1.86,6.42],['c',-1.02,3.48,-1.89,6.39,-1.92,6.42],['c',0.00,0.03,-0.12,0.12,-0.24,0.15],['c',-0.18,0.09,-0.21,0.09,-0.45,0.09],['c',-0.24,0.00,-0.30,0.00,-0.48,-0.06],['c',-0.09,-0.06,-0.21,-0.12,-0.21,-0.15],['c',-0.06,-0.03,0.15,-0.57,1.68,-4.92],['c',0.96,-2.67,1.74,-4.89,1.71,-4.89],['l',-0.51,0.15],['c',-1.08,0.36,-1.74,0.48,-2.55,0.48],['c',-0.66,0.00,-0.84,-0.03,-1.32,-0.27],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.33,-0.45,0.84,-0.81,1.38,-0.90],['z']],w:7.534,h:13.883},
    		'rests.16th':{d:[['M',3.33,-6.12],['c',0.66,-0.09,1.23,0.09,1.68,0.51],['c',0.27,0.30,0.39,0.54,0.57,1.26],['c',0.09,0.33,0.18,0.66,0.21,0.72],['c',0.15,0.39,0.57,0.57,0.87,0.42],['c',0.39,-0.18,1.20,-1.23,1.62,-2.07],['c',0.06,-0.15,0.24,-0.24,0.36,-0.24],['c',0.12,0.00,0.27,0.09,0.33,0.18],['c',0.03,0.06,-0.45,1.86,-2.67,10.17],['c',-1.50,5.55,-2.73,10.14,-2.76,10.17],['c',-0.03,0.03,-0.12,0.12,-0.24,0.15],['c',-0.18,0.09,-0.21,0.09,-0.45,0.09],['c',-0.24,0.00,-0.30,0.00,-0.48,-0.06],['c',-0.09,-0.06,-0.21,-0.12,-0.21,-0.15],['c',-0.06,-0.03,0.12,-0.57,1.44,-4.92],['c',0.81,-2.67,1.47,-4.86,1.47,-4.89],['c',-0.03,0.00,-0.27,0.06,-0.54,0.15],['c',-1.08,0.36,-1.77,0.48,-2.58,0.48],['c',-0.66,0.00,-0.84,-0.03,-1.32,-0.27],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.72,-1.05,2.22,-1.23,3.06,-0.42],['c',0.30,0.33,0.42,0.60,0.60,1.38],['c',0.09,0.45,0.21,0.78,0.33,0.90],['c',0.09,0.09,0.27,0.18,0.45,0.21],['c',0.12,0.00,0.18,0.00,0.33,-0.09],['c',0.33,-0.15,1.02,-0.93,1.41,-1.59],['c',0.12,-0.21,0.18,-0.39,0.39,-1.08],['c',0.66,-2.10,1.17,-3.84,1.17,-3.87],['c',0.00,0.00,-0.21,0.06,-0.42,0.15],['c',-0.51,0.15,-1.20,0.33,-1.68,0.42],['c',-0.33,0.06,-0.51,0.06,-0.96,0.06],['c',-0.66,0.00,-0.84,-0.03,-1.32,-0.27],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.33,-0.45,0.84,-0.81,1.38,-0.90],['z']],w:9.724,h:21.383},
    		'rests.32nd':{d:[['M',4.23,-13.62],['c',0.66,-0.09,1.23,0.09,1.68,0.51],['c',0.27,0.30,0.39,0.54,0.57,1.26],['c',0.09,0.33,0.18,0.66,0.21,0.72],['c',0.12,0.27,0.33,0.45,0.60,0.48],['c',0.12,0.00,0.18,0.00,0.27,-0.06],['c',0.33,-0.21,0.99,-1.11,1.44,-1.98],['c',0.09,-0.24,0.21,-0.33,0.39,-0.33],['c',0.12,0.00,0.27,0.09,0.33,0.18],['c',0.03,0.06,-0.57,2.67,-3.21,13.89],['c',-1.80,7.62,-3.30,13.89,-3.30,13.92],['c',-0.03,0.06,-0.12,0.12,-0.24,0.18],['c',-0.21,0.09,-0.24,0.09,-0.48,0.09],['c',-0.24,0.00,-0.30,0.00,-0.48,-0.06],['c',-0.09,-0.06,-0.21,-0.12,-0.21,-0.15],['c',-0.06,-0.03,0.09,-0.57,1.23,-4.92],['c',0.69,-2.67,1.26,-4.86,1.29,-4.89],['c',0.00,-0.03,-0.12,-0.03,-0.48,0.12],['c',-1.17,0.39,-2.22,0.57,-3.00,0.54],['c',-0.42,-0.03,-0.75,-0.12,-1.11,-0.30],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.72,-1.05,2.22,-1.23,3.06,-0.42],['c',0.30,0.33,0.42,0.60,0.60,1.38],['c',0.09,0.45,0.21,0.78,0.33,0.90],['c',0.12,0.09,0.30,0.18,0.48,0.21],['c',0.12,0.00,0.18,0.00,0.30,-0.09],['c',0.42,-0.21,1.29,-1.29,1.56,-1.89],['c',0.03,-0.12,1.23,-4.59,1.23,-4.65],['c',0.00,-0.03,-0.18,0.03,-0.39,0.12],['c',-0.63,0.18,-1.20,0.36,-1.74,0.45],['c',-0.39,0.06,-0.54,0.06,-1.02,0.06],['c',-0.66,0.00,-0.84,-0.03,-1.32,-0.27],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.72,-1.05,2.22,-1.23,3.06,-0.42],['c',0.30,0.33,0.42,0.60,0.60,1.38],['c',0.09,0.45,0.21,0.78,0.33,0.90],['c',0.18,0.18,0.51,0.27,0.72,0.15],['c',0.30,-0.12,0.69,-0.57,1.08,-1.17],['c',0.42,-0.60,0.39,-0.51,1.05,-3.03],['c',0.33,-1.26,0.60,-2.31,0.60,-2.34],['c',0.00,0.00,-0.21,0.03,-0.45,0.12],['c',-0.57,0.18,-1.14,0.33,-1.62,0.42],['c',-0.33,0.06,-0.51,0.06,-0.96,0.06],['c',-0.66,0.00,-0.84,-0.03,-1.32,-0.27],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.33,-0.45,0.84,-0.81,1.38,-0.90],['z']],w:11.373,h:28.883},
    		'rests.64th':{d:[['M',5.13,-13.62],['c',0.66,-0.09,1.23,0.09,1.68,0.51],['c',0.27,0.30,0.39,0.54,0.57,1.26],['c',0.15,0.63,0.21,0.81,0.33,0.96],['c',0.18,0.21,0.54,0.30,0.75,0.18],['c',0.24,-0.12,0.63,-0.66,1.08,-1.56],['c',0.33,-0.66,0.39,-0.72,0.60,-0.72],['c',0.12,0.00,0.27,0.09,0.33,0.18],['c',0.03,0.06,-0.69,3.66,-3.54,17.64],['c',-1.95,9.66,-3.57,17.61,-3.57,17.64],['c',-0.03,0.06,-0.12,0.12,-0.24,0.18],['c',-0.21,0.09,-0.24,0.09,-0.48,0.09],['c',-0.24,0.00,-0.30,0.00,-0.48,-0.06],['c',-0.09,-0.06,-0.21,-0.12,-0.21,-0.15],['c',-0.06,-0.03,0.06,-0.57,1.05,-4.95],['c',0.60,-2.70,1.08,-4.89,1.08,-4.92],['c',0.00,0.00,-0.24,0.06,-0.51,0.15],['c',-0.66,0.24,-1.20,0.36,-1.77,0.48],['c',-0.42,0.06,-0.57,0.06,-1.05,0.06],['c',-0.69,0.00,-0.87,-0.03,-1.35,-0.27],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.72,-1.05,2.22,-1.23,3.06,-0.42],['c',0.30,0.33,0.42,0.60,0.60,1.38],['c',0.09,0.45,0.21,0.78,0.33,0.90],['c',0.09,0.09,0.27,0.18,0.45,0.21],['c',0.21,0.03,0.39,-0.09,0.72,-0.42],['c',0.45,-0.45,1.02,-1.26,1.17,-1.65],['c',0.03,-0.09,0.27,-1.14,0.54,-2.34],['c',0.27,-1.20,0.48,-2.19,0.51,-2.22],['c',0.00,-0.03,-0.09,-0.03,-0.48,0.12],['c',-1.17,0.39,-2.22,0.57,-3.00,0.54],['c',-0.42,-0.03,-0.75,-0.12,-1.11,-0.30],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.36,-0.54,0.96,-0.87,1.65,-0.93],['c',0.54,-0.03,1.02,0.15,1.41,0.54],['c',0.27,0.30,0.39,0.54,0.57,1.26],['c',0.09,0.33,0.18,0.66,0.21,0.72],['c',0.15,0.39,0.57,0.57,0.90,0.42],['c',0.36,-0.18,1.20,-1.26,1.47,-1.89],['c',0.03,-0.09,0.30,-1.20,0.57,-2.43],['l',0.51,-2.28],['l',-0.54,0.18],['c',-1.11,0.36,-1.80,0.48,-2.61,0.48],['c',-0.66,0.00,-0.84,-0.03,-1.32,-0.27],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.36,-0.54,0.96,-0.87,1.65,-0.93],['c',0.54,-0.03,1.02,0.15,1.41,0.54],['c',0.27,0.30,0.39,0.54,0.57,1.26],['c',0.15,0.63,0.21,0.81,0.33,0.96],['c',0.21,0.21,0.54,0.30,0.75,0.18],['c',0.36,-0.18,0.93,-0.93,1.29,-1.68],['c',0.12,-0.24,0.18,-0.48,0.63,-2.55],['l',0.51,-2.31],['c',0.00,-0.03,-0.18,0.03,-0.39,0.12],['c',-1.14,0.36,-2.10,0.54,-2.82,0.51],['c',-0.42,-0.03,-0.75,-0.12,-1.11,-0.30],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.33,-0.45,0.84,-0.81,1.38,-0.90],['z']],w:12.453,h:36.383},
    		'rests.128th':{d:[['M',6.03,-21.12],['c',0.66,-0.09,1.23,0.09,1.68,0.51],['c',0.27,0.30,0.39,0.54,0.57,1.26],['c',0.09,0.33,0.18,0.66,0.21,0.72],['c',0.12,0.27,0.33,0.45,0.60,0.48],['c',0.21,0.00,0.33,-0.06,0.54,-0.36],['c',0.15,-0.21,0.54,-0.93,0.78,-1.47],['c',0.15,-0.33,0.18,-0.39,0.30,-0.48],['c',0.18,-0.09,0.45,0.00,0.51,0.15],['c',0.03,0.09,-7.11,42.75,-7.17,42.84],['c',-0.03,0.03,-0.15,0.09,-0.24,0.15],['c',-0.18,0.06,-0.24,0.06,-0.45,0.06],['c',-0.24,0.00,-0.30,0.00,-0.48,-0.06],['c',-0.09,-0.06,-0.21,-0.12,-0.21,-0.15],['c',-0.06,-0.03,0.03,-0.57,0.84,-4.98],['c',0.51,-2.70,0.93,-4.92,0.90,-4.92],['c',0.00,0.00,-0.15,0.06,-0.36,0.12],['c',-0.78,0.27,-1.62,0.48,-2.31,0.57],['c',-0.15,0.03,-0.54,0.03,-0.81,0.03],['c',-0.66,0.00,-0.84,-0.03,-1.32,-0.27],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.36,-0.54,0.96,-0.87,1.65,-0.93],['c',0.54,-0.03,1.02,0.15,1.41,0.54],['c',0.27,0.30,0.39,0.54,0.57,1.26],['c',0.09,0.33,0.18,0.66,0.21,0.72],['c',0.12,0.27,0.33,0.45,0.63,0.48],['c',0.12,0.00,0.18,0.00,0.30,-0.09],['c',0.42,-0.21,1.14,-1.11,1.50,-1.83],['c',0.12,-0.27,0.12,-0.27,0.54,-2.52],['c',0.24,-1.23,0.42,-2.25,0.39,-2.25],['c',0.00,0.00,-0.24,0.06,-0.51,0.18],['c',-1.26,0.39,-2.25,0.57,-3.06,0.54],['c',-0.42,-0.03,-0.75,-0.12,-1.11,-0.30],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.36,-0.54,0.96,-0.87,1.65,-0.93],['c',0.54,-0.03,1.02,0.15,1.41,0.54],['c',0.27,0.30,0.39,0.54,0.57,1.26],['c',0.15,0.63,0.21,0.81,0.33,0.96],['c',0.18,0.21,0.51,0.30,0.75,0.18],['c',0.36,-0.15,1.05,-0.99,1.41,-1.77],['l',0.15,-0.30],['l',0.42,-2.25],['c',0.21,-1.26,0.42,-2.28,0.39,-2.28],['l',-0.51,0.15],['c',-1.11,0.39,-1.89,0.51,-2.70,0.51],['c',-0.66,0.00,-0.84,-0.03,-1.32,-0.27],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.36,-0.54,0.96,-0.87,1.65,-0.93],['c',0.54,-0.03,1.02,0.15,1.41,0.54],['c',0.27,0.30,0.39,0.54,0.57,1.26],['c',0.15,0.63,0.21,0.81,0.33,0.96],['c',0.18,0.18,0.48,0.27,0.72,0.21],['c',0.33,-0.12,1.14,-1.26,1.41,-1.95],['c',0.00,-0.09,0.21,-1.11,0.45,-2.34],['c',0.21,-1.20,0.39,-2.22,0.39,-2.28],['c',0.03,-0.03,0.00,-0.03,-0.45,0.12],['c',-0.57,0.18,-1.20,0.33,-1.71,0.42],['c',-0.30,0.06,-0.51,0.06,-0.93,0.06],['c',-0.66,0.00,-0.84,-0.03,-1.32,-0.27],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.36,-0.54,0.96,-0.87,1.65,-0.93],['c',0.54,-0.03,1.02,0.15,1.41,0.54],['c',0.27,0.30,0.39,0.54,0.57,1.26],['c',0.09,0.33,0.18,0.66,0.21,0.72],['c',0.12,0.27,0.33,0.45,0.60,0.48],['c',0.18,0.00,0.36,-0.09,0.57,-0.33],['c',0.33,-0.36,0.78,-1.14,0.93,-1.56],['c',0.03,-0.12,0.24,-1.20,0.45,-2.40],['c',0.24,-1.20,0.42,-2.22,0.42,-2.28],['c',0.03,-0.03,0.00,-0.03,-0.39,0.09],['c',-1.05,0.36,-1.80,0.48,-2.58,0.48],['c',-0.63,0.00,-0.84,-0.03,-1.29,-0.27],['c',-1.32,-0.63,-1.77,-2.16,-1.02,-3.30],['c',0.33,-0.45,0.84,-0.81,1.38,-0.90],['z']],w:12.992,h:43.883},
    		'accidentals.sharp':{d:[['M',5.73,-11.19],['c',0.21,-0.12,0.54,-0.03,0.66,0.24],['c',0.06,0.12,0.06,0.21,0.06,2.31],['c',0.00,1.23,0.00,2.22,0.03,2.22],['c',0.00,0.00,0.27,-0.12,0.60,-0.24],['c',0.69,-0.27,0.78,-0.30,0.96,-0.15],['c',0.21,0.15,0.21,0.18,0.21,1.38],['c',0.00,1.02,0.00,1.11,-0.06,1.20],['c',-0.03,0.06,-0.09,0.12,-0.12,0.15],['c',-0.06,0.03,-0.42,0.21,-0.84,0.36],['l',-0.75,0.33],['l',-0.03,2.43],['c',0.00,1.32,0.00,2.43,0.03,2.43],['c',0.00,0.00,0.27,-0.12,0.60,-0.24],['c',0.69,-0.27,0.78,-0.30,0.96,-0.15],['c',0.21,0.15,0.21,0.18,0.21,1.38],['c',0.00,1.02,0.00,1.11,-0.06,1.20],['c',-0.03,0.06,-0.09,0.12,-0.12,0.15],['c',-0.06,0.03,-0.42,0.21,-0.84,0.36],['l',-0.75,0.33],['l',-0.03,2.52],['c',0.00,2.28,-0.03,2.55,-0.06,2.64],['c',-0.21,0.36,-0.72,0.36,-0.93,0.00],['c',-0.03,-0.09,-0.06,-0.33,-0.06,-2.43],['l',0.00,-2.31],['l',-1.29,0.51],['l',-1.26,0.51],['l',0.00,2.43],['c',0.00,2.58,0.00,2.52,-0.15,2.67],['c',-0.06,0.09,-0.27,0.18,-0.36,0.18],['c',-0.12,0.00,-0.33,-0.09,-0.39,-0.18],['c',-0.15,-0.15,-0.15,-0.09,-0.15,-2.43],['c',0.00,-1.23,0.00,-2.22,-0.03,-2.22],['c',0.00,0.00,-0.27,0.12,-0.60,0.24],['c',-0.69,0.27,-0.78,0.30,-0.96,0.15],['c',-0.21,-0.15,-0.21,-0.18,-0.21,-1.38],['c',0.00,-1.02,0.00,-1.11,0.06,-1.20],['c',0.03,-0.06,0.09,-0.12,0.12,-0.15],['c',0.06,-0.03,0.42,-0.21,0.84,-0.36],['l',0.78,-0.33],['l',0.00,-2.43],['c',0.00,-1.32,0.00,-2.43,-0.03,-2.43],['c',0.00,0.00,-0.27,0.12,-0.60,0.24],['c',-0.69,0.27,-0.78,0.30,-0.96,0.15],['c',-0.21,-0.15,-0.21,-0.18,-0.21,-1.38],['c',0.00,-1.02,0.00,-1.11,0.06,-1.20],['c',0.03,-0.06,0.09,-0.12,0.12,-0.15],['c',0.06,-0.03,0.42,-0.21,0.84,-0.36],['l',0.78,-0.33],['l',0.00,-2.52],['c',0.00,-2.28,0.03,-2.55,0.06,-2.64],['c',0.21,-0.36,0.72,-0.36,0.93,0.00],['c',0.03,0.09,0.06,0.33,0.06,2.43],['l',0.03,2.31],['l',1.26,-0.51],['l',1.26,-0.51],['l',0.00,-2.43],['c',0.00,-2.28,0.00,-2.43,0.06,-2.55],['c',0.06,-0.12,0.12,-0.18,0.27,-0.24],['z'],['m',-0.33,10.65],['l',0.00,-2.43],['l',-1.29,0.51],['l',-1.26,0.51],['l',0.00,2.46],['l',0.00,2.43],['l',0.09,-0.03],['c',0.06,-0.03,0.63,-0.27,1.29,-0.51],['l',1.17,-0.48],['l',0.00,-2.46],['z']],w:8.25,h:22.462},
    		'accidentals.halfsharp':{d:[['M',2.43,-10.05],['c',0.21,-0.12,0.54,-0.03,0.66,0.24],['c',0.06,0.12,0.06,0.21,0.06,2.01],['c',0.00,1.05,0.00,1.89,0.03,1.89],['l',0.72,-0.48],['c',0.69,-0.48,0.69,-0.51,0.87,-0.51],['c',0.15,0.00,0.18,0.03,0.27,0.09],['c',0.21,0.15,0.21,0.18,0.21,1.41],['c',0.00,1.11,-0.03,1.14,-0.09,1.23],['c',-0.03,0.03,-0.48,0.39,-1.02,0.75],['l',-0.99,0.66],['l',0.00,2.37],['c',0.00,1.32,0.00,2.37,0.03,2.37],['l',0.72,-0.48],['c',0.69,-0.48,0.69,-0.51,0.87,-0.51],['c',0.15,0.00,0.18,0.03,0.27,0.09],['c',0.21,0.15,0.21,0.18,0.21,1.41],['c',0.00,1.11,-0.03,1.14,-0.09,1.23],['c',-0.03,0.03,-0.48,0.39,-1.02,0.75],['l',-0.99,0.66],['l',0.00,2.25],['c',0.00,1.95,0.00,2.28,-0.06,2.37],['c',-0.06,0.12,-0.12,0.21,-0.24,0.27],['c',-0.27,0.12,-0.54,0.03,-0.69,-0.24],['c',-0.06,-0.12,-0.06,-0.21,-0.06,-2.01],['c',0.00,-1.05,0.00,-1.89,-0.03,-1.89],['l',-0.72,0.48],['c',-0.69,0.48,-0.69,0.48,-0.87,0.48],['c',-0.15,0.00,-0.18,0.00,-0.27,-0.06],['c',-0.21,-0.15,-0.21,-0.18,-0.21,-1.41],['c',0.00,-1.11,0.03,-1.14,0.09,-1.23],['c',0.03,-0.03,0.48,-0.39,1.02,-0.75],['l',0.99,-0.66],['l',0.00,-2.37],['c',0.00,-1.32,0.00,-2.37,-0.03,-2.37],['l',-0.72,0.48],['c',-0.69,0.48,-0.69,0.48,-0.87,0.48],['c',-0.15,0.00,-0.18,0.00,-0.27,-0.06],['c',-0.21,-0.15,-0.21,-0.18,-0.21,-1.41],['c',0.00,-1.11,0.03,-1.14,0.09,-1.23],['c',0.03,-0.03,0.48,-0.39,1.02,-0.75],['l',0.99,-0.66],['l',0.00,-2.25],['c',0.00,-2.13,0.00,-2.28,0.06,-2.40],['c',0.06,-0.12,0.12,-0.18,0.27,-0.24],['z']],w:5.25,h:20.174},
    		'accidentals.nat':{d:[['M',0.21,-11.40],['c',0.24,-0.06,0.78,0.00,0.99,0.15],['c',0.03,0.03,0.03,0.48,0.00,2.61],['c',-0.03,1.44,-0.03,2.61,-0.03,2.61],['c',0.00,0.03,0.75,-0.09,1.68,-0.24],['c',0.96,-0.18,1.71,-0.27,1.74,-0.27],['c',0.15,0.03,0.27,0.15,0.36,0.30],['l',0.06,0.12],['l',0.09,8.67],['c',0.09,6.96,0.12,8.67,0.09,8.67],['c',-0.03,0.03,-0.12,0.06,-0.21,0.09],['c',-0.24,0.09,-0.72,0.09,-0.96,0.00],['c',-0.09,-0.03,-0.18,-0.06,-0.21,-0.09],['c',-0.03,-0.03,-0.03,-0.48,0.00,-2.61],['c',0.03,-1.44,0.03,-2.61,0.03,-2.61],['c',0.00,-0.03,-0.75,0.09,-1.68,0.24],['c',-0.96,0.18,-1.71,0.27,-1.74,0.27],['c',-0.15,-0.03,-0.27,-0.15,-0.36,-0.30],['l',-0.06,-0.15],['l',-0.09,-7.53],['c',-0.06,-4.14,-0.09,-8.04,-0.12,-8.67],['l',0.00,-1.11],['l',0.15,-0.06],['c',0.09,-0.03,0.21,-0.06,0.27,-0.09],['z'],['m',3.75,8.40],['c',0.00,-0.33,0.00,-0.42,-0.03,-0.42],['c',-0.12,0.00,-2.79,0.45,-2.79,0.48],['c',-0.03,0.00,-0.09,6.30,-0.09,6.33],['c',0.03,0.00,2.79,-0.45,2.82,-0.48],['c',0.00,0.00,0.09,-4.53,0.09,-5.91],['z']],w:5.4,h:22.8},
    		'accidentals.flat':{d:[['M',-0.36,-14.07],['c',0.33,-0.06,0.87,0.00,1.08,0.15],['c',0.06,0.03,0.06,0.36,-0.03,5.25],['c',-0.06,2.85,-0.09,5.19,-0.09,5.19],['c',0.00,0.03,0.12,-0.03,0.24,-0.12],['c',0.63,-0.42,1.41,-0.66,2.19,-0.72],['c',0.81,-0.03,1.47,0.21,2.04,0.78],['c',0.57,0.54,0.87,1.26,0.93,2.04],['c',0.03,0.57,-0.09,1.08,-0.36,1.62],['c',-0.42,0.81,-1.02,1.38,-2.82,2.61],['c',-1.14,0.78,-1.44,1.02,-1.80,1.44],['c',-0.18,0.18,-0.39,0.39,-0.45,0.42],['c',-0.27,0.18,-0.57,0.15,-0.81,-0.06],['c',-0.06,-0.09,-0.12,-0.18,-0.15,-0.27],['c',-0.03,-0.06,-0.09,-3.27,-0.18,-8.34],['c',-0.09,-4.53,-0.15,-8.58,-0.18,-9.03],['l',0.00,-0.78],['l',0.12,-0.06],['c',0.06,-0.03,0.18,-0.09,0.27,-0.12],['z'],['m',3.18,11.01],['c',-0.21,-0.12,-0.54,-0.15,-0.81,-0.06],['c',-0.54,0.15,-0.99,0.63,-1.17,1.26],['c',-0.06,0.30,-0.12,2.88,-0.06,3.87],['c',0.03,0.42,0.03,0.81,0.06,0.90],['l',0.03,0.12],['l',0.45,-0.39],['c',0.63,-0.54,1.26,-1.17,1.56,-1.59],['c',0.30,-0.42,0.60,-0.99,0.72,-1.41],['c',0.18,-0.69,0.09,-1.47,-0.18,-2.07],['c',-0.15,-0.30,-0.33,-0.51,-0.60,-0.63],['z']],w:6.75,h:18.801},
    		'accidentals.halfflat':{d:[['M',4.83,-14.07],['c',0.33,-0.06,0.87,0.00,1.08,0.15],['c',0.06,0.03,0.06,0.60,-0.12,9.06],['c',-0.09,5.55,-0.15,9.06,-0.18,9.12],['c',-0.03,0.09,-0.09,0.18,-0.15,0.27],['c',-0.24,0.21,-0.54,0.24,-0.81,0.06],['c',-0.06,-0.03,-0.27,-0.24,-0.45,-0.42],['c',-0.36,-0.42,-0.66,-0.66,-1.80,-1.44],['c',-1.23,-0.84,-1.83,-1.32,-2.25,-1.77],['c',-0.66,-0.78,-0.96,-1.56,-0.93,-2.46],['c',0.09,-1.41,1.11,-2.58,2.40,-2.79],['c',0.30,-0.06,0.84,-0.03,1.23,0.06],['c',0.54,0.12,1.08,0.33,1.53,0.63],['c',0.12,0.09,0.24,0.15,0.24,0.12],['c',0.00,0.00,-0.12,-8.37,-0.18,-9.75],['l',0.00,-0.66],['l',0.12,-0.06],['c',0.06,-0.03,0.18,-0.09,0.27,-0.12],['z'],['m',-1.65,10.95],['c',-0.60,-0.18,-1.08,0.09,-1.38,0.69],['c',-0.27,0.60,-0.36,1.38,-0.18,2.07],['c',0.12,0.42,0.42,0.99,0.72,1.41],['c',0.30,0.42,0.93,1.05,1.56,1.59],['l',0.48,0.39],['l',0.00,-0.12],['c',0.03,-0.09,0.03,-0.48,0.06,-0.90],['c',0.03,-0.57,0.03,-1.08,0.00,-2.22],['c',-0.03,-1.62,-0.03,-1.62,-0.24,-2.07],['c',-0.21,-0.42,-0.60,-0.75,-1.02,-0.84],['z']],w:6.728,h:18.801},
    		'accidentals.dblflat':{d:[['M',-0.36,-14.07],['c',0.33,-0.06,0.87,0.00,1.08,0.15],['c',0.06,0.03,0.06,0.33,-0.03,4.89],['c',-0.06,2.67,-0.09,5.01,-0.09,5.22],['l',0.00,0.36],['l',0.15,-0.15],['c',0.36,-0.30,0.75,-0.51,1.20,-0.63],['c',0.33,-0.09,0.96,-0.09,1.26,-0.03],['c',0.27,0.09,0.63,0.27,0.87,0.45],['l',0.21,0.15],['l',0.00,-0.27],['c',0.00,-0.15,-0.03,-2.43,-0.09,-5.10],['c',-0.09,-4.56,-0.09,-4.86,-0.03,-4.89],['c',0.15,-0.12,0.39,-0.15,0.72,-0.15],['c',0.30,0.00,0.54,0.03,0.69,0.15],['c',0.06,0.03,0.06,0.33,-0.03,4.95],['c',-0.06,2.70,-0.09,5.04,-0.09,5.22],['l',0.03,0.30],['l',0.21,-0.15],['c',0.69,-0.48,1.44,-0.69,2.28,-0.69],['c',0.51,0.00,0.78,0.03,1.20,0.21],['c',1.32,0.63,2.01,2.28,1.53,3.69],['c',-0.21,0.57,-0.51,1.02,-1.05,1.56],['c',-0.42,0.42,-0.81,0.72,-1.92,1.50],['c',-1.26,0.87,-1.50,1.08,-1.86,1.50],['c',-0.39,0.45,-0.54,0.54,-0.81,0.51],['c',-0.18,0.00,-0.21,0.00,-0.33,-0.06],['l',-0.21,-0.21],['l',-0.06,-0.12],['l',-0.03,-0.99],['c',-0.03,-0.54,-0.03,-1.29,-0.06,-1.68],['l',0.00,-0.69],['l',-0.21,0.24],['c',-0.36,0.42,-0.75,0.75,-1.80,1.62],['c',-1.02,0.84,-1.20,0.99,-1.44,1.38],['c',-0.36,0.51,-0.54,0.60,-0.90,0.51],['c',-0.15,-0.03,-0.39,-0.27,-0.42,-0.42],['c',-0.03,-0.06,-0.09,-3.27,-0.18,-8.34],['c',-0.09,-4.53,-0.15,-8.58,-0.18,-9.03],['l',0.00,-0.78],['l',0.12,-0.06],['c',0.06,-0.03,0.18,-0.09,0.27,-0.12],['z'],['m',2.52,10.98],['c',-0.18,-0.09,-0.48,-0.12,-0.66,-0.06],['c',-0.39,0.15,-0.69,0.54,-0.84,1.14],['c',-0.06,0.24,-0.06,0.39,-0.09,1.74],['c',-0.03,1.44,0.00,2.73,0.06,3.18],['l',0.03,0.15],['l',0.27,-0.27],['c',0.93,-0.96,1.50,-1.95,1.74,-3.06],['c',0.06,-0.27,0.06,-0.39,0.06,-0.96],['c',0.00,-0.54,0.00,-0.69,-0.06,-0.93],['c',-0.09,-0.51,-0.27,-0.81,-0.51,-0.93],['z'],['m',5.43,0.00],['c',-0.18,-0.09,-0.51,-0.12,-0.72,-0.06],['c',-0.54,0.12,-0.96,0.63,-1.17,1.26],['c',-0.06,0.30,-0.12,2.88,-0.06,3.90],['c',0.03,0.42,0.03,0.81,0.06,0.90],['l',0.03,0.12],['l',0.36,-0.30],['c',0.42,-0.36,1.02,-0.96,1.29,-1.29],['c',0.36,-0.45,0.66,-0.99,0.81,-1.41],['c',0.42,-1.23,0.15,-2.76,-0.60,-3.12],['z']],w:11.613,h:18.804},
    		'accidentals.dblsharp':{d:[['M',-0.18,-3.96],['c',0.06,-0.03,0.12,-0.06,0.15,-0.06],['c',0.09,0.00,2.76,0.27,2.79,0.30],['c',0.12,0.03,0.15,0.12,0.15,0.51],['c',0.06,0.96,0.24,1.59,0.57,2.10],['c',0.06,0.09,0.15,0.21,0.18,0.24],['l',0.09,0.06],['l',0.09,-0.06],['c',0.03,-0.03,0.12,-0.15,0.18,-0.24],['c',0.33,-0.51,0.51,-1.14,0.57,-2.10],['c',0.00,-0.39,0.03,-0.45,0.12,-0.51],['c',0.03,0.00,0.66,-0.09,1.44,-0.15],['c',1.47,-0.15,1.50,-0.15,1.56,-0.03],['c',0.03,0.06,0.00,0.42,-0.09,1.44],['c',-0.09,0.72,-0.15,1.35,-0.15,1.38],['c',0.00,0.03,-0.03,0.09,-0.06,0.12],['c',-0.06,0.06,-0.12,0.09,-0.51,0.09],['c',-1.08,0.06,-1.80,0.30,-2.28,0.75],['l',-0.12,0.09],['l',0.09,0.09],['c',0.12,0.15,0.39,0.33,0.63,0.45],['c',0.42,0.18,0.96,0.27,1.68,0.33],['c',0.39,0.00,0.45,0.03,0.51,0.09],['c',0.03,0.03,0.06,0.09,0.06,0.12],['c',0.00,0.03,0.06,0.66,0.15,1.38],['c',0.09,1.02,0.12,1.38,0.09,1.44],['c',-0.06,0.12,-0.09,0.12,-1.56,-0.03],['c',-0.78,-0.06,-1.41,-0.15,-1.44,-0.15],['c',-0.09,-0.06,-0.12,-0.12,-0.12,-0.54],['c',-0.06,-0.93,-0.24,-1.56,-0.57,-2.07],['c',-0.06,-0.09,-0.15,-0.21,-0.18,-0.24],['l',-0.09,-0.06],['l',-0.09,0.06],['c',-0.03,0.03,-0.12,0.15,-0.18,0.24],['c',-0.33,0.51,-0.51,1.14,-0.57,2.07],['c',0.00,0.42,-0.03,0.48,-0.12,0.54],['c',-0.03,0.00,-0.66,0.09,-1.44,0.15],['c',-1.47,0.15,-1.50,0.15,-1.56,0.03],['c',-0.03,-0.06,0.00,-0.42,0.09,-1.44],['c',0.09,-0.72,0.15,-1.35,0.15,-1.38],['c',0.00,-0.03,0.03,-0.09,0.06,-0.12],['c',0.06,-0.06,0.12,-0.09,0.51,-0.09],['c',0.72,-0.06,1.26,-0.15,1.68,-0.33],['c',0.24,-0.12,0.51,-0.30,0.63,-0.45],['l',0.09,-0.09],['l',-0.12,-0.09],['c',-0.48,-0.45,-1.20,-0.69,-2.28,-0.75],['c',-0.39,0.00,-0.45,-0.03,-0.51,-0.09],['c',-0.03,-0.03,-0.06,-0.09,-0.06,-0.12],['c',0.00,-0.03,-0.06,-0.63,-0.12,-1.38],['c',-0.09,-0.72,-0.15,-1.35,-0.15,-1.38],['z']],w:7.95,h:7.977},
    		'dots.dot':{d:[['M',1.32,-1.68],['c',0.09,-0.03,0.27,-0.06,0.39,-0.06],['c',0.96,0.00,1.74,0.78,1.74,1.71],['c',0.00,0.96,-0.78,1.74,-1.71,1.74],['c',-0.96,0.00,-1.74,-0.78,-1.74,-1.71],['c',0.00,-0.78,0.54,-1.50,1.32,-1.68],['z']],w:3.45,h:3.45},
    		'noteheads.dbl':{d:[['M',-0.69,-4.02],['c',0.18,-0.09,0.36,-0.09,0.54,0.00],['c',0.18,0.09,0.24,0.15,0.33,0.30],['c',0.06,0.15,0.06,0.18,0.06,1.41],['l',0.00,1.23],['l',0.12,-0.18],['c',0.72,-1.26,2.64,-2.31,4.86,-2.64],['c',0.81,-0.15,1.11,-0.15,2.13,-0.15],['c',0.99,0.00,1.29,0.00,2.10,0.15],['c',0.75,0.12,1.38,0.27,2.04,0.54],['c',1.35,0.51,2.34,1.26,2.82,2.10],['l',0.12,0.18],['l',0.00,-1.23],['c',0.00,-1.20,0.00,-1.26,0.06,-1.38],['c',0.09,-0.18,0.15,-0.24,0.33,-0.33],['c',0.18,-0.09,0.36,-0.09,0.54,0.00],['c',0.18,0.09,0.24,0.15,0.33,0.30],['l',0.06,0.15],['l',0.00,3.54],['l',0.00,3.54],['l',-0.06,0.15],['c',-0.09,0.18,-0.15,0.24,-0.33,0.33],['c',-0.18,0.09,-0.36,0.09,-0.54,0.00],['c',-0.18,-0.09,-0.24,-0.15,-0.33,-0.33],['c',-0.06,-0.12,-0.06,-0.18,-0.06,-1.38],['l',0.00,-1.23],['l',-0.12,0.18],['c',-0.48,0.84,-1.47,1.59,-2.82,2.10],['c',-0.84,0.33,-1.71,0.54,-2.85,0.66],['c',-0.45,0.06,-2.16,0.06,-2.61,0.00],['c',-1.14,-0.12,-2.01,-0.33,-2.85,-0.66],['c',-1.35,-0.51,-2.34,-1.26,-2.82,-2.10],['l',-0.12,-0.18],['l',0.00,1.23],['c',0.00,1.23,0.00,1.26,-0.06,1.38],['c',-0.09,0.18,-0.15,0.24,-0.33,0.33],['c',-0.18,0.09,-0.36,0.09,-0.54,0.00],['c',-0.18,-0.09,-0.24,-0.15,-0.33,-0.33],['l',-0.06,-0.15],['l',0.00,-3.54],['c',0.00,-3.48,0.00,-3.54,0.06,-3.66],['c',0.09,-0.18,0.15,-0.24,0.33,-0.33],['z'],['m',7.71,0.63],['c',-0.36,-0.06,-0.90,-0.06,-1.14,0.00],['c',-0.30,0.03,-0.66,0.24,-0.87,0.42],['c',-0.60,0.54,-0.90,1.62,-0.75,2.82],['c',0.12,0.93,0.51,1.68,1.11,2.31],['c',0.75,0.72,1.83,1.20,2.85,1.26],['c',1.05,0.06,1.83,-0.54,2.10,-1.65],['c',0.21,-0.90,0.12,-1.95,-0.24,-2.82],['c',-0.36,-0.81,-1.08,-1.53,-1.95,-1.95],['c',-0.30,-0.15,-0.78,-0.30,-1.11,-0.39],['z']],w:16.83,h:8.145},
    		'noteheads.whole':{d:[['M',6.51,-4.05],['c',0.51,-0.03,2.01,0.00,2.52,0.03],['c',1.41,0.18,2.64,0.51,3.72,1.08],['c',1.20,0.63,1.95,1.41,2.19,2.31],['c',0.09,0.33,0.09,0.90,0.00,1.23],['c',-0.24,0.90,-0.99,1.68,-2.19,2.31],['c',-1.08,0.57,-2.28,0.90,-3.75,1.08],['c',-0.66,0.06,-2.31,0.06,-2.97,0.00],['c',-1.47,-0.18,-2.67,-0.51,-3.75,-1.08],['c',-1.20,-0.63,-1.95,-1.41,-2.19,-2.31],['c',-0.09,-0.33,-0.09,-0.90,0.00,-1.23],['c',0.24,-0.90,0.99,-1.68,2.19,-2.31],['c',1.20,-0.63,2.61,-0.99,4.23,-1.11],['z'],['m',0.57,0.66],['c',-0.87,-0.15,-1.53,0.00,-2.04,0.51],['c',-0.15,0.15,-0.24,0.27,-0.33,0.48],['c',-0.24,0.51,-0.36,1.08,-0.33,1.77],['c',0.03,0.69,0.18,1.26,0.42,1.77],['c',0.60,1.17,1.74,1.98,3.18,2.22],['c',1.11,0.21,1.95,-0.15,2.34,-0.99],['c',0.24,-0.51,0.36,-1.08,0.33,-1.80],['c',-0.06,-1.11,-0.45,-2.04,-1.17,-2.76],['c',-0.63,-0.63,-1.47,-1.05,-2.40,-1.20],['z']],w:14.985,h:8.097},
    		'noteheads.half':{d:[['M',7.44,-4.05],['c',0.06,-0.03,0.27,-0.03,0.48,-0.03],['c',1.05,0.00,1.71,0.24,2.10,0.81],['c',0.42,0.60,0.45,1.35,0.18,2.40],['c',-0.42,1.59,-1.14,2.73,-2.16,3.39],['c',-1.41,0.93,-3.18,1.44,-5.40,1.53],['c',-1.17,0.03,-1.89,-0.21,-2.28,-0.81],['c',-0.42,-0.60,-0.45,-1.35,-0.18,-2.40],['c',0.42,-1.59,1.14,-2.73,2.16,-3.39],['c',0.63,-0.42,1.23,-0.72,1.98,-0.96],['c',0.90,-0.30,1.65,-0.42,3.12,-0.54],['z'],['m',1.29,0.87],['c',-0.27,-0.09,-0.63,-0.12,-0.90,-0.03],['c',-0.72,0.24,-1.53,0.69,-3.27,1.80],['c',-2.34,1.50,-3.30,2.25,-3.57,2.79],['c',-0.36,0.72,-0.06,1.50,0.66,1.77],['c',0.24,0.12,0.69,0.09,0.99,0.00],['c',0.84,-0.30,1.92,-0.93,4.14,-2.37],['c',1.62,-1.08,2.37,-1.71,2.61,-2.19],['c',0.36,-0.72,0.06,-1.50,-0.66,-1.77],['z']],w:10.37,h:8.132},
    		'noteheads.quarter':{d:[['M',6.09,-4.05],['c',0.36,-0.03,1.20,0.00,1.53,0.06],['c',1.17,0.24,1.89,0.84,2.16,1.83],['c',0.06,0.18,0.06,0.30,0.06,0.66],['c',0.00,0.45,0.00,0.63,-0.15,1.08],['c',-0.66,2.04,-3.06,3.93,-5.52,4.38],['c',-0.54,0.09,-1.44,0.09,-1.83,0.03],['c',-1.23,-0.27,-1.98,-0.87,-2.25,-1.86],['c',-0.06,-0.18,-0.06,-0.30,-0.06,-0.66],['c',0.00,-0.45,0.00,-0.63,0.15,-1.08],['c',0.24,-0.78,0.75,-1.53,1.44,-2.22],['c',1.20,-1.20,2.85,-2.01,4.47,-2.22],['z']],w:9.81,h:8.094},
    		'noteheads.slash.nostem':{d:[['M',9.30,-7.77],['c',0.06,-0.06,0.18,-0.06,1.71,-0.06],['l',1.65,0.00],['l',0.09,0.09],['c',0.06,0.06,0.06,0.09,0.06,0.15],['c',-0.03,0.12,-9.21,15.24,-9.30,15.33],['c',-0.06,0.06,-0.18,0.06,-1.71,0.06],['l',-1.65,0.00],['l',-0.09,-0.09],['c',-0.06,-0.06,-0.06,-0.09,-0.06,-0.15],['c',0.03,-0.12,9.21,-15.24,9.30,-15.33],['z']],w:12.81,h:15.63},
    		'noteheads.indeterminate':{d:[['M',0.78,-4.05],['c',0.12,-0.03,0.24,-0.03,0.36,0.03],['c',0.03,0.03,0.93,0.72,1.95,1.56],['l',1.86,1.50],['l',1.86,-1.50],['c',1.02,-0.84,1.92,-1.53,1.95,-1.56],['c',0.21,-0.12,0.33,-0.09,0.75,0.24],['c',0.30,0.27,0.36,0.36,0.36,0.54],['c',0.00,0.03,-0.03,0.12,-0.06,0.18],['c',-0.03,0.06,-0.90,0.75,-1.89,1.56],['l',-1.80,1.47],['c',0.00,0.03,0.81,0.69,1.80,1.50],['c',0.99,0.81,1.86,1.50,1.89,1.56],['c',0.03,0.06,0.06,0.15,0.06,0.18],['c',0.00,0.18,-0.06,0.27,-0.36,0.54],['c',-0.42,0.33,-0.54,0.36,-0.75,0.24],['c',-0.03,-0.03,-0.93,-0.72,-1.95,-1.56],['l',-1.86,-1.50],['l',-1.86,1.50],['c',-1.02,0.84,-1.92,1.53,-1.95,1.56],['c',-0.21,0.12,-0.33,0.09,-0.75,-0.24],['c',-0.30,-0.27,-0.36,-0.36,-0.36,-0.54],['c',0.00,-0.03,0.03,-0.12,0.06,-0.18],['c',0.03,-0.06,0.90,-0.75,1.89,-1.56],['l',1.80,-1.47],['c',0.00,-0.03,-0.81,-0.69,-1.80,-1.50],['c',-0.99,-0.81,-1.86,-1.50,-1.89,-1.56],['c',-0.06,-0.12,-0.09,-0.21,-0.03,-0.36],['c',0.03,-0.09,0.57,-0.57,0.72,-0.63],['z']],w:9.843,h:8.139},
    		'scripts.ufermata':{d:[['M',-0.75,-10.77],['c',0.12,0.00,0.45,-0.03,0.69,-0.03],['c',2.91,-0.03,5.55,1.53,7.41,4.35],['c',1.17,1.71,1.95,3.72,2.43,6.03],['c',0.12,0.51,0.12,0.57,0.03,0.69],['c',-0.12,0.21,-0.48,0.27,-0.69,0.12],['c',-0.12,-0.09,-0.18,-0.24,-0.27,-0.69],['c',-0.78,-3.63,-3.42,-6.54,-6.78,-7.38],['c',-0.78,-0.21,-1.20,-0.24,-2.07,-0.24],['c',-0.63,0.00,-0.84,0.00,-1.20,0.06],['c',-1.83,0.27,-3.42,1.08,-4.80,2.37],['c',-1.41,1.35,-2.40,3.21,-2.85,5.19],['c',-0.09,0.45,-0.15,0.60,-0.27,0.69],['c',-0.21,0.15,-0.57,0.09,-0.69,-0.12],['c',-0.09,-0.12,-0.09,-0.18,0.03,-0.69],['c',0.33,-1.62,0.78,-3.00,1.47,-4.38],['c',1.77,-3.54,4.44,-5.67,7.56,-5.97],['z'],['m',0.33,7.47],['c',1.38,-0.30,2.58,0.90,2.31,2.25],['c',-0.15,0.72,-0.78,1.35,-1.47,1.50],['c',-1.38,0.27,-2.58,-0.93,-2.31,-2.31],['c',0.15,-0.69,0.78,-1.29,1.47,-1.44],['z']],w:19.748,h:11.289},
    		'scripts.dfermata':{d:[['M',-9.63,-0.42],['c',0.15,-0.09,0.36,-0.06,0.51,0.03],['c',0.12,0.09,0.18,0.24,0.27,0.66],['c',0.78,3.66,3.42,6.57,6.78,7.41],['c',0.78,0.21,1.20,0.24,2.07,0.24],['c',0.63,0.00,0.84,0.00,1.20,-0.06],['c',1.83,-0.27,3.42,-1.08,4.80,-2.37],['c',1.41,-1.35,2.40,-3.21,2.85,-5.22],['c',0.09,-0.42,0.15,-0.57,0.27,-0.66],['c',0.21,-0.15,0.57,-0.09,0.69,0.12],['c',0.09,0.12,0.09,0.18,-0.03,0.69],['c',-0.33,1.62,-0.78,3.00,-1.47,4.38],['c',-1.92,3.84,-4.89,6.00,-8.31,6.00],['c',-3.42,0.00,-6.39,-2.16,-8.31,-6.00],['c',-0.48,-0.96,-0.84,-1.92,-1.14,-2.97],['c',-0.18,-0.69,-0.42,-1.74,-0.42,-1.92],['c',0.00,-0.12,0.09,-0.27,0.24,-0.33],['z'],['m',9.21,0.00],['c',1.20,-0.27,2.34,0.63,2.34,1.86],['c',0.00,0.90,-0.66,1.68,-1.50,1.89],['c',-1.38,0.27,-2.58,-0.93,-2.31,-2.31],['c',0.15,-0.69,0.78,-1.29,1.47,-1.44],['z']],w:19.744,h:11.274},
    		'scripts.sforzato':{d:[['M',-6.45,-3.69],['c',0.06,-0.03,0.15,-0.06,0.18,-0.06],['c',0.06,0.00,2.85,0.72,6.24,1.59],['l',6.33,1.65],['c',0.33,0.06,0.45,0.21,0.45,0.51],['c',0.00,0.30,-0.12,0.45,-0.45,0.51],['l',-6.33,1.65],['c',-3.39,0.87,-6.18,1.59,-6.21,1.59],['c',-0.21,0.00,-0.48,-0.24,-0.51,-0.45],['c',0.00,-0.15,0.06,-0.36,0.18,-0.45],['c',0.09,-0.06,0.87,-0.27,3.84,-1.05],['c',2.04,-0.54,3.84,-0.99,4.02,-1.02],['c',0.15,-0.06,1.14,-0.24,2.22,-0.42],['c',1.05,-0.18,1.92,-0.36,1.92,-0.36],['c',0.00,0.00,-0.87,-0.18,-1.92,-0.36],['c',-1.08,-0.18,-2.07,-0.36,-2.22,-0.42],['c',-0.18,-0.03,-1.98,-0.48,-4.02,-1.02],['c',-2.97,-0.78,-3.75,-0.99,-3.84,-1.05],['c',-0.12,-0.09,-0.18,-0.30,-0.18,-0.45],['c',0.03,-0.15,0.15,-0.30,0.30,-0.39],['z']],w:13.5,h:7.5},
    		'scripts.staccato':{d:[['M',-0.36,-1.47],['c',0.93,-0.21,1.86,0.51,1.86,1.47],['c',0.00,0.93,-0.87,1.65,-1.80,1.47],['c',-0.54,-0.12,-1.02,-0.57,-1.14,-1.08],['c',-0.21,-0.81,0.27,-1.65,1.08,-1.86],['z']],w:2.989,h:3.004},
    		'scripts.tenuto':{d:[['M',-4.20,-0.48],['l',0.12,-0.06],['l',4.08,0.00],['l',4.08,0.00],['l',0.12,0.06],['c',0.39,0.21,0.39,0.75,0.00,0.96],['l',-0.12,0.06],['l',-4.08,0.00],['l',-4.08,0.00],['l',-0.12,-0.06],['c',-0.39,-0.21,-0.39,-0.75,0.00,-0.96],['z']],w:8.985,h:1.08},
    		'scripts.umarcato':{d:[['M',-0.15,-8.19],['c',0.15,-0.12,0.36,-0.03,0.45,0.15],['c',0.21,0.42,3.45,7.65,3.45,7.71],['c',0.00,0.12,-0.12,0.27,-0.21,0.30],['c',-0.03,0.03,-0.51,0.03,-1.14,0.03],['c',-1.05,0.00,-1.08,0.00,-1.17,-0.06],['c',-0.09,-0.06,-0.24,-0.36,-1.17,-2.40],['c',-0.57,-1.29,-1.05,-2.34,-1.08,-2.34],['c',0.00,-0.03,-0.51,1.02,-1.08,2.34],['c',-0.93,2.07,-1.08,2.34,-1.14,2.40],['c',-0.06,0.03,-0.15,0.06,-0.18,0.06],['c',-0.15,0.00,-0.33,-0.18,-0.33,-0.33],['c',0.00,-0.06,3.24,-7.32,3.45,-7.71],['c',0.03,-0.06,0.09,-0.15,0.15,-0.15],['z']],w:7.5,h:8.245},
    		'scripts.dmarcato':{d:[['M',-3.57,0.03],['c',0.03,0.00,0.57,-0.03,1.17,-0.03],['c',1.05,0.00,1.08,0.00,1.17,0.06],['c',0.09,0.06,0.24,0.36,1.17,2.40],['c',0.57,1.29,1.05,2.34,1.08,2.34],['c',0.00,0.03,0.51,-1.02,1.08,-2.34],['c',0.93,-2.07,1.08,-2.34,1.14,-2.40],['c',0.06,-0.03,0.15,-0.06,0.18,-0.06],['c',0.15,0.00,0.33,0.18,0.33,0.33],['c',0.00,0.09,-3.45,7.74,-3.54,7.83],['c',-0.12,0.12,-0.30,0.12,-0.42,0.00],['c',-0.09,-0.09,-3.54,-7.74,-3.54,-7.83],['c',0.00,-0.09,0.12,-0.27,0.18,-0.30],['z']],w:7.5,h:8.25},
    		'scripts.stopped':{d:[['M',-0.27,-4.08],['c',0.18,-0.09,0.36,-0.09,0.54,0.00],['c',0.18,0.09,0.24,0.15,0.33,0.30],['l',0.06,0.15],['l',0.00,1.50],['l',0.00,1.47],['l',1.47,0.00],['l',1.50,0.00],['l',0.15,0.06],['c',0.15,0.09,0.21,0.15,0.30,0.33],['c',0.09,0.18,0.09,0.36,0.00,0.54],['c',-0.09,0.18,-0.15,0.24,-0.33,0.33],['c',-0.12,0.06,-0.18,0.06,-1.62,0.06],['l',-1.47,0.00],['l',0.00,1.47],['l',0.00,1.47],['l',-0.06,0.15],['c',-0.09,0.18,-0.15,0.24,-0.33,0.33],['c',-0.18,0.09,-0.36,0.09,-0.54,0.00],['c',-0.18,-0.09,-0.24,-0.15,-0.33,-0.33],['l',-0.06,-0.15],['l',0.00,-1.47],['l',0.00,-1.47],['l',-1.47,0.00],['c',-1.44,0.00,-1.50,0.00,-1.62,-0.06],['c',-0.18,-0.09,-0.24,-0.15,-0.33,-0.33],['c',-0.09,-0.18,-0.09,-0.36,0.00,-0.54],['c',0.09,-0.18,0.15,-0.24,0.33,-0.33],['l',0.15,-0.06],['l',1.47,0.00],['l',1.47,0.00],['l',0.00,-1.47],['c',0.00,-1.44,0.00,-1.50,0.06,-1.62],['c',0.09,-0.18,0.15,-0.24,0.33,-0.33],['z']],w:8.295,h:8.295},
    		'scripts.upbow':{d:[['M',-4.65,-15.54],['c',0.12,-0.09,0.36,-0.06,0.48,0.03],['c',0.03,0.03,0.09,0.09,0.12,0.15],['c',0.03,0.06,0.66,2.13,1.41,4.62],['c',1.35,4.41,1.38,4.56,2.01,6.96],['l',0.63,2.46],['l',0.63,-2.46],['c',0.63,-2.40,0.66,-2.55,2.01,-6.96],['c',0.75,-2.49,1.38,-4.56,1.41,-4.62],['c',0.06,-0.15,0.18,-0.21,0.36,-0.24],['c',0.15,0.00,0.30,0.06,0.39,0.18],['c',0.15,0.21,0.24,-0.18,-2.10,7.56],['c',-1.20,3.96,-2.22,7.32,-2.25,7.41],['c',0.00,0.12,-0.06,0.27,-0.09,0.30],['c',-0.12,0.21,-0.60,0.21,-0.72,0.00],['c',-0.03,-0.03,-0.09,-0.18,-0.09,-0.30],['c',-0.03,-0.09,-1.05,-3.45,-2.25,-7.41],['c',-2.34,-7.74,-2.25,-7.35,-2.10,-7.56],['c',0.03,-0.03,0.09,-0.09,0.15,-0.12],['z']],w:9.73,h:15.608},
    		'scripts.downbow':{d:[['M',-5.55,-9.93],['l',0.09,-0.06],['l',5.46,0.00],['l',5.46,0.00],['l',0.09,0.06],['l',0.06,0.09],['l',0.00,4.77],['c',0.00,5.28,0.00,4.89,-0.18,5.01],['c',-0.18,0.12,-0.42,0.06,-0.54,-0.12],['c',-0.06,-0.09,-0.06,-0.18,-0.06,-2.97],['l',0.00,-2.85],['l',-4.83,0.00],['l',-4.83,0.00],['l',0.00,2.85],['c',0.00,2.79,0.00,2.88,-0.06,2.97],['c',-0.15,0.24,-0.51,0.24,-0.66,0.00],['c',-0.06,-0.09,-0.06,-0.21,-0.06,-4.89],['l',0.00,-4.77],['z']],w:11.22,h:9.992},
    		'scripts.turn':{d:[['M',-4.77,-3.90],['c',0.36,-0.06,1.05,-0.06,1.44,0.03],['c',0.78,0.15,1.50,0.51,2.34,1.14],['c',0.60,0.45,1.05,0.87,2.22,2.01],['c',1.11,1.08,1.62,1.50,2.22,1.86],['c',0.60,0.36,1.32,0.57,1.92,0.57],['c',0.90,0.00,1.71,-0.57,1.89,-1.35],['c',0.24,-0.93,-0.39,-1.89,-1.35,-2.10],['l',-0.15,-0.06],['l',-0.09,0.15],['c',-0.03,0.09,-0.15,0.24,-0.24,0.33],['c',-0.72,0.72,-2.04,0.54,-2.49,-0.36],['c',-0.48,-0.93,0.03,-1.86,1.17,-2.19],['c',0.30,-0.09,1.02,-0.09,1.35,0.00],['c',0.99,0.27,1.74,0.87,2.25,1.83],['c',0.69,1.41,0.63,3.00,-0.21,4.26],['c',-0.21,0.30,-0.69,0.81,-0.99,1.02],['c',-0.30,0.21,-0.84,0.45,-1.17,0.54],['c',-1.23,0.36,-2.49,0.15,-3.72,-0.60],['c',-0.75,-0.48,-1.41,-1.02,-2.85,-2.46],['c',-1.11,-1.08,-1.62,-1.50,-2.22,-1.86],['c',-0.60,-0.36,-1.32,-0.57,-1.92,-0.57],['c',-0.90,0.00,-1.71,0.57,-1.89,1.35],['c',-0.24,0.93,0.39,1.89,1.35,2.10],['l',0.15,0.06],['l',0.09,-0.15],['c',0.03,-0.09,0.15,-0.24,0.24,-0.33],['c',0.72,-0.72,2.04,-0.54,2.49,0.36],['c',0.48,0.93,-0.03,1.86,-1.17,2.19],['c',-0.30,0.09,-1.02,0.09,-1.35,0.00],['c',-0.99,-0.27,-1.74,-0.87,-2.25,-1.83],['c',-0.69,-1.41,-0.63,-3.00,0.21,-4.26],['c',0.21,-0.30,0.69,-0.81,0.99,-1.02],['c',0.48,-0.33,1.11,-0.57,1.74,-0.66],['z']],w:16.366,h:7.893},
    		'scripts.trill':{d:[['M',-0.51,-16.02],['c',0.12,-0.09,0.21,-0.18,0.21,-0.18],['l',-0.81,4.02],['l',-0.81,4.02],['c',0.03,0.00,0.51,-0.27,1.08,-0.60],['c',0.60,-0.30,1.14,-0.63,1.26,-0.66],['c',1.14,-0.54,2.31,-0.60,3.09,-0.18],['c',0.27,0.15,0.54,0.36,0.60,0.51],['l',0.06,0.12],['l',0.21,-0.21],['c',0.90,-0.81,2.22,-0.99,3.12,-0.42],['c',0.60,0.42,0.90,1.14,0.78,2.07],['c',-0.15,1.29,-1.05,2.31,-1.95,2.25],['c',-0.48,-0.03,-0.78,-0.30,-0.96,-0.81],['c',-0.09,-0.27,-0.09,-0.90,-0.03,-1.20],['c',0.21,-0.75,0.81,-1.23,1.59,-1.32],['l',0.24,-0.03],['l',-0.09,-0.12],['c',-0.51,-0.66,-1.62,-0.63,-2.31,0.03],['c',-0.39,0.42,-0.30,0.09,-1.23,4.77],['l',-0.81,4.14],['c',-0.03,0.00,-0.12,-0.03,-0.21,-0.09],['c',-0.33,-0.15,-0.54,-0.18,-0.99,-0.18],['c',-0.42,0.00,-0.66,0.03,-1.05,0.18],['c',-0.12,0.06,-0.21,0.09,-0.21,0.09],['c',0.00,-0.03,0.36,-1.86,0.81,-4.11],['c',0.90,-4.47,0.87,-4.26,0.69,-4.53],['c',-0.21,-0.36,-0.66,-0.51,-1.17,-0.36],['c',-0.15,0.06,-2.22,1.14,-2.58,1.38],['c',-0.12,0.09,-0.12,0.09,-0.21,0.60],['l',-0.09,0.51],['l',0.21,0.24],['c',0.63,0.75,1.02,1.47,1.20,2.19],['c',0.06,0.27,0.06,0.36,0.06,0.81],['c',0.00,0.42,0.00,0.54,-0.06,0.78],['c',-0.15,0.54,-0.33,0.93,-0.63,1.35],['c',-0.18,0.24,-0.57,0.63,-0.81,0.78],['c',-0.24,0.15,-0.63,0.36,-0.84,0.42],['c',-0.27,0.06,-0.66,0.06,-0.87,0.03],['c',-0.81,-0.18,-1.32,-1.05,-1.38,-2.46],['c',-0.03,-0.60,0.03,-0.99,0.33,-2.46],['c',0.21,-1.08,0.24,-1.32,0.21,-1.29],['c',-1.20,0.48,-2.40,0.75,-3.21,0.72],['c',-0.69,-0.06,-1.17,-0.30,-1.41,-0.72],['c',-0.39,-0.75,-0.12,-1.80,0.66,-2.46],['c',0.24,-0.18,0.69,-0.42,1.02,-0.51],['c',0.69,-0.18,1.53,-0.15,2.31,0.09],['c',0.30,0.09,0.75,0.30,0.99,0.45],['c',0.12,0.09,0.15,0.09,0.15,0.03],['c',0.03,-0.03,0.33,-1.59,0.72,-3.45],['c',0.36,-1.86,0.66,-3.42,0.69,-3.45],['c',0.00,-0.03,0.03,-0.03,0.21,0.03],['c',0.21,0.06,0.27,0.06,0.48,0.06],['c',0.42,-0.03,0.78,-0.18,1.26,-0.48],['c',0.15,-0.12,0.36,-0.27,0.48,-0.39],['z'],['m',-5.73,7.68],['c',-0.27,-0.03,-0.96,-0.06,-1.20,-0.03],['c',-0.81,0.12,-1.35,0.57,-1.50,1.20],['c',-0.18,0.66,0.12,1.14,0.75,1.29],['c',0.66,0.12,1.92,-0.12,3.18,-0.66],['l',0.33,-0.15],['l',0.09,-0.39],['c',0.06,-0.21,0.09,-0.42,0.09,-0.45],['c',0.00,-0.03,-0.45,-0.30,-0.75,-0.45],['c',-0.27,-0.15,-0.66,-0.27,-0.99,-0.36],['z'],['m',4.29,3.63],['c',-0.24,-0.39,-0.51,-0.75,-0.51,-0.69],['c',-0.06,0.12,-0.39,1.92,-0.45,2.28],['c',-0.09,0.54,-0.12,1.14,-0.06,1.38],['c',0.06,0.42,0.21,0.60,0.51,0.57],['c',0.39,-0.06,0.75,-0.48,0.93,-1.14],['c',0.09,-0.33,0.09,-1.05,0.00,-1.38],['c',-0.09,-0.39,-0.24,-0.69,-0.42,-1.02],['z']],w:17.963,h:16.49},
    		'scripts.segno':{d:[['M',-3.72,-11.22],['c',0.78,-0.09,1.59,0.03,2.31,0.42],['c',1.20,0.60,2.01,1.71,2.31,3.09],['c',0.09,0.42,0.09,1.20,0.03,1.50],['c',-0.15,0.45,-0.39,0.81,-0.66,0.93],['c',-0.33,0.18,-0.84,0.21,-1.23,0.15],['c',-0.81,-0.18,-1.32,-0.93,-1.26,-1.89],['c',0.03,-0.36,0.09,-0.57,0.24,-0.90],['c',0.15,-0.33,0.45,-0.60,0.72,-0.75],['c',0.12,-0.06,0.18,-0.09,0.18,-0.12],['c',0.00,-0.03,-0.03,-0.15,-0.09,-0.24],['c',-0.18,-0.45,-0.54,-0.87,-0.96,-1.08],['c',-1.11,-0.57,-2.34,-0.18,-2.88,0.90],['c',-0.24,0.51,-0.33,1.11,-0.24,1.83],['c',0.27,1.92,1.50,3.54,3.93,5.13],['c',0.48,0.33,1.26,0.78,1.29,0.78],['c',0.03,0.00,1.35,-2.19,2.94,-4.89],['l',2.88,-4.89],['l',0.84,0.00],['l',0.87,0.00],['l',-0.03,0.06],['c',-0.15,0.21,-6.15,10.41,-6.15,10.44],['c',0.00,0.00,0.21,0.15,0.48,0.27],['c',2.61,1.47,4.35,3.03,5.13,4.65],['c',1.14,2.34,0.51,5.07,-1.44,6.39],['c',-0.66,0.42,-1.32,0.63,-2.13,0.69],['c',-2.01,0.09,-3.81,-1.41,-4.26,-3.54],['c',-0.09,-0.42,-0.09,-1.20,-0.03,-1.50],['c',0.15,-0.45,0.39,-0.81,0.66,-0.93],['c',0.33,-0.18,0.84,-0.21,1.23,-0.15],['c',0.81,0.18,1.32,0.93,1.26,1.89],['c',-0.03,0.36,-0.09,0.57,-0.24,0.90],['c',-0.15,0.33,-0.45,0.60,-0.72,0.75],['c',-0.12,0.06,-0.18,0.09,-0.18,0.12],['c',0.00,0.03,0.03,0.15,0.09,0.24],['c',0.18,0.45,0.54,0.87,0.96,1.08],['c',1.11,0.57,2.34,0.18,2.88,-0.90],['c',0.24,-0.51,0.33,-1.11,0.24,-1.83],['c',-0.27,-1.92,-1.50,-3.54,-3.93,-5.13],['c',-0.48,-0.33,-1.26,-0.78,-1.29,-0.78],['c',-0.03,0.00,-1.35,2.19,-2.91,4.89],['l',-2.88,4.89],['l',-0.87,0.00],['l',-0.87,0.00],['l',0.03,-0.06],['c',0.15,-0.21,6.15,-10.41,6.15,-10.44],['c',0.00,0.00,-0.21,-0.15,-0.48,-0.30],['c',-2.61,-1.44,-4.35,-3.00,-5.13,-4.62],['c',-0.90,-1.89,-0.72,-4.02,0.48,-5.52],['c',0.69,-0.84,1.68,-1.41,2.73,-1.53],['z'],['m',8.76,9.09],['c',0.03,-0.03,0.15,-0.03,0.27,-0.03],['c',0.33,0.03,0.57,0.18,0.72,0.48],['c',0.09,0.18,0.09,0.57,0.00,0.75],['c',-0.09,0.18,-0.21,0.30,-0.36,0.39],['c',-0.15,0.06,-0.21,0.06,-0.39,0.06],['c',-0.21,0.00,-0.27,0.00,-0.39,-0.06],['c',-0.30,-0.15,-0.48,-0.45,-0.48,-0.75],['c',0.00,-0.39,0.24,-0.72,0.63,-0.84],['z'],['m',-10.53,2.61],['c',0.03,-0.03,0.15,-0.03,0.27,-0.03],['c',0.33,0.03,0.57,0.18,0.72,0.48],['c',0.09,0.18,0.09,0.57,0.00,0.75],['c',-0.09,0.18,-0.21,0.30,-0.36,0.39],['c',-0.15,0.06,-0.21,0.06,-0.39,0.06],['c',-0.21,0.00,-0.27,0.00,-0.39,-0.06],['c',-0.30,-0.15,-0.48,-0.45,-0.48,-0.75],['c',0.00,-0.39,0.24,-0.72,0.63,-0.84],['z']],w:15,h:22.504},
    		'scripts.coda':{d:[['M',-0.21,-10.47],['c',0.18,-0.12,0.42,-0.06,0.54,0.12],['c',0.06,0.09,0.06,0.18,0.06,1.50],['l',0.00,1.38],['l',0.18,0.00],['c',0.39,0.06,0.96,0.24,1.38,0.48],['c',1.68,0.93,2.82,3.24,3.03,6.12],['c',0.03,0.24,0.03,0.45,0.03,0.45],['c',0.00,0.03,0.60,0.03,1.35,0.03],['c',1.50,0.00,1.47,0.00,1.59,0.18],['c',0.09,0.12,0.09,0.30,0.00,0.42],['c',-0.12,0.18,-0.09,0.18,-1.59,0.18],['c',-0.75,0.00,-1.35,0.00,-1.35,0.03],['c',0.00,0.00,0.00,0.21,-0.03,0.42],['c',-0.24,3.15,-1.53,5.58,-3.45,6.36],['c',-0.27,0.12,-0.72,0.24,-0.96,0.27],['l',-0.18,0.00],['l',0.00,1.38],['c',0.00,1.32,0.00,1.41,-0.06,1.50],['c',-0.15,0.24,-0.51,0.24,-0.66,0.00],['c',-0.06,-0.09,-0.06,-0.18,-0.06,-1.50],['l',0.00,-1.38],['l',-0.18,0.00],['c',-0.39,-0.06,-0.96,-0.24,-1.38,-0.48],['c',-1.68,-0.93,-2.82,-3.24,-3.03,-6.15],['c',-0.03,-0.21,-0.03,-0.42,-0.03,-0.42],['c',0.00,-0.03,-0.60,-0.03,-1.35,-0.03],['c',-1.50,0.00,-1.47,0.00,-1.59,-0.18],['c',-0.09,-0.12,-0.09,-0.30,0.00,-0.42],['c',0.12,-0.18,0.09,-0.18,1.59,-0.18],['c',0.75,0.00,1.35,0.00,1.35,-0.03],['c',0.00,0.00,0.00,-0.21,0.03,-0.45],['c',0.24,-3.12,1.53,-5.55,3.45,-6.33],['c',0.27,-0.12,0.72,-0.24,0.96,-0.27],['l',0.18,0.00],['l',0.00,-1.38],['c',0.00,-1.53,0.00,-1.50,0.18,-1.62],['z'],['m',-0.18,6.93],['c',0.00,-2.97,0.00,-3.15,-0.06,-3.15],['c',-0.09,0.00,-0.51,0.15,-0.66,0.21],['c',-0.87,0.51,-1.38,1.62,-1.56,3.51],['c',-0.06,0.54,-0.12,1.59,-0.12,2.16],['l',0.00,0.42],['l',1.20,0.00],['l',1.20,0.00],['l',0.00,-3.15],['z'],['m',1.17,-3.06],['c',-0.09,-0.03,-0.21,-0.06,-0.27,-0.09],['l',-0.12,0.00],['l',0.00,3.15],['l',0.00,3.15],['l',1.20,0.00],['l',1.20,0.00],['l',0.00,-0.81],['c',-0.06,-2.40,-0.33,-3.69,-0.93,-4.59],['c',-0.27,-0.39,-0.66,-0.69,-1.08,-0.81],['z'],['m',-1.17,10.14],['l',0.00,-3.15],['l',-1.20,0.00],['l',-1.20,0.00],['l',0.00,0.81],['c',0.03,0.96,0.06,1.47,0.15,2.13],['c',0.24,2.04,0.96,3.12,2.13,3.36],['l',0.12,0.00],['l',0.00,-3.15],['z'],['m',3.18,-2.34],['l',0.00,-0.81],['l',-1.20,0.00],['l',-1.20,0.00],['l',0.00,3.15],['l',0.00,3.15],['l',0.12,0.00],['c',1.17,-0.24,1.89,-1.32,2.13,-3.36],['c',0.09,-0.66,0.12,-1.17,0.15,-2.13],['z']],w:16.035,h:21.062},
    		'scripts.comma':{d:[['M',1.14,-4.62],['c',0.30,-0.12,0.69,-0.03,0.93,0.15],['c',0.12,0.12,0.36,0.45,0.51,0.78],['c',0.90,1.77,0.54,4.05,-1.08,6.75],['c',-0.36,0.63,-0.87,1.38,-0.96,1.44],['c',-0.18,0.12,-0.42,0.06,-0.54,-0.12],['c',-0.09,-0.18,-0.09,-0.30,0.12,-0.60],['c',0.96,-1.44,1.44,-2.97,1.38,-4.35],['c',-0.06,-0.93,-0.30,-1.68,-0.78,-2.46],['c',-0.27,-0.39,-0.33,-0.63,-0.24,-0.96],['c',0.09,-0.27,0.36,-0.54,0.66,-0.63],['z']],w:3.042,h:9.237},
    		'scripts.roll':{d:[['M',1.95,-6.00],['c',0.21,-0.09,0.36,-0.09,0.57,0.00],['c',0.39,0.15,0.63,0.39,1.47,1.35],['c',0.66,0.75,0.78,0.87,1.08,1.05],['c',0.75,0.45,1.65,0.42,2.40,-0.06],['c',0.12,-0.09,0.27,-0.27,0.54,-0.60],['c',0.42,-0.54,0.51,-0.63,0.69,-0.63],['c',0.09,0.00,0.30,0.12,0.36,0.21],['c',0.09,0.12,0.12,0.30,0.03,0.42],['c',-0.06,0.12,-3.15,3.90,-3.30,4.08],['c',-0.06,0.06,-0.18,0.12,-0.27,0.18],['c',-0.27,0.12,-0.60,0.06,-0.99,-0.27],['c',-0.27,-0.21,-0.42,-0.39,-1.08,-1.14],['c',-0.63,-0.72,-0.81,-0.90,-1.17,-1.08],['c',-0.36,-0.18,-0.57,-0.21,-0.99,-0.21],['c',-0.39,0.00,-0.63,0.03,-0.93,0.18],['c',-0.36,0.15,-0.51,0.27,-0.90,0.81],['c',-0.24,0.27,-0.45,0.51,-0.48,0.54],['c',-0.12,0.09,-0.27,0.06,-0.39,0.00],['c',-0.24,-0.15,-0.33,-0.39,-0.21,-0.60],['c',0.09,-0.12,3.18,-3.87,3.33,-4.02],['c',0.06,-0.06,0.18,-0.15,0.24,-0.21],['z']],w:10.817,h:6.125},
    		'scripts.prall':{d:[['M',-4.38,-3.69],['c',0.06,-0.03,0.18,-0.06,0.24,-0.06],['c',0.30,0.00,0.27,-0.03,1.89,1.95],['l',1.53,1.83],['c',0.03,0.00,0.57,-0.84,1.23,-1.83],['c',1.14,-1.68,1.23,-1.83,1.35,-1.89],['c',0.06,-0.03,0.18,-0.06,0.24,-0.06],['c',0.30,0.00,0.27,-0.03,1.89,1.95],['l',1.53,1.83],['l',0.48,-0.69],['c',0.51,-0.78,0.54,-0.84,0.69,-0.90],['c',0.42,-0.18,0.87,0.15,0.81,0.60],['c',-0.03,0.12,-0.30,0.51,-1.50,2.37],['c',-1.38,2.07,-1.50,2.22,-1.62,2.28],['c',-0.06,0.03,-0.18,0.06,-0.24,0.06],['c',-0.30,0.00,-0.27,0.03,-1.89,-1.95],['l',-1.53,-1.83],['c',-0.03,0.00,-0.57,0.84,-1.23,1.83],['c',-1.14,1.68,-1.23,1.83,-1.35,1.89],['c',-0.06,0.03,-0.18,0.06,-0.24,0.06],['c',-0.30,0.00,-0.27,0.03,-1.89,-1.95],['l',-1.53,-1.83],['l',-0.48,0.69],['c',-0.51,0.78,-0.54,0.84,-0.69,0.90],['c',-0.42,0.18,-0.87,-0.15,-0.81,-0.60],['c',0.03,-0.12,0.30,-0.51,1.50,-2.37],['c',1.38,-2.07,1.50,-2.22,1.62,-2.28],['z']],w:15.011,h:7.5},
    		'scripts.arpeggio':{d:[['M',1.5,0],['c',1.5,2,1.5,3,1.5,3],['s',0,1,-2,1.5],['s',-0.5,3,1,5.5],['l',1.5,0],['s',-1.75,-2,-1.9,-3.25],['s',2.15,-0.6,2.95,-1.6],['s',0.45,-1,0.5,-1.25],['s',0,-1,-2,-3.9],['l',-1.5,0],['z']],w:5,h:10},
    		'scripts.mordent':{d:[['M',-0.21,-4.95],['c',0.27,-0.15,0.63,0.00,0.75,0.27],['c',0.06,0.12,0.06,0.24,0.06,1.44],['l',0.00,1.29],['l',0.57,-0.84],['c',0.51,-0.75,0.57,-0.84,0.69,-0.90],['c',0.06,-0.03,0.18,-0.06,0.24,-0.06],['c',0.30,0.00,0.27,-0.03,1.89,1.95],['l',1.53,1.83],['l',0.48,-0.69],['c',0.51,-0.78,0.54,-0.84,0.69,-0.90],['c',0.42,-0.18,0.87,0.15,0.81,0.60],['c',-0.03,0.12,-0.30,0.51,-1.50,2.37],['c',-1.38,2.07,-1.50,2.22,-1.62,2.28],['c',-0.06,0.03,-0.18,0.06,-0.24,0.06],['c',-0.30,0.00,-0.27,0.03,-1.83,-1.89],['c',-0.81,-0.99,-1.50,-1.80,-1.53,-1.86],['c',-0.06,-0.03,-0.06,-0.03,-0.12,0.03],['c',-0.06,0.06,-0.06,0.15,-0.06,2.28],['c',0.00,1.95,0.00,2.25,-0.06,2.34],['c',-0.18,0.45,-0.81,0.48,-1.05,0.03],['c',-0.03,-0.06,-0.06,-0.24,-0.06,-1.41],['l',0.00,-1.35],['l',-0.57,0.84],['c',-0.54,0.78,-0.60,0.87,-0.72,0.93],['c',-0.06,0.03,-0.18,0.06,-0.24,0.06],['c',-0.30,0.00,-0.27,0.03,-1.89,-1.95],['l',-1.53,-1.83],['l',-0.48,0.69],['c',-0.51,0.78,-0.54,0.84,-0.69,0.90],['c',-0.42,0.18,-0.87,-0.15,-0.81,-0.60],['c',0.03,-0.12,0.30,-0.51,1.50,-2.37],['c',1.38,-2.07,1.50,-2.22,1.62,-2.28],['c',0.06,-0.03,0.18,-0.06,0.24,-0.06],['c',0.30,0.00,0.27,-0.03,1.89,1.95],['l',1.53,1.83],['c',0.03,0.00,0.06,-0.06,0.09,-0.09],['c',0.06,-0.12,0.06,-0.15,0.06,-2.28],['c',0.00,-1.92,0.00,-2.22,0.06,-2.31],['c',0.06,-0.15,0.15,-0.24,0.30,-0.30],['z']],w:15.011,h:10.012},
    		'flags.u8th':{d:[['M',-0.42,3.75],['l',0.00,-3.75],['l',0.21,0.00],['l',0.21,0.00],['l',0.00,0.18],['c',0.00,0.30,0.06,0.84,0.12,1.23],['c',0.24,1.53,0.90,3.12,2.13,5.16],['l',0.99,1.59],['c',0.87,1.44,1.38,2.34,1.77,3.09],['c',0.81,1.68,1.20,3.06,1.26,4.53],['c',0.03,1.53,-0.21,3.27,-0.75,5.01],['c',-0.21,0.69,-0.51,1.50,-0.60,1.59],['c',-0.09,0.12,-0.27,0.21,-0.42,0.21],['c',-0.15,0.00,-0.42,-0.12,-0.51,-0.21],['c',-0.15,-0.18,-0.18,-0.42,-0.09,-0.66],['c',0.15,-0.33,0.45,-1.20,0.57,-1.62],['c',0.42,-1.38,0.60,-2.58,0.60,-3.90],['c',0.00,-0.66,0.00,-0.81,-0.06,-1.11],['c',-0.39,-2.07,-1.80,-4.26,-4.59,-7.14],['l',-0.42,-0.45],['l',-0.21,0.00],['l',-0.21,0.00],['l',0.00,-3.75],['z']],w:6.692,h:22.59},
    		'flags.u16th':{d:[['M',-0.42,7.50],['l',0.00,-7.50],['l',0.21,0.00],['l',0.21,0.00],['l',0.00,0.39],['c',0.06,1.08,0.39,2.19,0.99,3.39],['c',0.45,0.90,0.87,1.59,1.95,3.12],['c',1.29,1.86,1.77,2.64,2.22,3.57],['c',0.45,0.93,0.72,1.80,0.87,2.64],['c',0.06,0.51,0.06,1.50,0.00,1.92],['c',-0.12,0.60,-0.30,1.20,-0.54,1.71],['l',-0.09,0.24],['l',0.18,0.45],['c',0.51,1.20,0.72,2.22,0.69,3.42],['c',-0.06,1.53,-0.39,3.03,-0.99,4.53],['c',-0.30,0.75,-0.36,0.81,-0.57,0.90],['c',-0.15,0.09,-0.33,0.06,-0.48,0.00],['c',-0.18,-0.09,-0.27,-0.18,-0.33,-0.33],['c',-0.09,-0.18,-0.06,-0.30,0.12,-0.75],['c',0.66,-1.41,1.02,-2.88,1.08,-4.32],['c',0.00,-0.60,-0.03,-1.05,-0.18,-1.59],['c',-0.30,-1.20,-0.99,-2.40,-2.25,-3.87],['c',-0.42,-0.48,-1.53,-1.62,-2.19,-2.22],['l',-0.45,-0.42],['l',-0.03,1.11],['l',0.00,1.11],['l',-0.21,0.00],['l',-0.21,0.00],['l',0.00,-7.50],['z'],['m',1.65,0.09],['c',-0.30,-0.30,-0.69,-0.72,-0.90,-0.87],['l',-0.33,-0.33],['l',0.00,0.15],['c',0.00,0.30,0.06,0.81,0.15,1.26],['c',0.27,1.29,0.87,2.61,2.04,4.29],['c',0.15,0.24,0.60,0.87,0.96,1.38],['l',1.08,1.53],['l',0.42,0.63],['c',0.03,0.00,0.12,-0.36,0.21,-0.72],['c',0.06,-0.33,0.06,-1.20,0.00,-1.62],['c',-0.33,-1.71,-1.44,-3.48,-3.63,-5.70],['z']],w:6.693,h:26.337},
    		'flags.u32nd':{d:[['M',-0.42,11.25],['l',0.00,-11.25],['l',0.21,0.00],['l',0.21,0.00],['l',0.00,0.36],['c',0.09,1.68,0.69,3.27,2.07,5.46],['l',0.87,1.35],['c',1.02,1.62,1.47,2.37,1.86,3.18],['c',0.48,1.02,0.78,1.92,0.93,2.88],['c',0.06,0.48,0.06,1.50,0.00,1.89],['c',-0.09,0.42,-0.21,0.87,-0.36,1.26],['l',-0.12,0.30],['l',0.15,0.39],['c',0.69,1.56,0.84,2.88,0.54,4.38],['c',-0.09,0.45,-0.27,1.08,-0.45,1.47],['l',-0.12,0.24],['l',0.18,0.36],['c',0.33,0.72,0.57,1.56,0.69,2.34],['c',0.12,1.02,-0.06,2.52,-0.42,3.84],['c',-0.27,0.93,-0.75,2.13,-0.93,2.31],['c',-0.18,0.15,-0.45,0.18,-0.66,0.09],['c',-0.18,-0.09,-0.27,-0.18,-0.33,-0.33],['c',-0.09,-0.18,-0.06,-0.30,0.06,-0.60],['c',0.21,-0.36,0.42,-0.90,0.57,-1.38],['c',0.51,-1.41,0.69,-3.06,0.48,-4.08],['c',-0.15,-0.81,-0.57,-1.68,-1.20,-2.55],['c',-0.72,-0.99,-1.83,-2.13,-3.30,-3.33],['l',-0.48,-0.42],['l',-0.03,1.53],['l',0.00,1.56],['l',-0.21,0.00],['l',-0.21,0.00],['l',0.00,-11.25],['z'],['m',1.26,-3.96],['c',-0.27,-0.30,-0.54,-0.60,-0.66,-0.72],['l',-0.18,-0.21],['l',0.00,0.42],['c',0.06,0.87,0.24,1.74,0.66,2.67],['c',0.36,0.87,0.96,1.86,1.92,3.18],['c',0.21,0.33,0.63,0.87,0.87,1.23],['c',0.27,0.39,0.60,0.84,0.75,1.08],['l',0.27,0.39],['l',0.03,-0.12],['c',0.12,-0.45,0.15,-1.05,0.09,-1.59],['c',-0.27,-1.86,-1.38,-3.78,-3.75,-6.33],['z'],['m',-0.27,6.09],['c',-0.27,-0.21,-0.48,-0.42,-0.51,-0.45],['c',-0.06,-0.03,-0.06,-0.03,-0.06,0.21],['c',0.00,0.90,0.30,2.04,0.81,3.09],['c',0.48,1.02,0.96,1.77,2.37,3.63],['c',0.60,0.78,1.05,1.44,1.29,1.77],['c',0.06,0.12,0.15,0.21,0.15,0.18],['c',0.03,-0.03,0.18,-0.57,0.24,-0.87],['c',0.06,-0.45,0.06,-1.32,-0.03,-1.74],['c',-0.09,-0.48,-0.24,-0.90,-0.51,-1.44],['c',-0.66,-1.35,-1.83,-2.70,-3.75,-4.38],['z']],w:6.697,h:32.145},
    		'flags.u64th':{d:[['M',-0.42,15.00],['l',0.00,-15.00],['l',0.21,0.00],['l',0.21,0.00],['l',0.00,0.36],['c',0.06,1.20,0.39,2.37,1.02,3.66],['c',0.39,0.81,0.84,1.56,1.80,3.09],['c',0.81,1.26,1.05,1.68,1.35,2.22],['c',0.87,1.50,1.35,2.79,1.56,4.08],['c',0.06,0.54,0.06,1.56,-0.03,2.04],['c',-0.09,0.48,-0.21,0.99,-0.36,1.35],['l',-0.12,0.27],['l',0.12,0.27],['c',0.09,0.15,0.21,0.45,0.27,0.66],['c',0.69,1.89,0.63,3.66,-0.18,5.46],['l',-0.18,0.39],['l',0.15,0.33],['c',0.30,0.66,0.51,1.44,0.63,2.10],['c',0.06,0.48,0.06,1.35,0.00,1.71],['c',-0.15,0.57,-0.42,1.20,-0.78,1.68],['l',-0.21,0.27],['l',0.18,0.33],['c',0.57,1.05,0.93,2.13,1.02,3.18],['c',0.06,0.72,0.00,1.83,-0.21,2.79],['c',-0.18,1.02,-0.63,2.34,-1.02,3.09],['c',-0.15,0.33,-0.48,0.45,-0.78,0.30],['c',-0.18,-0.09,-0.27,-0.18,-0.33,-0.33],['c',-0.09,-0.18,-0.06,-0.30,0.03,-0.54],['c',0.75,-1.50,1.23,-3.45,1.17,-4.89],['c',-0.06,-1.02,-0.42,-2.01,-1.17,-3.15],['c',-0.48,-0.72,-1.02,-1.35,-1.89,-2.22],['c',-0.57,-0.57,-1.56,-1.50,-1.92,-1.77],['l',-0.12,-0.09],['l',0.00,1.68],['l',0.00,1.68],['l',-0.21,0.00],['l',-0.21,0.00],['l',0.00,-15.00],['z'],['m',0.93,-8.07],['c',-0.27,-0.30,-0.48,-0.54,-0.51,-0.54],['c',0.00,0.00,0.00,0.69,0.03,1.02],['c',0.15,1.47,0.75,2.94,2.04,4.83],['l',1.08,1.53],['c',0.39,0.57,0.84,1.20,0.99,1.44],['c',0.15,0.24,0.30,0.45,0.30,0.45],['c',0.00,0.00,0.03,-0.09,0.06,-0.21],['c',0.36,-1.59,-0.15,-3.33,-1.47,-5.40],['c',-0.63,-0.93,-1.35,-1.83,-2.52,-3.12],['z'],['m',0.06,6.72],['c',-0.24,-0.21,-0.48,-0.42,-0.51,-0.45],['l',-0.06,-0.06],['l',0.00,0.33],['c',0.00,1.20,0.30,2.34,0.93,3.60],['c',0.45,0.90,0.96,1.68,2.25,3.51],['c',0.39,0.54,0.84,1.17,1.02,1.44],['c',0.21,0.33,0.33,0.51,0.33,0.48],['c',0.06,-0.09,0.21,-0.63,0.30,-0.99],['c',0.06,-0.33,0.06,-0.45,0.06,-0.96],['c',0.00,-0.60,-0.03,-0.84,-0.18,-1.35],['c',-0.30,-1.08,-1.02,-2.28,-2.13,-3.57],['c',-0.39,-0.45,-1.44,-1.47,-2.01,-1.98],['z'],['m',0.00,6.72],['c',-0.24,-0.21,-0.48,-0.39,-0.51,-0.42],['l',-0.06,-0.06],['l',0.00,0.33],['c',0.00,1.41,0.45,2.82,1.38,4.35],['c',0.42,0.72,0.72,1.14,1.86,2.73],['c',0.36,0.45,0.75,0.99,0.87,1.20],['c',0.15,0.21,0.30,0.36,0.30,0.36],['c',0.06,0.00,0.30,-0.48,0.39,-0.75],['c',0.09,-0.36,0.12,-0.63,0.12,-1.05],['c',-0.06,-1.05,-0.45,-2.04,-1.20,-3.18],['c',-0.57,-0.87,-1.11,-1.53,-2.07,-2.49],['c',-0.36,-0.33,-0.84,-0.78,-1.08,-1.02],['z']],w:6.682,h:39.694},
    		'flags.d8th':{d:[['M',5.67,-21.63],['c',0.24,-0.12,0.54,-0.06,0.69,0.15],['c',0.06,0.06,0.21,0.36,0.39,0.66],['c',0.84,1.77,1.26,3.36,1.32,5.10],['c',0.03,1.29,-0.21,2.37,-0.81,3.63],['c',-0.60,1.23,-1.26,2.13,-3.21,4.38],['c',-1.35,1.53,-1.86,2.19,-2.40,2.97],['c',-0.63,0.93,-1.11,1.92,-1.38,2.79],['c',-0.15,0.54,-0.27,1.35,-0.27,1.80],['l',0.00,0.15],['l',-0.21,0.00],['l',-0.21,0.00],['l',0.00,-3.75],['l',0.00,-3.75],['l',0.21,0.00],['l',0.21,0.00],['l',0.48,-0.30],['c',1.83,-1.11,3.12,-2.10,4.17,-3.12],['c',0.78,-0.81,1.32,-1.53,1.71,-2.31],['c',0.45,-0.93,0.60,-1.74,0.51,-2.88],['c',-0.12,-1.56,-0.63,-3.18,-1.47,-4.68],['c',-0.12,-0.21,-0.15,-0.33,-0.06,-0.51],['c',0.06,-0.15,0.15,-0.24,0.33,-0.33],['z']],w:8.492,h:21.691},
    		'flags.ugrace':{d:[['M',6.03,6.93],['c',0.15,-0.09,0.33,-0.06,0.51,0.00],['c',0.15,0.09,0.21,0.15,0.30,0.33],['c',0.09,0.18,0.06,0.39,-0.03,0.54],['c',-0.06,0.15,-10.89,8.88,-11.07,8.97],['c',-0.15,0.09,-0.33,0.06,-0.48,0.00],['c',-0.18,-0.09,-0.24,-0.15,-0.33,-0.33],['c',-0.09,-0.18,-0.06,-0.39,0.03,-0.54],['c',0.06,-0.15,10.89,-8.88,11.07,-8.97],['z']],w:12.019,h:9.954},
    		'flags.dgrace':{d:[['M',-6.06,-15.93],['c',0.18,-0.09,0.33,-0.12,0.48,-0.06],['c',0.18,0.09,14.01,8.04,14.10,8.10],['c',0.12,0.12,0.18,0.33,0.18,0.51],['c',-0.03,0.21,-0.15,0.39,-0.36,0.48],['c',-0.18,0.09,-0.33,0.12,-0.48,0.06],['c',-0.18,-0.09,-14.01,-8.04,-14.10,-8.10],['c',-0.12,-0.12,-0.18,-0.33,-0.18,-0.51],['c',0.03,-0.21,0.15,-0.39,0.36,-0.48],['z']],w:15.12,h:9.212},
    		'flags.d16th':{d:[['M',6.84,-22.53],['c',0.27,-0.12,0.57,-0.06,0.72,0.15],['c',0.15,0.15,0.33,0.87,0.45,1.56],['c',0.06,0.33,0.06,1.35,0.00,1.65],['c',-0.06,0.33,-0.15,0.78,-0.27,1.11],['c',-0.12,0.33,-0.45,0.96,-0.66,1.32],['l',-0.18,0.27],['l',0.09,0.18],['c',0.48,1.02,0.72,2.25,0.69,3.30],['c',-0.06,1.23,-0.42,2.28,-1.26,3.45],['c',-0.57,0.87,-0.99,1.32,-3.00,3.39],['c',-1.56,1.56,-2.22,2.40,-2.76,3.45],['c',-0.42,0.84,-0.66,1.80,-0.66,2.55],['l',0.00,0.15],['l',-0.21,0.00],['l',-0.21,0.00],['l',0.00,-7.50],['l',0.00,-7.50],['l',0.21,0.00],['l',0.21,0.00],['l',0.00,1.14],['l',0.00,1.11],['l',0.27,-0.15],['c',1.11,-0.57,1.77,-0.99,2.52,-1.47],['c',2.37,-1.56,3.69,-3.15,4.05,-4.83],['c',0.03,-0.18,0.03,-0.39,0.03,-0.78],['c',0.00,-0.60,-0.03,-0.93,-0.24,-1.50],['c',-0.06,-0.18,-0.12,-0.39,-0.15,-0.45],['c',-0.03,-0.24,0.12,-0.48,0.36,-0.60],['z'],['m',-0.63,7.50],['c',-0.06,-0.18,-0.15,-0.36,-0.15,-0.36],['c',-0.03,0.00,-0.03,0.03,-0.06,0.06],['c',-0.06,0.12,-0.96,1.02,-1.95,1.98],['c',-0.63,0.57,-1.26,1.17,-1.44,1.35],['c',-1.53,1.62,-2.28,2.85,-2.55,4.32],['c',-0.03,0.18,-0.03,0.54,-0.06,0.99],['l',0.00,0.69],['l',0.18,-0.09],['c',0.93,-0.54,2.10,-1.29,2.82,-1.83],['c',0.69,-0.51,1.02,-0.81,1.53,-1.29],['c',1.86,-1.89,2.37,-3.66,1.68,-5.82],['z']],w:8.475,h:22.591},
    		'flags.d32nd':{d:[['M',6.84,-29.13],['c',0.27,-0.12,0.57,-0.06,0.72,0.15],['c',0.12,0.12,0.27,0.63,0.36,1.11],['c',0.33,1.59,0.06,3.06,-0.81,4.47],['l',-0.18,0.27],['l',0.09,0.15],['c',0.12,0.24,0.33,0.69,0.45,1.05],['c',0.63,1.83,0.45,3.57,-0.57,5.22],['l',-0.18,0.30],['l',0.15,0.27],['c',0.42,0.87,0.60,1.71,0.57,2.61],['c',-0.06,1.29,-0.48,2.46,-1.35,3.78],['c',-0.54,0.81,-0.93,1.29,-2.46,3.00],['c',-0.51,0.54,-1.05,1.17,-1.26,1.41],['c',-1.56,1.86,-2.25,3.36,-2.37,5.01],['l',0.00,0.33],['l',-0.21,0.00],['l',-0.21,0.00],['l',0.00,-11.25],['l',0.00,-11.25],['l',0.21,0.00],['l',0.21,0.00],['l',0.00,1.35],['l',0.03,1.35],['l',0.78,-0.39],['c',1.38,-0.69,2.34,-1.26,3.24,-1.92],['c',1.38,-1.02,2.28,-2.13,2.64,-3.21],['c',0.15,-0.48,0.18,-0.72,0.18,-1.29],['c',0.00,-0.57,-0.06,-0.90,-0.24,-1.47],['c',-0.06,-0.18,-0.12,-0.39,-0.15,-0.45],['c',-0.03,-0.24,0.12,-0.48,0.36,-0.60],['z'],['m',-0.63,7.20],['c',-0.09,-0.18,-0.12,-0.21,-0.12,-0.15],['c',-0.03,0.09,-1.02,1.08,-2.04,2.04],['c',-1.17,1.08,-1.65,1.56,-2.07,2.04],['c',-0.84,0.96,-1.38,1.86,-1.68,2.76],['c',-0.21,0.57,-0.27,0.99,-0.30,1.65],['l',0.00,0.54],['l',0.66,-0.33],['c',3.57,-1.86,5.49,-3.69,5.94,-5.70],['c',0.06,-0.39,0.06,-1.20,-0.03,-1.65],['c',-0.06,-0.39,-0.24,-0.90,-0.36,-1.20],['z'],['m',-0.06,7.20],['c',-0.06,-0.15,-0.12,-0.33,-0.15,-0.45],['l',-0.06,-0.18],['l',-0.18,0.21],['l',-1.83,1.83],['c',-0.87,0.90,-1.77,1.80,-1.95,2.01],['c',-1.08,1.29,-1.62,2.31,-1.89,3.51],['c',-0.06,0.30,-0.06,0.51,-0.09,0.93],['l',0.00,0.57],['l',0.09,-0.06],['c',0.75,-0.45,1.89,-1.26,2.52,-1.74],['c',0.81,-0.66,1.74,-1.53,2.22,-2.16],['c',1.26,-1.53,1.68,-3.06,1.32,-4.47],['z']],w:8.385,h:29.191},
    		'flags.d64th':{d:[['M',7.08,-32.88],['c',0.30,-0.12,0.66,-0.03,0.78,0.24],['c',0.18,0.33,0.27,2.10,0.15,2.64],['c',-0.09,0.39,-0.21,0.78,-0.39,1.08],['l',-0.15,0.30],['l',0.09,0.27],['c',0.03,0.12,0.09,0.45,0.12,0.69],['c',0.27,1.44,0.18,2.55,-0.30,3.60],['l',-0.12,0.33],['l',0.06,0.42],['c',0.27,1.35,0.33,2.82,0.21,3.63],['c',-0.12,0.60,-0.30,1.23,-0.57,1.80],['l',-0.15,0.27],['l',0.03,0.42],['c',0.06,1.02,0.06,2.70,0.03,3.06],['c',-0.15,1.47,-0.66,2.76,-1.74,4.41],['c',-0.45,0.69,-0.75,1.11,-1.74,2.37],['c',-1.05,1.38,-1.50,1.98,-1.95,2.73],['c',-0.93,1.50,-1.38,2.82,-1.44,4.20],['l',0.00,0.42],['l',-0.21,0.00],['l',-0.21,0.00],['l',0.00,-15.00],['l',0.00,-15.00],['l',0.21,0.00],['l',0.21,0.00],['l',0.00,1.86],['l',0.00,1.89],['c',0.00,0.00,0.21,-0.03,0.45,-0.09],['c',2.22,-0.39,4.08,-1.11,5.19,-2.01],['c',0.63,-0.54,1.02,-1.14,1.20,-1.80],['c',0.06,-0.30,0.06,-1.14,-0.03,-1.65],['c',-0.03,-0.18,-0.06,-0.39,-0.09,-0.48],['c',-0.03,-0.24,0.12,-0.48,0.36,-0.60],['z'],['m',-0.45,6.15],['c',-0.03,-0.18,-0.06,-0.42,-0.06,-0.54],['l',-0.03,-0.18],['l',-0.33,0.30],['c',-0.42,0.36,-0.87,0.72,-1.68,1.29],['c',-1.98,1.38,-2.25,1.59,-2.85,2.16],['c',-0.75,0.69,-1.23,1.44,-1.47,2.19],['c',-0.15,0.45,-0.18,0.63,-0.21,1.35],['l',0.00,0.66],['l',0.39,-0.18],['c',1.83,-0.90,3.45,-1.95,4.47,-2.91],['c',0.93,-0.90,1.53,-1.83,1.74,-2.82],['c',0.06,-0.33,0.06,-0.87,0.03,-1.32],['z'],['m',-0.27,4.86],['c',-0.03,-0.21,-0.06,-0.36,-0.06,-0.36],['c',0.00,-0.03,-0.12,0.09,-0.24,0.24],['c',-0.39,0.48,-0.99,1.08,-2.16,2.19],['c',-1.47,1.38,-1.92,1.83,-2.46,2.49],['c',-0.66,0.87,-1.08,1.74,-1.29,2.58],['c',-0.09,0.42,-0.15,0.87,-0.15,1.44],['l',0.00,0.54],['l',0.48,-0.33],['c',1.50,-1.02,2.58,-1.89,3.51,-2.82],['c',1.47,-1.47,2.25,-2.85,2.40,-4.26],['c',0.03,-0.39,0.03,-1.17,-0.03,-1.71],['z'],['m',-0.66,7.68],['c',0.03,-0.15,0.03,-0.60,0.03,-0.99],['l',0.00,-0.72],['l',-0.27,0.33],['l',-1.74,1.98],['c',-1.77,1.92,-2.43,2.76,-2.97,3.90],['c',-0.51,1.02,-0.72,1.77,-0.75,2.91],['c',0.00,0.63,0.00,0.63,0.06,0.60],['c',0.03,-0.03,0.30,-0.27,0.63,-0.54],['c',0.66,-0.60,1.86,-1.80,2.31,-2.31],['c',1.65,-1.89,2.52,-3.54,2.70,-5.16],['z']],w:8.485,h:32.932},
    		'clefs.C':{d:[['M',0.06,-14.94],['l',0.09,-0.06],['l',1.92,0.00],['l',1.92,0.00],['l',0.09,0.06],['l',0.06,0.09],['l',0.00,14.85],['l',0.00,14.82],['l',-0.06,0.09],['l',-0.09,0.06],['l',-1.92,0.00],['l',-1.92,0.00],['l',-0.09,-0.06],['l',-0.06,-0.09],['l',0.00,-14.82],['l',0.00,-14.85],['z'],['m',5.37,0.00],['c',0.09,-0.06,0.09,-0.06,0.57,-0.06],['c',0.45,0.00,0.45,0.00,0.54,0.06],['l',0.06,0.09],['l',0.00,7.14],['l',0.00,7.11],['l',0.09,-0.06],['c',0.18,-0.18,0.72,-0.84,0.96,-1.20],['c',0.30,-0.45,0.66,-1.17,0.84,-1.65],['c',0.36,-0.90,0.57,-1.83,0.60,-2.79],['c',0.03,-0.48,0.03,-0.54,0.09,-0.63],['c',0.12,-0.18,0.36,-0.21,0.54,-0.12],['c',0.18,0.09,0.21,0.15,0.24,0.66],['c',0.06,0.87,0.21,1.56,0.57,2.22],['c',0.51,1.02,1.26,1.68,2.22,1.92],['c',0.21,0.06,0.33,0.06,0.78,0.06],['c',0.45,0.00,0.57,0.00,0.84,-0.06],['c',0.45,-0.12,0.81,-0.33,1.08,-0.60],['c',0.57,-0.57,0.87,-1.41,0.99,-2.88],['c',0.06,-0.54,0.06,-3.00,0.00,-3.57],['c',-0.21,-2.58,-0.84,-3.87,-2.16,-4.50],['c',-0.48,-0.21,-1.17,-0.36,-1.77,-0.36],['c',-0.69,0.00,-1.29,0.27,-1.50,0.72],['c',-0.06,0.15,-0.06,0.21,-0.06,0.42],['c',0.00,0.24,0.00,0.30,0.06,0.45],['c',0.12,0.24,0.24,0.39,0.63,0.66],['c',0.42,0.30,0.57,0.48,0.69,0.72],['c',0.06,0.15,0.06,0.21,0.06,0.48],['c',0.00,0.39,-0.03,0.63,-0.21,0.96],['c',-0.30,0.60,-0.87,1.08,-1.50,1.26],['c',-0.27,0.06,-0.87,0.06,-1.14,0.00],['c',-0.78,-0.24,-1.44,-0.87,-1.65,-1.68],['c',-0.12,-0.42,-0.09,-1.17,0.09,-1.71],['c',0.51,-1.65,1.98,-2.82,3.81,-3.09],['c',0.84,-0.09,2.46,0.03,3.51,0.27],['c',2.22,0.57,3.69,1.80,4.44,3.75],['c',0.36,0.93,0.57,2.13,0.57,3.36],['c',0.00,1.44,-0.48,2.73,-1.38,3.81],['c',-1.26,1.50,-3.27,2.43,-5.28,2.43],['c',-0.48,0.00,-0.51,0.00,-0.75,-0.09],['c',-0.15,-0.03,-0.48,-0.21,-0.78,-0.36],['c',-0.69,-0.36,-0.87,-0.42,-1.26,-0.42],['c',-0.27,0.00,-0.30,0.00,-0.51,0.09],['c',-0.57,0.30,-0.81,0.90,-0.81,2.10],['c',0.00,1.23,0.24,1.83,0.81,2.13],['c',0.21,0.09,0.24,0.09,0.51,0.09],['c',0.39,0.00,0.57,-0.06,1.26,-0.42],['c',0.30,-0.15,0.63,-0.33,0.78,-0.36],['c',0.24,-0.09,0.27,-0.09,0.75,-0.09],['c',2.01,0.00,4.02,0.93,5.28,2.40],['c',0.90,1.11,1.38,2.40,1.38,3.84],['c',0.00,1.50,-0.30,2.88,-0.84,3.96],['c',-0.78,1.59,-2.19,2.64,-4.17,3.15],['c',-1.05,0.24,-2.67,0.36,-3.51,0.27],['c',-1.83,-0.27,-3.30,-1.44,-3.81,-3.09],['c',-0.18,-0.54,-0.21,-1.29,-0.09,-1.74],['c',0.15,-0.60,0.63,-1.20,1.23,-1.47],['c',0.36,-0.18,0.57,-0.21,0.99,-0.21],['c',0.42,0.00,0.63,0.03,1.02,0.21],['c',0.42,0.21,0.84,0.63,1.05,1.05],['c',0.18,0.36,0.21,0.60,0.21,0.96],['c',0.00,0.30,0.00,0.36,-0.06,0.51],['c',-0.12,0.24,-0.27,0.42,-0.69,0.72],['c',-0.57,0.42,-0.69,0.63,-0.69,1.08],['c',0.00,0.24,0.00,0.30,0.06,0.45],['c',0.12,0.21,0.30,0.39,0.57,0.54],['c',0.42,0.18,0.87,0.21,1.53,0.15],['c',1.08,-0.15,1.80,-0.57,2.34,-1.32],['c',0.54,-0.75,0.84,-1.83,0.99,-3.51],['c',0.06,-0.57,0.06,-3.03,0.00,-3.57],['c',-0.12,-1.47,-0.42,-2.31,-0.99,-2.88],['c',-0.27,-0.27,-0.63,-0.48,-1.08,-0.60],['c',-0.27,-0.06,-0.39,-0.06,-0.84,-0.06],['c',-0.45,0.00,-0.57,0.00,-0.78,0.06],['c',-1.14,0.27,-2.01,1.17,-2.46,2.49],['c',-0.21,0.57,-0.30,0.99,-0.33,1.65],['c',-0.03,0.51,-0.06,0.57,-0.24,0.66],['c',-0.12,0.06,-0.27,0.06,-0.39,0.00],['c',-0.21,-0.09,-0.21,-0.15,-0.24,-0.75],['c',-0.09,-1.92,-0.78,-3.72,-2.01,-5.19],['c',-0.18,-0.21,-0.36,-0.42,-0.39,-0.45],['l',-0.09,-0.06],['l',0.00,7.11],['l',0.00,7.14],['l',-0.06,0.09],['c',-0.09,0.06,-0.09,0.06,-0.54,0.06],['c',-0.48,0.00,-0.48,0.00,-0.57,-0.06],['l',-0.06,-0.09],['l',0.00,-14.82],['l',0.00,-14.85],['z']],w:20.31,h:29.97},
    		'clefs.F':{d:[['M',6.30,-7.80],['c',0.36,-0.03,1.65,0.00,2.13,0.03],['c',3.60,0.42,6.03,2.10,6.93,4.86],['c',0.27,0.84,0.36,1.50,0.36,2.58],['c',0.00,0.90,-0.03,1.35,-0.18,2.16],['c',-0.78,3.78,-3.54,7.08,-8.37,9.96],['c',-1.74,1.05,-3.87,2.13,-6.18,3.12],['c',-0.39,0.18,-0.75,0.33,-0.81,0.36],['c',-0.06,0.03,-0.15,0.06,-0.18,0.06],['c',-0.15,0.00,-0.33,-0.18,-0.33,-0.33],['c',0.00,-0.15,0.06,-0.21,0.51,-0.48],['c',3.00,-1.77,5.13,-3.21,6.84,-4.74],['c',0.51,-0.45,1.59,-1.50,1.95,-1.95],['c',1.89,-2.19,2.88,-4.32,3.15,-6.78],['c',0.06,-0.42,0.06,-1.77,0.00,-2.19],['c',-0.24,-2.01,-0.93,-3.63,-2.04,-4.71],['c',-0.63,-0.63,-1.29,-1.02,-2.07,-1.20],['c',-1.62,-0.39,-3.36,0.15,-4.56,1.44],['c',-0.54,0.60,-1.05,1.47,-1.32,2.22],['l',-0.09,0.21],['l',0.24,-0.12],['c',0.39,-0.21,0.63,-0.24,1.11,-0.24],['c',0.30,0.00,0.45,0.00,0.66,0.06],['c',1.92,0.48,2.85,2.55,1.95,4.38],['c',-0.45,0.99,-1.41,1.62,-2.46,1.71],['c',-1.47,0.09,-2.91,-0.87,-3.39,-2.25],['c',-0.18,-0.57,-0.21,-1.32,-0.03,-2.28],['c',0.39,-2.25,1.83,-4.20,3.81,-5.19],['c',0.69,-0.36,1.59,-0.60,2.37,-0.69],['z'],['m',11.58,2.52],['c',0.84,-0.21,1.71,0.30,1.89,1.14],['c',0.30,1.17,-0.72,2.19,-1.89,1.89],['c',-0.99,-0.21,-1.50,-1.32,-1.02,-2.25],['c',0.18,-0.39,0.60,-0.69,1.02,-0.78],['z'],['m',0.00,7.50],['c',0.84,-0.21,1.71,0.30,1.89,1.14],['c',0.21,0.87,-0.30,1.71,-1.14,1.89],['c',-0.87,0.21,-1.71,-0.30,-1.89,-1.14],['c',-0.21,-0.84,0.30,-1.71,1.14,-1.89],['z']],w:20.153,h:23.142},
    		'clefs.G':{d:[['M',9.69,-37.41],['c',0.09,-0.09,0.24,-0.06,0.36,0.00],['c',0.12,0.09,0.57,0.60,0.96,1.11],['c',1.77,2.34,3.21,5.85,3.57,8.73],['c',0.21,1.56,0.03,3.27,-0.45,4.86],['c',-0.69,2.31,-1.92,4.47,-4.23,7.44],['c',-0.30,0.39,-0.57,0.72,-0.60,0.75],['c',-0.03,0.06,0.00,0.15,0.18,0.78],['c',0.54,1.68,1.38,4.44,1.68,5.49],['l',0.09,0.42],['l',0.39,0.00],['c',1.47,0.09,2.76,0.51,3.96,1.29],['c',1.83,1.23,3.06,3.21,3.39,5.52],['c',0.09,0.45,0.12,1.29,0.06,1.74],['c',-0.09,1.02,-0.33,1.83,-0.75,2.73],['c',-0.84,1.71,-2.28,3.06,-4.02,3.72],['l',-0.33,0.12],['l',0.03,1.26],['c',0.00,1.74,-0.06,3.63,-0.21,4.62],['c',-0.45,3.06,-2.19,5.49,-4.47,6.21],['c',-0.57,0.18,-0.90,0.21,-1.59,0.21],['c',-0.69,0.00,-1.02,-0.03,-1.65,-0.21],['c',-1.14,-0.27,-2.13,-0.84,-2.94,-1.65],['c',-0.99,-0.99,-1.56,-2.16,-1.71,-3.54],['c',-0.09,-0.81,0.06,-1.53,0.45,-2.13],['c',0.63,-0.99,1.83,-1.56,3.00,-1.53],['c',1.50,0.09,2.64,1.32,2.73,2.94],['c',0.06,1.47,-0.93,2.70,-2.37,2.97],['c',-0.45,0.06,-0.84,0.03,-1.29,-0.09],['l',-0.21,-0.09],['l',0.09,0.12],['c',0.39,0.54,0.78,0.93,1.32,1.26],['c',1.35,0.87,3.06,1.02,4.35,0.36],['c',1.44,-0.72,2.52,-2.28,2.97,-4.35],['c',0.15,-0.66,0.24,-1.50,0.30,-3.03],['c',0.03,-0.84,0.03,-2.94,0.00,-3.00],['c',-0.03,0.00,-0.18,0.00,-0.36,0.03],['c',-0.66,0.12,-0.99,0.12,-1.83,0.12],['c',-1.05,0.00,-1.71,-0.06,-2.61,-0.30],['c',-4.02,-0.99,-7.11,-4.35,-7.80,-8.46],['c',-0.12,-0.66,-0.12,-0.99,-0.12,-1.83],['c',0.00,-0.84,0.00,-1.14,0.15,-1.92],['c',0.36,-2.28,1.41,-4.62,3.30,-7.29],['l',2.79,-3.60],['c',0.54,-0.66,0.96,-1.20,0.96,-1.23],['c',0.00,-0.03,-0.09,-0.33,-0.18,-0.69],['c',-0.96,-3.21,-1.41,-5.28,-1.59,-7.68],['c',-0.12,-1.38,-0.15,-3.09,-0.06,-3.96],['c',0.33,-2.67,1.38,-5.07,3.12,-7.08],['c',0.36,-0.42,0.99,-1.05,1.17,-1.14],['z'],['m',2.01,4.71],['c',-0.15,-0.30,-0.30,-0.54,-0.30,-0.54],['c',-0.03,0.00,-0.18,0.09,-0.30,0.21],['c',-2.40,1.74,-3.87,4.20,-4.26,7.11],['c',-0.06,0.54,-0.06,1.41,-0.03,1.89],['c',0.09,1.29,0.48,3.12,1.08,5.22],['c',0.15,0.42,0.24,0.78,0.24,0.81],['c',0.00,0.03,0.84,-1.11,1.23,-1.68],['c',1.89,-2.73,2.88,-5.07,3.15,-7.53],['c',0.09,-0.57,0.12,-1.74,0.06,-2.37],['c',-0.09,-1.23,-0.27,-1.92,-0.87,-3.12],['z'],['m',-2.94,20.70],['c',-0.21,-0.72,-0.39,-1.32,-0.42,-1.32],['c',0.00,0.00,-1.20,1.47,-1.86,2.37],['c',-2.79,3.63,-4.02,6.30,-4.35,9.30],['c',-0.03,0.21,-0.03,0.69,-0.03,1.08],['c',0.00,0.69,0.00,0.75,0.06,1.11],['c',0.12,0.54,0.27,0.99,0.51,1.47],['c',0.69,1.38,1.83,2.55,3.42,3.42],['c',0.96,0.54,2.07,0.90,3.21,1.08],['c',0.78,0.12,2.04,0.12,2.94,-0.03],['c',0.51,-0.06,0.45,-0.03,0.42,-0.30],['c',-0.24,-3.33,-0.72,-6.33,-1.62,-10.08],['c',-0.09,-0.39,-0.18,-0.75,-0.18,-0.78],['c',-0.03,-0.03,-0.42,0.00,-0.81,0.09],['c',-0.90,0.18,-1.65,0.57,-2.22,1.14],['c',-0.72,0.72,-1.08,1.65,-1.05,2.64],['c',0.06,0.96,0.48,1.83,1.23,2.58],['c',0.36,0.36,0.72,0.63,1.17,0.90],['c',0.33,0.18,0.36,0.21,0.42,0.33],['c',0.18,0.42,-0.18,0.90,-0.60,0.87],['c',-0.18,-0.03,-0.84,-0.36,-1.26,-0.63],['c',-0.78,-0.51,-1.38,-1.11,-1.86,-1.83],['c',-1.77,-2.70,-0.99,-6.42,1.71,-8.19],['c',0.30,-0.21,0.81,-0.48,1.17,-0.63],['c',0.30,-0.09,1.02,-0.30,1.14,-0.30],['c',0.06,0.00,0.09,0.00,0.09,-0.03],['c',0.03,-0.03,-0.51,-1.92,-1.23,-4.26],['z'],['m',3.78,7.41],['c',-0.18,-0.03,-0.36,-0.06,-0.39,-0.06],['c',-0.03,0.00,0.00,0.21,0.18,1.02],['c',0.75,3.18,1.26,6.30,1.50,9.09],['c',0.06,0.72,0.00,0.69,0.51,0.42],['c',0.78,-0.36,1.44,-0.96,1.98,-1.77],['c',1.08,-1.62,1.20,-3.69,0.30,-5.55],['c',-0.81,-1.62,-2.31,-2.79,-4.08,-3.15],['z']],w:19.051,h:57.057},
    		'clefs.perc':{d:[['M',5.07,-7.44],['l',0.09,-0.06],['l',1.53,0.00],['l',1.53,0.00],['l',0.09,0.06],['l',0.06,0.09],['l',0.00,7.35],['l',0.00,7.32],['l',-0.06,0.09],['l',-0.09,0.06],['l',-1.53,0.00],['l',-1.53,0.00],['l',-0.09,-0.06],['l',-0.06,-0.09],['l',0.00,-7.32],['l',0.00,-7.35],['z'],['m',6.63,0.00],['l',0.09,-0.06],['l',1.53,0.00],['l',1.53,0.00],['l',0.09,0.06],['l',0.06,0.09],['l',0.00,7.35],['l',0.00,7.32],['l',-0.06,0.09],['l',-0.09,0.06],['l',-1.53,0.00],['l',-1.53,0.00],['l',-0.09,-0.06],['l',-0.06,-0.09],['l',0.00,-7.32],['l',0.00,-7.35],['z']],w:9.99,h:14.97},
    		'timesig.common':{d:[['M',6.66,-7.83],['c',0.72,-0.06,1.41,-0.03,1.98,0.09],['c',1.20,0.27,2.34,0.96,3.09,1.92],['c',0.63,0.81,1.08,1.86,1.14,2.73],['c',0.06,1.02,-0.51,1.92,-1.44,2.22],['c',-0.24,0.09,-0.30,0.09,-0.63,0.09],['c',-0.33,0.00,-0.42,0.00,-0.63,-0.06],['c',-0.66,-0.24,-1.14,-0.63,-1.41,-1.20],['c',-0.15,-0.30,-0.21,-0.51,-0.24,-0.90],['c',-0.06,-1.08,0.57,-2.04,1.56,-2.37],['c',0.18,-0.06,0.27,-0.06,0.63,-0.06],['l',0.45,0.00],['c',0.06,0.03,0.09,0.03,0.09,0.00],['c',0.00,0.00,-0.09,-0.12,-0.24,-0.27],['c',-1.02,-1.11,-2.55,-1.68,-4.08,-1.50],['c',-1.29,0.15,-2.04,0.69,-2.40,1.74],['c',-0.36,0.93,-0.42,1.89,-0.42,5.37],['c',0.00,2.97,0.06,3.96,0.24,4.77],['c',0.24,1.08,0.63,1.68,1.41,2.07],['c',0.81,0.39,2.16,0.45,3.18,0.09],['c',1.29,-0.45,2.37,-1.53,3.03,-2.97],['c',0.15,-0.33,0.33,-0.87,0.39,-1.17],['c',0.09,-0.24,0.15,-0.36,0.30,-0.39],['c',0.21,-0.03,0.42,0.15,0.39,0.36],['c',-0.06,0.39,-0.42,1.38,-0.69,1.89],['c',-0.96,1.80,-2.49,2.94,-4.23,3.18],['c',-0.99,0.12,-2.58,-0.06,-3.63,-0.45],['c',-0.96,-0.36,-1.71,-0.84,-2.40,-1.50],['c',-1.11,-1.11,-1.80,-2.61,-2.04,-4.56],['c',-0.06,-0.60,-0.06,-2.01,0.00,-2.61],['c',0.24,-1.95,0.90,-3.45,2.01,-4.56],['c',0.69,-0.66,1.44,-1.11,2.37,-1.47],['c',0.63,-0.24,1.47,-0.42,2.22,-0.48],['z']],w:13.038,h:15.689},
    		'timesig.cut':{d:[['M',6.24,-10.44],['c',0.09,-0.06,0.09,-0.06,0.48,-0.06],['c',0.36,0.00,0.36,0.00,0.45,0.06],['l',0.06,0.09],['l',0.00,1.23],['l',0.00,1.26],['l',0.27,0.00],['c',1.26,0.00,2.49,0.45,3.48,1.29],['c',1.05,0.87,1.80,2.28,1.89,3.48],['c',0.06,1.02,-0.51,1.92,-1.44,2.22],['c',-0.24,0.09,-0.30,0.09,-0.63,0.09],['c',-0.33,0.00,-0.42,0.00,-0.63,-0.06],['c',-0.66,-0.24,-1.14,-0.63,-1.41,-1.20],['c',-0.15,-0.30,-0.21,-0.51,-0.24,-0.90],['c',-0.06,-1.08,0.57,-2.04,1.56,-2.37],['c',0.18,-0.06,0.27,-0.06,0.63,-0.06],['l',0.45,0.00],['c',0.06,0.03,0.09,0.03,0.09,0.00],['c',0.00,-0.03,-0.45,-0.51,-0.66,-0.69],['c',-0.87,-0.69,-1.83,-1.05,-2.94,-1.11],['l',-0.42,0.00],['l',0.00,7.17],['l',0.00,7.14],['l',0.42,0.00],['c',0.69,-0.03,1.23,-0.18,1.86,-0.51],['c',1.05,-0.51,1.89,-1.47,2.46,-2.70],['c',0.15,-0.33,0.33,-0.87,0.39,-1.17],['c',0.09,-0.24,0.15,-0.36,0.30,-0.39],['c',0.21,-0.03,0.42,0.15,0.39,0.36],['c',-0.03,0.24,-0.21,0.78,-0.39,1.20],['c',-0.96,2.37,-2.94,3.90,-5.13,3.90],['l',-0.30,0.00],['l',0.00,1.26],['l',0.00,1.23],['l',-0.06,0.09],['c',-0.09,0.06,-0.09,0.06,-0.45,0.06],['c',-0.39,0.00,-0.39,0.00,-0.48,-0.06],['l',-0.06,-0.09],['l',0.00,-1.29],['l',0.00,-1.29],['l',-0.21,-0.03],['c',-1.23,-0.21,-2.31,-0.63,-3.21,-1.29],['c',-0.15,-0.09,-0.45,-0.36,-0.66,-0.57],['c',-1.11,-1.11,-1.80,-2.61,-2.04,-4.56],['c',-0.06,-0.60,-0.06,-2.01,0.00,-2.61],['c',0.24,-1.95,0.93,-3.45,2.04,-4.59],['c',0.42,-0.39,0.78,-0.66,1.26,-0.93],['c',0.75,-0.45,1.65,-0.75,2.61,-0.90],['l',0.21,-0.03],['l',0.00,-1.29],['l',0.00,-1.29],['z'],['m',-0.06,10.44],['c',0.00,-5.58,0.00,-6.99,-0.03,-6.99],['c',-0.15,0.00,-0.63,0.27,-0.87,0.45],['c',-0.45,0.36,-0.75,0.93,-0.93,1.77],['c',-0.18,0.81,-0.24,1.80,-0.24,4.74],['c',0.00,2.97,0.06,3.96,0.24,4.77],['c',0.24,1.08,0.66,1.68,1.41,2.07],['c',0.12,0.06,0.30,0.12,0.33,0.15],['l',0.09,0.00],['l',0.00,-6.96],['z']],w:13.038,h:20.97},
    		'timesig.imperfectum':{d:[['M',13,-5],['a',8,8,0,1,0,0,10]],w:13.038,h:20.97},
    		'timesig.imperfectum2':{d:[['M',13,-5],['a',8,8,0,1,0,0,10]],w:13.038,h:20.97},
    		'timesig.perfectum':{d:[['M',13,-5],['a',8,8,0,1,0,0,10]],w:13.038,h:20.97},
    		'timesig.perfectum2':{d:[['M',13,-5],['a',8,8,0,1,0,0,10]],w:13.038,h:20.97},
    		'f':{d:[['M',9.93,-14.28],['c',1.53,-0.18,2.88,0.45,3.12,1.50],['c',0.12,0.51,0.00,1.32,-0.27,1.86],['c',-0.15,0.30,-0.42,0.57,-0.63,0.69],['c',-0.69,0.36,-1.56,0.03,-1.83,-0.69],['c',-0.09,-0.24,-0.09,-0.69,0.00,-0.87],['c',0.06,-0.12,0.21,-0.24,0.45,-0.42],['c',0.42,-0.24,0.57,-0.45,0.60,-0.72],['c',0.03,-0.33,-0.09,-0.39,-0.63,-0.42],['c',-0.30,0.00,-0.45,0.00,-0.60,0.03],['c',-0.81,0.21,-1.35,0.93,-1.74,2.46],['c',-0.06,0.27,-0.48,2.25,-0.48,2.31],['c',0.00,0.03,0.39,0.03,0.90,0.03],['c',0.72,0.00,0.90,0.00,0.99,0.06],['c',0.42,0.15,0.45,0.72,0.03,0.90],['c',-0.12,0.06,-0.24,0.06,-1.17,0.06],['l',-1.05,0.00],['l',-0.78,2.55],['c',-0.45,1.41,-0.87,2.79,-0.96,3.06],['c',-0.87,2.37,-2.37,4.74,-3.78,5.91],['c',-1.05,0.90,-2.04,1.23,-3.09,1.08],['c',-1.11,-0.18,-1.89,-0.78,-2.04,-1.59],['c',-0.12,-0.66,0.15,-1.71,0.54,-2.19],['c',0.69,-0.75,1.86,-0.54,2.22,0.39],['c',0.06,0.15,0.09,0.27,0.09,0.48],['c',0.00,0.24,-0.03,0.27,-0.12,0.42],['c',-0.03,0.09,-0.15,0.18,-0.27,0.27],['c',-0.09,0.06,-0.27,0.21,-0.36,0.27],['c',-0.24,0.18,-0.36,0.36,-0.39,0.60],['c',-0.03,0.33,0.09,0.39,0.63,0.42],['c',0.42,0.00,0.63,-0.03,0.90,-0.15],['c',0.60,-0.30,0.96,-0.96,1.38,-2.64],['c',0.09,-0.42,0.63,-2.55,1.17,-4.77],['l',1.02,-4.08],['c',0.00,-0.03,-0.36,-0.03,-0.81,-0.03],['c',-0.72,0.00,-0.81,0.00,-0.93,-0.06],['c',-0.42,-0.18,-0.39,-0.75,0.03,-0.90],['c',0.09,-0.06,0.27,-0.06,1.05,-0.06],['l',0.96,0.00],['l',0.00,-0.09],['c',0.06,-0.18,0.30,-0.72,0.51,-1.17],['c',1.20,-2.46,3.30,-4.23,5.34,-4.50],['z']],w:16.155,h:19.445},
    		'm':{d:[['M',2.79,-8.91],['c',0.09,0.00,0.30,-0.03,0.45,-0.03],['c',0.24,0.03,0.30,0.03,0.45,0.12],['c',0.36,0.15,0.63,0.54,0.75,1.02],['l',0.03,0.21],['l',0.33,-0.30],['c',0.69,-0.69,1.38,-1.02,2.07,-1.02],['c',0.27,0.00,0.33,0.00,0.48,0.06],['c',0.21,0.09,0.48,0.36,0.63,0.60],['c',0.03,0.09,0.12,0.27,0.18,0.42],['c',0.03,0.15,0.09,0.27,0.12,0.27],['c',0.00,0.00,0.09,-0.09,0.18,-0.21],['c',0.33,-0.39,0.87,-0.81,1.29,-0.99],['c',0.78,-0.33,1.47,-0.21,2.01,0.33],['c',0.30,0.33,0.48,0.69,0.60,1.14],['c',0.09,0.42,0.06,0.54,-0.54,3.06],['c',-0.33,1.29,-0.57,2.40,-0.57,2.43],['c',0.00,0.12,0.09,0.21,0.21,0.21],['c',0.24,0.00,0.75,-0.30,1.20,-0.72],['c',0.45,-0.39,0.60,-0.45,0.78,-0.27],['c',0.18,0.18,0.09,0.36,-0.45,0.87],['c',-1.05,0.96,-1.83,1.47,-2.58,1.71],['c',-0.93,0.33,-1.53,0.21,-1.80,-0.33],['c',-0.06,-0.15,-0.06,-0.21,-0.06,-0.45],['c',0.00,-0.24,0.03,-0.48,0.60,-2.82],['c',0.42,-1.71,0.60,-2.64,0.63,-2.79],['c',0.03,-0.57,-0.30,-0.75,-0.84,-0.48],['c',-0.24,0.12,-0.54,0.39,-0.66,0.63],['c',-0.03,0.09,-0.42,1.38,-0.90,3.00],['c',-0.90,3.15,-0.84,3.00,-1.14,3.15],['l',-0.15,0.09],['l',-0.78,0.00],['c',-0.60,0.00,-0.78,0.00,-0.84,-0.06],['c',-0.09,-0.03,-0.18,-0.18,-0.18,-0.27],['c',0.00,-0.03,0.36,-1.38,0.84,-2.97],['c',0.57,-2.04,0.81,-2.97,0.84,-3.12],['c',0.03,-0.54,-0.30,-0.72,-0.84,-0.45],['c',-0.24,0.12,-0.57,0.42,-0.66,0.63],['c',-0.06,0.09,-0.51,1.44,-1.05,2.97],['c',-0.51,1.56,-0.99,2.85,-0.99,2.91],['c',-0.06,0.12,-0.21,0.24,-0.36,0.30],['c',-0.12,0.06,-0.21,0.06,-0.90,0.06],['c',-0.60,0.00,-0.78,0.00,-0.84,-0.06],['c',-0.09,-0.03,-0.18,-0.18,-0.18,-0.27],['c',0.00,-0.03,0.45,-1.38,0.99,-2.97],['c',1.05,-3.18,1.05,-3.18,0.93,-3.45],['c',-0.12,-0.27,-0.39,-0.30,-0.72,-0.15],['c',-0.54,0.27,-1.14,1.17,-1.56,2.40],['c',-0.06,0.15,-0.15,0.30,-0.18,0.36],['c',-0.21,0.21,-0.57,0.27,-0.72,0.09],['c',-0.09,-0.09,-0.06,-0.21,0.06,-0.63],['c',0.48,-1.26,1.26,-2.46,2.01,-3.21],['c',0.57,-0.54,1.20,-0.87,1.83,-1.02],['z']],w:14.687,h:9.126},
    		'p':{d:[['M',1.92,-8.70],['c',0.27,-0.09,0.81,-0.06,1.11,0.03],['c',0.54,0.18,0.93,0.51,1.17,0.99],['c',0.09,0.15,0.15,0.33,0.18,0.36],['l',0.00,0.12],['l',0.30,-0.27],['c',0.66,-0.60,1.35,-1.02,2.13,-1.20],['c',0.21,-0.06,0.33,-0.06,0.78,-0.06],['c',0.45,0.00,0.51,0.00,0.84,0.09],['c',1.29,0.33,2.07,1.32,2.25,2.79],['c',0.09,0.81,-0.09,2.01,-0.45,2.79],['c',-0.54,1.26,-1.86,2.55,-3.18,3.03],['c',-0.45,0.18,-0.81,0.24,-1.29,0.24],['c',-0.69,-0.03,-1.35,-0.18,-1.86,-0.45],['c',-0.30,-0.15,-0.51,-0.18,-0.69,-0.09],['c',-0.09,0.03,-0.18,0.09,-0.18,0.12],['c',-0.09,0.12,-1.05,2.94,-1.05,3.06],['c',0.00,0.24,0.18,0.48,0.51,0.63],['c',0.18,0.06,0.54,0.15,0.75,0.15],['c',0.21,0.00,0.36,0.06,0.42,0.18],['c',0.12,0.18,0.06,0.42,-0.12,0.54],['c',-0.09,0.03,-0.15,0.03,-0.78,0.00],['c',-1.98,-0.15,-3.81,-0.15,-5.79,0.00],['c',-0.63,0.03,-0.69,0.03,-0.78,0.00],['c',-0.24,-0.15,-0.24,-0.57,0.03,-0.66],['c',0.06,-0.03,0.48,-0.09,0.99,-0.12],['c',0.87,-0.06,1.11,-0.09,1.35,-0.21],['c',0.18,-0.06,0.33,-0.18,0.39,-0.30],['c',0.06,-0.12,3.24,-9.42,3.27,-9.60],['c',0.06,-0.33,0.03,-0.57,-0.15,-0.69],['c',-0.09,-0.06,-0.12,-0.06,-0.30,-0.06],['c',-0.69,0.06,-1.53,1.02,-2.28,2.61],['c',-0.09,0.21,-0.21,0.45,-0.27,0.51],['c',-0.09,0.12,-0.33,0.24,-0.48,0.24],['c',-0.18,0.00,-0.36,-0.15,-0.36,-0.30],['c',0.00,-0.24,0.78,-1.83,1.26,-2.55],['c',0.72,-1.11,1.47,-1.74,2.28,-1.92],['z'],['m',5.37,1.47],['c',-0.27,-0.12,-0.75,-0.03,-1.14,0.21],['c',-0.75,0.48,-1.47,1.68,-1.89,3.15],['c',-0.45,1.47,-0.42,2.34,0.00,2.70],['c',0.45,0.39,1.26,0.21,1.83,-0.36],['c',0.51,-0.51,0.99,-1.68,1.38,-3.27],['c',0.30,-1.17,0.33,-1.74,0.15,-2.13],['c',-0.09,-0.15,-0.15,-0.21,-0.33,-0.30],['z']],w:14.689,h:13.127},
    		'r':{d:[['M',6.33,-9.12],['c',0.27,-0.03,0.93,0.00,1.20,0.06],['c',0.84,0.21,1.23,0.81,1.02,1.53],['c',-0.24,0.75,-0.90,1.17,-1.56,0.96],['c',-0.33,-0.09,-0.51,-0.30,-0.66,-0.75],['c',-0.03,-0.12,-0.09,-0.24,-0.12,-0.30],['c',-0.09,-0.15,-0.30,-0.24,-0.48,-0.24],['c',-0.57,0.00,-1.38,0.54,-1.65,1.08],['c',-0.06,0.15,-0.33,1.17,-0.90,3.27],['c',-0.57,2.31,-0.81,3.12,-0.87,3.21],['c',-0.03,0.06,-0.12,0.15,-0.18,0.21],['l',-0.12,0.06],['l',-0.81,0.03],['c',-0.69,0.00,-0.81,0.00,-0.90,-0.03],['c',-0.09,-0.06,-0.18,-0.21,-0.18,-0.30],['c',0.00,-0.06,0.39,-1.62,0.90,-3.51],['c',0.84,-3.24,0.87,-3.45,0.87,-3.72],['c',0.00,-0.21,0.00,-0.27,-0.03,-0.36],['c',-0.12,-0.15,-0.21,-0.24,-0.42,-0.24],['c',-0.24,0.00,-0.45,0.15,-0.78,0.42],['c',-0.33,0.36,-0.45,0.54,-0.72,1.14],['c',-0.03,0.12,-0.21,0.24,-0.36,0.27],['c',-0.12,0.00,-0.15,0.00,-0.24,-0.06],['c',-0.18,-0.12,-0.18,-0.21,-0.06,-0.54],['c',0.21,-0.57,0.42,-0.93,0.78,-1.32],['c',0.54,-0.51,1.20,-0.81,1.95,-0.87],['c',0.81,-0.03,1.53,0.30,1.92,0.87],['l',0.12,0.18],['l',0.09,-0.09],['c',0.57,-0.45,1.41,-0.84,2.19,-0.96],['z']],w:9.41,h:9.132},
    		's':{d:[['M',4.47,-8.73],['c',0.09,0.00,0.36,-0.03,0.57,-0.03],['c',0.75,0.03,1.29,0.24,1.71,0.63],['c',0.51,0.54,0.66,1.26,0.36,1.83],['c',-0.24,0.42,-0.63,0.57,-1.11,0.42],['c',-0.33,-0.09,-0.60,-0.36,-0.60,-0.57],['c',0.00,-0.03,0.06,-0.21,0.15,-0.39],['c',0.12,-0.21,0.15,-0.33,0.18,-0.48],['c',0.00,-0.24,-0.06,-0.48,-0.15,-0.60],['c',-0.15,-0.21,-0.42,-0.24,-0.75,-0.15],['c',-0.27,0.06,-0.48,0.18,-0.69,0.36],['c',-0.39,0.39,-0.51,0.96,-0.33,1.38],['c',0.09,0.21,0.42,0.51,0.78,0.72],['c',1.11,0.69,1.59,1.11,1.89,1.68],['c',0.21,0.39,0.24,0.78,0.15,1.29],['c',-0.18,1.20,-1.17,2.16,-2.52,2.52],['c',-1.02,0.24,-1.95,0.12,-2.70,-0.42],['c',-0.72,-0.51,-0.99,-1.47,-0.60,-2.19],['c',0.24,-0.48,0.72,-0.63,1.17,-0.42],['c',0.33,0.18,0.54,0.45,0.57,0.81],['c',0.00,0.21,-0.03,0.30,-0.33,0.51],['c',-0.33,0.24,-0.39,0.42,-0.27,0.69],['c',0.06,0.15,0.21,0.27,0.45,0.33],['c',0.30,0.09,0.87,0.09,1.20,0.00],['c',0.75,-0.21,1.23,-0.72,1.29,-1.35],['c',0.03,-0.42,-0.15,-0.81,-0.54,-1.20],['c',-0.24,-0.24,-0.48,-0.42,-1.41,-1.02],['c',-0.69,-0.42,-1.05,-0.93,-1.05,-1.47],['c',0.00,-0.39,0.12,-0.87,0.30,-1.23],['c',0.27,-0.57,0.78,-1.05,1.38,-1.35],['c',0.24,-0.12,0.63,-0.27,0.90,-0.30],['z']],w:6.632,h:8.758},
    		'z':{d:[['M',2.64,-7.95],['c',0.36,-0.09,0.81,-0.03,1.71,0.27],['c',0.78,0.21,0.96,0.27,1.74,0.30],['c',0.87,0.06,1.02,0.03,1.38,-0.21],['c',0.21,-0.15,0.33,-0.15,0.48,-0.06],['c',0.15,0.09,0.21,0.30,0.15,0.45],['c',-0.03,0.06,-1.26,1.26,-2.76,2.67],['l',-2.73,2.55],['l',0.54,0.03],['c',0.54,0.03,0.72,0.03,2.01,0.15],['c',0.36,0.03,0.90,0.06,1.20,0.09],['c',0.66,0.00,0.81,-0.03,1.02,-0.24],['c',0.30,-0.30,0.39,-0.72,0.27,-1.23],['c',-0.06,-0.27,-0.06,-0.27,-0.03,-0.39],['c',0.15,-0.30,0.54,-0.27,0.69,0.03],['c',0.15,0.33,0.27,1.02,0.27,1.50],['c',0.00,1.47,-1.11,2.70,-2.52,2.79],['c',-0.57,0.03,-1.02,-0.09,-2.01,-0.51],['c',-1.02,-0.42,-1.23,-0.48,-2.13,-0.54],['c',-0.81,-0.06,-0.96,-0.03,-1.26,0.18],['c',-0.12,0.06,-0.24,0.12,-0.27,0.12],['c',-0.27,0.00,-0.45,-0.30,-0.36,-0.51],['c',0.03,-0.06,1.32,-1.32,2.91,-2.79],['l',2.88,-2.73],['c',-0.03,0.00,-0.21,0.03,-0.42,0.06],['c',-0.21,0.03,-0.78,0.09,-1.23,0.12],['c',-1.11,0.12,-1.23,0.15,-1.95,0.27],['c',-0.72,0.15,-1.17,0.18,-1.29,0.09],['c',-0.27,-0.18,-0.21,-0.75,0.12,-1.26],['c',0.39,-0.60,0.93,-1.02,1.59,-1.20],['z']],w:8.573,h:8.743},
    		'+':{d:[['M',3.48,-9.3],['c',0.18,-0.09,0.36,-0.09,0.54,0.00],['c',0.18,0.09,0.24,0.15,0.33,0.30],['l',0.06,0.15],['l',0.00,1.29],['l',0.00,1.29],['l',1.29,0.00],['c',1.23,0.00,1.29,0.00,1.41,0.06],['c',0.06,0.03,0.15,0.09,0.18,0.12],['c',0.12,0.09,0.21,0.33,0.21,0.48],['c',0.00,0.15,-0.09,0.39,-0.21,0.48],['c',-0.03,0.03,-0.12,0.09,-0.18,0.12],['c',-0.12,0.06,-0.18,0.06,-1.41,0.06],['l',-1.29,0.00],['l',0.00,1.29],['c',0.00,1.23,0.00,1.29,-0.06,1.41],['c',-0.09,0.18,-0.15,0.24,-0.30,0.33],['c',-0.21,0.09,-0.39,0.09,-0.57,0.00],['c',-0.18,-0.09,-0.24,-0.15,-0.33,-0.33],['c',-0.06,-0.12,-0.06,-0.18,-0.06,-1.41],['l',0.00,-1.29],['l',-1.29,0.00],['c',-1.23,0.00,-1.29,0.00,-1.41,-0.06],['c',-0.18,-0.09,-0.24,-0.15,-0.33,-0.33],['c',-0.09,-0.18,-0.09,-0.36,0.00,-0.54],['c',0.09,-0.18,0.15,-0.24,0.33,-0.33],['l',0.15,-0.06],['l',1.26,0.00],['l',1.29,0.00],['l',0.00,-1.29],['c',0.00,-1.23,0.00,-1.29,0.06,-1.41],['c',0.09,-0.18,0.15,-0.24,0.33,-0.33],['z']],w:7.507,h:7.515},
    		',':{d:[['M',1.32,-3.36],['c',0.57,-0.15,1.17,0.03,1.59,0.45],['c',0.45,0.45,0.60,0.96,0.51,1.89],['c',-0.09,1.23,-0.42,2.46,-0.99,3.93],['c',-0.30,0.72,-0.72,1.62,-0.78,1.68],['c',-0.18,0.21,-0.51,0.18,-0.66,-0.06],['c',-0.03,-0.06,-0.06,-0.15,-0.06,-0.18],['c',0.00,-0.06,0.12,-0.33,0.24,-0.63],['c',0.84,-1.80,1.02,-2.61,0.69,-3.24],['c',-0.12,-0.24,-0.27,-0.36,-0.75,-0.60],['c',-0.36,-0.15,-0.42,-0.21,-0.60,-0.39],['c',-0.69,-0.69,-0.69,-1.71,0.00,-2.40],['c',0.21,-0.21,0.51,-0.39,0.81,-0.45],['z']],w:3.452,h:8.143},
    		'-':{d:[['M',0.18,-5.34],['c',0.09,-0.06,0.15,-0.06,2.31,-0.06],['c',2.46,0.00,2.37,0.00,2.46,0.21],['c',0.12,0.21,0.03,0.42,-0.15,0.54],['c',-0.09,0.06,-0.15,0.06,-2.28,0.06],['c',-2.16,0.00,-2.22,0.00,-2.31,-0.06],['c',-0.27,-0.15,-0.27,-0.54,-0.03,-0.69],['z']],w:5.001,h:0.81},
    		'.':{d:[['M',1.32,-3.36],['c',1.05,-0.27,2.10,0.57,2.10,1.65],['c',0.00,1.08,-1.05,1.92,-2.10,1.65],['c',-0.90,-0.21,-1.50,-1.14,-1.26,-2.04],['c',0.12,-0.63,0.63,-1.11,1.26,-1.26],['z']],w:3.413,h:3.402},
    		'scripts.wedge':{d:[['M',-3.66,-7.44],['c',0.06,-0.09,0.00,-0.09,0.81,0.03],['c',1.86,0.30,3.84,0.30,5.73,0.00],['c',0.78,-0.12,0.72,-0.12,0.78,-0.03],['c',0.15,0.15,0.12,0.24,-0.24,0.60],['c',-0.93,0.93,-1.98,2.76,-2.67,4.62],['c',-0.30,0.78,-0.51,1.71,-0.51,2.13],['c',0.00,0.15,0.00,0.18,-0.06,0.27],['c',-0.12,0.09,-0.24,0.09,-0.36,0.00],['c',-0.06,-0.09,-0.06,-0.12,-0.06,-0.27],['c',0.00,-0.42,-0.21,-1.35,-0.51,-2.13],['c',-0.69,-1.86,-1.74,-3.69,-2.67,-4.62],['c',-0.36,-0.36,-0.39,-0.45,-0.24,-0.60],['z']],w:7.49,h:7.752},
    		'scripts.thumb':{d:[['M',-0.54,-3.69],['c',0.15,-0.03,0.36,-0.06,0.51,-0.06],['c',1.44,0.00,2.58,1.11,2.94,2.85],['c',0.09,0.48,0.09,1.32,0.00,1.80],['c',-0.27,1.41,-1.08,2.43,-2.16,2.73],['l',-0.18,0.06],['l',0.00,0.12],['c',0.03,0.06,0.06,0.45,0.09,0.87],['c',0.03,0.57,0.03,0.78,0.00,0.84],['c',-0.09,0.27,-0.39,0.48,-0.66,0.48],['c',-0.27,0.00,-0.57,-0.21,-0.66,-0.48],['c',-0.03,-0.06,-0.03,-0.27,0.00,-0.84],['c',0.03,-0.42,0.06,-0.81,0.09,-0.87],['l',0.00,-0.12],['l',-0.18,-0.06],['c',-1.08,-0.30,-1.89,-1.32,-2.16,-2.73],['c',-0.09,-0.48,-0.09,-1.32,0.00,-1.80],['c',0.15,-0.84,0.51,-1.53,1.02,-2.04],['c',0.39,-0.39,0.84,-0.63,1.35,-0.75],['z'],['m',1.05,0.90],['c',-0.15,-0.09,-0.21,-0.09,-0.45,-0.12],['c',-0.15,0.00,-0.30,0.03,-0.39,0.03],['c',-0.57,0.18,-0.90,0.72,-1.08,1.74],['c',-0.06,0.48,-0.06,1.80,0.00,2.28],['c',0.15,0.90,0.42,1.44,0.90,1.65],['c',0.18,0.09,0.21,0.09,0.51,0.09],['c',0.30,0.00,0.33,0.00,0.51,-0.09],['c',0.48,-0.21,0.75,-0.75,0.90,-1.65],['c',0.03,-0.27,0.03,-0.54,0.03,-1.14],['c',0.00,-0.60,0.00,-0.87,-0.03,-1.14],['c',-0.15,-0.90,-0.45,-1.44,-0.90,-1.65],['z']],w:5.955,h:9.75},
    		'scripts.open':{d:[['M',-0.54,-3.69],['c',0.15,-0.03,0.36,-0.06,0.51,-0.06],['c',1.44,0.00,2.58,1.11,2.94,2.85],['c',0.09,0.48,0.09,1.32,0.00,1.80],['c',-0.33,1.74,-1.47,2.85,-2.91,2.85],['c',-1.44,0.00,-2.58,-1.11,-2.91,-2.85],['c',-0.09,-0.48,-0.09,-1.32,0.00,-1.80],['c',0.15,-0.84,0.51,-1.53,1.02,-2.04],['c',0.39,-0.39,0.84,-0.63,1.35,-0.75],['z'],['m',1.11,0.90],['c',-0.21,-0.09,-0.27,-0.09,-0.51,-0.12],['c',-0.30,0.00,-0.42,0.03,-0.66,0.15],['c',-0.24,0.12,-0.51,0.39,-0.66,0.63],['c',-0.54,0.93,-0.63,2.64,-0.21,3.81],['c',0.21,0.54,0.51,0.90,0.93,1.11],['c',0.21,0.09,0.24,0.09,0.54,0.09],['c',0.30,0.00,0.33,0.00,0.54,-0.09],['c',0.42,-0.21,0.72,-0.57,0.93,-1.11],['c',0.36,-0.99,0.36,-2.37,0.00,-3.36],['c',-0.21,-0.54,-0.51,-0.90,-0.90,-1.11],['z']],w:5.955,h:7.5},
    		'scripts.longphrase':{d:[['M',1.47,-15.09],['c',0.36,-0.09,0.66,-0.18,0.69,-0.18],['c',0.06,0.00,0.06,0.54,0.06,11.25],['l',0.00,11.25],['l',-0.63,0.15],['c',-0.66,0.18,-1.44,0.39,-1.50,0.39],['c',-0.03,0.00,-0.03,-3.39,-0.03,-11.25],['l',0.00,-11.25],['l',0.36,-0.09],['c',0.21,-0.06,0.66,-0.18,1.05,-0.27],['z']],w:2.16,h:23.04},
    		'scripts.mediumphrase':{d:[['M',1.47,-7.59],['c',0.36,-0.09,0.66,-0.18,0.69,-0.18],['c',0.06,0.00,0.06,0.39,0.06,7.50],['l',0.00,7.50],['l',-0.63,0.15],['c',-0.66,0.18,-1.44,0.39,-1.50,0.39],['c',-0.03,0.00,-0.03,-2.28,-0.03,-7.50],['l',0.00,-7.50],['l',0.36,-0.09],['c',0.21,-0.06,0.66,-0.18,1.05,-0.27],['z']],w:2.16,h:15.54},
    		'scripts.shortphrase':{d:[['M',1.47,-7.59],['c',0.36,-0.09,0.66,-0.18,0.69,-0.18],['c',0.06,0.00,0.06,0.21,0.06,3.75],['l',0.00,3.75],['l',-0.42,0.09],['c',-0.57,0.18,-1.65,0.45,-1.71,0.45],['c',-0.03,0.00,-0.03,-0.72,-0.03,-3.75],['l',0.00,-3.75],['l',0.36,-0.09],['c',0.21,-0.06,0.66,-0.18,1.05,-0.27],['z']],w:2.16,h:8.04},
    		'scripts.snap':{d:[['M',4.50,-3.39],['c',0.36,-0.03,0.96,-0.03,1.35,0.00],['c',1.56,0.15,3.15,0.90,4.20,2.01],['c',0.24,0.27,0.33,0.42,0.33,0.60],['c',0.00,0.27,0.03,0.24,-2.46,2.22],['c',-1.29,1.02,-2.40,1.86,-2.49,1.92],['c',-0.18,0.09,-0.30,0.09,-0.48,0.00],['c',-0.09,-0.06,-1.20,-0.90,-2.49,-1.92],['c',-2.49,-1.98,-2.46,-1.95,-2.46,-2.22],['c',0.00,-0.18,0.09,-0.33,0.33,-0.60],['c',1.05,-1.08,2.64,-1.86,4.17,-2.01],['z'],['m',1.29,1.17],['c',-1.47,-0.15,-2.97,0.30,-4.14,1.20],['l',-0.18,0.15],['l',0.06,0.09],['c',0.15,0.12,3.63,2.85,3.66,2.85],['c',0.03,0.00,3.51,-2.73,3.66,-2.85],['l',0.06,-0.09],['l',-0.18,-0.15],['c',-0.84,-0.66,-1.89,-1.08,-2.94,-1.20],['z']],w:10.38,h:6.84}};

    	// Custom characters that weren't generated from the font:
    	glyphs['noteheads.slash.whole'] = {d:[['M',5,-5],['l',1,1],['l',-5,5],['l',-1,-1],['z'],['m',4,6],['l',-5,-5],['l',2,-2],['l',5,5],['z'],['m',0,-2],['l',1,1],['l',-5,5],['l',-1,-1],['z'],['m',-4,6],['l',-5,-5],['l',2,-2],['l',5,5],['z']],w:10.81,h:15.63};

    	glyphs['noteheads.slash.quarter'] = {d:[['M',9,-6],['l',0,4],['l',-9,9],['l',0,-4],['z']],w:9,h:9};

    	glyphs['noteheads.harmonic.quarter'] = {d:[['M',3.63,-4.02],['c',0.09,-0.06,0.18,-0.09,0.24,-0.03],['c',0.03,0.03,0.87,0.93,1.83,2.01],['c',1.50,1.65,1.80,1.98,1.80,2.04],['c',0.00,0.06,-0.30,0.39,-1.80,2.04],['c',-0.96,1.08,-1.80,1.98,-1.83,2.01],['c',-0.06,0.06,-0.15,0.03,-0.24,-0.03],['c',-0.12,-0.09,-3.54,-3.84,-3.60,-3.93],['c',-0.03,-0.03,-0.03,-0.09,-0.03,-0.15],['c',0.03,-0.06,3.45,-3.84,3.63,-3.96],['z']],w:7.5,h:8.165};

    var pathClone = function (pathArray) {
    	var res = [];
    	for (var i = 0, ii = pathArray.length; i < ii; i++) {
    		res[i] = [];
    		for (var j = 0, jj = pathArray[i].length; j < jj; j++) {
    			res[i][j] = pathArray[i][j];
    		}
    	}
    	return res;
    };

    var pathScale = function (pathArray, kx, ky) {
    	for (var i = 0, ii = pathArray.length; i < ii; i++) {
    		var p = pathArray[i];
    		var j, jj;
    		for (j = 1, jj = p.length; j < jj; j++) {
    			p[j] *= (j % 2) ? kx : ky;
    		}
    	}
    };

    var Glyphs = {
    	printSymbol: function (x,y,symb,paper, klass) {
        if (!glyphs[symb]) return null;
        var pathArray = pathClone(glyphs[symb].d);
        pathArray[0][1] +=x;
        pathArray[0][2] +=y;
        var path = "";
        for (var i = 0; i < pathArray.length; i++)
        	path += pathArray[i].join(" ");
        return paper.path({path:path, stroke:"none", fill:"#000000", 'class': klass });
       },

      getPathForSymbol: function (x,y,symb,scalex, scaley) {
        scalex = scalex || 1;
        scaley = scaley || 1;
        if (!glyphs[symb]) return null;
        var pathArray = pathClone(glyphs[symb].d);
        if (scalex!==1 || scaley!==1) pathScale(pathArray,scalex,scaley);
        pathArray[0][1] +=x;
        pathArray[0][2] +=y;

        return pathArray;
      },

      getSymbolWidth: function (symbol) {
        if (glyphs[symbol]) return glyphs[symbol].w;
        return 0;
      },

    	symbolHeightInPitches: function(symbol) {
    		var height = glyphs[symbol] ? glyphs[symbol].h : 0;
    		return height / abc_spacing.STEP;
    	},

      getSymbolAlign: function (symbol) {
        if (symbol.substring(0,7)==="scripts" &&
    	symbol!=="scripts.roll") {
          return "center";
        }
        return "left";
      },

      getYCorr: function (symbol) {
        switch(symbol) {
        case "0":
        case "1":
        case "2":
        case "3":
        case "4":
        case "5":
        case "6":
        case "7":
        case "8":
        case "9":
        case "+": return -2;
        case "timesig.common":
        case "timesig.cut": return 0;
        case "flags.d32nd": return -1;
        case "flags.d64th": return -2;
        case "flags.u32nd": return 1;
        case "flags.u64th": return 3;
        case "rests.whole": return 1;
        case "rests.half": return -1;
        case "rests.8th": return -1;
        case "rests.quarter": return -1;
        case "rests.16th": return -1;
        case "rests.32nd": return -1;
        case "rests.64th": return -1;
    		case "f":
    		case "m":
    		case "p":
    		case "s":
    		case "z":
    			return -4;
    		case "scripts.trill":
    		case "scripts.upbow":
    		case "scripts.downbow":
    			return -2;
    		case "scripts.ufermata":
    		case "scripts.wedge":
    		case "scripts.roll":
    		case "scripts.shortphrase":
    		case "scripts.longphrase":
    			return -1;
    		case "scripts.dfermata":
    			return 1;
        default: return 0;
        }
      },
    	setSymbol: function(name, path) {
    		glyphs[name] = path;
    	}
    };

    var abc_glyphs = Glyphs; // we need the glyphs for layout information

    //    abc_create_clef.js
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.





    var createClef;

    (function() {

    	createClef = function(elem, tuneNumber) {
    		var clef;
    		var octave = 0;
    		var abselem = new abc_absolute_element(elem,0,10, 'staff-extra', tuneNumber);
    		abselem.isClef = true;
    		switch (elem.type) {
    			case "treble": clef = "clefs.G"; break;
    			case "tenor": clef="clefs.C"; break;
    			case "alto": clef="clefs.C"; break;
    			case "bass": clef="clefs.F"; break;
    			case 'treble+8': clef = "clefs.G"; octave = 1; break;
    			case 'tenor+8':clef="clefs.C"; octave = 1; break;
    			case 'bass+8': clef="clefs.F"; octave = 1; break;
    			case 'alto+8': clef="clefs.C"; octave = 1; break;
    			case 'treble-8': clef = "clefs.G"; octave = -1; break;
    			case 'tenor-8':clef="clefs.C"; octave = -1; break;
    			case 'bass-8': clef="clefs.F"; octave = -1; break;
    			case 'alto-8': clef="clefs.C"; octave = -1; break;
    			case 'none': return null;
    			case 'perc': clef="clefs.perc"; break;
    			default: abselem.addChild(new abc_relative_element("clef="+elem.type, 0, 0, undefined, {type:"debug"}));
    		}
    		// if (elem.verticalPos) {
    		// pitch = elem.verticalPos;
    		// }
    		var dx =5;
    		if (clef) {
    			abselem.addRight(new abc_relative_element(clef, dx, abc_glyphs.getSymbolWidth(clef), elem.clefPos));

    			if (clef === 'clefs.G') {
    				abselem.top = 13;
    				abselem.bottom = -1;
    			} else {
    				abselem.top = 10;
    				abselem.bottom = 2;
    			}
    			if (octave !== 0) {
    				var scale = 2 / 3;
    				var adjustspacing = (abc_glyphs.getSymbolWidth(clef) - abc_glyphs.getSymbolWidth("8") * scale) / 2;
    				abselem.addRight(new abc_relative_element("8", dx + adjustspacing, abc_glyphs.getSymbolWidth("8") * scale, (octave > 0) ? abselem.top + 3 : abselem.bottom - 1, {
    					scalex: scale,
    					scaley: scale
    				}));
    				abselem.top += 2;
    			}
    		}
    		return abselem;
    	};

    })();

    var abc_create_clef = createClef;

    //    abc_create_key_signature.js
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.







    var createKeySignature;

    (function() {

    	createKeySignature = function(elem, tuneNumber) {
    		if (!elem.accidentals || elem.accidentals.length === 0)
    			return null;
    		var abselem = new abc_absolute_element(elem, 0, 10, 'staff-extra', tuneNumber);
    		abselem.isKeySig = true;
    		var dx = 0;
    		abc_common.each(elem.accidentals, function(acc) {
    			var symbol;
    			switch(acc.acc) {
    				case "sharp": symbol = "accidentals.sharp"; break;
    				case "natural": symbol = "accidentals.nat"; break;
    				case "flat": symbol = "accidentals.flat"; break;
    				case "quartersharp": symbol = "accidentals.halfsharp"; break;
    				case "quarterflat": symbol = "accidentals.halfflat"; break;
    				default: symbol = "accidentals.flat";
    			}
    			abselem.addRight(new abc_relative_element(symbol, dx, abc_glyphs.getSymbolWidth(symbol), acc.verticalPos, {thickness: abc_glyphs.symbolHeightInPitches(symbol)}));
    			dx += abc_glyphs.getSymbolWidth(symbol) + 2;
    		}, this);
    		return abselem;
    	};
    })();

    var abc_create_key_signature = createKeySignature;

    //    abc_create_time_signature.js
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.





    var createTimeSignature;

    (function() {

    	createTimeSignature = function(elem, tuneNumber) {
    		var abselem = new abc_absolute_element(elem,0,10, 'staff-extra', tuneNumber);
    		if (elem.type === "specified") {
    			var x = 0;
    			for (var i = 0; i < elem.value.length; i++) {
    				if (i !== 0) {
    					abselem.addRight(new abc_relative_element('+', x+1, abc_glyphs.getSymbolWidth("+"), 6, {thickness: abc_glyphs.symbolHeightInPitches("+")}));
    					x += abc_glyphs.getSymbolWidth("+")+2;
    				}
    				if (elem.value[i].den) {
    					var numWidth = 0;
    					for (var i2 = 0; i2 < elem.value[i].num.length; i2++)
    						numWidth += abc_glyphs.getSymbolWidth(elem.value[i].num.charAt(i2));
    					var denWidth = 0;
    					for (i2 = 0; i2 < elem.value[i].num.length; i2++)
    						denWidth += abc_glyphs.getSymbolWidth(elem.value[i].den.charAt(i2));
    					var maxWidth = Math.max(numWidth, denWidth);
    					abselem.addRight(new abc_relative_element(elem.value[i].num, x+(maxWidth-numWidth)/2, numWidth, 8, { thickness: abc_glyphs.symbolHeightInPitches(elem.value[i].num.charAt(0)) }));
    					abselem.addRight(new abc_relative_element(elem.value[i].den, x+(maxWidth-denWidth)/2, denWidth, 4, { thickness: abc_glyphs.symbolHeightInPitches(elem.value[i].den.charAt(0)) }));
    					x += maxWidth;
    				} else {
    					var thisWidth = 0;
    					for (var i3 = 0; i3 < elem.value[i].num.length; i3++)
    						thisWidth += abc_glyphs.getSymbolWidth(elem.value[i].num.charAt(i3));
    					abselem.addRight(new abc_relative_element(elem.value[i].num, x, thisWidth, 6, { thickness: abc_glyphs.symbolHeightInPitches(elem.value[i].num.charAt(0)) }));
    					x += thisWidth;
    				}
    			}
    		} else if (elem.type === "common_time") {
    			abselem.addRight(new abc_relative_element("timesig.common", 0, abc_glyphs.getSymbolWidth("timesig.common"), 6, { thickness: abc_glyphs.symbolHeightInPitches("timesig.common") }));

    		} else if (elem.type === "cut_time") {
    			abselem.addRight(new abc_relative_element("timesig.cut", 0, abc_glyphs.getSymbolWidth("timesig.cut"), 6, { thickness: abc_glyphs.symbolHeightInPitches("timesig.cut") }));
    		} else if (elem.type === "tempus_imperfectum") {
    			abselem.addRight(new abc_relative_element("timesig.imperfectum", 0, abc_glyphs.getSymbolWidth("timesig.imperfectum"), 6, { thickness: abc_glyphs.symbolHeightInPitches("timesig.imperfectum") }));
    		} else if (elem.type === "tempus_imperfectum_prolatio") {
    			abselem.addRight(new abc_relative_element("timesig.imperfectum2", 0, abc_glyphs.getSymbolWidth("timesig.imperfectum2"), 6, { thickness: abc_glyphs.symbolHeightInPitches("timesig.imperfectum2") }));
    		} else if (elem.type === "tempus_perfectum") {
    			abselem.addRight(new abc_relative_element("timesig.perfectum", 0, abc_glyphs.getSymbolWidth("timesig.perfectum"), 6, { thickness: abc_glyphs.symbolHeightInPitches("timesig.perfectum") }));
    		} else if (elem.type === "tempus_perfectum_prolatio") {
    			abselem.addRight(new abc_relative_element("timesig.perfectum2", 0, abc_glyphs.getSymbolWidth("timesig.perfectum2"), 6, { thickness: abc_glyphs.symbolHeightInPitches("timesig.perfectum2") }));
    		} else {
    			console.log("time signature:",elem);
    		}
    		return abselem;
    	};
    })();

    var abc_create_time_signature = createTimeSignature;

    //    abc_dynamic_decoration.js: Definition of the DynamicDecoration class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



    var DynamicDecoration = function DynamicDecoration(anchor, dec, position) {
    	this.anchor = anchor;
    	this.dec = dec;
    	if (position === 'below')
    		this.volumeHeightBelow = 5;
    	else
    		this.volumeHeightAbove = 5;
    	this.pitch = undefined; // This will be set later
    };

    DynamicDecoration.prototype.setUpperAndLowerElements = function(positionY) {
    	if (this.volumeHeightAbove)
    		this.pitch = positionY.volumeHeightAbove;
    	else
    		this.pitch = positionY.volumeHeightBelow;
    };

    DynamicDecoration.prototype.draw = function(renderer, linestartx, lineendx) {
    	if (this.pitch === undefined)
    		window.console.error("Dynamic Element y-coordinate not set.");
    	var scalex = 1;
    	var scaley = 1;
    	renderer.printSymbol(this.anchor.x, this.pitch, this.dec, scalex, scaley, renderer.addClasses('decoration'));
    };

    var abc_dynamic_decoration = DynamicDecoration;

    /**
     * sprintf() for JavaScript v.0.4
     *
     Copyright (c) 2007-present, Alexandru Mărășteanu <hello@alexei.ro>
     All rights reserved.

     Redistribution and use in source and binary forms, with or without
     modification, are permitted provided that the following conditions are met:
     * Redistributions of source code must retain the above copyright
     notice, this list of conditions and the following disclaimer.
     * Redistributions in binary form must reproduce the above copyright
     notice, this list of conditions and the following disclaimer in the
     documentation and/or other materials provided with the distribution.
     * Neither the name of this software nor the names of its contributors may be
     used to endorse or promote products derived from this software without
     specific prior written permission.

     THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
     ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
     WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
     DISCLAIMED. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR
     ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
     (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
     LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
     ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
     (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
     SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
     */

    //function str_repeat(i, m) { for (var o = []; m > 0; o[--m] = i); return(o.join('')); }

    var sprintf = function() {
      var i = 0, a, f = arguments[i++], o = [], m, p, c, x;
      while (f) {
        if (m = /^[^\x25]+/.exec(f)) o.push(m[0]);
        else if (m = /^\x25{2}/.exec(f)) o.push('%');
        else if (m = /^\x25(?:(\d+)\$)?(\+)?(0|'[^$])?(-)?(\d+)?(?:\.(\d+))?([b-fosuxX])/.exec(f)) {
          if (((a = arguments[m[1] || i++]) == null) || (a == undefined)) throw("Too few arguments.");
          if (/[^s]/.test(m[7]) && (typeof(a) != 'number'))
            throw("Expecting number but found " + typeof(a));
          switch (m[7]) {
            case 'b': a = a.toString(2); break;
            case 'c': a = String.fromCharCode(a); break;
            case 'd': a = parseInt(a); break;
            case 'e': a = m[6] ? a.toExponential(m[6]) : a.toExponential(); break;
            case 'f': a = m[6] ? parseFloat(a).toFixed(m[6]) : parseFloat(a); break;
            case 'o': a = a.toString(8); break;
            case 's': a = ((a = String(a)) && m[6] ? a.substring(0, m[6]) : a); break;
            case 'u': a = Math.abs(a); break;
            case 'x': a = a.toString(16); break;
            case 'X': a = a.toString(16).toUpperCase(); break;
          }
          a = (/[def]/.test(m[7]) && m[2] && a > 0 ? '+' + a : a);
          c = m[3] ? m[3] == '0' ? '0' : m[3].charAt(1) : ' ';
          x = m[5] - String(a).length;
          p = m[5] ? str_repeat(c, x) : '';
          o.push(m[4] ? a + p : p + a);
        }
        else throw ("Huh ?!");
        f = f.substring(m[0].length);
      }
      return o.join('');
    };

    var sprintf_1 = sprintf;

    //    abc_crescendo_element.js: Definition of the CrescendoElem class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



    var CrescendoElem = function CrescendoElem(anchor1, anchor2, dir, positioning) {
    	this.anchor1 = anchor1; // must have a .x and a .parent property or be null (means starts at the "beginning" of the line - after keysig)
    	this.anchor2 = anchor2; // must have a .x property or be null (means ends at the end of the line)
    	this.dir = dir; // either "<" or ">"
    	if (positioning === 'above')
    		this.dynamicHeightAbove = 4;
    	else
    		this.dynamicHeightBelow = 4;
    	this.pitch = undefined; // This will be set later
    };

    CrescendoElem.prototype.setUpperAndLowerElements = function(positionY) {
    	if (this.dynamicHeightAbove)
    		this.pitch = positionY.dynamicHeightAbove;
    	else
    		this.pitch = positionY.dynamicHeightBelow;
    };

    CrescendoElem.prototype.draw = function (renderer) {
    	if (this.pitch === undefined)
    		window.console.error("Crescendo Element y-coordinate not set.");
    	var y = renderer.calcY(this.pitch) + 4; // This is the top pixel to use (it is offset a little so that it looks good with the volume marks.)
    	var height = 8;
    	if (this.dir === "<") {
    		this.drawLine(renderer, y+height/2, y);
    		this.drawLine(renderer, y+height/2, y+height);
    	} else {
    		this.drawLine(renderer, y, y+height/2);
    		this.drawLine(renderer, y+height, y+height/2);
    	}
    };

    CrescendoElem.prototype.drawLine = function (renderer, y1, y2) {
    	// TODO-PER: This is just a quick hack to make the dynamic marks not crash if they are mismatched. See the slur treatment for the way to get the beginning and end.
    	var left = this.anchor1 ? this.anchor1.x : 0;
    	var right = this.anchor2 ? this.anchor2.x : 800;
    	var pathString = sprintf_1("M %f %f L %f %f",
    		left, y1, right, y2);
    	renderer.printPath({path:pathString, stroke:"#000000", 'class': renderer.addClasses('decoration')});
    };

    var abc_crescendo_element = CrescendoElem;

    //    abc_tie_element.js: Definition of the TieElement class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    var TieElem = function TieElem(options) {
    //	console.log("constructor", options.anchor1 ? options.anchor1.pitch : "N/A", options.anchor2 ? options.anchor2.pitch : "N/A", options.isTie, options.isGrace);
    	this.anchor1 = options.anchor1; // must have a .x and a .pitch, and a .parent property or be null (means starts at the "beginning" of the line - after keysig)
    	this.anchor2 = options.anchor2; // must have a .x and a .pitch property or be null (means ends at the end of the line)
    	if (options.isGrace)
    		this.isGrace = true;
    	if (options.fixedY)
    		this.fixedY = true;
    	if (options.stemDir)
    		this.stemDir = options.stemDir;
    	if (options.voiceNumber !== undefined)
    		this.voiceNumber = options.voiceNumber;
    	this.internalNotes = [];
    };

    TieElem.prototype.addInternalNote = function(note) {
    	this.internalNotes.push(note);
    };

    TieElem.prototype.setEndAnchor = function(anchor2) {
    //	console.log("end", this.anchor1 ? this.anchor1.pitch : "N/A", anchor2 ? anchor2.pitch : "N/A", this.isTie, this.isGrace);
    	this.anchor2 = anchor2; // must have a .x and a .pitch property or be null (means ends at the end of the line)
    };

    // If we encounter a repeat sign, then we don't want to extend either a tie or a slur past it, so these are called to be a limit.
    TieElem.prototype.setStartX = function(startLimitElem) {
    	this.startLimitX = startLimitElem;
    };

    TieElem.prototype.setEndX = function(endLimitElem) {
    	this.endLimitX = endLimitElem;
    };

    TieElem.prototype.setHint = function () {
    	this.hint = true;
    };

    TieElem.prototype.setUpperAndLowerElements = function(positionY) {
    	// Doesn't depend on the highest and lowest, so there's nothing to do here.
    };

    TieElem.prototype.calcTieDirection = function () {
    	// The rules:
    	// 1) If it is in a grace note group, then the direction is always BELOW.
    	// 2) If it is in a single voice, then the direction is always OPPOSITE of the stem (or where the stem would have been in the case of whole notes.)
    	// 3) If the stem direction is forced (probably because there are two voices on the same line), then the direction is the SAME as the stem direction.

    	if (this.isGrace)
    		this.above = false;
    	else if (this.voiceNumber === 0)
    		this.above = true;
    	else if (this.voiceNumber > 0)
    		this.above = false;
    	else {
    		var referencePitch;
    		if (this.anchor1)
    			referencePitch = this.anchor1.pitch;
    		else if (this.anchor2)
    			referencePitch = this.anchor2.pitch;
    		else
    			referencePitch = 14; // TODO-PER: this can't really happen normally. This would imply that a tie crossed over three lines, something like "C-\nz\nC"
    		// Put the arc in the opposite direction of the stem. That isn't always the pitch if one or both of the notes are beamed with something that affects its stem.
    		if ((this.anchor1 && this.anchor1.stemDir === 'down') && (this.anchor2 && this.anchor2.stemDir === "down"))
    			this.above = true;
    		else if ((this.anchor1 && this.anchor1.stemDir === 'up') && (this.anchor2 && this.anchor2.stemDir === "up"))
    			this.above = false;
    		else if (this.anchor1 && this.anchor2)
    			this.above = referencePitch >= 6;
    		else if (this.anchor1)
    			this.above = this.anchor1.stemDir === "down";
    		else if (this.anchor2)
    			this.above = this.anchor2.stemDir === "down";
    		else
    			this.above = referencePitch >= 6;
    	}
    };

    // From "standard music notation practice" by Music Publishers’ Association:
    // 1) Slurs are placed under the note heads if all stems go up.
    // 2) Slurs are placed over the note heads if all stems go down.
    // 3) If there are both up stems and down stems, prefer placing the slur over.
    // 4) When the staff has opposite stemmed voices, all slurs should be on the stemmed side.

    TieElem.prototype.calcSlurDirection = function () {
    	if (this.isGrace)
    		this.above = false;
    	else if (this.voiceNumber === 0)
    		this.above = true;
    	else if (this.voiceNumber > 0)
    		this.above = false;
    	else {
    		var hasDownStem = false;
    		if (this.anchor1 && this.anchor1.stemDir === "down")
    			hasDownStem = true;
    		if (this.anchor2 && this.anchor2.stemDir === "down")
    			hasDownStem = true;
    		for (var i = 0; i < this.internalNotes.length; i++) {
    			var n = this.internalNotes[i];
    			if (n.stemDir === "down")
    				hasDownStem = true;
    		}
    		this.above = hasDownStem;
    	}
    };

    TieElem.prototype.calcX = function (lineStartX, lineEndX) {
    	if (this.anchor1) {
    		this.startX = this.anchor1.x; // The normal case where there is a starting element to attach to.
    		if (this.anchor1.scalex < 1) // this is a grace note - don't offset the tie as much.
    			this.startX -= 3;
    	} else if (this.startLimitX)
    		this.startX = this.startLimitX.x+this.startLimitX.w; // if there is no start element, but there is a repeat mark before the start of the line.
    	else
    		this.startX = lineStartX; // There is no element and no repeat mark: extend to the beginning of the line.

    	if (this.anchor2)
    		this.endX = this.anchor2.x; // The normal case where there is a starting element to attach to.
    	else if (this.endLimitX)
    		this.endX = this.endLimitX.x; // if there is no start element, but there is a repeat mark before the start of the line.
    	else
    		this.endX = lineEndX; // There is no element and no repeat mark: extend to the beginning of the line.
    };

    TieElem.prototype.calcTieY = function () {
    	// If the tie comes from another line, then one or both anchors will be missing.
    	if (this.anchor1)
    		this.startY = this.anchor1.pitch;
    	else if (this.anchor2)
    		this.startY = this.anchor2.pitch;
    	else
    		this.startY = this.above ? 14 : 0;

    	if (this.anchor2)
    		this.endY = this.anchor2.pitch;
    	else if (this.anchor1)
    		this.endY = this.anchor1.pitch;
    	else
    		this.endY = this.above ? 14 : 0;
    };

    // From "standard music notation practice" by Music Publishers’ Association:
    // 1) If the anchor note is down stem, the slur points to the note head.
    // 2) If the anchor note is up stem, and the slur is over, then point to middle of stem.

    TieElem.prototype.calcSlurY = function () {
    	if (this.anchor1 && this.anchor2) {
    		if (this.above && this.anchor1.stemDir === "up" && !this.fixedY) {
    			this.startY = (this.anchor1.highestVert + this.anchor1.pitch) / 2;
    			this.startX += this.anchor1.w/2; // When going to the middle of the stem, bump the line to the right a little bit to make it look right.
    		} else
    			this.startY = this.anchor1.pitch;

    		// If the closing note has an up stem, and it is beamed, and it isn't the first note in the beam, then the beam will get in the way.
    		var beamInterferes = this.anchor2.parent.beam && this.anchor2.parent.beam.stemsUp && this.anchor2.parent.beam.elems[0] !== this.anchor2.parent;
    		var midPoint = (this.anchor2.highestVert + this.anchor2.pitch) / 2;
    		if (this.above && this.anchor2.stemDir === "up" && !this.fixedY && !beamInterferes && (midPoint < this.startY)) {
    			this.endY = midPoint;
    			this.endX += this.anchor2.w/2; // When going to the middle of the stem, bump the line to the right a little bit to make it look right.
    		} else
    			this.endY = this.above && beamInterferes ? this.anchor2.highestVert : this.anchor2.pitch;

    	} else if (this.anchor1) {
    		this.startY = this.endY = this.anchor1.pitch;
    	} else if (this.anchor2) {
    		this.startY = this.endY = this.anchor2.pitch;
    	} else {
    		// This is the case where the slur covers the entire line.
    		// TODO-PER: figure out where the real top and bottom of the line are.
    		this.startY = this.above ? 14 : 0;
    		this.endY = this.above ? 14 : 0;
    	}
    };

    TieElem.prototype.avoidCollisionAbove = function () {
    	// Double check that an interior note in the slur isn't so high that it interferes.
    	if (this.above) {
    		var maxInnerHeight = -50;
    		for (var i = 0; i < this.internalNotes.length; i++) {
    			if (this.internalNotes[i].highestVert > maxInnerHeight)
    				maxInnerHeight = this.internalNotes[i].highestVert;
    		}
    		if (maxInnerHeight > this.startY && maxInnerHeight > this.endY)
    			this.startY = this.endY = maxInnerHeight - 1;
    	}
    };

    TieElem.prototype.layout = function (lineStartX, lineEndX) {
    	// We now have all of the input variables set, so we can figure out the start and ending x,y coordinates, and finalize the direction of the arc.

    	// Ties and slurs are handled a little differently, so do calculations for them separately.
    	if (!this.anchor1 || !this.anchor2)
    		this.isTie = true; // if the slur goes off the end of the line, then draw it like a tie
    	else if (this.anchor1.pitch === this.anchor2.pitch && this.internalNotes.length === 0)
    		this.isTie = true;
    	else
    		this.isTie = false;

    	// TODO-PER: Not sure why this would be needed, but it would be better to figure out a way to have the anchors be immutable here anyway.
    	// if (this.isTie) {
    	// 	if (this.anchor1) // this can happen if the tie comes from the previous line.
    	// 		this.anchor1.isTie = true;
    	// 	if (this.anchor2) // this can happen if the tie does not go to the next line.
    	// 		this.anchor2.isTie = true;
    	// }

    	if (this.isTie) {
    		this.calcTieDirection();
    		// TODO-PER: Not sure why this would be needed, but it would be better to figure out a way to have the anchors be immutable here anyway.
    		// if (this.anchor1) // this can happen if the tie comes from the previous line.
    		// 	this.anchor1.tieAbove = this.above;
    		// if (this.anchor2) // this can happen if the tie goes to the next line.
    		// 	this.anchor2.tieAbove = this.above;
    		this.calcX(lineStartX, lineEndX);
    		this.calcTieY();

    	} else {
    		this.calcSlurDirection();
    		this.calcX(lineStartX, lineEndX);
    		this.calcSlurY();
    	}
    	this.avoidCollisionAbove();
    };

    TieElem.prototype.draw = function (renderer, linestartx, lineendx) {
    	this.layout(linestartx, lineendx);

    	var klass;
    	if (this.hint)
    			klass = "abcjs-hint";
    	var fudgeY =  this.fixedY ? 1.5 : 0; // TODO-PER: This just compensates for drawArc, which contains too much knowledge of ties and slurs.
    	renderer.drawArc(this.startX, this.endX, this.startY+fudgeY, this.endY+fudgeY,  this.above, klass, this.isTie);

    };

    var abc_tie_element = TieElem;

    // abc_decoration.js: Creates a data structure suitable for printing a line of abc
    // Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) & Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    /*global window */







    var Decoration;

    (function() {

    	Decoration = function Decoration() {
    		this.startDiminuendoX = undefined;
    		this.startCrescendoX = undefined;
    		this.minTop = 12;	// TODO-PER: this is assuming a 5-line staff. Pass that info in.
    		this.minBottom = 0;
    	};

    	var closeDecoration = function(voice, decoration, pitch, width, abselem, roomtaken, dir, minPitch) {
    		var yPos;
    		for (var i=0;i<decoration.length; i++) {
    			if (decoration[i]==="staccato" || decoration[i]==="tenuto" || decoration[i] === "accent") {
    				var symbol = "scripts." + decoration[i];
    				if (decoration[i] === "accent") symbol = "scripts.sforzato";
    				if (yPos === undefined)
    					yPos = (dir==="down") ? pitch+2:minPitch-2;
    				else
    					yPos = (dir==="down") ? yPos+2:yPos-2;
    				if (decoration[i] === "accent") {
    					// Always place the accent three pitches away, no matter whether that is a line or space.
    					if (dir === "up") yPos--;
    					else yPos++;
    				} else {
    					// don't place on a stave line. The stave lines are 2,4,6,8,10
    					switch (yPos) {
    						case 2:
    						case 4:
    						case 6:
    						case 8:
    						case 10:
    							if (dir === "up") yPos--;
    							else yPos++;
    							break;
    					}
    				}
    				if (pitch>9) yPos++; // take up some room of those that are above
    				var deltaX = width/2;
    				if (abc_glyphs.getSymbolAlign(symbol)!=="center") {
    					deltaX -= (abc_glyphs.getSymbolWidth(symbol)/2);
    				}
    				abselem.addChild(new abc_relative_element(symbol, deltaX, abc_glyphs.getSymbolWidth(symbol), yPos));
    			}
    			if (decoration[i]==="slide" && abselem.heads[0]) {
    				var yPos2 = abselem.heads[0].pitch;
    				yPos2 -= 2; // TODO-PER: not sure what this fudge factor is.
    				var blank1 = new abc_relative_element("", -roomtaken-15, 0, yPos2-1);
    				var blank2 = new abc_relative_element("", -roomtaken-5, 0, yPos2+1);
    				abselem.addChild(blank1);
    				abselem.addChild(blank2);
    				voice.addOther(new abc_tie_element({ anchor1: blank1, anchor2: blank2, fixedY: true}));
    			}
    		}
    		if (yPos === undefined)
    			yPos = pitch;

    		return { above: yPos, below: abselem.bottom };
    	};

    	var volumeDecoration = function(voice, decoration, abselem, positioning) {
    		for (var i=0;i<decoration.length; i++) {
    			switch(decoration[i]) {
    				case "p":
    				case "mp":
    				case "pp":
    				case "ppp":
    				case "pppp":
    				case "f":
    				case "ff":
    				case "fff":
    				case "ffff":
    				case "sfz":
    				case "mf":
    					var elem = new abc_dynamic_decoration(abselem, decoration[i], positioning);
    					voice.addOther(elem);
    			}
    		}
    	};

    	var compoundDecoration = function(decoration, pitch, width, abselem, dir) {
    		function highestPitch() {
    			if (abselem.heads.length === 0)
    				return 10;	// TODO-PER: I don't know if this can happen, but we'll return the top of the staff if so.
    			var pitch = abselem.heads[0].pitch;
    			for (var i = 1; i < abselem.heads.length; i++)
    				pitch = Math.max(pitch, abselem.heads[i].pitch);
    			return pitch;
    		}
    		function lowestPitch() {
    			if (abselem.heads.length === 0)
    				return 2;	// TODO-PER: I don't know if this can happen, but we'll return the bottom of the staff if so.
    			var pitch = abselem.heads[0].pitch;
    			for (var i = 1; i < abselem.heads.length; i++)
    				pitch = Math.min(pitch, abselem.heads[i].pitch);
    			return pitch;
    		}
    		function compoundDecoration(symbol, count) {
    			var placement = (dir === 'down') ? lowestPitch()+1:highestPitch()+9;
    			if (dir !== 'down' && count === 1)
    				placement--;
    			var deltaX = width/2;
    			deltaX += (dir === 'down') ? -5 : 3;
    			for (var i = 0; i < count; i++) {
    				placement -= 1;
    				abselem.addChild(new abc_relative_element(symbol, deltaX, abc_glyphs.getSymbolWidth(symbol), placement));
    			}
    		}

    		for (var i=0;i<decoration.length; i++) {
    			switch(decoration[i]) {
    				case "/": compoundDecoration("flags.ugrace", 1); break;
    				case "//": compoundDecoration("flags.ugrace", 2); break;
    				case "///": compoundDecoration("flags.ugrace", 3); break;
    				case "////": compoundDecoration("flags.ugrace", 4); break;
    			}
    		}
    	};

    	var stackedDecoration = function(decoration, width, abselem, yPos, positioning, minTop, minBottom) {
    		function incrementPlacement(placement, height) {
    			if (placement === 'above')
    				yPos.above += height;
    			else
    				yPos.below -= height;
    		}
    		function getPlacement(placement) {
    			var y;
    			if (placement === 'above') {
    				y = yPos.above;
    				if (y < minTop)
    					y = minTop;
    			} else {
    				y = yPos.below;
    				if (y > minBottom)
    					y = minBottom;
    			}
    			return y;
    		}
    		function textDecoration(text, placement) {
    			var y = getPlacement(placement);
    			var textFudge = 2;
    			var textHeight = 5;
    			// TODO-PER: Get the height of the current font and use that for the thickness.
    			abselem.addChild(new abc_relative_element(text, width/2, 0, y+textFudge, {type:"decoration", klass: 'ornament', thickness: 3}));

    			incrementPlacement(placement, textHeight);
    		}
    		function symbolDecoration(symbol, placement) {
    			var deltaX = width/2;
    			if (abc_glyphs.getSymbolAlign(symbol) !== "center") {
    				deltaX -= (abc_glyphs.getSymbolWidth(symbol) / 2);
    			}
    			var height = abc_glyphs.symbolHeightInPitches(symbol) + 1; // adding a little padding so nothing touches.
    			var y = getPlacement(placement);
    			y = (placement === 'above') ? y + height/2 : y - height/2;// Center the element vertically.
    			abselem.addChild(new abc_relative_element(symbol, deltaX, abc_glyphs.getSymbolWidth(symbol), y, { klass: 'ornament', thickness: abc_glyphs.symbolHeightInPitches(symbol) }));

    			incrementPlacement(placement, height);
    		}

    		var symbolList = {
    			"+": "scripts.stopped",
    			"open": "scripts.open",
    			"snap": "scripts.snap",
    			"wedge": "scripts.wedge",
    			"thumb": "scripts.thumb",
    			"shortphrase": "scripts.shortphrase",
    			"mediumphrase": "scripts.mediumphrase",
    			"longphrase": "scripts.longphrase",
    			"trill": "scripts.trill",
    			"roll": "scripts.roll",
    			"irishroll": "scripts.roll",
    			"marcato": "scripts.umarcato",
    			"dmarcato": "scripts.dmarcato",
    			"umarcato": "scripts.umarcato",
    			"turn": "scripts.turn",
    			"uppermordent": "scripts.prall",
    			"pralltriller": "scripts.prall",
    			"mordent": "scripts.mordent",
    			"lowermordent": "scripts.mordent",
    			"downbow": "scripts.downbow",
    			"upbow": "scripts.upbow",
    			"fermata": "scripts.ufermata",
    			"invertedfermata": "scripts.dfermata",
    			"breath": ",",
    			"coda": "scripts.coda",
    			"segno": "scripts.segno"
    		};

    		var hasOne = false;
    		for (var i=0;i<decoration.length; i++) {
    			switch(decoration[i]) {
    				case "0":
    				case "1":
    				case "2":
    				case "3":
    				case "4":
    				case "5":
    				case "D.C.":
    				case "D.S.":
    					textDecoration(decoration[i], positioning);
    					hasOne = true;
    					break;
    				case "fine":
    					textDecoration("FINE", positioning);
    					hasOne = true;
    					break;
    				case "+":
    				case "open":
    				case "snap":
    				case "wedge":
    				case "thumb":
    				case "shortphrase":
    				case "mediumphrase":
    				case "longphrase":
    				case "trill":
    				case "roll":
    				case "irishroll":
    				case "marcato":
    				case "dmarcato":
    				case "turn":
    				case "uppermordent":
    				case "pralltriller":
    				case "mordent":
    				case "lowermordent":
    				case "downbow":
    				case "upbow":
    				case "fermata":
    				case "breath":
    				case "umarcato":
    				case "coda":
    				case "segno":
    					symbolDecoration(symbolList[decoration[i]], positioning);
    					hasOne = true;
    					break;
    				case "invertedfermata":
    					symbolDecoration(symbolList[decoration[i]], 'below');
    					hasOne = true;
    					break;
    				case "mark":
    					abselem.klass = "mark";
    					break;
    			}
    		}
    		return hasOne;
    	};

    	function leftDecoration(decoration, abselem, roomtaken) {
    		for (var i=0;i<decoration.length; i++) {
    			switch (decoration[i]) {
    				case "arpeggio":
    					// The arpeggio symbol is the height of a note (that is, two Y units). This stacks as many as we need to go from the
    					// top note to the bottom note. The arpeggio should also be a little taller than the stacked notes, so there is an extra
    					// one drawn and it is offset by half of a note height (that is, one Y unit).
    					for (var j = abselem.abcelem.minpitch - 1; j <= abselem.abcelem.maxpitch; j += 2) {
    						abselem.addExtra(
    							new abc_relative_element(
    								"scripts.arpeggio",
    								-abc_glyphs.getSymbolWidth("scripts.arpeggio")*2 - roomtaken,
    								0,
    								j+2,
    								{klass: 'ornament', thickness: abc_glyphs.symbolHeightInPitches("scripts.arpeggio")}
    							)
    						);
    					}
    					break;
    			}
    		}
    	}

    	Decoration.prototype.dynamicDecoration = function(voice, decoration, abselem, positioning) {
    		var diminuendo;
    		var crescendo;
    		for (var i=0;i<decoration.length; i++) {
    			switch(decoration[i]) {
    				case "diminuendo(":
    					this.startDiminuendoX = abselem;
    					diminuendo = undefined;
    					break;
    				case "diminuendo)":
    					diminuendo = { start: this.startDiminuendoX, stop: abselem};
    					this.startDiminuendoX = undefined;
    					break;
    				case "crescendo(":
    					this.startCrescendoX = abselem;
    					crescendo = undefined;
    					break;
    				case "crescendo)":
    					crescendo = { start: this.startCrescendoX, stop: abselem};
    					this.startCrescendoX = undefined;
    					break;
    			}
    		}
    		if (diminuendo) {
    			voice.addOther(new abc_crescendo_element(diminuendo.start, diminuendo.stop, ">", positioning));
    		}
    		if (crescendo) {
    			voice.addOther(new abc_crescendo_element(crescendo.start, crescendo.stop, "<", positioning));
    		}
    	};

    	Decoration.prototype.createDecoration = function(voice, decoration, pitch, width, abselem, roomtaken, dir, minPitch, positioning, hasVocals) {
    		if (!positioning)
    			positioning = { ornamentPosition: 'above', volumePosition: hasVocals ? 'above' :'below', dynamicPosition: hasVocals ? 'above' : 'below' };
    		// These decorations don't affect the placement of other decorations
    		volumeDecoration(voice, decoration, abselem, positioning.volumePosition);
    		this.dynamicDecoration(voice, decoration, abselem, positioning.dynamicPosition);
    		compoundDecoration(decoration, pitch, width, abselem, dir);

    		// treat staccato, accent, and tenuto first (may need to shift other markers)
    		var yPos = closeDecoration(voice, decoration, pitch, width, abselem, roomtaken, dir, minPitch);
    		// yPos is an object containing 'above' and 'below'. That is the placement of the next symbol on either side.

    		yPos.above = Math.max(yPos.above, this.minTop);
    		var hasOne = stackedDecoration(decoration, width, abselem, yPos, positioning.ornamentPosition, this.minTop, this.minBottom);
    		leftDecoration(decoration, abselem, roomtaken);
    	};

    })();

    var abc_decoration = Decoration;

    //    abc_ending_element.js: Definition of the EndingElement class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



    var EndingElem = function EndingElem(text, anchor1, anchor2) {
    	this.text = text; // text to be displayed top left
    	this.anchor1 = anchor1; // must have a .x property or be null (means starts at the "beginning" of the line - after keysig)
    	this.anchor2 = anchor2; // must have a .x property or be null (means ends at the end of the line)
    	this.endingHeightAbove = 5;
    	this.pitch = undefined; // This will be set later
    };

    EndingElem.prototype.setUpperAndLowerElements = function(positionY) {
    	this.pitch = positionY.endingHeightAbove - 2;
    };

    EndingElem.prototype.draw = function (renderer, linestartx, lineendx) {
    	if (this.pitch === undefined)
    		window.console.error("Ending Element y-coordinate not set.");
    	var y = renderer.calcY(this.pitch);
    	var height = 20;
    	var pathString;
    	if (this.anchor1) {
    		linestartx = this.anchor1.x+this.anchor1.w;
    		pathString = sprintf_1("M %f %f L %f %f",
    			linestartx, y, linestartx, y+height);
    		renderer.printPath({path:pathString, stroke:"#000000", fill:"#000000", 'class': renderer.addClasses('ending')});
    		renderer.renderText(linestartx+5, renderer.calcY(this.pitch-0.5), this.text, 'repeatfont', 'ending',"start");
    	}

    	if (this.anchor2) {
    		lineendx = this.anchor2.x;
    		pathString = sprintf_1("M %f %f L %f %f",
    			lineendx, y, lineendx, y+height);
    		renderer.printPath({path:pathString, stroke:"#000000", fill:"#000000", 'class': renderer.addClasses('ending')});
    	}


    	pathString = sprintf_1("M %f %f L %f %f",
    		linestartx, y, lineendx, y);
    	renderer.printPath({path:pathString, stroke:"#000000", fill:"#000000", 'class': renderer.addClasses('ending')});
    };

    var abc_ending_element = EndingElem;

    //    abc_staff_group_element.js: Definition of the StaffGroupElement class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    /*globals console */



    // StaffGroupElement contains all the elements that go together to make one line of music.
    // That might be multiple staves that are tied together, and it might be multiple voices on one staff.
    //
    // Methods:
    // constructor: some basic initialization
    // addVoice(): Called once for each voice. May add a new staff if needed.
    // finished(): Called only internally by layout()
    // layout(): This does all the layout. It sets the following: spacingunits, startx, minspace, w, and the x-coordinate of each element in each voice.
    // draw(): Calls the underlying methods on the voice objects to do the drawing. Sets y and height.
    //
    // Members:
    // staffs: an array of all the staves in this group. Each staff contains the following elements:
    //    { top, bottom, highest, lowest, y }
    // voices: array of VoiceElement objects. This is mostly passed in, but the VoiceElement objects are modified here.
    //
    // spacingunits: number of relative x-units in the line. Used by the calling function to pass back in as the "spacing" input parameter.
    // TODO-PER: This should actually be passed back as a return value.
    // minspace: smallest space between two notes. Used by the calling function to pass back in as the "spacing" input parameter.
    // TODO-PER: This should actually be passed back as a return value.
    // startx: The left edge, taking the margin and the optional voice name. Used by the draw() method.
    // w: The width of the line. Used by calling function to pass back in as the "spacing" input parameter, and the draw() method.
    // TODO-PER: This should actually be passed back as a return value.  (TODO-PER: in pixels or spacing units?)
    // y: The top of the staff group, in pixels. This is set in the draw method.
    // TODO-PER: Where is that used? It looks like it might not be needed.
    // height: Set in the draw() method to the height actually used. Used by the calling function to know where to start the next staff group.
    // TODO-PER: This should actually be set in the layout method and passed back as a return value.

    var StaffGroupElement = function() {
    	this.voices = [];
    	this.staffs = [];
    	this.brace = undefined; //tony
    };

    StaffGroupElement.prototype.setLimit = function(member, voice) {
    	if (!voice.specialY[member]) return;
    	if (!voice.staff.specialY[member])
    		voice.staff.specialY[member] = voice.specialY[member];
    	else
    		voice.staff.specialY[member] = Math.max(voice.staff.specialY[member], voice.specialY[member]);
    };

    StaffGroupElement.prototype.addVoice = function (voice, staffnumber, stafflines) {
    	var voiceNum = this.voices.length;
    	this.voices[voiceNum] = voice;
    	if (this.staffs[staffnumber])
    		this.staffs[staffnumber].voices.push(voiceNum);
    	else {
    		// TODO-PER: how does the min/max change when stafflines is not 5?
    		this.staffs[this.staffs.length] = {
    			top: 10,
    			bottom: 2,
    			lines: stafflines,
    			voices: [voiceNum],
    			specialY: {
    				tempoHeightAbove: 0,
    				partHeightAbove: 0,
    				volumeHeightAbove: 0,
    				dynamicHeightAbove: 0,
    				endingHeightAbove: 0,
    				chordHeightAbove: 0,
    				lyricHeightAbove: 0,

    				lyricHeightBelow: 0,
    				chordHeightBelow: 0,
    				volumeHeightBelow: 0,
    				dynamicHeightBelow: 0
    			}
    		};
    	}
    	voice.staff = this.staffs[staffnumber];
    };

    StaffGroupElement.prototype.setStaffLimits = function (voice) {
    	voice.staff.top = Math.max(voice.staff.top, voice.top);
    	voice.staff.bottom = Math.min(voice.staff.bottom, voice.bottom);
    	this.setLimit('tempoHeightAbove', voice);
    	this.setLimit('partHeightAbove', voice);
    	this.setLimit('volumeHeightAbove', voice);
    	this.setLimit('dynamicHeightAbove', voice);
    	this.setLimit('endingHeightAbove', voice);
    	this.setLimit('chordHeightAbove', voice);
    	this.setLimit('lyricHeightAbove', voice);
    	this.setLimit('lyricHeightBelow', voice);
    	this.setLimit('chordHeightBelow', voice);
    	this.setLimit('volumeHeightBelow', voice);
    	this.setLimit('dynamicHeightBelow', voice);
    };

    StaffGroupElement.prototype.setUpperAndLowerElements = function(renderer) {
    	// Each staff already has the top and bottom set, now we see if there are elements that are always on top and bottom, and resolve their pitch.
    	// Also, get the overall height of all the staves in this group.
    	var lastStaffBottom;
    	for (var i = 0; i < this.staffs.length; i++) {
    		var staff = this.staffs[i];
    		// the vertical order of elements that are above is: tempo, part, volume/dynamic, ending/chord, lyric
    		// the vertical order of elements that are below is: lyric, chord, volume/dynamic
    		var positionY = {
    			tempoHeightAbove: 0,
    			partHeightAbove: 0,
    			volumeHeightAbove: 0,
    			dynamicHeightAbove: 0,
    			endingHeightAbove: 0,
    			chordHeightAbove: 0,
    			lyricHeightAbove: 0,

    			lyricHeightBelow: 0,
    			chordHeightBelow: 0,
    			volumeHeightBelow: 0,
    			dynamicHeightBelow: 0
    		};

    		if (staff.specialY.lyricHeightAbove) { staff.top += staff.specialY.lyricHeightAbove; positionY.lyricHeightAbove = staff.top; }
    		if (staff.specialY.chordHeightAbove) { staff.top += staff.specialY.chordHeightAbove; positionY.chordHeightAbove = staff.top; }
    		if (staff.specialY.endingHeightAbove) {
    			if (staff.specialY.chordHeightAbove)
    				staff.top += 2;
    			else
    				staff.top += staff.specialY.endingHeightAbove;
    			positionY.endingHeightAbove = staff.top;
    		}
    		if (staff.specialY.dynamicHeightAbove && staff.specialY.volumeHeightAbove) {
    			staff.top += Math.max(staff.specialY.dynamicHeightAbove, staff.specialY.volumeHeightAbove);
    			positionY.dynamicHeightAbove = staff.top;
    			positionY.volumeHeightAbove = staff.top;
    		} else if (staff.specialY.dynamicHeightAbove) {
    			staff.top += staff.specialY.dynamicHeightAbove; positionY.dynamicHeightAbove = staff.top;
    		} else if (staff.specialY.volumeHeightAbove) { staff.top += staff.specialY.volumeHeightAbove; positionY.volumeHeightAbove = staff.top; }
    		if (staff.specialY.partHeightAbove) { staff.top += staff.specialY.partHeightAbove; positionY.partHeightAbove = staff.top; }
    		if (staff.specialY.tempoHeightAbove) { staff.top += staff.specialY.tempoHeightAbove; positionY.tempoHeightAbove = staff.top; }

    		if (staff.specialY.lyricHeightBelow) { positionY.lyricHeightBelow = staff.bottom; staff.bottom -= staff.specialY.lyricHeightBelow; }
    		if (staff.specialY.chordHeightBelow) { positionY.chordHeightBelow = staff.bottom; staff.bottom -= staff.specialY.chordHeightBelow; }
    		if (staff.specialY.volumeHeightBelow && staff.specialY.dynamicHeightBelow) {
    			positionY.volumeHeightBelow = staff.bottom;
    			positionY.dynamicHeightBelow = staff.bottom;
    			staff.bottom -= Math.max(staff.specialY.volumeHeightBelow, staff.specialY.dynamicHeightBelow);
    		} else if (staff.specialY.volumeHeightBelow) {
    			positionY.volumeHeightBelow = staff.bottom; staff.bottom -= staff.specialY.volumeHeightBelow;
    		} else if (staff.specialY.dynamicHeightBelow) {
    			positionY.dynamicHeightBelow = staff.bottom; staff.bottom -= staff.specialY.dynamicHeightBelow;
    		}

    		for (var j = 0; j < staff.voices.length; j++) {
    			var voice = this.voices[staff.voices[j]];
    			voice.setUpperAndLowerElements(positionY);
    		}
    		// We might need a little space in between staves if the staves haven't been pushed far enough apart by notes or extra vertical stuff.
    		// Only try to put in extra space if this isn't the top staff.
    		if (lastStaffBottom !== undefined) {
    			var thisStaffTop = staff.top - 10;
    			var forcedSpacingBetween = lastStaffBottom + thisStaffTop;
    			var minSpacingInPitches = renderer.spacing.systemStaffSeparation/abc_spacing.STEP;
    			var addedSpace = minSpacingInPitches - forcedSpacingBetween;
    			if (addedSpace > 0)
    				staff.top += addedSpace;
    		}
    		lastStaffBottom = 2 - staff.bottom; // the staff starts at position 2 and the bottom variable is negative. Therefore to find out how large the bottom is, we reverse the sign of the bottom, and add the 2 in.

    		// Now we need a little margin on the top, so we'll just throw that in.
    		//staff.top += 4;
    		//console.log("Staff Y: ",i,heightInPitches,staff.top,staff.bottom);
    	}
    	//console.log("Staff Height: ",heightInPitches,this.height);
    };

    StaffGroupElement.prototype.finished = function() {
    	for (var i=0;i<this.voices.length;i++) {
    		if (!this.voices[i].layoutEnded()) return false;
    	}
    	return true;
    };

    function getLeftEdgeOfStaff(renderer, voices, brace) {
    	var x = renderer.padding.left;

    	// find out how much space will be taken up by voice headers
    	var voiceheaderw = 0;
    	for (var i=0;i<voices.length;i++) {
    		if(voices[i].header) {
    			var size = renderer.getTextSize(voices[i].header, 'voicefont', '');
    			voiceheaderw = Math.max(voiceheaderw,size.width);
    		}
    	}
    	if (voiceheaderw) {
    		// Give enough spacing to the right - we use the width of an A for the amount of spacing.
    		var sizeW = renderer.getTextSize("A", 'voicefont', '');
    		voiceheaderw += sizeW.width;
    	}
    	x += voiceheaderw;

    	if (brace) {
    		brace.setLocation(x);
    		x += brace.getWidth();
    	}
    	return x;
    }

    StaffGroupElement.prototype.layout = function(spacing, renderer, debug) {
    	var epsilon = 0.0000001; // Fudging for inexactness of floating point math.
    	var spacingunits = 0; // number of times we will have ended up using the spacing distance (as opposed to fixed width distances)
    	var minspace = 1000; // a big number to start off with - used to find out what the smallest space between two notes is -- GD 2014.1.7

    	var x = getLeftEdgeOfStaff(renderer, this.voices, this.brace);
    	this.startx=x;
    	var i;

    	var currentduration = 0;
    	if (debug) console.log("init layout", spacing);
    	for (i=0;i<this.voices.length;i++) {
    		this.voices[i].beginLayout(x);
    	}

    	var spacingunit = 0; // number of spacingunits coming from the previously laid out element to this one
    	while (!this.finished()) {
    		// find first duration level to be laid out among candidates across voices
    		currentduration= null; // candidate smallest duration level
    		for (i=0;i<this.voices.length;i++) {
    			if (!this.voices[i].layoutEnded() && (!currentduration || this.voices[i].getDurationIndex()<currentduration))
    				currentduration=this.voices[i].getDurationIndex();
    		}


    		// isolate voices at current duration level
    		var currentvoices = [];
    		var othervoices = [];
    		for (i=0;i<this.voices.length;i++) {
    			var durationIndex = this.voices[i].getDurationIndex();
    			// PER: Because of the inexactness of JS floating point math, we just get close.
    			if (durationIndex - currentduration > epsilon) {
    				othervoices.push(this.voices[i]);
    				//console.log("out: voice ",i);
    			} else {
    				currentvoices.push(this.voices[i]);
    				//if (debug) console.log("in: voice ",i);
    			}
    		}

    		// among the current duration level find the one which needs starting furthest right
    		spacingunit = 0; // number of spacingunits coming from the previously laid out element to this one
    		var spacingduration = 0;
    		for (i=0;i<currentvoices.length;i++) {
    			//console.log("greatest spacing unit", x, currentvoices[i].getNextX(), currentvoices[i].getSpacingUnits(), currentvoices[i].spacingduration);
    			if (currentvoices[i].getNextX()>x) {
    				x=currentvoices[i].getNextX();
    				spacingunit=currentvoices[i].getSpacingUnits();
    				spacingduration = currentvoices[i].spacingduration;
    			}
    		}
    		spacingunits+=spacingunit;
    		minspace = Math.min(minspace,spacingunit);
    		if (debug) console.log("currentduration: ",currentduration, spacingunits, minspace);

    		for (i=0;i<currentvoices.length;i++) {
    			var voicechildx = currentvoices[i].layoutOneItem(x,spacing);
    			var dx = voicechildx-x;
    			if (dx>0) {
    				x = voicechildx; //update x
    				for (var j=0;j<i;j++) { // shift over all previously laid out elements
    					currentvoices[j].shiftRight(dx);
    				}
    			}
    		}

    		// remove the value of already counted spacing units in other voices (e.g. if a voice had planned to use up 5 spacing units but is not in line to be laid out at this duration level - where we've used 2 spacing units - then we must use up 3 spacing units, not 5)
    		for (i=0;i<othervoices.length;i++) {
    			othervoices[i].spacingduration-=spacingduration;
    			othervoices[i].updateNextX(x,spacing); // adjust other voices expectations
    		}

    		// update indexes of currently laid out elems
    		for (i=0;i<currentvoices.length;i++) {
    			var voice = currentvoices[i];
    			voice.updateIndices();
    		}
    	} // finished laying out


    	// find the greatest remaining x as a base for the width
    	for (i=0;i<this.voices.length;i++) {
    		if (this.voices[i].getNextX()>x) {
    			x=this.voices[i].getNextX();
    			spacingunit=this.voices[i].getSpacingUnits();
    		}
    	}
    	//console.log("greatest remaining",spacingunit,x);
    	spacingunits+=spacingunit;
    	this.w = x;

    	for (i=0;i<this.voices.length;i++) {
    		this.voices[i].w=this.w;
    	}
    	return { spacingUnits: spacingunits, minSpace: minspace };
    };

    StaffGroupElement.prototype.calcHeight = function () {
    	// the height is calculated here in a parallel way to the drawing below in hopes that both of these functions will be modified together.
    	// TODO-PER: also add the space between staves. (That's systemStaffSeparation, which is the minimum distance between the staff LINES.)
    	var height = 0;
    	for (var i=0;i<this.voices.length;i++) {
    		var staff = this.voices[i].staff;
    		if (!this.voices[i].duplicate) {
    			height += staff.top;
    			if (staff.bottom < 0)
    				height += -staff.bottom;
    		}
    	}
    	return height;
    };

    StaffGroupElement.prototype.draw = function (renderer) {

    	// An invisible marker is useful to be able to find where each system starts.
    	renderer.addInvisibleMarker("abcjs-top-of-system");

    	var startY = renderer.y; // So that it can be restored after we're done.
    	// Set the absolute Y position for each staff here, so the voice drawing below can just use if.
    	for (var j = 0; j < this.staffs.length; j++) {
    		var staff1 = this.staffs[j];
    		//renderer.printHorizontalLine(50, renderer.y, "start");
    		renderer.moveY(abc_spacing.STEP, staff1.top);
    		staff1.absoluteY = renderer.y;
    		if (staff1.bottom < 0)
    			renderer.moveY(abc_spacing.STEP, -staff1.bottom);
    	}
    	var topLine; // these are to connect multiple staves. We need to remember where they are.
    	var bottomLine;

    	var bartop = 0;
    	renderer.measureNumber = null;
    	renderer.noteNumber = null;
    	for (var i=0;i<this.voices.length;i++) {
    		var staff = this.voices[i].staff;
    		renderer.y = staff.absoluteY;
    		renderer.voiceNumber = i;
    		//renderer.y = staff.y;
    		// offset for starting the counting at middle C
    		if (!this.voices[i].duplicate) {
    //			renderer.moveY(spacing.STEP, staff.top);
    			if (!topLine) topLine  = renderer.calcY(10);
    			bottomLine  = renderer.calcY(2);
    			if (staff.lines !== 0) {
    				renderer.measureNumber = null;
    				renderer.noteNumber = null;
    				renderer.printStave(this.startx, this.w, staff.lines);
    			}
    		}
    		this.voices[i].draw(renderer, bartop);
    		renderer.measureNumber = null;
    		renderer.noteNumber = null;
    		if (!this.voices[i].duplicate) {
    			bartop = renderer.calcY(2); // This connects the bar lines between two different staves.
    //			if (staff.bottom < 0)
    //				renderer.moveY(spacing.STEP, -staff.bottom);
    		}
    		if(this.brace) {//Tony
    			if (i === this.brace.length - 1) {
    				if (this.brace) {
    					this.brace.draw(renderer, topLine, bottomLine); //tony
    				}
    			}
    		}
    	}
    	renderer.measureNumber = null;
    	renderer.noteNumber = null;

    	// connect all the staves together with a vertical line
    	if (this.staffs.length>1) {
    		renderer.printStem(this.startx, 0.6, topLine, bottomLine);
    	}
    	renderer.y = startY;
    };

    var abc_staff_group_element = StaffGroupElement;

    //    abc_tempo_element.js: Definition of the TempoElement class.
    //    Copyright (C) 2014-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.




    var TempoElement;
    (function() {
    	var totalHeightInPitches = 5;

    	TempoElement = function TempoElement(tempo, tuneNumber, createNoteHead) {
    		this.tempo = tempo;
    		this.tuneNumber = tuneNumber;
    		this.tempoHeightAbove = totalHeightInPitches;
    		this.pitch = undefined; // This will be set later
    		if (this.tempo.duration && !this.tempo.suppressBpm) {
    			this.note = this.createNote(createNoteHead, tempo, tuneNumber);
    		}
    	};

    	TempoElement.prototype.setUpperAndLowerElements = function(positionY) { // TODO-PER: This might not be called.
    		this.pitch = positionY.tempoHeightAbove;
    		this.top = positionY.tempoHeightAbove;
    		this.bottom = positionY.tempoHeightAbove;
    		if (this.note) {
    			var tempoPitch = this.pitch - totalHeightInPitches + 1; // The pitch we receive is the top of the allotted area: change that to practically the bottom.
    			this.note.top = tempoPitch;
    			this.note.bottom = tempoPitch;
    			for (var i = 0; i < this.note.children.length; i++) {
    				var child = this.note.children[i];
    				child.top += tempoPitch;
    				child.bottom += tempoPitch;
    				child.pitch += tempoPitch;
    				if (child.pitch2 !== undefined)
    					child.pitch2 += tempoPitch;
    			}
    		}
    	};

    	TempoElement.prototype.setX = function (x) {
    		this.x = x;
    	};

    	TempoElement.prototype.createNote = function(createNoteHead, tempo, tuneNumber) {
    		var temposcale = 0.75;
    		var duration = tempo.duration[0]; // TODO when multiple durations
    		var absElem = new abc_absolute_element(tempo, duration, 1, 'tempo', tuneNumber);
    		// There aren't an infinite number of note values, but we are passed a float, so just in case something is off upstream,
    		// merge all of the in between points.
    		var dot;
    		var flag;
    		var note;
    		if (duration <= 1/32) { note = "noteheads.quarter"; flag = "flags.u32nd"; dot = 0; }
    		else if (duration <= 1/16) { note = "noteheads.quarter"; flag = "flags.u16th"; dot = 0; }
    		else if (duration <= 3/32) { note = "noteheads.quarter"; flag = "flags.u16nd"; dot = 1; }
    		else if (duration <= 1/8) { note = "noteheads.quarter"; flag = "flags.u8th"; dot = 0; }
    		else if (duration <= 3/16) { note = "noteheads.quarter"; flag = "flags.u8th"; dot = 1; }
    		else if (duration <= 1/4) { note = "noteheads.quarter"; dot = 0; }
    		else if (duration <= 3/8) { note = "noteheads.quarter"; dot = 1; }
    		else if (duration <= 1/2) { note = "noteheads.half"; dot = 0; }
    		else if (duration <= 3/4) { note = "noteheads.half"; dot = 1; }
    		else if (duration <= 1) { note = "noteheads.whole"; dot = 0; }
    		else if (duration <= 1.5) { note = "noteheads.whole"; dot = 1; }
    		else if (duration <= 2) { note = "noteheads.dbl"; dot = 0; }
    		else { note = "noteheads.dbl"; dot = 1; }

    		var ret = createNoteHead(absElem,
    			note,
    			{ verticalPos: 0}, // This is just temporary: we'll offset the vertical positioning when we get the actual vertical spot.
    			"up",
    			0,
    			0,
    			flag,
    			dot,
    			0,
    			temposcale,
    			[],
    			false
    		);
    		var tempoNote = ret.notehead;
    		absElem.addHead(tempoNote);
    		var stem;
    		if (note !== "noteheads.whole" && note !== "noteheads.dbl") {
    			var p1 = 1 / 3 * temposcale;
    			var p2 = 7 * temposcale;
    			var dx = tempoNote.dx + tempoNote.w;
    			var width = -0.6;
    			stem = new abc_relative_element(null, dx, 0, p1, {"type": "stem", "pitch2": p2, linewidth: width});
    			absElem.addExtra(stem);
    		}
    		return absElem;
    	};

    	TempoElement.prototype.draw = function(renderer) {
    		var x = this.x;
    		if (this.pitch === undefined)
    			window.console.error("Tempo Element y-coordinate not set.");

    		var y = renderer.calcY(this.pitch);
    		var text;
    		if (this.tempo.preString) {
    			text = renderer.renderText(x, y, this.tempo.preString, 'tempofont', 'tempo', "start");
    			var size = renderer.getTextSize(this.tempo.preString, 'tempofont', 'tempo', text);
    			var preWidth = size.width;
    			var charWidth = preWidth / this.tempo.preString.length; // Just get some average number to increase the spacing.
    			x += preWidth + charWidth;
    		}
    		if (this.note) {
    			if (this.note)
    				this.note.setX(x);
    			for (var i = 0; i < this.note.children.length; i++)
    				this.note.children[i].draw(renderer, x);
    			x += (this.note.w + 5);
    			var str = "= " + this.tempo.bpm;
    			text = renderer.renderText(x, y, str, 'tempofont', 'tempo', "start");
    			size = renderer.getTextSize(str, 'tempofont', 'tempo', text);
    			var postWidth = size.width;
    			var charWidth2 = postWidth / str.length; // Just get some average number to increase the spacing.
    			x += postWidth + charWidth2;
    		}
    		if (this.tempo.postString) {
    			renderer.renderText(x, y, this.tempo.postString, 'tempofont', 'tempo', "start");
    		}
    	};
    })();

    var abc_tempo_element = TempoElement;

    //    abc_triplet_element.js: Definition of the TripletElem class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



    var TripletElem;

    (function() {

    	TripletElem = function TripletElem(number, anchor1, options) {
    		this.anchor1 = anchor1; // must have a .x and a .parent property or be null (means starts at the "beginning" of the line - after key signature)
    		this.number = number;
    		this.duration = (''+anchor1.parent.durationClass).replace(/\./, '-');
    		this.middleElems = []; // This is to calculate the highest interior pitch. It is used to make sure that the drawn bracket never crosses a really high middle note.
    		this.flatBeams = options.flatBeams;
    	};

    	TripletElem.prototype.isClosed = function() {
    		return this.anchor2;
    	};

    	TripletElem.prototype.middleNote = function(elem) {
    		this.middleElems.push(elem);
    	};

    	TripletElem.prototype.setCloseAnchor = function(anchor2) {
    		this.anchor2 = anchor2;
    		// TODO-PER: Unfortunately, I don't know if there is a beam above until after the vertical positioning is done,
    		// so I don't know whether to leave room for the number above. Therefore, If there is a beam on the first note, I'll leave room just in case.
    		if (this.anchor1.parent.beam)
    			this.endingHeightAbove = 4;
    	};

    	TripletElem.prototype.setUpperAndLowerElements = function(/*positionY*/) {
    	};

    	TripletElem.prototype.layout = function() {
    		// TODO end and beginning of line (PER: P.S. I'm not sure this can happen: I think the parser will always specify both the start and end points.)
    		if (this.anchor1 && this.anchor2) {
    			this.hasBeam = this.anchor1.parent.beam && this.anchor1.parent.beam === this.anchor2.parent.beam;

    			if (this.hasBeam) {
    				// If there is a beam then we don't need to draw anything except the text. The beam could either be above or below.
    				var beam = this.anchor1.parent.beam;
    				var left = beam.isAbove() ? this.anchor1.x + this.anchor1.w : this.anchor1.x;
    				this.yTextPos = beam.heightAtMidpoint(left,  this.anchor2.x);
    				this.yTextPos += beam.isAbove() ? 3 : -2; // This creates some space between the beam and the number.
    				this.top = this.yTextPos + 1;
    				this.bottom = this.yTextPos - 2;
    				if (beam.isAbove())
    					this.endingHeightAbove = 4;
    			} else {
    				// If there isn't a beam, then we need to draw the bracket and the text. The bracket is always above.
    				// The bracket is never lower than the 'a' line, but is 4 pitches above the first and last notes. If there is
    				// a tall note in the middle, the bracket is horizontal and above the highest note.
    				this.startNote = Math.max(this.anchor1.parent.top, 9) + 4;
    				this.endNote = Math.max(this.anchor2.parent.top, 9) + 4;
    				// If it starts or ends on a rest, make the beam horizontal
    				if (this.anchor1.parent.type === "rest" && this.anchor2.parent.type !== "rest")
    					this.startNote = this.endNote;
    				else if (this.anchor2.parent.type === "rest" && this.anchor1.parent.type !== "rest")
    					this.endNote = this.startNote;
    				// See if the middle note is really high.
    				var max = 0;
    				for (var i = 0; i < this.middleElems.length; i++) {
    					max = Math.max(max, this.middleElems[i].top);
    				}
    				max += 4;
    				if (max > this.startNote || max > this.endNote) {
    					this.startNote = max;
    					this.endNote = max;
    				}
    				if (this.flatBeams) {
    					this.startNote = Math.max(this.startNote, this.endNote);
    					this.endNote = Math.max(this.startNote, this.endNote);
    				}

    				this.yTextPos = this.startNote + (this.endNote - this.startNote) / 2;
    				this.top = this.yTextPos + 1;
    			}
    		}
    		delete this.middleElems;
    		delete this.flatBeams;
    	};

    	TripletElem.prototype.draw = function(renderer) {
    		var xTextPos;
    		if (this.hasBeam) {
    			var left = this.anchor1.parent.beam.isAbove() ? this.anchor1.x + this.anchor1.w : this.anchor1.x;
    			xTextPos = this.anchor1.parent.beam.xAtMidpoint(left, this.anchor2.x);
    		} else {
    			xTextPos = this.anchor1.x + (this.anchor2.x + this.anchor2.w - this.anchor1.x) / 2;
    			drawBracket(renderer, this.anchor1.x, this.startNote, this.anchor2.x + this.anchor2.w, this.endNote, this.duration);
    		}
    		renderer.renderText(xTextPos, renderer.calcY(this.yTextPos), "" + this.number, 'tripletfont', renderer.addClasses('triplet d'+this.duration), "middle", true);
    	};

    	function drawLine(renderer, l, t, r, b, duration) {
    		var pathString = sprintf_1("M %f %f L %f %f",
    			l, t, r, b);
    		renderer.printPath({path: pathString, stroke: "#000000", 'class': renderer.addClasses('triplet d'+duration)});
    	}

    	function drawBracket(renderer, x1, y1, x2, y2, duration) {
    		y1 = renderer.calcY(y1);
    		y2 = renderer.calcY(y2);
    		var bracketHeight = 5;

    		// Draw vertical lines at the beginning and end
    		drawLine(renderer, x1, y1, x1, y1 + bracketHeight, duration);
    		drawLine(renderer, x2, y2, x2, y2 + bracketHeight, duration);

    		// figure out midpoints to draw the broken line.
    		var midX = x1 + (x2-x1)/2;
    		//var midY = y1 + (y2-y1)/2;
    		var gapWidth = 8;
    		var slope = (y2 - y1) / (x2 - x1);
    		var leftEndX = midX - gapWidth;
    		var leftEndY = y1 + (leftEndX - x1) * slope;
    		drawLine(renderer, x1, y1, leftEndX, leftEndY, duration);
    		var rightStartX = midX + gapWidth;
    		var rightStartY = y1 + (rightStartX - x1) * slope;
    		drawLine(renderer, rightStartX, rightStartY, x2, y2, duration);
    	}
    })();

    var abc_triplet_element = TripletElem;

    //    abc_voice_element.js: Definition of the VoiceElement class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.



    var VoiceElement = function VoiceElement(voicenumber, voicetotal) {
    	this.children = [];
    	this.beams = [];
    	this.otherchildren = []; // ties, slurs, triplets
    	this.w = 0;
    	this.duplicate = false;
    	this.voicenumber = voicenumber; //number of the voice on a given stave (not staffgroup)
    	this.voicetotal = voicetotal;
    	this.bottom = 7;
    	this.top = 7;
    	this.specialY = {
    		tempoHeightAbove: 0,
    		partHeightAbove: 0,
    		volumeHeightAbove: 0,
    		dynamicHeightAbove: 0,
    		endingHeightAbove: 0,
    		chordHeightAbove: 0,
    		lyricHeightAbove: 0,

    		lyricHeightBelow: 0,
    		chordHeightBelow: 0,
    		volumeHeightBelow: 0,
    		dynamicHeightBelow: 0
    	};
    };

    VoiceElement.prototype.addChild = function (child) {
    	if (child.type === 'bar') {
    		var firstItem = true;
    		for (var i = 0; firstItem && i < this.children.length; i++) {
    			if (this.children[i].type !== "staff-extra" && this.children[i].type !== "tempo")
    				firstItem = false;
    		}
    		if (!firstItem) {
    			this.beams.push("bar");
    			this.otherchildren.push("bar");
    		}
    	}
    	this.children[this.children.length] = child;
    	this.setRange(child);
    };

    VoiceElement.prototype.setLimit = function(member, child) {
    	// Sometimes we get an absolute element in here and sometimes we get some type of relative element.
    	// If there is a "specialY" element, then assume it is an absolute element. If that doesn't exist, look for the
    	// same members at the top level, because that's where they are in relative elements.
    	var specialY = child.specialY;
    	if (!specialY) specialY = child;
    	if (!specialY[member]) return;
    	if (!this.specialY[member])
    		this.specialY[member] = specialY[member];
    	else
    		this.specialY[member] = Math.max(this.specialY[member], specialY[member]);
    };

    VoiceElement.prototype.moveDecorations = function(beam) {
    	var padding = 1.5; // This is the vertical padding between elements, in pitches.
    	for (var ch = 0; ch < beam.elems.length; ch++) {
    		var child = beam.elems[ch];
    		if (child.top) {
    			// We now know where the ornaments should have been placed, so move them if they would overlap.
    			var top = beam.yAtNote(child);
    			for (var i = 0; i < child.children.length; i++) {
    				var el = child.children[i];
    				if (el.klass === 'ornament') {
    					if (el.bottom - padding < top) {
    						var distance = top - el.bottom + padding; // Find the distance that it needs to move and add a little margin so the element doesn't touch the beam.
    						el.bottom += distance;
    						el.top += distance;
    						el.pitch += distance;
    						top = child.top = el.top;
    					}
    				}
    			}
    		}
    	}
    };

    VoiceElement.prototype.adjustRange = function(child) {
    	if (child.bottom !== undefined)
    		this.bottom = Math.min(this.bottom, child.bottom);
    	if (child.top !== undefined)
    		this.top = Math.max(this.top, child.top);
    };

    VoiceElement.prototype.setRange = function(child) {
    	this.adjustRange(child);
    	this.setLimit('tempoHeightAbove', child);
    	this.setLimit('partHeightAbove', child);
    	this.setLimit('volumeHeightAbove', child);
    	this.setLimit('dynamicHeightAbove', child);
    	this.setLimit('endingHeightAbove', child);
    	this.setLimit('chordHeightAbove', child);
    	this.setLimit('lyricHeightAbove', child);
    	this.setLimit('lyricHeightBelow', child);
    	this.setLimit('chordHeightBelow', child);
    	this.setLimit('volumeHeightBelow', child);
    	this.setLimit('dynamicHeightBelow', child);
    };

    VoiceElement.prototype.setUpperAndLowerElements = function(positionY) {
    	var i;
    	for (i = 0; i < this.children.length; i++) {
    		var abselem = this.children[i];
    		abselem.setUpperAndLowerElements(positionY);
    	}
    	for (i = 0; i < this.otherchildren.length; i++) {
    		var abselem = this.otherchildren[i];
    		if (typeof abselem !== 'string')
    			abselem.setUpperAndLowerElements(positionY);
    	}
    };

    VoiceElement.prototype.addOther = function (child) {
    	this.otherchildren.push(child);
    	this.setRange(child);
    };

    VoiceElement.prototype.addBeam = function (child) {
    	this.beams.push(child);
    };

    VoiceElement.prototype.updateIndices = function () {
    	if (!this.layoutEnded()) {
    		this.durationindex += this.children[this.i].duration;
    		if (this.children[this.i].type === 'bar') this.durationindex = Math.round(this.durationindex*64)/64; // everytime we meet a barline, do rounding to nearest 64th
    		this.i++;
    	}
    };

    VoiceElement.prototype.layoutEnded = function () {
    	return (this.i>=this.children.length);
    };

    VoiceElement.prototype.getDurationIndex = function () {
    	return this.durationindex - (this.children[this.i] && (this.children[this.i].duration>0)?0:0.0000005); // if the ith element doesn't have a duration (is not a note), its duration index is fractionally before. This enables CLEF KEYSIG TIMESIG PART, etc. to be laid out before we get to the first note of other voices
    };

    // number of spacing units expected for next positioning
    VoiceElement.prototype.getSpacingUnits = function () {
    	return Math.sqrt(this.spacingduration*8);
    	// TODO-PER: On short lines, this would never trigger, so the spacing was wrong. I just changed this line empirically, though, so I don't know if there are other ramifications.
    	//return (this.minx<this.nextx) ? Math.sqrt(this.spacingduration*8) : 0; // we haven't used any spacing units if we end up using minx
    };

    //
    VoiceElement.prototype.getNextX = function () {
    	return Math.max(this.minx, this.nextx);
    };

    VoiceElement.prototype.beginLayout = function (startx) {
    	this.i=0;
    	this.durationindex=0;
    	//this.ii=this.children.length;
    	this.startx=startx;
    	this.minx=startx; // furthest left to where negatively positioned elements are allowed to go
    	this.nextx=startx; // x position where the next element of this voice should be placed assuming no other voices and no fixed width constraints
    	this.spacingduration=0; // duration left to be laid out in current iteration (omitting additional spacing due to other aspects, such as bars, dots, sharps and flats)
    };

    // Try to layout the element at index this.i
    // x - position to try to layout the element at
    // spacing - base spacing
    // can't call this function more than once per iteration
    VoiceElement.prototype.layoutOneItem = function (x, spacing) {
    	var child = this.children[this.i];
    	if (!child) return 0;
    	var er = x - this.minx; // available extrawidth to the left
    	var extraWidth = child.getExtraWidth();
    	if (er<extraWidth) { // shift right by needed amount
    		// There's an exception if a bar element is after a Part element, there is no shift.
    		if (this.i === 0 || child.type !== 'bar' || (this.children[this.i-1].type !== 'part' && this.children[this.i-1].type !== 'tempo') )
    			x+=extraWidth-er;
    	}
    	child.setX(x);

    	this.spacingduration = child.duration;
    	//update minx
    	this.minx = x+child.getMinWidth(); // add necessary layout space
    	if (this.i!==this.children.length-1) this.minx+=child.minspacing; // add minimumspacing except on last elem

    	this.updateNextX(x, spacing);

    	// contribute to staff y position
    	//this.staff.top = Math.max(child.top,this.staff.top);
    	//this.staff.bottom = Math.min(child.bottom,this.staff.bottom);

    	return x; // where we end up having placed the child
    };

    // call when spacingduration has been updated
    VoiceElement.prototype.updateNextX = function (x, spacing) {
    	this.nextx= x + (spacing*Math.sqrt(this.spacingduration*8));
    };

    VoiceElement.prototype.shiftRight = function (dx) {
    	var child = this.children[this.i];
    	if (!child) return;
    	child.setX(child.x+dx);
    	this.minx+=dx;
    	this.nextx+=dx;
    };

    function isNonSpacerRest(elem) {
    	if (elem.type !== 'rest')
    		return false;
    	if (elem.abcelem && elem.abcelem.rest && elem.abcelem.rest.type !== 'spacer')
    		return true;
    	return false;
    }
    VoiceElement.prototype.draw = function (renderer, bartop) {
    	var width = this.w-1;
    	renderer.staffbottom = this.staff.bottom;
    	//this.barbottom = renderer.calcY(2);

    	renderer.measureNumber = null;
    	renderer.noteNumber = null;
    	if (this.header) { // print voice name
    		var textpitch = 14 - (this.voicenumber+1)*(12/(this.voicetotal+1));
    		renderer.renderText(renderer.padding.left, renderer.calcY(textpitch), this.header, 'voicefont', 'staff-extra voice-name', 'start');
    	}

    	for (var i=0, ii=this.children.length; i<ii; i++) {
    		var child = this.children[i];
    		var justInitializedMeasureNumber = false;
    		if (child.type !== 'staff-extra' && renderer.measureNumber === null) {
    			renderer.measureNumber = 0;
    			renderer.noteNumber = 0;
    			justInitializedMeasureNumber = true;
    		}
    		child.draw(renderer, (this.barto || i===ii-1)?bartop:0);
    		if (child.type === 'note' || isNonSpacerRest(child))
    			renderer.noteNumber++;
    		if (child.type === 'bar' && !justInitializedMeasureNumber) {
    			renderer.measureNumber++;
    			renderer.noteNumber = 0;
    		}
    	}

    	renderer.measureNumber = 0;
    	renderer.noteNumber = 0;
    	abc_common.each(this.beams, function(beam) {
    		if (beam === 'bar') {
    			renderer.measureNumber++;
    			renderer.noteNumber = 0;
    		} else
    			beam.draw(renderer); // beams must be drawn first for proper printing of triplets, slurs and ties.
    	});

    	renderer.measureNumber = 0;
    	renderer.noteNumber = 0;
    	var self = this;
    	abc_common.each(this.otherchildren, function(child) {
    		if (child === 'bar') {
    			renderer.measureNumber++;
    			renderer.noteNumber = 0;
    		} else
    			child.draw(renderer,self.startx+10,width);
    	});

    };

    VoiceElement.prototype.layoutBeams = function() {
    	for (var i = 0; i < this.beams.length; i++) {
    		if (this.beams[i].layout) {
    			this.beams[i].layout();
    			this.moveDecorations(this.beams[i]);
    			// The above will change the top and bottom of the abselem children, so see if we need to expand our range.
    			for (var j = 0; j < this.beams[i].elems.length; j++) {
    				this.adjustRange(this.beams[i].elems[j]);
    			}
    		}
    	}
    	// Now we can layout the triplets
    	for (i = 0; i < this.otherchildren.length; i++) {
    		var child = this.otherchildren[i];
    		if (child.layout) {
    			child.layout();
    			this.adjustRange(child);
    		}
    	}
    	this.staff.top = Math.max(this.staff.top, this.top);
    	this.staff.bottom = Math.min(this.staff.bottom, this.bottom);
    };

    var abc_voice_element = VoiceElement;

    // abc_abstract_engraver.js: Creates a data structure suitable for printing a line of abc
    // Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.




















    var AbstractEngraver;

    (function() {

    var getDuration = function(elem) {
      var d = 0;
      if (elem.duration) {
        d = elem.duration;
      }
      return d;
    };

    var hint = false;

    	var chartable = {
    		rest:{0:"rests.whole", 1:"rests.half", 2:"rests.quarter", 3:"rests.8th", 4: "rests.16th",5: "rests.32nd", 6: "rests.64th", 7: "rests.128th", "multi": "rests.multimeasure"},
    		note:{"-1": "noteheads.dbl", 0:"noteheads.whole", 1:"noteheads.half", 2:"noteheads.quarter", 3:"noteheads.quarter", 4:"noteheads.quarter", 5:"noteheads.quarter", 6:"noteheads.quarter", 7:"noteheads.quarter", 'nostem':"noteheads.quarter"},
    		rhythm:{"-1": "noteheads.slash.whole", 0:"noteheads.slash.whole", 1:"noteheads.slash.whole", 2:"noteheads.slash.quarter", 3:"noteheads.slash.quarter", 4:"noteheads.slash.quarter", 5:"noteheads.slash.quarter", 6:"noteheads.slash.quarter", 7:"noteheads.slash.quarter", nostem: "noteheads.slash.nostem"},
    		x:{"-1": "noteheads.indeterminate", 0:"noteheads.indeterminate", 1:"noteheads.indeterminate", 2:"noteheads.indeterminate", 3:"noteheads.indeterminate", 4:"noteheads.indeterminate", 5:"noteheads.indeterminate", 6:"noteheads.indeterminate", 7:"noteheads.indeterminate", nostem: "noteheads.indeterminate"},
    		harmonic:{"-1": "noteheads.harmonic.quarter", 0:"noteheads.harmonic.quarter", 1:"noteheads.harmonic.quarter", 2:"noteheads.harmonic.quarter", 3:"noteheads.harmonic.quarter", 4:"noteheads.harmonic.quarter", 5:"noteheads.harmonic.quarter", 6:"noteheads.harmonic.quarter", 7:"noteheads.harmonic.quarter", nostem: "noteheads.harmonic.quarter"},
    		uflags:{3:"flags.u8th", 4:"flags.u16th", 5:"flags.u32nd", 6:"flags.u64th"},
    		dflags:{3:"flags.d8th", 4:"flags.d16th", 5:"flags.d32nd", 6:"flags.d64th"}
    	};

    AbstractEngraver = function(renderer, tuneNumber, options) {
    	this.decoration = new abc_decoration();
    	this.renderer = renderer;
    	this.tuneNumber = tuneNumber;
    	this.isBagpipes = options.bagpipes;
    	this.flatBeams = options.flatbeams;
    	this.reset();
    };

    AbstractEngraver.prototype.reset = function() {
    	this.slurs = {};
    	this.ties = [];
    	this.voiceScale = 1;
    	this.slursbyvoice = {};
    	this.tiesbyvoice = {};
    	this.endingsbyvoice = {};
    	this.scaleByVoice = {};
    	this.tripletmultiplier = 1;

    	this.abcline = undefined;
    	this.accidentalSlot = undefined;
    	this.accidentalshiftx = undefined;
    	this.dotshiftx = undefined;
    	this.hasVocals = false;
    	this.minY = undefined;
    	this.partstartelem = undefined;
    	this.startlimitelem = undefined;
    	this.stemdir = undefined;
    };

    AbstractEngraver.prototype.setStemHeight = function(heightInPixels) {
    	this.stemHeight = heightInPixels / abc_spacing.STEP;
    };

    AbstractEngraver.prototype.getCurrentVoiceId = function(s,v) {
      return "s"+s+"v"+v;
    };

    AbstractEngraver.prototype.pushCrossLineElems = function(s,v) {
      this.slursbyvoice[this.getCurrentVoiceId(s,v)] = this.slurs;
      this.tiesbyvoice[this.getCurrentVoiceId(s,v)] = this.ties;
      this.endingsbyvoice[this.getCurrentVoiceId(s,v)] = this.partstartelem;
      this.scaleByVoice[this.getCurrentVoiceId(s,v)] = this.voiceScale;
    };

    AbstractEngraver.prototype.popCrossLineElems = function(s,v) {
      this.slurs = this.slursbyvoice[this.getCurrentVoiceId(s,v)] || {};
      this.ties = this.tiesbyvoice[this.getCurrentVoiceId(s,v)] || [];
      this.partstartelem = this.endingsbyvoice[this.getCurrentVoiceId(s,v)];
      this.voiceScale = this.scaleByVoice[this.getCurrentVoiceId(s,v)];
      if (this.voiceScale === undefined) this.voiceScale = 1;
    };

    	AbstractEngraver.prototype.containsLyrics = function(staves) {
    		for (var i = 0; i < staves.length; i++) {
    			for (var j = 0; j < staves[i].voices.length; j++) {
    				for (var k = 0; k < staves[i].voices[j].length; k++) {
    					var el = staves[i].voices[j][k];
    					if (el.lyric) {
    						// We just want to see if there are vocals below the music to know where to put the dynamics.
    						if (!el.positioning || el.positioning.vocalPosition === 'below')
    							this.hasVocals = true;
    						return;
    					}
    				}
    			}
    		}
    	};

    AbstractEngraver.prototype.createABCLine = function(staffs, tempo) {
        this.minY = 2; // PER: This will be the lowest that any note reaches. It will be used to set the dynamics row.
    	// See if there are any lyrics on this line.
    	this.containsLyrics(staffs);
      var staffgroup = new abc_staff_group_element();
    	this.tempoSet = false;
      for (var s = 0; s < staffs.length; s++) {
    	  if (hint)
    		  this.restoreState();
    	  hint = false;
        this.createABCStaff(staffgroup, staffs[s], tempo, s);
      }
      return staffgroup;
    };

    AbstractEngraver.prototype.createABCStaff = function(staffgroup, abcstaff, tempo, s) {
    // If the tempo is passed in, then the first element should get the tempo attached to it.
      for (var v = 0; v < abcstaff.voices.length; v++) {
        var voice = new abc_voice_element(v,abcstaff.voices.length);
        if (v===0) {
    	    voice.barfrom = (abcstaff.connectBarLines==="start" || abcstaff.connectBarLines==="continue");
    	    voice.barto = (abcstaff.connectBarLines==="continue" || abcstaff.connectBarLines==="end");
        } else {
    	    voice.duplicate = true; // bar lines and other duplicate info need not be created
        }
        if (abcstaff.title && abcstaff.title[v]) voice.header=abcstaff.title[v];
    	  var clef = abc_create_clef(abcstaff.clef, this.tuneNumber);
    	  if (clef) {
    		  if (v ===0 && abcstaff.barNumber) {
    			  this.addMeasureNumber(abcstaff.barNumber, clef);
    		  }
    		  voice.addChild(clef);
    	  }
    	  var keySig = abc_create_key_signature(abcstaff.key, this.tuneNumber);
    	  if (keySig) {
    		  voice.addChild(keySig);
    		  this.startlimitelem = keySig; // limit ties here
    	  }
        if (abcstaff.meter) {
        	if (abcstaff.meter.type === 'specified') {
        		this.measureLength = abcstaff.meter.value[0].num / abcstaff.meter.value[0].den;
    	    } else
    	    	this.measureLength = 1;
    		var ts = abc_create_time_signature(abcstaff.meter, this.tuneNumber);
    	    voice.addChild(ts);
    		this.startlimitelem = ts; // limit ties here
    	}
    	  if (voice.duplicate)
    		  voice.children = []; // we shouldn't reprint the above if we're reusing the same staff. We just created them to get the right spacing.
        var staffLines = abcstaff.clef.stafflines || abcstaff.clef.stafflines === 0 ? abcstaff.clef.stafflines : 5;
        staffgroup.addVoice(voice,s,staffLines);
    	  var isSingleLineStaff = staffLines === 1;
    	  this.createABCVoice(abcstaff.voices[v],tempo, s, v, isSingleLineStaff, voice);
    	  staffgroup.setStaffLimits(voice);
                //Tony: Here I am following what staves need to be surrounded by the brace, by incrementing the length of the brace class.
                //So basically this keeps incrementing the number of staff surrounded by the brace until it sees "end".
                //This then gets processed in abc_staff_group_element.js, so that it will have the correct top and bottom coordinates for the brace.
    			if(abcstaff.brace === "start"){
    				staffgroup.brace = new abc_brace_element(1, true);
    			}
    			else if(abcstaff.brace === "end" && staffgroup.brace) {
    				staffgroup.brace.increaseStavesIncluded();
    			}
    			else if(abcstaff.brace === "continue" && staffgroup.brace){
    				staffgroup.brace.increaseStavesIncluded();
    			}
      }
    };

    function getBeamGroup(abcline, pos) {
    	// If there are notes beamed together, they are handled as a group, so find all of them here.
    	var elem = abcline[pos];
    	if (elem.el_type !== 'note' || !elem.startBeam || elem.endBeam)
    		return { count: 1, elem: elem };

    	var group = [];
    	while (pos < abcline.length && abcline[pos].el_type === 'note') {
    		group.push(abcline[pos]);
    		if (abcline[pos].endBeam)
    			break;
    		pos++;
    	}
    	return { count: group.length, elem: group };
    }

    AbstractEngraver.prototype.createABCVoice = function(abcline, tempo, s, v, isSingleLineStaff, voice) {
      this.popCrossLineElems(s,v);
      this.stemdir = (this.isBagpipes)?"down":null;
      this.abcline = abcline;
      if (this.partstartelem) {
        this.partstartelem = new abc_ending_element("", null, null);
    	  voice.addOther(this.partstartelem);
      }
    	var voiceNumber = voice.voicetotal < 2 ? -1 : voice.voicenumber;
      for (var slur in this.slurs) {
        if (this.slurs.hasOwnProperty(slur)) {
    	    // this is already a slur element, but it was created for the last line, so recreate it.
          this.slurs[slur]= new abc_tie_element({force: this.slurs[slur].force, voiceNumber: voiceNumber, stemDir: this.slurs[slur].stemDir});
    		if (hint) this.slurs[slur].setHint();
    	    voice.addOther(this.slurs[slur]);
        }
      }
      for (var i=0; i<this.ties.length; i++) {
      	// this is already a tie element, but it was created for the last line, so recreate it.
        this.ties[i]=new abc_tie_element({ force: this.ties[i].force, stemDir: this.ties[i].stemDir, voiceNumber: voiceNumber });
    	  if (hint) this.ties[i].setHint();
    	  voice.addOther(this.ties[i]);
      }

      for (var j = 0; j < this.abcline.length; j++) {
    	  setAveragePitch(this.abcline[j]);
    	  this.minY = Math.min(this.abcline[j].minpitch, this.minY);
      }

    	var isFirstStaff = (s === 0);
    	var pos = 0;
    	while (pos < this.abcline.length) {
    		var ret = getBeamGroup(this.abcline, pos);
    		var abselems = this.createABCElement(isFirstStaff, isSingleLineStaff, voice, ret.elem);
    		if (abselems) {
    			for (i = 0; i < abselems.length; i++) {
    				if (!this.tempoSet && tempo && !tempo.suppress) {
    					this.tempoSet = true;
    					var tempoElement = new abc_absolute_element(ret.elem, 0, 0, "tempo", this.tuneNumber, {});
    					tempoElement.addChild(new abc_tempo_element(tempo, this.tuneNumber, createNoteHead));
    					voice.addChild(tempoElement);
    				}
    				voice.addChild(abselems[i]);
    			}
    		}
    		pos += ret.count;
    	}
    	this.pushCrossLineElems(s, v);
    };

    	AbstractEngraver.prototype.saveState = function() {
    		this.tiesSave = abc_common.cloneArray(this.ties);
    		this.slursSave = abc_common.cloneHashOfHash(this.slurs);
    		this.slursbyvoiceSave = abc_common.cloneHashOfHash(this.slursbyvoice);
    		this.tiesbyvoiceSave = abc_common.cloneHashOfArrayOfHash(this.tiesbyvoice);
    	};

    	AbstractEngraver.prototype.restoreState = function() {
    		this.ties = abc_common.cloneArray(this.tiesSave);
    		this.slurs = abc_common.cloneHashOfHash(this.slursSave);
    		this.slursbyvoice = abc_common.cloneHashOfHash(this.slursbyvoiceSave);
    		this.tiesbyvoice = abc_common.cloneHashOfArrayOfHash(this.tiesbyvoiceSave);
    	};

    	// function writeMeasureWidth(voice) {
    	// 	var width = 0;
    	// 	for (var i = voice.children.length-1; i >= 0; i--) {
    	// 		var elem = voice.children[i];
    	// 		if (elem.abcelem.el_type === 'bar')
    	// 			break;
    	// 		width += elem.w;
    	// 	}
    	// 	return new RelativeElement(width.toFixed(2), -70, 0, undefined, {type:"debug"});
    	// }

    	// return an array of AbsoluteElement
    AbstractEngraver.prototype.createABCElement = function(isFirstStaff, isSingleLineStaff, voice, elem) {
      var elemset = [];
      switch (elem.el_type) {
    	  case undefined:
    	  	// it is undefined if we were passed an array in - an array means a set of notes that should be beamed together.
    		  elemset = this.createBeam(isSingleLineStaff, voice, elem);
    	  	break;
      case "note":
    	  elemset[0] = this.createNote(elem, false, isSingleLineStaff, voice);
    	  if (this.triplet && this.triplet.isClosed()) {
    		  voice.addOther(this.triplet);
    		  this.triplet = null;
    		  this.tripletmultiplier = 1;
    	  }
        break;
      case "bar":
        elemset[0] = this.createBarLine(voice, elem, isFirstStaff);
        if (voice.duplicate && elemset.length > 0) elemset[0].invisible = true;
    //	  elemset[0].addChild(writeMeasureWidth(voice));
        break;
      case "meter":
        elemset[0] = abc_create_time_signature(elem, this.tuneNumber);
    	  this.startlimitelem = elemset[0]; // limit ties here
        if (voice.duplicate && elemset.length > 0) elemset[0].invisible = true;
        break;
      case "clef":
        elemset[0] = abc_create_clef(elem, this.tuneNumber);
    	  if (!elemset[0]) return null;
        if (voice.duplicate && elemset.length > 0) elemset[0].invisible = true;
        break;
      case "key":
    	  var absKey = abc_create_key_signature(elem, this.tuneNumber);
    	  if (absKey) {
    		  elemset[0] = absKey;
    		  this.startlimitelem = elemset[0]; // limit ties here
    	  }
        if (voice.duplicate && elemset.length > 0) elemset[0].invisible = true;
        break;
      case "stem":
        this.stemdir=elem.direction;
        break;
      case "part":
        var abselem = new abc_absolute_element(elem,0,0, 'part', this.tuneNumber);
    	  var dim = this.renderer.getTextSize(elem.title, 'partsfont', "part");
        abselem.addChild(new abc_relative_element(elem.title, 0, 0, undefined, {type:"part", height: dim.height/abc_spacing.STEP}));
        elemset[0] = abselem;
        break;
      case "tempo":
        var abselem3 = new abc_absolute_element(elem,0,0, 'tempo', this.tuneNumber);
        abselem3.addChild(new abc_tempo_element(elem, this.tuneNumber, createNoteHead));
        elemset[0] = abselem3;
        break;
    	  case "style":
    		  if (elem.head === "normal")
    			  delete this.style;
    		  else
    			  this.style = elem.head;
    		  break;
    	  case "hint":
    		  hint = true;
    		  this.saveState();
    		  break;
    	  case "midi":
    		// This has no effect on the visible music, so just skip it.
    		break;
    	  case "scale":
    	  	this.voiceScale = elem.size;
    	  	break;

      default:
        var abselem2 = new abc_absolute_element(elem,0,0, 'unsupported', this.tuneNumber);
        abselem2.addChild(new abc_relative_element("element type "+elem.el_type, 0, 0, undefined, {type:"debug"}));
        elemset[0] = abselem2;
      }

      return elemset;
    };

    	function setAveragePitch(elem) {
    		if (elem.pitches) {
    			sortPitch(elem);
    			var sum = 0;
    			for (var p = 0; p < elem.pitches.length; p++) {
    				sum += elem.pitches[p].verticalPos;
    			}
    			elem.averagepitch = sum / elem.pitches.length;
    			elem.minpitch = elem.pitches[0].verticalPos;
    			elem.maxpitch = elem.pitches[elem.pitches.length - 1].verticalPos;
    		}
    	}

    	AbstractEngraver.prototype.calcBeamDir = function (isSingleLineStaff, voice, elems) {
    		if (this.stemdir) // If the user or voice is forcing the stem direction, we already know the answer.
    			return this.stemdir;
    		var beamelem = new abc_beam_element(this.stemHeight * this.voiceScale, this.stemdir, this.flatBeams);
    		for (var i = 0; i < elems.length; i++) {
    			beamelem.add({abcelem: elems[i]}); // This is a hack to call beam elem with just a minimum of processing: for our purposes, we don't need to construct the whole note.
    		}

    		var dir = beamelem.calcDir();
    		return dir ? "up" : "down";
    	};

    	AbstractEngraver.prototype.createBeam = function (isSingleLineStaff, voice, elems) {
    		var abselemset = [];

    		var dir = this.calcBeamDir(isSingleLineStaff, voice, elems);
    		var beamelem = new abc_beam_element(this.stemHeight * this.voiceScale, dir, this.flatBeams);
    		if (hint) beamelem.setHint();
    		var oldDir = this.stemdir;
    		this.stemdir = dir;
    		for (var i = 0; i < elems.length; i++) {
    			var elem = elems[i];
    			var abselem = this.createNote(elem, true, isSingleLineStaff, voice);
    			abselemset.push(abselem);
    			beamelem.add(abselem);
    			if (this.triplet && this.triplet.isClosed()) {
    				voice.addOther(this.triplet);
    				this.triplet = null;
    				this.tripletmultiplier = 1;
    			}
    		}
    		this.stemdir = oldDir;
    		voice.addBeam(beamelem);
    		return abselemset;
    	};

    var sortPitch = function(elem) {
      var sorted;
      do {
        sorted = true;
        for (var p = 0; p<elem.pitches.length-1; p++) {
          if (elem.pitches[p].pitch>elem.pitches[p+1].pitch) {
            sorted = false;
            var tmp = elem.pitches[p];
            elem.pitches[p] = elem.pitches[p+1];
            elem.pitches[p+1] = tmp;
          }
        }
      } while (!sorted);
    };

    var ledgerLines = function(abselem, minPitch, maxPitch, isRest, symbolWidth, additionalLedgers, dir, dx, scale) {
    	for (var i=maxPitch; i>11; i--) {
    		if (i%2===0 && !isRest) {
    			abselem.addChild(new abc_relative_element(null, dx, (symbolWidth+4)*scale, i, {type:"ledger"}));
    		}
    	}

    	for (i=minPitch; i<1; i++) {
    		if (i%2===0 && !isRest) {
    			abselem.addChild(new abc_relative_element(null, dx, (symbolWidth+4)*scale, i, {type:"ledger"}));
    		}
    	}

    	for (i = 0; i < additionalLedgers.length; i++) { // PER: draw additional ledgers
    		var ofs = symbolWidth;
    		if (dir === 'down') ofs = -ofs;
    		abselem.addChild(new abc_relative_element(null, ofs+dx, (symbolWidth+4)*scale, additionalLedgers[i], {type:"ledger"}));
    	}
    };

    	AbstractEngraver.prototype.addGraceNotes = function (elem, voice, abselem, notehead, stemHeight, isBagpipes, roomtaken) {
    		var gracescale = 3 / 5;
    		var graceScaleStem = 3.5 / 5; // TODO-PER: empirically found constant.
    		var gracebeam = null;
    		var flag;

    		if (elem.gracenotes.length > 1) {
    			gracebeam = new abc_beam_element(stemHeight * graceScaleStem, "grace", isBagpipes);
    			if (hint) gracebeam.setHint();
    			gracebeam.mainNote = abselem;	// this gives us a reference back to the note this is attached to so that the stems can be attached somewhere.
    		}

    		var graceoffsets = [];
    		for (i = elem.gracenotes.length - 1; i >= 0; i--) { // figure out where to place each gracenote
    			roomtaken += 10;
    			graceoffsets[i] = roomtaken;
    			if (elem.gracenotes[i].accidental) {
    				roomtaken += 7;
    			}
    		}

    		var i;
    		for (i = 0; i < elem.gracenotes.length; i++) {
    			var gracepitch = elem.gracenotes[i].verticalPos;

    			flag = (gracebeam) ? null : chartable.uflags[(isBagpipes) ? 5 : 3];
    			var accidentalSlot = [];
    			var ret = createNoteHead(abselem, "noteheads.quarter", elem.gracenotes[i], "up", -graceoffsets[i], -graceoffsets[i], flag, 0, 0, gracescale*this.voiceScale, accidentalSlot, false);
    			ret.notehead.highestVert = ret.notehead.pitch + stemHeight * graceScaleStem;
    			var grace = ret.notehead;
    			this.addSlursAndTies(abselem, elem.gracenotes[i], grace, voice, "up", true);

    			abselem.addExtra(grace);
    			// PER: added acciaccatura slash
    			if (elem.gracenotes[i].acciaccatura) {
    				var pos = elem.gracenotes[i].verticalPos + 7 * gracescale;        // the same formula that determines the flag position.
    				var dAcciaccatura = gracebeam ? 5 : 6;        // just an offset to make it line up correctly.
    				abselem.addRight(new abc_relative_element("flags.ugrace", -graceoffsets[i] + dAcciaccatura, 0, pos, {scalex: gracescale, scaley: gracescale}));
    			}
    			if (gracebeam) { // give the beam the necessary info
    				var graceDuration = elem.gracenotes[i].duration / 2;
    				if (isBagpipes) graceDuration /= 2;
    				var pseudoabselem = {
    					heads: [grace],
    					abcelem: {averagepitch: gracepitch, minpitch: gracepitch, maxpitch: gracepitch, duration: graceDuration}
    				};
    				gracebeam.add(pseudoabselem);
    			} else { // draw the stem
    				var p1 = gracepitch + 1 / 3 * gracescale;
    				var p2 = gracepitch + 7 * gracescale;
    				var dx = grace.dx + grace.w;
    				var width = -0.6;
    				abselem.addExtra(new abc_relative_element(null, dx, 0, p1, {"type": "stem", "pitch2": p2, linewidth: width}));
    			}
    			ledgerLines(abselem, gracepitch, gracepitch, false, abc_glyphs.getSymbolWidth("noteheads.quarter"), [], true, grace.dx - 1, 0.6);

    			if (i === 0 && !isBagpipes && !(elem.rest && (elem.rest.type === "spacer" || elem.rest.type === "invisible"))) {
    				// This is the overall slur that is under the grace notes.
    				var isTie = (elem.gracenotes.length === 1 && grace.pitch === notehead.pitch);
    				voice.addOther(new abc_tie_element({ anchor1: grace, anchor2: notehead, isGrace: true}));
    			}
    		}

    		if (gracebeam) {
    			voice.addBeam(gracebeam);
    		}
    		return roomtaken;
    	};

    	function addRestToAbsElement(abselem, elem, duration, dot, isMultiVoice, stemdir, isSingleLineStaff, durlog, voiceScale) {
    		var c;
    		var restpitch = 7;
    		var noteHead;
    		var roomTaken;
    		var roomTakenRight;

    		if (isMultiVoice) {
    			if (stemdir === "down") restpitch = 3;
    			if (stemdir === "up") restpitch = 11;
    		}
    		// There is special placement for the percussion staff. If there is one staff line, then move the rest position.
    		if (isSingleLineStaff) {
    			// The half and whole rests are attached to different lines normally, so we need to tweak their position to get them to both be attached to the same one.
    			if (duration < 0.5)
    				restpitch = 7;
    			else if (duration < 1)
    				restpitch = 7;	// half rest
    			else
    				restpitch = 5; // whole rest
    		}
    		switch (elem.rest.type) {
    			case "whole":
    				c = chartable.rest[0];
    				elem.averagepitch = restpitch;
    				elem.minpitch = restpitch;
    				elem.maxpitch = restpitch;
    				dot = 0;
    				break;
    			case "rest":
    				if (elem.style === "rhythm") // special case for rhythm: rests are a handy way to express the rhythm.
    					c = chartable.rhythm[-durlog];
    				else
    					c = chartable.rest[-durlog];
    				elem.averagepitch = restpitch;
    				elem.minpitch = restpitch;
    				elem.maxpitch = restpitch;
    				break;
    			case "invisible":
    			case "spacer":
    				c = "";
    				elem.averagepitch = restpitch;
    				elem.minpitch = restpitch;
    				elem.maxpitch = restpitch;
    				break;
    			case "multimeasure":
    				c = chartable.rest['multi'];
    				elem.averagepitch = restpitch;
    				elem.minpitch = restpitch;
    				elem.maxpitch = restpitch;
    				dot = 0;
    				var mmWidth = abc_glyphs.getSymbolWidth(c);
    				abselem.addHead(new abc_relative_element(c, -mmWidth, mmWidth * 2, 7));
    				var numMeasures = new abc_relative_element("" + elem.duration, 0, mmWidth, 16, {type: "multimeasure-text"});
    				abselem.addExtra(numMeasures);
    		}
    		if (elem.rest.type !== "multimeasure") {
    			var ret = createNoteHead(abselem, c, {verticalPos: restpitch}, null, 0, 0, null, dot, 0, voiceScale, [], false);
    			noteHead = ret.notehead;
    			if (noteHead) {
    				abselem.addHead(noteHead);
    				roomTaken = ret.accidentalshiftx;
    				roomTakenRight = ret.dotshiftx;
    			}
    		}
    		return { noteHead: noteHead, roomTaken: roomTaken, roomTakenRight: roomTakenRight };
    	}

    	function addIfNotExist(arr, item) {
    		for (var i = 0; i < arr.length; i++) {
    			if (JSON.stringify(arr[i]) === JSON.stringify(item))
    				return;
    		}
    		arr.push(item);
    	}

    	AbstractEngraver.prototype.addNoteToAbcElement = function(abselem, elem, dot, stemdir, style, zeroDuration, durlog, nostem, voice) {
    		var dotshiftx = 0; // room taken by chords with displaced noteheads which cause dots to shift
    		var noteHead;
    		var roomTaken = 0;
    		var roomTakenRight = 0;
    		var min;
    		var i;
    		var additionalLedgers = [];
    		// The accidentalSlot will hold a list of all the accidentals on this chord. Each element is a vertical place,
    		// and contains a pitch, which is the last pitch that contains an accidental in that slot. The slots are numbered
    		// from closest to the note to farther left. We only need to know the last accidental we placed because
    		// we know that the pitches are sorted by now.
    		var accidentalSlot = [];
    		var symbolWidth = 0;

    		var dir = (elem.averagepitch>=6) ? "down": "up";
    		if (stemdir) dir=stemdir;

    		style = elem.style ? elem.style : style; // get the style of note head.
    		if (!style || style === "normal") style = "note";
    		var noteSymbol;
    		if (zeroDuration)
    			noteSymbol = chartable[style].nostem;
    		else
    			noteSymbol = chartable[style][-durlog];
    		if (!noteSymbol)
    			console.log("noteSymbol:", style, durlog, zeroDuration);

    		// determine elements of chords which should be shifted
    		var p;
    		for (p=(dir==="down")?elem.pitches.length-2:1; (dir==="down")?p>=0:p<elem.pitches.length; p=(dir==="down")?p-1:p+1) {
    			var prev = elem.pitches[(dir==="down")?p+1:p-1];
    			var curr = elem.pitches[p];
    			var delta = (dir==="down")?prev.pitch-curr.pitch:curr.pitch-prev.pitch;
    			if (delta<=1 && !prev.printer_shift) {
    				curr.printer_shift=(delta)?"different":"same";
    				if (curr.verticalPos > 11 || curr.verticalPos < 1) {        // PER: add extra ledger line
    					additionalLedgers.push(curr.verticalPos - (curr.verticalPos%2));
    				}
    				if (dir==="down") {
    					roomTaken = abc_glyphs.getSymbolWidth(noteSymbol)+2;
    				} else {
    					dotshiftx = abc_glyphs.getSymbolWidth(noteSymbol)+2;
    				}
    			}
    		}

    		var pp = elem.pitches.length;
    		for (p=0; p<elem.pitches.length; p++) {

    			if (!nostem) {
    				var flag;
    				if ((dir==="down" && p!==0) || (dir==="up" && p!==pp-1)) { // not the stemmed elem of the chord
    					flag = null;
    				} else {
    					flag = chartable[(dir==="down")?"dflags":"uflags"][-durlog];
    				}
    			}
    			var c;
    			if (elem.pitches[p].style) { // There is a style for the whole group of pitches, but there could also be an override for a particular pitch.
    				c = chartable[elem.pitches[p].style][-durlog];
    			} else
    				c = noteSymbol;
    			// The highest position for the sake of placing slurs is itself if the slur is internal. It is the highest position possible if the slur is for the whole chord.
    			// If the note is the only one in the chord, then any slur it has counts as if it were on the whole chord.
    			elem.pitches[p].highestVert = elem.pitches[p].verticalPos;
    			var isTopWhenStemIsDown = (stemdir==="up" || dir==="up") && p===0;
    			var isBottomWhenStemIsUp = (stemdir==="down" || dir==="down") && p===pp-1;
    			if (isTopWhenStemIsDown || isBottomWhenStemIsUp) { // place to put slurs if not already on pitches

    				if (elem.startSlur || pp === 1) {
    					elem.pitches[p].highestVert = elem.pitches[pp-1].verticalPos;
    					if (getDuration(elem) < 1 && (stemdir==="up" || dir==="up"))
    						elem.pitches[p].highestVert += 6;        // If the stem is up, then compensate for the length of the stem
    				}
    				if (elem.startSlur) {
    					if (!elem.pitches[p].startSlur) elem.pitches[p].startSlur = []; //TODO possibly redundant, provided array is not optional
    					for (i=0; i<elem.startSlur.length; i++) {
    						addIfNotExist(elem.pitches[p].startSlur, elem.startSlur[i]);
    					}
    				}

    				if (elem.endSlur) {
    					elem.pitches[p].highestVert = elem.pitches[pp-1].verticalPos;
    					if (getDuration(elem) < 1 && (stemdir==="up" || dir==="up"))
    						elem.pitches[p].highestVert += 6;        // If the stem is up, then compensate for the length of the stem
    					if (!elem.pitches[p].endSlur) elem.pitches[p].endSlur = []; //TODO possibly redundant, provided array is not optional
    					for (i=0; i<elem.endSlur.length; i++) {
    						addIfNotExist(elem.pitches[p].endSlur, elem.endSlur[i]);
    					}
    				}
    			}

    			var hasStem = !nostem && durlog<=-1;
    			var ret = createNoteHead(abselem, c, elem.pitches[p], dir, 0, -roomTaken, flag, dot, dotshiftx, this.voiceScale, accidentalSlot, !stemdir);
    			symbolWidth = Math.max(abc_glyphs.getSymbolWidth(c), symbolWidth);
    			abselem.extraw -= ret.extraLeft;
    			noteHead = ret.notehead;
    			if (noteHead) {
    				this.addSlursAndTies(abselem, elem.pitches[p], noteHead, voice, hasStem ? dir : null, false);

    				if (elem.gracenotes && elem.gracenotes.length > 0)
    					noteHead.bottom = noteHead.bottom - 1;	 // If there is a tie to the grace notes, leave a little more room for the note to avoid collisions.
    				abselem.addHead(noteHead);
    			}
    			roomTaken += ret.accidentalshiftx;
    			roomTakenRight = Math.max(roomTakenRight,ret.dotshiftx);
    		}

    		// draw stem from the furthest note to a pitch above/below the stemmed note
    		if (hasStem) {
    			var stemHeight = 7 * this.voiceScale;
    			var p1 = (dir==="down") ? elem.minpitch-stemHeight : elem.minpitch+1/3;
    			// PER added stemdir test to make the line meet the note.
    			if (p1>6 && !stemdir) p1=6;
    			var p2 = (dir==="down") ? elem.maxpitch-1/3 : elem.maxpitch+stemHeight;
    			// PER added stemdir test to make the line meet the note.
    			if (p2<6 && !stemdir) p2=6;
    			var dx = (dir==="down" || abselem.heads.length === 0)?0:abselem.heads[0].w;
    			var width = (dir==="down")?1:-1;
    			// TODO-PER-HACK: One type of note head has a different placement of the stem. This should be more generically calculated:
    			if (noteHead.c === 'noteheads.slash.quarter') {
    				if (dir === 'down')
    					p2 -= 1;
    				else
    					p1 += 1;
    			}
    			abselem.addExtra(new abc_relative_element(null, dx, 0, p1, {"type": "stem", "pitch2":p2, linewidth: width}));
    			//var RelativeElement = function RelativeElement(c, dx, w, pitch, opt) {
    			min = Math.min(p1, p2);
    		}
    		return { noteHead: noteHead, roomTaken: roomTaken, roomTakenRight: roomTakenRight, min: min, additionalLedgers: additionalLedgers, dir: dir, symbolWidth: symbolWidth };
    	};

    	AbstractEngraver.prototype.addLyric = function(abselem, elem) {
    		var lyricStr = "";
    		abc_common.each(elem.lyric, function(ly) {
    			var div = ly.divider === ' ' ? "" : ly.divider;
    			lyricStr += ly.syllable + div + "\n";
    		});
    		var lyricDim = this.renderer.getTextSize(lyricStr, 'vocalfont', "lyric");
    		var position = elem.positioning ? elem.positioning.vocalPosition : 'below';
    		abselem.addCentered(new abc_relative_element(lyricStr, 0, lyricDim.width, undefined, {type:"lyric", position: position, height: lyricDim.height / abc_spacing.STEP }));
    	};

    	AbstractEngraver.prototype.addChord = function(abselem, elem, roomTaken, roomTakenRight) {
    		var chordMargin = 8; // If there are chords next to each other, this is how close they can get.
    		for (var i = 0; i < elem.chord.length; i++) {
    			var x = 0;
    			var y;
    			var dim = this.renderer.getTextSize(elem.chord[i].name, 'annotationfont', "annotation");
    			var chordWidth = dim.width;
    			var chordHeight = dim.height / abc_spacing.STEP;
    			switch (elem.chord[i].position) {
    				case "left":
    					roomTaken+=chordWidth+7;
    					x = -roomTaken;        // TODO-PER: This is just a guess from trial and error
    					y = elem.averagepitch;
    					abselem.addExtra(new abc_relative_element(elem.chord[i].name, x, chordWidth+4, y, {type:"text", height: chordHeight}));
    					break;
    				case "right":
    					roomTakenRight+=4;
    					x = roomTakenRight;// TODO-PER: This is just a guess from trial and error
    					y = elem.averagepitch;
    					abselem.addRight(new abc_relative_element(elem.chord[i].name, x, chordWidth+4, y, {type:"text", height: chordHeight}));
    					break;
    				case "below":
    					// setting the y-coordinate to undefined for now: it will be overwritten later on, after we figure out what the highest element on the line is.
    					abselem.addRight(new abc_relative_element(elem.chord[i].name, 0, chordWidth+chordMargin, undefined, {type: "text", position: "below", height: chordHeight}));
    					break;
    				case "above":
    					// setting the y-coordinate to undefined for now: it will be overwritten later on, after we figure out what the highest element on the line is.
    					abselem.addRight(new abc_relative_element(elem.chord[i].name, 0, chordWidth+chordMargin, undefined, {type: "text", height: chordHeight}));
    					break;
    				default:
    					if (elem.chord[i].rel_position) {
    						var relPositionY = elem.chord[i].rel_position.y + 3*abc_spacing.STEP; // TODO-PER: this is a fudge factor to make it line up with abcm2ps
    						abselem.addChild(new abc_relative_element(elem.chord[i].name, x + elem.chord[i].rel_position.x, 0, elem.minpitch + relPositionY / abc_spacing.STEP, {type: "text", height: chordHeight}));
    					} else {
    						// setting the y-coordinate to undefined for now: it will be overwritten later on, after we figure out what the highest element on the line is.
    						var pos2 = 'above';
    						if (elem.positioning && elem.positioning.chordPosition)
    							pos2 = elem.positioning.chordPosition;

    						dim = this.renderer.getTextSize(elem.chord[i].name, 'gchordfont', "chord");
    						chordHeight = dim.height / abc_spacing.STEP;
    						chordWidth = dim.width; // Since the chord is centered, we only use half the width.
    						abselem.addCentered(new abc_relative_element(elem.chord[i].name, x, chordWidth, undefined, {type: "chord", position: pos2, height: chordHeight }));
    					}
    			}
    		}
    		return { roomTaken: roomTaken, roomTakenRight: roomTakenRight };
    	};

    AbstractEngraver.prototype.createNote = function(elem, nostem, isSingleLineStaff, voice) { //stem presence: true for drawing stemless notehead
      var notehead = null;
      var roomtaken = 0; // room needed to the left of the note
      var roomtakenright = 0; // room needed to the right of the note
      var symbolWidth = 0;
      var additionalLedgers = []; // PER: handle the case of [bc'], where the b doesn't have a ledger line
      var dir;

    	var duration = getDuration(elem);
    	var zeroDuration = false;
      if (duration === 0) { zeroDuration = true; duration = 0.25; nostem = true; }        //PER: zero duration will draw a quarter note head.
      var durlog = Math.floor(Math.log(duration)/Math.log(2)); //TODO use getDurlog
      var dot=0;

      for (var tot = Math.pow(2,durlog), inc=tot/2; tot<duration; dot++,tot+=inc,inc/=2);


    	if (elem.startTriplet) {
    		this.tripletmultiplier = elem.tripletMultiplier;
    	}

      var durationForSpacing = duration * this.tripletmultiplier;
      if (elem.rest && elem.rest.type === 'multimeasure')
      	durationForSpacing = 1;
      var absType = elem.rest ? "rest" : "note";
      var abselem = new abc_absolute_element(elem, durationForSpacing, 1, absType, this.tuneNumber, { durationClassOveride: elem.duration * this.tripletmultiplier});
      if (hint) abselem.setHint();

      if (elem.rest) {
      	if (this.measureLength === duration && elem.rest.type !== 'invisible' && elem.rest.type !== 'spacer')
    	    elem.rest.type = 'whole'; // If the rest is exactly a measure, always use a whole rest
    	  var ret1 = addRestToAbsElement(abselem, elem, duration, dot, voice.voicetotal > 1, this.stemdir, isSingleLineStaff, durlog, this.voiceScale);
    	  notehead = ret1.noteHead;
    	  roomtaken = ret1.roomTaken;
    	  roomtakenright = ret1.roomTakenRight;
      } else {
    	  var ret2 = this.addNoteToAbcElement(abselem, elem, dot, this.stemdir, this.style, zeroDuration, durlog, nostem, voice);
    	  if (ret2.min !== undefined)
    		  this.minY = Math.min(ret2.min, this.minY);
    	  notehead = ret2.noteHead;
    	  roomtaken = ret2.roomTaken;
    	  roomtakenright = ret2.roomTakenRight;
    	  additionalLedgers = ret2.additionalLedgers;
    	  dir = ret2.dir;
    	  symbolWidth = ret2.symbolWidth;
      }

      if (elem.lyric !== undefined) {
      	this.addLyric(abselem, elem);
      }

      if (elem.gracenotes !== undefined) {
    	roomtaken += this.addGraceNotes(elem, voice, abselem, notehead, this.stemHeight * this.voiceScale, this.isBagpipes, roomtaken);
      }

      if (elem.decoration) {
    	  this.decoration.createDecoration(voice, elem.decoration, abselem.top, (notehead)?notehead.w:0, abselem, roomtaken, dir, abselem.bottom, elem.positioning, this.hasVocals);
      }

      if (elem.barNumber) {
        abselem.addChild(new abc_relative_element(elem.barNumber, -10, 0, 0, {type:"barNumber"}));
      }

      // ledger lines
    	ledgerLines(abselem, elem.minpitch, elem.maxpitch, elem.rest, symbolWidth, additionalLedgers, dir, -2, 1);

      if (elem.chord !== undefined) {
      	var ret3 = this.addChord(abselem, elem, roomtaken, roomtakenright);
    	  roomtaken = ret3.roomTaken;
    	  roomtakenright = ret3.roomTakenRight;
      }


      if (elem.startTriplet) {
        this.triplet = new abc_triplet_element(elem.startTriplet, notehead, { flatBeams: this.flatBeams }); // above is opposite from case of slurs
      }

      if (elem.endTriplet && this.triplet) {
        this.triplet.setCloseAnchor(notehead);
      }

      if (this.triplet && !elem.startTriplet && !elem.endTriplet) {
      	this.triplet.middleNote(notehead);
      }


      return abselem;
    };




    var createNoteHead = function(abselem, c, pitchelem, dir, headx, extrax, flag, dot, dotshiftx, scale, accidentalSlot, shouldExtendStem) {
      // TODO scale the dot as well
      var pitch = pitchelem.verticalPos;
      var notehead;
      var accidentalshiftx = 0;
      var newDotShiftX = 0;
      var extraLeft = 0;
      if (c === undefined)
        abselem.addChild(new abc_relative_element("pitch is undefined", 0, 0, 0, {type:"debug"}));
      else if (c==="") {
        notehead = new abc_relative_element(null, 0, 0, pitch);
      } else {
        var shiftheadx = headx;
        if (pitchelem.printer_shift) {
          var adjust = (pitchelem.printer_shift==="same")?1:0;
          shiftheadx = (dir==="down")?-abc_glyphs.getSymbolWidth(c)*scale+adjust:abc_glyphs.getSymbolWidth(c)*scale-adjust;
        }
    	  var opts = {scalex:scale, scaley: scale, thickness: abc_glyphs.symbolHeightInPitches(c)*scale };
        notehead = new abc_relative_element(c, shiftheadx, abc_glyphs.getSymbolWidth(c)*scale, pitch, opts);
        notehead.stemDir = dir;
        if (flag) {
          var pos = pitch+((dir==="down")?-7:7)*scale;
          // if this is a regular note, (not grace or tempo indicator) then the stem will have been stretched to the middle line if it is far from the center.
    	    if (shouldExtendStem) {
    	    	if (dir==="down" && pos > 6)
    	    		pos = 6;
    	    	if (dir==="up" && pos < 6)
    	    		pos = 6;
    	    }
          //if (scale===1 && (dir==="down")?(pos>6):(pos<6)) pos=6;
          var xdelta = (dir==="down")?headx:headx+notehead.w-0.6;
          abselem.addRight(new abc_relative_element(flag, xdelta, abc_glyphs.getSymbolWidth(flag)*scale, pos, {scalex:scale, scaley: scale}));
        }
    	  newDotShiftX = notehead.w+dotshiftx-2+5*dot;
        for (;dot>0;dot--) {
          var dotadjusty = (1-Math.abs(pitch)%2); //PER: take abs value of the pitch. And the shift still happens on ledger lines.
          abselem.addRight(new abc_relative_element("dots.dot", notehead.w+dotshiftx-2+5*dot, abc_glyphs.getSymbolWidth("dots.dot"), pitch+dotadjusty));
        }
      }
            if (notehead)
                    notehead.highestVert = pitchelem.highestVert;

      if (pitchelem.accidental) {
        var symb;
        switch (pitchelem.accidental) {
        case "quartersharp":
          symb = "accidentals.halfsharp";
            break;
        case "dblsharp":
          symb = "accidentals.dblsharp";
          break;
        case "sharp":
          symb = "accidentals.sharp";
          break;
        case "quarterflat":
          symb = "accidentals.halfflat";
          break;
        case "flat":
          symb = "accidentals.flat";
          break;
        case "dblflat":
          symb = "accidentals.dblflat";
          break;
        case "natural":
          symb = "accidentals.nat";
        }
             // if a note is at least a sixth away, it can share a slot with another accidental
             var accSlotFound = false;
             var accPlace = extrax;
             for (var j = 0; j < accidentalSlot.length; j++) {
                     if (pitch - accidentalSlot[j][0] >= 6) {
                             accidentalSlot[j][0] = pitch;
                             accPlace = accidentalSlot[j][1];
                             accSlotFound = true;
                             break;
                     }
             }
             if (accSlotFound === false) {
                     accPlace -= (abc_glyphs.getSymbolWidth(symb)*scale+2);
                     accidentalSlot.push([pitch,accPlace]);
                     accidentalshiftx = (abc_glyphs.getSymbolWidth(symb)*scale+2);
             }
        abselem.addExtra(new abc_relative_element(symb, accPlace, abc_glyphs.getSymbolWidth(symb), pitch, {scalex:scale, scaley: scale}));
    	  extraLeft = abc_glyphs.getSymbolWidth(symb) / 2; // TODO-PER: We need a little extra width if there is an accidental, but I'm not sure why it isn't the full width of the accidental.
      }

      return { notehead: notehead, accidentalshiftx: accidentalshiftx, dotshiftx: newDotShiftX, extraLeft: extraLeft };

    };

    	AbstractEngraver.prototype.addSlursAndTies = function(abselem, pitchelem, notehead, voice, dir, isGrace) {
    		if (pitchelem.endTie) {
    			if (this.ties.length > 0) {
    				// If there are multiple open ties, find the one that applies by matching the pitch, if possible.
    				var found = false;
    				for (var j = 0; j < this.ties.length; j++) {
    					if (this.ties[j].anchor1 && this.ties[j].anchor1.pitch === notehead.pitch) {
    						this.ties[j].setEndAnchor(notehead);
    						this.ties.splice(j, 1);
    						found = true;
    						break;
    					}
    				}
    				if (!found) {
    					this.ties[0].setEndAnchor(notehead);
    					this.ties.splice(0, 1);
    				}
    			}
    		}

    		var voiceNumber = voice.voicetotal < 2 ? -1 : voice.voicenumber;
    		if (pitchelem.startTie) {
    			var tie = new abc_tie_element({ anchor1: notehead, force: (this.stemdir==="down" || this.stemdir==="up"), stemDir: this.stemdir, isGrace: isGrace, voiceNumber: voiceNumber});
    			if (hint) tie.setHint();

    			this.ties[this.ties.length]=tie;
    			voice.addOther(tie);
    			// HACK-PER: For the animation, we need to know if a note is tied to the next one, so here's a flag.
    			// Unfortunately, only some of the notes in the current event might be tied, but this will consider it
    			// tied if any one of them is. That will work for most cases.
    			abselem.startTie = true;
    		}

    		if (pitchelem.endSlur) {
    			for (var i=0; i<pitchelem.endSlur.length; i++) {
    				var slurid = pitchelem.endSlur[i];
    				var slur;
    				if (this.slurs[slurid]) {
    					slur = this.slurs[slurid];
    					slur.setEndAnchor(notehead);
    					delete this.slurs[slurid];
    				} else {
    					slur = new abc_tie_element({ anchor2: notehead, stemDir: this.stemdir, voiceNumber: voiceNumber});
    					if (hint) slur.setHint();
    					voice.addOther(slur);
    				}
    				if (this.startlimitelem) {
    					slur.setStartX(this.startlimitelem);
    				}
    			}
    		} else if (!isGrace) {
    			for (var s in this.slurs) {
    				if (this.slurs.hasOwnProperty(s)) {
    					this.slurs[s].addInternalNote(notehead);
    				}
    			}
    		}

    		if (pitchelem.startSlur) {
    			for (i=0; i<pitchelem.startSlur.length; i++) {
    				var slurid = pitchelem.startSlur[i].label;
    				var slur = new abc_tie_element({ anchor1: notehead, stemDir: this.stemdir, voiceNumber: voiceNumber});
    				if (hint) slur.setHint();
    				this.slurs[slurid]=slur;
    				voice.addOther(slur);
    			}
    		}
    	};

    AbstractEngraver.prototype.addMeasureNumber = function (number, abselem) {
    	var measureNumHeight = this.renderer.getTextSize(number, "measurefont", 'bar-number');
    	abselem.addChild(new abc_relative_element(number, 0, 0, 11+measureNumHeight.height / abc_spacing.STEP, {type:"barNumber"}));
    };

    AbstractEngraver.prototype.createBarLine = function (voice, elem, isFirstStaff) {
    // bar_thin, bar_thin_thick, bar_thin_thin, bar_thick_thin, bar_right_repeat, bar_left_repeat, bar_double_repeat

      var abselem = new abc_absolute_element(elem, 0, 10, 'bar', this.tuneNumber);
      var anchor = null; // place to attach part lines
      var dx = 0;

    	if (elem.barNumber) {
    		this.addMeasureNumber(elem.barNumber, abselem);
    	}


      var firstdots = (elem.type==="bar_right_repeat" || elem.type==="bar_dbl_repeat");
      var firstthin = (elem.type!=="bar_left_repeat" && elem.type!=="bar_thick_thin" && elem.type!=="bar_invisible");
      var thick = (elem.type==="bar_right_repeat" || elem.type==="bar_dbl_repeat" || elem.type==="bar_left_repeat" ||
             elem.type==="bar_thin_thick" || elem.type==="bar_thick_thin");
      var secondthin = (elem.type==="bar_left_repeat" || elem.type==="bar_thick_thin" || elem.type==="bar_thin_thin" || elem.type==="bar_dbl_repeat");
      var seconddots = (elem.type==="bar_left_repeat" || elem.type==="bar_dbl_repeat");

      // limit positioning of slurs
      if (firstdots || seconddots) {
        for (var slur in this.slurs) {
          if (this.slurs.hasOwnProperty(slur)) {
            this.slurs[slur].setEndX(abselem);
          }
        }
        this.startlimitelem = abselem;
      }

      if (firstdots) {
        abselem.addRight(new abc_relative_element("dots.dot", dx, 1, 7));
        abselem.addRight(new abc_relative_element("dots.dot", dx, 1, 5));
        dx+=6; //2 hardcoded, twice;
      }

      if (firstthin) {
        anchor = new abc_relative_element(null, dx, 1, 2, {"type": "bar", "pitch2":10, linewidth:0.6});
        abselem.addRight(anchor);
      }

      if (elem.type==="bar_invisible") {
        anchor = new abc_relative_element(null, dx, 1, 2, {"type": "none", "pitch2":10, linewidth:0.6});
        abselem.addRight(anchor);
      }

      if (elem.decoration) {
        this.decoration.createDecoration(voice, elem.decoration, 12, (thick)?3:1, abselem, 0, "down", 2, elem.positioning, this.hasVocals);
      }

      if (thick) {
        dx+=4; //3 hardcoded;
        anchor = new abc_relative_element(null, dx, 4, 2, {"type": "bar", "pitch2":10, linewidth:4});
        abselem.addRight(anchor);
        dx+=5;
      }

    // if (this.partstartelem && (thick || (firstthin && secondthin))) { // means end of nth part
    // this.partstartelem.anchor2=anchor;
    // this.partstartelem = null;
    // }

      if (this.partstartelem && elem.endEnding) {
        this.partstartelem.anchor2=anchor;
        this.partstartelem = null;
      }

      if (secondthin) {
        dx+=3; //3 hardcoded;
        anchor = new abc_relative_element(null, dx, 1, 2, {"type": "bar", "pitch2":10, linewidth:0.6});
        abselem.addRight(anchor); // 3 is hardcoded
      }

      if (seconddots) {
        dx+=3; //3 hardcoded;
        abselem.addRight(new abc_relative_element("dots.dot", dx, 1, 7));
        abselem.addRight(new abc_relative_element("dots.dot", dx, 1, 5));
      } // 2 is hardcoded

      if (elem.startEnding && isFirstStaff) { // only put the first & second ending marks on the first staff
    	  var textWidth = this.renderer.getTextSize(elem.startEnding, "repeatfont", '').width;
    	  abselem.minspacing += textWidth + 10; // Give plenty of room for the ending number.
        this.partstartelem = new abc_ending_element(elem.startEnding, anchor, null);
    	  voice.addOther(this.partstartelem);
      }

      // Add a little space to the left of the bar line so that nothing can crowd it.
    	abselem.extraw -= 5;

    	return abselem;

    };


    })();

    var abc_abstract_engraver = AbstractEngraver;

    //    abc_voice_element.js: Definition of the VoiceElement class.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    /*global module */

    var svgNS = "http://www.w3.org/2000/svg";

    function Svg(wrapper) {
    	this.svg = createSvg();
    	wrapper.appendChild(this.svg);
    }

    Svg.prototype.clear = function() {
    	if (this.svg) {
    		var wrapper = this.svg.parentNode;
    		this.svg = createSvg();
    		if (wrapper) {
    			// TODO-PER: If the wrapper is not present, then the underlying div was pulled out from under this instance. It's possible that is still useful (for creating the music off page?)
    			wrapper.innerHTML = "";
    			wrapper.appendChild(this.svg);
    		}
    	}
    };

    Svg.prototype.setTitle = function(title) {
    	var titleEl = document.createElement("title");
    	var titleNode = document.createTextNode(title);
    	titleEl.appendChild(titleNode);
    	this.svg.insertBefore(titleEl, this.svg.firstChild);
    };

    Svg.prototype.setResponsiveWidth = function(w, h) {
    	// this technique is from: http://thenewcode.com/744/Make-SVG-Responsive, thx to https://github.com/iantresman
    	this.svg.setAttribute("viewBox", "0 0 " + w + " " + h);
    	this.svg.setAttribute("preserveAspectRatio", "xMinYMin meet");
    	this.svg.removeAttribute("height");
    	this.svg.removeAttribute("width");
    	this.svg.style['display'] = "inline-block";
    	this.svg.style['position'] = "absolute";
    	this.svg.style['top'] = "0";
    	this.svg.style['left'] = "0";

    	if (this.svg.parentNode) {
    		var cls = this.svg.parentNode.getAttribute("class");
    		if (!cls)
    			this.svg.parentNode.setAttribute("class", "abcjs-container");
    		else if (cls.indexOf("abcjs-container") < 0)
    			this.svg.parentNode.setAttribute("class", cls + " abcjs-container");
    		this.svg.parentNode.style['display'] = "inline-block";
    		this.svg.parentNode.style['position'] = "relative";
    		this.svg.parentNode.style['width'] = "100%";
    		// PER: I changed the padding from 100% to this through trial and error.
    		// The example was using a square image, but this music might be either wider or taller.
    		var padding = h / w * 100;
    		this.svg.parentNode.style['padding-bottom'] = padding + "%";
    		this.svg.parentNode.style['vertical-align'] = "middle";
    		this.svg.parentNode.style['overflow'] = "hidden";
    	}
    };

    Svg.prototype.setSize = function(w, h) {
    	this.svg.setAttribute('width', w);
    	this.svg.setAttribute('height', h);
    	// TODO-PER: Is this hack still needed?
    	// Correct for IE problem in calculating height
    	// var isIE = /*@cc_on!@*/false;//IE detector
    	// if (isIE) {
    	// 	this.paper.canvas.parentNode.style.width = w + "px";
    	// 	this.paper.canvas.parentNode.style.height = "" + h + "px";
    	// } else
    	// 	this.paper.canvas.parentNode.setAttribute("style", "width:" + w + "px");
    };

    Svg.prototype.setScale = function(scale) {
    	if (scale !== 1) {
    		this.svg.style.transform = "scale("+scale+","+scale+")";
    		this.svg.style['-ms-transform'] = "scale("+scale+","+scale+")";
    		this.svg.style['-webkit-transform'] = "scale("+scale+","+scale+")";
    		this.svg.style['transform-origin'] = "0 0";
    		this.svg.style['-ms-transform-origin-x'] = "0";
    		this.svg.style['-ms-transform-origin-y'] = "0";
    		this.svg.style['-webkit-transform-origin-x'] = "0";
    		this.svg.style['-webkit-transform-origin-y'] = "0";
    	} else {
    		this.svg.style.transform = "";
    		this.svg.style['-ms-transform'] = "";
    		this.svg.style['-webkit-transform'] = "";
    	}
    };

    Svg.prototype.setParentStyles = function(attr) {
    	// This is needed to get the size right when there is scaling involved.
    	for (var key in attr) {
    		if (attr.hasOwnProperty(key)) {
    			if (this.svg.parentNode)
    				this.svg.parentNode.style[key] = attr[key];
    		}
    	}
    	// This is the last thing that gets called, so delete the temporary SVG if one was created
    	if (this.dummySvg) {
    		var body = document.querySelector('body');
    		body.removeChild(this.dummySvg);
    		this.dummySvg = null;
    	}

    };

    Svg.prototype.rect = function(attr) {
    	var el = document.createElementNS(svgNS, "rect");
    	for (var key in attr) {
    		if (attr.hasOwnProperty(key)) {
    			var tmp = "" + attr[key];
    			if (tmp.indexOf("NaN") >= 0)
    				debugger;
    			el.setAttributeNS(null, key, attr[key]);
    		}
    	}
    	this.append(el);
    	return el;
    };

    Svg.prototype.text = function(text, attr, target) {
    	var el = document.createElementNS(svgNS, 'text');
    	for (var key in attr) {
    		if (attr.hasOwnProperty(key)) {
    			el.setAttribute(key, attr[key]);
    		}
    	}
    	var lines = (""+text).split("\n");
    	for (var i = 0; i < lines.length; i++) {
    		var line = document.createElementNS(svgNS, 'tspan');
    		line.textContent = lines[i];
    		line.setAttribute("x", attr.x ? attr.x : 0);
    		if (i !== 0)
    			line.setAttribute("dy", "1.2em");
    		el.appendChild(line);
    	}
    	if (target)
    		target.appendChild(el);
    	else
    		this.append(el);
    	return el;
    };

    Svg.prototype.guessWidth = function(text, attr) {
    	var svg = this.createDummySvg();
    	var el = this.text(text, attr, svg);
    	var size;
    	try {
    		size  = el.getBBox();
    		if (isNaN(size.height) || !size.height) // TODO-PER: I don't think this can happen unless there isn't a browser at all.
    			size = { width: attr['font-size']/2, height: attr['font-size'] + 2 }; // Just a wild guess.
    		else
    			size = {width: size.width, height: size.height};
    	} catch (ex) {
    		size = { width: attr['font-size']/2, height: attr['font-size'] + 2 }; // Just a wild guess.
    	}
    	svg.removeChild(el);
    	return size;
    };

    Svg.prototype.createDummySvg = function() {
    	if (!this.dummySvg) {
    		this.dummySvg = createSvg();
    		var styles = [
    			"display: block !important;",
    			"height: 1px;",
    			"width: 1px;",
    			"position: absolute;"
    		];
    		this.dummySvg.setAttribute('style', styles.join(""));
    		var body = document.querySelector('body');
    		body.appendChild(this.dummySvg);
    	}

    	return this.dummySvg;
    };

    Svg.prototype.getTextSize = function(text, attr, el) {
    	if (typeof text === 'number')
    		text = ''+text;
    	if (!text || text.match(/^\s+$/))
    		return { width: 0, height: 0 };
    	var removeLater = !el;
    	if (!el)
    		el = this.text(text, attr);
    	var size;
    	try {
    		size  = el.getBBox();
    		if (isNaN(size.height) || !size.height)
    			size = this.guessWidth(text, attr);
    		else
    			size = {width: size.width, height: size.height};
    	} catch (ex) {
    		size = this.guessWidth(text, attr);
    	}
    	if (removeLater) {
    		if (this.currentGroup)
    			this.currentGroup.removeChild(el);
    		else
    			this.svg.removeChild(el);
    	}
    	return size;
    };

    Svg.prototype.openGroup = function(options) {
    	options = options ? options : {};
    	var el = document.createElementNS(svgNS, "g");
    	if (options.prepend)
    		this.svg.insertBefore(el, this.svg.firstChild);
    	else
    		this.svg.appendChild(el);
    	this.currentGroup = el;
    	return el;
    };

    Svg.prototype.closeGroup = function() {
    	var g = this.currentGroup;
    	this.currentGroup = null;
    	return g;
    };

    Svg.prototype.path = function(attr) {
    	var el = document.createElementNS(svgNS, "path");
    	for (var key in attr) {
    		if (attr.hasOwnProperty(key)) {
    			if (key === 'path')
    				el.setAttributeNS(null, 'd', attr.path);
    			else
    				el.setAttributeNS(null, key, attr[key]);
    		}
    	}
    	this.append(el);
    	return el;
    };

    Svg.prototype.pathToBack = function(attr) {
    	var el = document.createElementNS(svgNS, "path");
    	for (var key in attr) {
    		if (attr.hasOwnProperty(key)) {
    			if (key === 'path')
    				el.setAttributeNS(null, 'd', attr.path);
    			else
    				el.setAttributeNS(null, key, attr[key]);
    		}
    	}
    	this.prepend(el);
    	return el;
    };

    Svg.prototype.append = function(el) {
    	if (this.currentGroup)
    		this.currentGroup.appendChild(el);
    	else
    		this.svg.appendChild(el);
    };

    Svg.prototype.prepend = function(el) {
    	// The entire group is prepended, so don't prepend the individual elements.
    	if (this.currentGroup)
    		this.currentGroup.appendChild(el);
    	else
    		this.svg.insertBefore(el, this.svg.firstChild);
    };

    Svg.prototype.setAttributeOnElement = function(el, attr) {
    	for (var key in attr) {
    		if (attr.hasOwnProperty(key)) {
    			el.setAttributeNS(null, key, attr[key]);
    		}
    	}
    };

    function createSvg() {
    	var svg = document.createElementNS(svgNS, "svg");
    	svg.setAttributeNS("http://www.w3.org/2000/xmlns/", "xmlns:xlink", "http://www.w3.org/1999/xlink");
    	svg.setAttribute('role', 'img');    // for accessibility
    	return svg;
    }


    var svg = Svg;

    //    abc_renderer.js: API to render to SVG/Raphael/whatever rendering engine
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


    /*global Math, console */






    /**
     * Implements the API for rendering ABCJS Abstract Rendering Structure to a canvas/paper (e.g. SVG, Raphael, etc)
     * @param {Object} paper
     * @param {bool} doRegression
     */
    var Renderer = function(paper, doRegression, shouldAddClasses) {
      this.paper = new svg(paper);
      this.controller = null; //TODO-GD only used when drawing the ABCJS ARS to connect the controller with the elements for highlighting

    	this.space = 3*abc_spacing.SPACE;
      this.padding = {}; // renderer's padding is managed by the controller
      this.doRegression = doRegression;
      this.shouldAddClasses = shouldAddClasses;
      if (this.doRegression)
        this.regressionLines = [];
    	this.reset();
    };

    Renderer.prototype.reset = function() {

    	this.paper.clear();
    	this.y = 0;
    	this.abctune = null;
    	this.lastM = null;
    	this.ingroup = false;
    	this.path = null;
    	this.isPrint = false;
    	this.initVerticalSpace();
    	if (this.doRegression)
    		this.regressionLines = [];
    	// HACK-PER: There was a problem in Raphael where every path string that was sent to it was cached.
    	// That was causing the browser's memory to steadily grow until the browser went slower and slower until
    	// it crashed. The fix to that was a patch to Raphael, so it is only patched on the versions of this library that
    	// bundle Raphael with it. Also, if Raphael gets an update, then that patch will be lost. On version 2.1.2 of Raphael,
    	// the patch is on line 1542 and 1545 and it is:
    	//             p[ps].sleep = 1;
    };

    Renderer.prototype.newTune = function(abcTune) {
    	this.abctune = abcTune; // TODO-PER: this is just to get the font info.
    	this.setVerticalSpace(abcTune.formatting);
    	this.measureNumber = null;
    	this.noteNumber = null;
    	this.setPrintMode(abcTune.media === 'print');
    	this.setPadding(abcTune);
    };

    Renderer.prototype.createElemSet = function() {
    	return this.paper.openGroup();
    };

    Renderer.prototype.closeElemSet = function() {
    	return this.paper.closeGroup();
    };

    /**
     * Set whether we are formatting this for the screen, or as a preview for creating a PDF version.
     * @param {bool} isPrint
     */
    Renderer.prototype.setPrintMode = function (isPrint) {
    	this.isPrint = isPrint;
    };

    /**
     * Set the size of the canvas.
     * @param {object} maxwidth
     * @param {object} scale
     */
    Renderer.prototype.setPaperSize = function (maxwidth, scale, responsive) {
    	var w = (maxwidth+this.padding.right)*scale;
    	var h = (this.y+this.padding.bottom)*scale;
    	if (this.isPrint)
    		h = Math.max(h, 1056); // 11in x 72pt/in x 1.33px/pt
    	// TODO-PER: We are letting the page get as long as it needs now, but eventually that should go to a second page.
    	if (this.doRegression)
    		this.regressionLines.push("PAPER SIZE: ("+w+","+h+")");

    	// for accessibility
    	var text = "Sheet Music";
    	if (this.abctune && this.abctune.metaText && this.abctune.metaText.title)
    		text += " for \"" + this.abctune.metaText.title + '"';
    	this.paper.setTitle(text);

    	var parentStyles = { overflow: "hidden" };
    	if (responsive === 'resize') {
    		this.paper.setResponsiveWidth(w, h);
    	} else {
    		parentStyles.width = "";
    		parentStyles.height = h + "px";
    		if (scale < 1) {
    			parentStyles.width = w + "px";
    			this.paper.setSize(w / scale, h / scale);
    		} else
    			this.paper.setSize(w, h);
    	}
    	this.paper.setScale(scale);
    	this.paper.setParentStyles(parentStyles);
    };

    /**
     * Set the padding
     * @param {object} params
     */
    Renderer.prototype.setPaddingOverride = function(params) {
    	this.paddingOverride = { top: params.paddingtop, bottom: params.paddingbottom,
    		right: params.paddingright, left: params.paddingleft };
    };

    /**
     * Set the padding
     * @param {object} params
     */
    Renderer.prototype.setPadding = function(abctune) {
    	// If the padding is set in the tune, then use that.
    	// Otherwise, if the padding is set in the override, use that.
    	// Otherwise, use the defaults (there are a different set of defaults for screen and print.)
    	function setPaddingVariable(self, paddingKey, formattingKey, printDefault, screenDefault) {
    		if (abctune.formatting[formattingKey] !== undefined)
    			self.padding[paddingKey] = abctune.formatting[formattingKey];
    		else if (self.paddingOverride[paddingKey] !== undefined)
    			self.padding[paddingKey] = self.paddingOverride[paddingKey];
    		else if (self.isPrint)
    			self.padding[paddingKey] = printDefault;
    		else
    			self.padding[paddingKey] = screenDefault;
    	}
    	// 1cm x 0.393701in/cm x 72pt/in x 1.33px/pt = 38px
    	// 1.8cm x 0.393701in/cm x 72pt/in x 1.33px/pt = 68px
    	setPaddingVariable(this, 'top', 'topmargin', 38, 15);
    	setPaddingVariable(this, 'bottom', 'botmargin', 38, 15);
    	setPaddingVariable(this, 'left', 'leftmargin', 68, 15);
    	setPaddingVariable(this, 'right', 'rightmargin', 68, 15);
    };

    /**
     * Some of the items on the page are not scaled, so adjust them in the opposite direction of scaling to cancel out the scaling.
     * @param {float} scale
     */
    Renderer.prototype.adjustNonScaledItems = function (scale) {
    	this.padding.top /= scale;
    	this.padding.bottom /= scale;
    	this.padding.left /= scale;
    	this.padding.right /= scale;
    	this.abctune.formatting.headerfont.size /= scale;
    	this.abctune.formatting.footerfont.size /= scale;
    };

    /**
     * Set the the values for all the configurable vertical space options.
     */
    Renderer.prototype.initVerticalSpace = function() {
    	// conversion: 37.7953 = conversion factor for cm to px.
    	// All of the following values are in px.
    	this.spacing = {
    		composer: 7.56, // Set the vertical space above the composer.
    		graceBefore: 8.67, // Define the space before, inside and after the grace notes.
    		graceInside: 10.67,
    		graceAfter: 16,
    		info: 0, // Set the vertical space above the infoline.
    		lineSkipFactor: 1.1, // Set the factor for spacing between lines of text. (multiply this by the font size)
    		music: 7.56, // Set the vertical space above the first staff.
    		paragraphSkipFactor: 0.4, // Set the factor for spacing between text paragraphs. (multiply this by the font size)
    		parts: 11.33, // Set the vertical space above a new part.
    		slurHeight: 1.0, // Set the slur height factor.
    		staffSeparation: 61.33, // Do not put a staff system closer than <unit> from the previous system.
    		stemHeight: 26.67+10, // Set the stem height.
    		subtitle: 3.78, // Set the vertical space above the subtitle.
    		systemStaffSeparation: 48, // Do not place the staves closer than <unit> inside a system. * This values applies to all staves when in the tune header. Otherwise, it applies to the next staff
    		text: 18.9, // Set the vertical space above the history.
    		title: 7.56, // Set the vertical space above the title.
    		top: 30.24, //Set the vertical space above the tunes and on the top of the continuation pages.
    		vocal: 30.67, // Set the vertical space above the lyrics under the staves.
    		words: 0 // Set the vertical space above the lyrics at the end of the tune.
    	};
    	/*
    	TODO-PER: Handle the x-coordinate spacing items, too.
    maxshrink <float>Default: 0.65
    Set how much to compress horizontally when music line breaks
    are automatic.
    <float> must be between 0 (natural spacing)
    and 1 (max shrinking).

    // This next value is used to compute the natural spacing of
    // the notes. The base spacing of the crotchet is always
    // 40 pts. When the duration of a note type is twice the
    // duration of an other note type, its spacing is multiplied
    // by this factor.
    // The default value causes the note spacing to be multiplied
    // by 2 when its duration is multiplied by 4, i.e. the
    // space of the semibreve is 80 pts and the space of the
    // semiquaver is 20 pts.
    // Setting this value to 1 sets all note spacing to 40 pts.
    noteSpacingFactor: 1.414, // Set the note spacing factor to <float> (range 1..2).

    scale <float> Default: 0.75 Set the page scale factor. Note that the header and footer are not scaled.

    stretchlast <float>Default: 0.8
    Stretch the last music line of a tune when it exceeds
    the <float> fraction of the page width.
    <float> range is 0.0 to 1.0.
    	 */
    };

    Renderer.prototype.setVerticalSpace = function(formatting) {
    	// conversion from pts to px 4/3
    	if (formatting.staffsep !== undefined)
    		this.spacing.staffSeparation = formatting.staffsep *4/3;
    	if (formatting.composerspace !== undefined)
    		this.spacing.composer = formatting.composerspace *4/3;
    	if (formatting.partsspace !== undefined)
    		this.spacing.parts = formatting.partsspace *4/3;
    	if (formatting.textspace !== undefined)
    		this.spacing.text = formatting.textspace *4/3;
    	if (formatting.musicspace !== undefined)
    		this.spacing.music = formatting.musicspace *4/3;
    	if (formatting.titlespace !== undefined)
    		this.spacing.title = formatting.titlespace *4/3;
    	if (formatting.sysstaffsep !== undefined)
    		this.spacing.systemStaffSeparation = formatting.sysstaffsep *4/3;
    	if (formatting.subtitlespace !== undefined)
    		this.spacing.subtitle = formatting.subtitlespace *4/3;
    	if (formatting.topspace !== undefined)
    		this.spacing.top = formatting.topspace *4/3;
    	if (formatting.vocalspace !== undefined)
    		this.spacing.vocal = formatting.vocalspace *4/3;
    	if (formatting.wordsspace !== undefined)
    		this.spacing.words = formatting.wordsspace *4/3;
    };

    /**
     * Leave space at the top of the paper
     * @param {object} abctune
     */
    Renderer.prototype.topMargin = function(abctune) {
    		this.moveY(this.padding.top);
    };

    /**
     * Leave space before printing the music
     */
    Renderer.prototype.addMusicPadding = function() {
    		this.moveY(this.spacing.music);
    };

    /**
     * Leave space before printing a staff system
     */
    Renderer.prototype.addStaffPadding = function(lastStaffGroup, thisStaffGroup) {
    	var lastStaff = lastStaffGroup.staffs[lastStaffGroup.staffs.length-1];
    	var lastBottomLine = -(lastStaff.bottom - 2); // The 2 is because the scale goes to 2 below the last line.
    	var nextTopLine = thisStaffGroup.staffs[0].top - 10; // Because 10 represents the top line.
    	var naturalSeparation = nextTopLine + lastBottomLine; // This is how far apart they'd be without extra spacing
    	var separationInPixels = naturalSeparation * abc_spacing.STEP;
    	if (separationInPixels < this.spacing.staffSeparation)
    		this.moveY(this.spacing.staffSeparation-separationInPixels);
    };

    /**
     * Text that goes above the score
     * @param {number} width
     * @param {object} abctune
     */
    Renderer.prototype.engraveTopText = function(width, abctune) {
    	if (abctune.metaText.header && this.isPrint) {
    		// Note: whether there is a header or not doesn't change any other positioning, so this doesn't change the Y-coordinate.
    		// This text goes above the margin, so we'll temporarily move up.
    		var headerTextHeight = this.getTextSize("XXXX", "headerfont", 'abcjs-header abcjs-meta-top').height;
    		this.y -=headerTextHeight;
    		this.outputTextIf(this.padding.left, abctune.metaText.header.left, 'headerfont', 'header meta-top', 0, null, 'start');
    		this.outputTextIf(this.padding.left + width / 2, abctune.metaText.header.center, 'headerfont', 'header meta-top', 0, null, 'middle');
    		this.outputTextIf(this.padding.left + width, abctune.metaText.header.right, 'headerfont', 'header meta-top', 0, null, 'end');
    		this.y += headerTextHeight;
    	}
    	if (this.isPrint)
    		this.moveY(this.spacing.top);
    	this.outputTextIf(this.padding.left + width / 2, abctune.metaText.title, 'titlefont', 'title meta-top', this.spacing.title, 0, 'middle');
    	if (abctune.lines[0])
    		this.outputTextIf(this.padding.left + width / 2, abctune.lines[0].subtitle, 'subtitlefont', 'text meta-top', this.spacing.subtitle, 0, 'middle');

    	if (abctune.metaText.rhythm || abctune.metaText.origin || abctune.metaText.composer) {
    		this.moveY(this.spacing.composer);
    		var rSpace = this.outputTextIf(this.padding.left, abctune.metaText.rhythm, 'infofont', 'meta-top', 0, null, "start");

    		var composerLine = "";
    		if (abctune.metaText.composer) composerLine += abctune.metaText.composer;
    		if (abctune.metaText.origin) composerLine += ' (' + abctune.metaText.origin + ')';
    		if (composerLine.length > 0) {
    			var space = this.outputTextIf(this.padding.left + width, composerLine, 'composerfont', 'meta-top', 0, null, "end");
    			this.moveY(space[1]);
    		} else {
    			this.moveY(rSpace[1]);
    		}
    		// TODO-PER: The following is a hack to make the elements line up with abcm2ps. Don't know where the extra space is coming from.
    		this.moveY(-6);
    	//} else if (this.isPrint) {
    	//	// abcm2ps adds this space whether there is anything to write or not.
    	//	this.moveY(this.spacing.composer);
    	//	var space2 = this.getTextSize("M", 'composerfont', 'meta-top');
    	//	this.moveY(space2.height);
    	}

    	this.outputTextIf(this.padding.left + width, abctune.metaText.author, 'composerfont', 'meta-top', 0, 0, "end");
    	//this.skipSpaceY();

    	this.outputTextIf(this.padding.left, abctune.metaText.partOrder, 'partsfont', 'meta-bottom', 0, 0, "start");
    };

    /**
     * Text that goes below the score
     * @param {number} width
     * @param {object} abctune
     */
    Renderer.prototype.engraveExtraText = function(width, abctune) {
    	this.lineNumber = null;
    	this.measureNumber = null;
    	this.noteNumber = null;
    	this.voiceNumber = null;

    	if (abctune.metaText.unalignedWords) {
    		var hash = this.getFontAndAttr("wordsfont", 'meta-bottom');
    		var space = this.getTextSize("i", 'wordsfont', 'meta-bottom');

    		if (abctune.metaText.unalignedWords.length > 0)
    			this.moveY(this.spacing.words, 1);
    		for (var j = 0; j < abctune.metaText.unalignedWords.length; j++) {
    			if (abctune.metaText.unalignedWords[j] === '')
    				this.moveY(hash.font.size, 1);
    			else if (typeof abctune.metaText.unalignedWords[j] === 'string') {
    				this.outputTextIf(this.padding.left + abc_spacing.INDENT, abctune.metaText.unalignedWords[j], 'wordsfont', 'meta-bottom', 0, 0, "start");
    			} else {
    				var largestY = 0;
    				var offsetX = 0;
    				for (var k = 0; k < abctune.metaText.unalignedWords[j].length; k++) {
    					var thisWord = abctune.metaText.unalignedWords[j][k];
    					var type = (thisWord.font) ? thisWord.font : "wordsfont";
    					var el = this.renderText(this.padding.left + abc_spacing.INDENT + offsetX, this.y, thisWord.text, type, 'meta-bottom', false);
    					var size = this.getTextSize(thisWord.text, type, 'meta-bottom');
    					largestY = Math.max(largestY, size.height);
    					offsetX += size.width;
    					// If the phrase ends in a space, then that is not counted in the width, so we need to add that in ourselves.
    					if (thisWord.text[thisWord.text.length-1] === ' ') {
    						offsetX += space.width;
    					}
    				}
    				this.moveY(largestY, 1);
    			}
    		}
    		if (abctune.metaText.unalignedWords.length > 0)
    			this.moveY(hash.font.size, 2);
    	}

    	var extraText = "";
    	if (abctune.metaText.book) extraText += "Book: " + abctune.metaText.book + "\n";
    	if (abctune.metaText.source) extraText += "Source: " + abctune.metaText.source + "\n";
    	if (abctune.metaText.discography) extraText += "Discography: " + abctune.metaText.discography + "\n";
    	if (abctune.metaText.notes) extraText += "Notes: " + abctune.metaText.notes + "\n";
    	if (abctune.metaText.transcription) extraText += "Transcription: " + abctune.metaText.transcription + "\n";
    	if (abctune.metaText.history) extraText += "History: " + abctune.metaText.history + "\n";
    	if (abctune.metaText['abc-copyright']) extraText += "Copyright: " + abctune.metaText['abc-copyright'] + "\n";
    	if (abctune.metaText['abc-creator']) extraText += "Creator: " + abctune.metaText['abc-creator'] + "\n";
    	if (abctune.metaText['abc-edited-by']) extraText += "Edited By: " + abctune.metaText['abc-edited-by'] + "\n";
    	this.outputTextIf(this.padding.left, extraText, 'historyfont', 'meta-bottom', this.spacing.info, 0, "start");

    	if (abctune.metaText.footer && this.isPrint) {
    		// Note: whether there is a footer or not doesn't change any other positioning, so this doesn't change the Y-coordinate.
    		this.outputTextIf(this.padding.left, abctune.metaText.footer.left, 'footerfont', 'header meta-bottom', 0, null, 'start');
    		this.outputTextIf(this.padding.left + width / 2, abctune.metaText.footer.center, 'footerfont', 'header meta-bottom', 0, null, 'middle');
    		this.outputTextIf(this.padding.left + width, abctune.metaText.footer.right, 'footerfont', 'header meta-bottom', 0, null, 'end');
    	}
    };

    /**
     * Output text defined with %%text.
     * @param {array or string} text
     */
    Renderer.prototype.outputFreeText = function (text, vskip) {
    	if (vskip)
    		this.moveY(vskip);
    	var hash = this.getFontAndAttr('textfont', 'defined-text');
    	if (text === "") {	// we do want to print out blank lines if they have been specified.
    		this.moveY(hash.attr['font-size'] * 2); // move the distance of the line, plus the distance of the margin, which is also one line.
    	} else if (typeof text === 'string') {
    		this.moveY(hash.attr['font-size']/2); // TODO-PER: move down some - the y location should be the top of the text, but we output text specifying the center line.
    		this.outputTextIf(this.padding.left, text, 'textfont', 'defined-text', 0, 0, "start");
    	} else {
    		var str = "";
    		var isCentered = false; // The structure is wrong here: it requires an array to do centering, but it shouldn't have.
    		for (var i = 0; i < text.length; i++) {
    			if (text[i].font)
    				str += "FONT(" + text[i].font + ")";
    			str += text[i].text;
    			if (text[i].center)
    				isCentered = true;
    		}
    		var alignment = isCentered ? 'middle' : 'start';
    		var x = isCentered ? this.controller.width / 2 : this.padding.left;
    		this.outputTextIf(x, str, 'textfont', 'defined-text', 0, 1, alignment);
    	}
    };

    Renderer.prototype.outputSeparator = function (separator) {
    	if (!separator.lineLength)
    		return;
    	this.moveY(separator.spaceAbove);
    	this.printSeparator(separator.lineLength);
    	this.moveY(separator.spaceBelow);
    };

    /**
     * Output an extra subtitle that is defined later in the tune.
     */
    Renderer.prototype.outputSubtitle = function (width, subtitle) {
    	this.outputTextIf(this.padding.left + width / 2, subtitle, 'subtitlefont', 'text meta-top', this.spacing.subtitle, 0, 'middle');
    };

    /**
     * Begin a group of glyphs that will always be moved, scaled and highlighted together
     */
    Renderer.prototype.beginGroup = function () {
      this.path = [];
      this.lastM = [0,0];
      this.ingroup = true;
    };

    /**
     * Add a path to the current group
     * @param {Array} path
     * @private
     */
    Renderer.prototype.addPath = function (path) {
      path = path || [];
      if (path.length===0) return;
      path[0][0]="m";
      path[0][1]-=this.lastM[0];
      path[0][2]-=this.lastM[1];
      this.lastM[0]+=path[0][1];
      this.lastM[1]+=path[0][2];
      this.path.push(path[0]);
      for (var i=1,ii=path.length;i<ii;i++) {
        if (path[i][0]==="m") {
          this.lastM[0]+=path[i][1];
          this.lastM[1]+=path[i][2];
        }
        this.path.push(path[i]);
      }
    };

    /**
     * End a group of glyphs that will always be moved, scaled and highlighted together
     */
    Renderer.prototype.endGroup = function (klass) {
      this.ingroup = false;
      if (this.path.length===0) return null;
      var path = "";
    	for (var i = 0; i < this.path.length; i++)
    		path += this.path[i].join(" ");
    	var ret = this.paper.path({path: path, stroke:"none", fill:"#000000", 'class': this.addClasses(klass)});
    	this.path = [];
      if (this.doRegression) this.addToRegression(ret);

      return ret;
    };

    /**
     * gets scaled
     * @param {number} x1 start x
     * @param {number} x2 end x
     * @param {number} pitch pitch the stave line is drawn at
     */
    Renderer.prototype.printStaveLine = function (x1,x2, pitch, klass) {
    	var extraClass = "staff";
    	if (klass !== undefined)
    		extraClass += " " + klass;
      var dy = 0.35;
      var fill = "#000000";
      var y = this.calcY(pitch);
      var pathString = sprintf_1("M %f %f L %f %f L %f %f L %f %f z", x1, y-dy, x2, y-dy,
         x2, y+dy, x1, y+dy);
      var ret = this.paper.pathToBack({path:pathString, stroke:"none", fill:fill, 'class': this.addClasses(extraClass)});
      if (this.doRegression) this.addToRegression(ret);

      return ret;
    };

    /**
     * gets scaled if not in a group
     * @param {number} x x coordinate of the stem
     * @param {number} dx stem width
     * @param {number} y1 y coordinate of the stem bottom
     * @param {number} y2 y coordinate of the stem top
     */
    Renderer.prototype.printStem = function (x, dx, y1, y2) {
      if (dx<0) { // correct path "handedness" for intersection with other elements
        var tmp = y2;
        y2 = y1;
        y1 = tmp;
      }
      var fill = "#000000";
      if (~~x === x) x+=0.05; // raphael does weird rounding (for VML)
      var pathArray = [["M",x,y1],["L", x, y2],["L", x+dx, y2],["L",x+dx,y1],["z"]];
      if ( this.ingroup) {
        this.addPath(pathArray);
      } else {
      	var path = "";
      	for (var i = 0; i < pathArray.length; i++)
      		path += pathArray[i].join(" ");
        var ret = this.paper.pathToBack({path:path, stroke:"none", fill:fill, 'class': this.addClasses('stem')});
        if (this.doRegression) this.addToRegression(ret);

        return ret;
      }
    };

    function kernSymbols(lastSymbol, thisSymbol, lastSymbolWidth) {
    	// This is just some adjustments to make it look better.
    	var width = lastSymbolWidth;
    	if (lastSymbol === 'f' && thisSymbol === 'f')
    		width = width*2/3;
    	if (lastSymbol === 'p' && thisSymbol === 'p')
    		width = width*5/6;
    	if (lastSymbol === 'f' && thisSymbol === 'z')
    		width = width*5/8;
    	return width;
    }

    /**
     * assumes this.y is set appropriately
     * if symbol is a multichar string without a . (as in scripts.staccato) 1 symbol per char is assumed
     * not scaled if not in printgroup
     */
    Renderer.prototype.printSymbol = function (x, offset, symbol, scalex, scaley, klass) {
    	var el;
    	var ycorr;
    	if (!symbol) return null;
    	if (symbol.length > 1 && symbol.indexOf(".") < 0) {
    		this.paper.openGroup();
    		var dx = 0;
    		for (var i = 0; i < symbol.length; i++) {
    			var s = symbol.charAt(i);
    			ycorr = abc_glyphs.getYCorr(s);
    			el = abc_glyphs.printSymbol(x + dx, this.calcY(offset + ycorr), s, this.paper, klass);
    			if (el) {
    				if (this.doRegression) this.addToRegression(el);
    				//elemset.push(el);
    				if (i < symbol.length - 1)
    					dx += kernSymbols(s, symbol.charAt(i + 1), abc_glyphs.getSymbolWidth(s));
    			} else {
    				this.renderText(x, this.y, "no symbol:" + symbol, "debugfont", 'debug-msg', 'start');
    			}
    		}
    		return this.paper.closeGroup();
    	} else {
    		ycorr = abc_glyphs.getYCorr(symbol);
    		if (this.ingroup) {
    			this.addPath(abc_glyphs.getPathForSymbol(x, this.calcY(offset + ycorr), symbol, scalex, scaley));
    		} else {
    			el = abc_glyphs.printSymbol(x, this.calcY(offset + ycorr), symbol, this.paper, klass);
    			if (el) {
    				if (this.doRegression) this.addToRegression(el);
    				return el;
    			} else
    				this.renderText(x, this.y, "no symbol:" + symbol, "debugfont", 'debug-msg', 'start');
    		}
    		return null;
    	}
    };

    Renderer.prototype.scaleExistingElem = function (elem, scaleX, scaleY, x, y) {
    	this.paper.setAttributeOnElement(elem, { style: "transform:scale("+scaleX+","+scaleY + ");transform-origin:" + x + "px " + y + "px;"});
    };

    Renderer.prototype.printPath = function (attrs) {
      var ret = this.paper.path(attrs);
      if (this.doRegression) this.addToRegression(ret);
      return ret;
    };

    Renderer.prototype.drawBrace = function(xLeft, yTop, yBottom) {//Tony
    	var yHeight = yBottom - yTop;

    	var xCurve = [7.5, -8, 21, 0, 18.5, -10.5, 7.5];
    	var yCurve = [0, yHeight/5.5, yHeight/3.14, yHeight/2, yHeight/2.93, yHeight/4.88, 0];

    	var pathString = sprintf_1("M %f %f C %f %f %f %f %f %f C %f %f %f %f %f %f z",
    		xLeft+xCurve[0], yTop+yCurve[0],
    		xLeft+xCurve[1], yTop+yCurve[1],
    		xLeft+xCurve[2], yTop+yCurve[2],
    		xLeft+xCurve[3], yTop+yCurve[3],
    		xLeft+xCurve[4], yTop+yCurve[4],
    		xLeft+xCurve[5], yTop+yCurve[5],
    		xLeft+xCurve[6], yTop+yCurve[6]);
    	var ret1 = this.paper.path({path:pathString, stroke:"#000000", fill:"#000000", 'class': this.addClasses('brace')});

    	xCurve = [0, 17.5, -7.5, 6.6, -5, 20, 0];
    	yCurve = [yHeight/2, yHeight/1.46, yHeight/1.22, yHeight, yHeight/1.19, yHeight/1.42, yHeight/2];

    	pathString = sprintf_1("M %f %f C %f %f %f %f %f %f C %f %f %f %f %f %f z",
    		xLeft+xCurve[ 0], yTop+yCurve[0],
    		xLeft+xCurve[1], yTop+yCurve[1],
    		xLeft+xCurve[2], yTop+yCurve[2],
    		xLeft+xCurve[3], yTop+yCurve[3],
    		xLeft+xCurve[4], yTop+yCurve[4],
    		xLeft+xCurve[5], yTop+yCurve[5],
    		xLeft+xCurve[6], yTop+yCurve[6]);
    	var ret2 = this.paper.path({path:pathString, stroke:"#000000", fill:"#000000", 'class': this.addClasses('brace')});

    	if (this.doRegression){
    		this.addToRegression(ret1);
    		this.addToRegression(ret2);
    	}
    	return ret1 + ret2;
    };

    Renderer.prototype.drawArc = function(x1, x2, pitch1, pitch2, above, klass, isTie) {
    	// If it is a tie vs. a slur, draw it shallower.
    	var spacing = isTie ? 1.2 : 1.5;

      x1 = x1 + 6;
      x2 = x2 + 4;
      pitch1 = pitch1 + ((above)?spacing:-spacing);
      pitch2 = pitch2 + ((above)?spacing:-spacing);
      var y1 = this.calcY(pitch1);
      var y2 = this.calcY(pitch2);

      //unit direction vector
      var dx = x2-x1;
      var dy = y2-y1;
      var norm= Math.sqrt(dx*dx+dy*dy);
      var ux = dx/norm;
      var uy = dy/norm;

      var flatten = norm/3.5;
      var maxFlatten = isTie ? 10 : 25;  // If it is a tie vs. a slur, draw it shallower.
      var curve = ((above)?-1:1)*Math.min(maxFlatten, Math.max(4, flatten));

      var controlx1 = x1+flatten*ux-curve*uy;
      var controly1 = y1+flatten*uy+curve*ux;
      var controlx2 = x2-flatten*ux-curve*uy;
      var controly2 = y2-flatten*uy+curve*ux;
      var thickness = 2;
      var pathString = sprintf_1("M %f %f C %f %f %f %f %f %f C %f %f %f %f %f %f z", x1, y1,
         controlx1, controly1, controlx2, controly2, x2, y2,
         controlx2-thickness*uy, controly2+thickness*ux, controlx1-thickness*uy, controly1+thickness*ux, x1, y1);
    	if (klass)
    		klass += ' slur';
    	else
    		klass = 'slur';
      var ret = this.paper.path({path:pathString, stroke:"none", fill:"#000000", 'class': this.addClasses(klass)});
      if (this.doRegression) this.addToRegression(ret);

      return ret;
    };
    /**
     * Calculates the y for a given pitch value (relative to the stave the renderer is currently printing)
     * @param {number} ofs pitch value (bottom C on a G clef = 0, D=1, etc.)
     */
    Renderer.prototype.calcY = function(ofs) {
      return this.y - ofs*abc_spacing.STEP;
    };

    /**
     * Print @param {number} numLines. If there is 1 line it is the B line. Otherwise the bottom line is the E line.
     */
    Renderer.prototype.printStave = function (startx, endx, numLines) {
    	var klass = "top-line";
    	this.paper.openGroup({ prepend: true });
    	// If there is one line, it is the B line. Otherwise, the bottom line is the E line.
    	if (numLines === 1) {
    		this.printStaveLine(startx,endx,6, klass);
    		return;
    	}
    	for (var i = numLines-1; i >= 0; i--) {
    		this.printStaveLine(startx,endx,(i+1)*2, klass);
    		klass = undefined;
    	}
    	this.paper.closeGroup();
    };

    /**
     *
     * @private
     */
    Renderer.prototype.addClasses = function (c, isNote) {
    	if (!this.shouldAddClasses)
    		return "";
    	var ret = [];
    	if (c.length > 0) ret.push(c);
    	if (this.lineNumber !== null && this.lineNumber !== undefined) ret.push("l"+this.lineNumber);
    	if (this.measureNumber !== null && this.measureNumber !== undefined) ret.push("m"+this.measureNumber);
    	if (this.voiceNumber !== null && this.voiceNumber !== undefined) ret.push("v"+this.voiceNumber);
    	if ((c.indexOf('note') >= 0 || c.indexOf('rest') >= 0 || c.indexOf('lyric') >= 0 ) && this.noteNumber !== null && this.noteNumber !== undefined) ret.push("n"+this.noteNumber);
    	// add a prefix to all classes that abcjs adds.
    	if (ret.length > 0) {
    		ret = ret.join(' '); // Some strings are compound classes - that is, specify more than one class in a string.
    		ret = ret.split(' ');
    		for (var i = 0; i < ret.length; i++) {
    			if (ret[i].indexOf('abcjs-') !== 0 && ret[i].length > 0) // if the prefix doesn't already exist and the class is not blank.
    				ret[i] = 'abcjs-' + ret[i];
    		}
    	}
    	return ret.join(' ');
    };

    Renderer.prototype.getFontAndAttr = function(type, klass) {
    	var font;
    	if (typeof type === 'string') {
    		font = this.abctune.formatting[type];
    		// Raphael deliberately changes the font units to pixels for some reason, so we need to change points to pixels here.
    		if (font)
    			font = {face: font.face, size: font.size * 4 / 3, decoration: font.decoration, style: font.style, weight: font.weight, box: font.box};
    		else
    			font = {face: "Arial", size: 12 * 4 / 3, decoration: "underline", style: "normal", weight: "normal"};
    	} else
    		font = {face: type.face, size: type.size * 4 / 3, decoration: type.decoration, style: type.style, weight: type.weight, box: type.box};

    	var attr = {"font-size": font.size, 'font-style': font.style,
    		"font-family": font.face, 'font-weight': font.weight, 'text-decoration': font.decoration,
    		'class': this.addClasses(klass) };
    	attr.font = "";	// There is a spurious font definition that is put on all text elements. This overwrites it.
    	return { font: font, attr: attr };
    };

    Renderer.prototype.getTextSize = function(text, type, klass, el) {
    	var hash = this.getFontAndAttr(type, klass);
    	var size = this.paper.getTextSize(text, hash.attr, el);
    	if (hash.font.box) {
    		size.height += 8;
    		size.width += 8;
    	}
    	return size;
    };

    Renderer.prototype.renderText = function(x, y, text, type, klass, anchor, centerVertically) {
    	var hash = this.getFontAndAttr(type, klass);
    	if (anchor)
    		hash.attr["text-anchor"] = anchor;
    	hash.attr.x = x;
    	hash.attr.y = y + 7; // TODO-PER: Not sure why the text appears to be 7 pixels off.
    	if (!centerVertically)
    		hash.attr.dy = "0.5em";
    	if (type === 'debugfont') {
    		console.log("Debug msg: " + text);
    		hash.attr.stroke = "#ff0000";
    	}

    	text = text.replace(/\n\n/g, "\n \n");
    	text = text.replace(/^\n/, "\xA0\n");

    	if (hash.font.box) {
    		hash.attr.x += 2;
    		hash.attr.y += 4;
    	}
    	var el = this.paper.text(text, hash.attr);

    	if (hash.font.box) {
    		var size = this.getTextSize(text, type, klass);
    		var padding = 2;
    		var margin = 2;
    		this.paper.rect({ x: x - padding, y: y, width: size.width + padding*2, height: size.height + padding*2 - margin,  stroke: "#888888", fill: "transparent"});
    		//size.height += 8;
    	}
    	if (this.doRegression) this.addToRegression(el);
    	return el;
    };

    Renderer.prototype.moveY = function (em, numLines) {
    	if (numLines === undefined) numLines = 1;
    	this.y += em*numLines;
    };

    Renderer.prototype.skipSpaceY = function () {
    	this.y += this.space;
    };

    // Call with 'kind' being the font type to use,
    // if marginBottom === null then don't increment the Y after printing, otherwise that is the extra number of em's to leave below the line.
    // and alignment being "start", "middle", or "end".
    Renderer.prototype.outputTextIf = function(x, str, kind, klass, marginTop, marginBottom, alignment) {
    	if (str) {
    		if (marginTop)
    			this.moveY(marginTop);
    		var el = this.renderText(x, this.y, str, kind, klass, alignment);
    		var bb = this.getTextSize(str, kind, klass);
    		var width = isNaN(bb.width) ? 0 : bb.width;
    		var height = isNaN(bb.height) ? 0 : bb.height;
    		var hash = this.getFontAndAttr(kind, klass);
    		if (hash.font.box) {
    			width += 8;
    			height += 8;
    		}
    		if (marginBottom !== null) {
    			var numLines = str.split("\n").length;
    			if (!isNaN(bb.height))
    				this.moveY(height/numLines, (numLines + marginBottom));
    		}
    		return [width, height];
    	}
    	return [0,0];
    };

    Renderer.prototype.addInvisibleMarker = function (className) {
    	var dy = 0.35;
    	var fill = "rgba(0,0,0,0)";
    	var y = this.y;
    	y = Math.round(y);
    	var x1 = 0;
    	var x2 = 100;
    	var pathString = sprintf_1("M %f %f L %f %f L %f %f L %f %f z", x1, y-dy, x1+x2, y-dy,
    		x2, y+dy, x1, y+dy);
    	this.paper.pathToBack({path:pathString, stroke:"none", fill:fill, "fill-opacity": 0, 'class': this.addClasses(className), 'data-vertical': y });
    };

    Renderer.prototype.printSeparator = function(width) {
    	var fill = "rgba(0,0,0,255)";
    	var stroke = "rgba(0,0,0,0)";
    	var y = Math.round(this.y);
    	var staffWidth = this.controller.width;
    	var x1 = (staffWidth - width)/2;
    	var x2 = x1 + width;
    	var pathString = 'M ' + x1 + ' ' + y +
    		' L ' + x2 + ' ' + y +
    		' L ' + x2 + ' ' + (y+1) +
    		' L ' + x1 + ' ' + (y+1) +
    		' L ' + x1 + ' ' + y + ' z';
    	this.paper.pathToBack({path:pathString, stroke:stroke, fill:fill, 'class': this.addClasses('defined-text')});
    };

    // For debugging, it is sometimes useful to know where you are vertically.
    Renderer.prototype.printHorizontalLine = function (width, vertical, comment) {
    	var dy = 0.35;
    	var fill = "rgba(0,0,255,.4)";
    	var y = this.y;
    	if (vertical) y = vertical;
    	y = Math.round(y);
    	this.paper.text(""+Math.round(y), {x: 10, y: y, "text-anchor": "start", "font-size":"18px", fill: fill, stroke: fill });
    	var x1 = 50;
    	var x2 = width;
    	var pathString = sprintf_1("M %f %f L %f %f L %f %f L %f %f z", x1, y-dy, x1+x2, y-dy,
    		x2, y+dy, x1, y+dy);
    	this.paper.pathToBack({path:pathString, stroke:"none", fill:fill, 'class': this.addClasses('staff')});
    	for (var i = 1; i < width/100; i++) {
    		pathString = sprintf_1("M %f %f L %f %f L %f %f L %f %f z", i*100-dy, y-5, i*100-dy, y+5,
    			i*100+dy, y-5, i*100+dy, y+5);
    		this.paper.pathToBack({path:pathString, stroke:"none", fill:fill, 'class': this.addClasses('staff')});
    	}
    	if (comment)
    		this.paper.text(comment, {x: width+70, y: y, "text-anchor": "start", "font-size":"18px", fill: fill, stroke: fill });
    };

    Renderer.prototype.printShadedBox = function (x, y, width, height, color, opacity, comment) {
    	var box = this.paper.rect({ x: x, y: y, width: width, height: height, fill: color, stroke: color, "fill-opacity": opacity, "stroke-opacity": opacity });
    	if (comment)
    		this.paper.text(comment, {x: 0, y: y+7, "text-anchor": "start", "font-size":"14px", fill: "rgba(0,0,255,.4)", stroke: "rgba(0,0,255,.4)" });
    	return box;
    };

    Renderer.prototype.printVerticalLine = function (x, y1, y2) {
    	var dy = 0.35;
    	var fill = "#00aaaa";
    	var pathString = sprintf_1("M %f %f L %f %f L %f %f L %f %f z", x - dy, y1, x - dy, y2,
    			x + dy, y1, x + dy, y2);
    	this.paper.pathToBack({path: pathString, stroke: "none", fill: fill, 'class': this.addClasses('staff')});
    	pathString = sprintf_1("M %f %f L %f %f L %f %f L %f %f z", x - 20, y1, x - 20, y1+3,
    		x, y1, x, y1+3);
    	this.paper.pathToBack({path: pathString, stroke: "none", fill: fill, 'class': this.addClasses('staff')});
    	pathString = sprintf_1("M %f %f L %f %f L %f %f L %f %f z", x + 20, y2, x + 20, y2+3,
    		x, y2, x, y2+3);
    	this.paper.pathToBack({path: pathString, stroke: "none", fill: fill, 'class': this.addClasses('staff')});

    };

    /**
     * @private
     */
    Renderer.prototype.addToRegression = function (el) {
    	var box;
    	try {
    		box = el.getBBox();
    	} catch(e) {
    		box = { width: 0, height: 0 };
    	}
    	//var str = "("+box.x+","+box.y+")["+box.width+","+box.height+"] "
    	var str = el.type + ' ' + box.toString() + ' ';
    	var attrs = [];
    	for (var key in el.attrs) {
    		if (el.attrs.hasOwnProperty(key)) {
    			if (key === 'class')
    				str = el.attrs[key] + " " + str;
    			else
    				attrs.push(key+": "+el.attrs[key]);
    		}
    	}
    	attrs.sort();
    	str += "{ " +attrs.join(" ") + " }";
    	this.regressionLines.push(str);
    };

    var abc_renderer = Renderer;

    //    abc_engraver_controller.js: Controls the engraving process of an ABCJS abstract syntax tree as produced by ABCJS/parse
    //    Copyright (C) 2014-2018 Gregory Dyke (gregdyke at gmail dot com)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


    /*global Math */

    var spacing$1 = abc_spacing;



    /**
     * @class
     * Controls the engraving process, from ABCJS Abstract Syntax Tree (ABCJS AST) to rendered score sheet
     *
     * Call engraveABC to run the process. This creates a graphelems ABCJS Abstract Engraving Structure (ABCJS AES) that can be accessed through this.staffgroups
     * this data structure is first laid out (giving the graphelems x and y coordinates) and then drawn onto the renderer
     * each ABCJS AES represents a single staffgroup - all elements that are not in a staffgroup are rendered directly by the controller
     *
     * elements in ABCJS AES know their "source data" in the ABCJS AST, and their "target shape"
     * in the renderer for highlighting purposes
     *
     * @param {Object} paper div element that will wrap the SVG
     * @param {Object} params all the params -- documented on github //TODO-GD move some of that documentation here
     */
    var EngraverController = function(paper, params) {
      params = params || {};
      this.responsive = params.responsive;
      this.space = 3*spacing$1.SPACE;
      this.scale = params.scale ? parseFloat(params.scale) : 0;
      if (!(this.scale > 0.1))
      	this.scale = undefined;

    	if (params.staffwidth) {
    		// Note: Normally all measurements to the engraver are in POINTS. However, if a person is formatting for the
    		// screen and directly inputting the width, then it is more logical to have the measurement in pixels.
    		this.staffwidthScreen = params.staffwidth;
    		this.staffwidthPrint = params.staffwidth;
    	} else {
    		this.staffwidthScreen = 740; // TODO-PER: Not sure where this number comes from, but this is how it's always been.
    		this.staffwidthPrint = 680; // The number of pixels in 8.5", after 1cm of margin has been removed.
    	}
      this.editable = params.editable || false;
    	this.listeners = [];
    	if (params.clickListener)
    		this.addSelectListener(params.clickListener);

      this.renderer=new abc_renderer(paper, params.regression, params.add_classes);
    	this.renderer.setPaddingOverride(params);
      this.renderer.controller = this; // TODO-GD needed for highlighting

    	this.reset();
    };

    EngraverController.prototype.reset = function() {
    	this.selected = [];
    	this.ingroup = false;
    	this.staffgroups = [];
    	this.lastStaffGroupIndex = -1;
    	if (this.engraver)
    		this.engraver.reset();
    	this.engraver = null;
    	this.renderer.reset();
    };

    /**
     * run the engraving process
     * @param {ABCJS.Tune|ABCJS.Tune[]} abctunes
     */
    EngraverController.prototype.engraveABC = function(abctunes, tuneNumber) {
      if (abctunes[0]===undefined) {
        abctunes = [abctunes];
      }
    	this.reset();

      for (var i = 0; i < abctunes.length; i++) {
      	if (tuneNumber === undefined)
      		tuneNumber = i;
        this.engraveTune(abctunes[i], tuneNumber);
      }
    	if (this.renderer.doRegression)
    		return this.renderer.regressionLines.join("\n");
    };

    /**
     * Some of the items on the page are not scaled, so adjust them in the opposite direction of scaling to cancel out the scaling.
     * @param {float} scale
     */
    EngraverController.prototype.adjustNonScaledItems = function (scale) {
    	this.width /= scale;
    	this.renderer.adjustNonScaledItems(scale);
    };

    EngraverController.prototype.getMeasureWidths = function(abcTune) {
    	this.reset();

    	this.renderer.lineNumber = null;

    	this.renderer.newTune(abcTune);
    	this.engraver = new abc_abstract_engraver(this.renderer, 0, { bagpipes: abcTune.formatting.bagpipes, flatbeams: abcTune.formatting.flatbeams });
    	this.engraver.setStemHeight(this.renderer.spacing.stemHeight);
    	if (abcTune.formatting.staffwidth) {
    		this.width = abcTune.formatting.staffwidth * 1.33; // The width is expressed in pt; convert to px.
    	} else {
    		this.width = this.renderer.isPrint ? this.staffwidthPrint : this.staffwidthScreen;
    	}

    	var scale = abcTune.formatting.scale ? abcTune.formatting.scale : this.scale;
    	if (this.responsive === "resize") // The resizing will mess with the scaling, so just don't do it explicitly.
    		scale = undefined;
    	if (scale === undefined) scale = this.renderer.isPrint ? 0.75 : 1;
    	this.adjustNonScaledItems(scale);

    	var ret = { left: 0, measureWidths: [], height: 0, total: 0 };
    	// TODO-PER: need to add the height of the title block, too.
    	ret.height = this.renderer.padding.top + this.renderer.spacing.music + this.renderer.padding.bottom + 24; // the 24 is the empirical value added to the bottom of all tunes.
    	var debug = false;
    	var hasPrintedTempo = false;
    	for(var i=0; i<abcTune.lines.length; i++) {
    		var abcLine = abcTune.lines[i];
    		if (abcLine.staff) {
    			abcLine.staffGroup = this.engraver.createABCLine(abcLine.staff, !hasPrintedTempo ? abcTune.metaText.tempo: null);

    			abcLine.staffGroup.layout(0, this.renderer, debug);
    			// At this point, the voices are laid out so that the bar lines are even with each other. So we just need to get the placement of the first voice.
    			if (abcLine.staffGroup.voices.length > 0) {
    				var voice = abcLine.staffGroup.voices[0];
    				var foundNotStaffExtra = false;
    				var lastXPosition = 0;
    				for (var k = 0; k < voice.children.length; k++) {
    					var child = voice.children[k];
    					if (!foundNotStaffExtra && !child.isClef && !child.isKeySig) {
    						foundNotStaffExtra = true;
    						ret.left = child.x;
    						lastXPosition = child.x;
    					}
    					if (child.type === 'bar') {
    						ret.measureWidths.push(child.x - lastXPosition);
    						ret.total += (child.x - lastXPosition);
    						lastXPosition = child.x;
    					}
    				}
    			}
    			hasPrintedTempo = true;
    			ret.height += abcLine.staffGroup.calcHeight() * spacing$1.STEP;
    		}
    	}
    	return ret;
    };

    /**
     * Run the engraving process on a single tune
     * @param {ABCJS.Tune} abctune
     */
    EngraverController.prototype.engraveTune = function (abctune, tuneNumber) {
    	this.renderer.lineNumber = null;

    	this.renderer.newTune(abctune);
    	this.engraver = new abc_abstract_engraver(this.renderer, tuneNumber, { bagpipes: abctune.formatting.bagpipes, flatbeams: abctune.formatting.flatbeams });
    	this.engraver.setStemHeight(this.renderer.spacing.stemHeight);
    	this.engraver.measureLength = abctune.getMeterFraction().num/abctune.getMeterFraction().den;
    	if (abctune.formatting.staffwidth) {
    		this.width = abctune.formatting.staffwidth * 1.33; // The width is expressed in pt; convert to px.
    	} else {
    		this.width = this.renderer.isPrint ? this.staffwidthPrint : this.staffwidthScreen;
    	}

    	var scale = abctune.formatting.scale ? abctune.formatting.scale : this.scale;
    	if (this.responsive === "resize") // The resizing will mess with the scaling, so just don't do it explicitly.
    		scale = undefined;
    	if (scale === undefined) scale = this.renderer.isPrint ? 0.75 : 1;
    	this.adjustNonScaledItems(scale);

    	// Generate the raw staff line data
    	var i;
    	var abcLine;
    	var hasPrintedTempo = false;
    	for(i=0; i<abctune.lines.length; i++) {
    		abcLine = abctune.lines[i];
    		if (abcLine.staff) {
    			abcLine.staffGroup = this.engraver.createABCLine(abcLine.staff, !hasPrintedTempo ? abctune.metaText.tempo: null);
    			hasPrintedTempo = true;
    		}
    	}

    	// Adjust the x-coordinates to their absolute positions
    	var maxWidth = this.width;
    	for(i=0; i<abctune.lines.length; i++) {
    		abcLine = abctune.lines[i];
    		if (abcLine.staff) {
    			this.setXSpacing(abcLine.staffGroup, abctune.formatting, i === abctune.lines.length - 1, false);
    			if (abcLine.staffGroup.w > maxWidth) maxWidth = abcLine.staffGroup.w;
    		}
    	}

    	// Layout the beams and add the stems to the beamed notes.
    	for(i=0; i<abctune.lines.length; i++) {
    		abcLine = abctune.lines[i];
    		if (abcLine.staffGroup && abcLine.staffGroup.voices) {
    			for (var j = 0; j < abcLine.staffGroup.voices.length; j++)
    				abcLine.staffGroup.voices[j].layoutBeams();
    			abcLine.staffGroup.setUpperAndLowerElements(this.renderer);
    		}
    	}

    	// Set the staff spacing
    	// TODO-PER: we should have been able to do this by the time we called setUpperAndLowerElements, but for some reason the "bottom" element seems to be set as a side effect of setting the X spacing.
    	for(i=0; i<abctune.lines.length; i++) {
    		abcLine = abctune.lines[i];
    		if (abcLine.staffGroup) {
    			abcLine.staffGroup.height = abcLine.staffGroup.calcHeight();
    		}
    	}

    	// Do all the writing to output
    	this.renderer.topMargin(abctune);
    	//this.renderer.printHorizontalLine(this.width + this.renderer.padding.left + this.renderer.padding.right);
    	this.renderer.engraveTopText(this.width, abctune);
    	this.renderer.addMusicPadding();

    	this.staffgroups = [];
    	this.lastStaffGroupIndex = -1;
    	for (var line = 0; line < abctune.lines.length; line++) {
    		this.renderer.lineNumber = line;
    		abcLine = abctune.lines[line];
    		if (abcLine.staff) {
    			this.engraveStaffLine(abcLine.staffGroup);
    		} else if (abcLine.subtitle && line !== 0) {
    			this.renderer.outputSubtitle(this.width, abcLine.subtitle);
    		} else if (abcLine.text !== undefined) {
    			this.renderer.outputFreeText(abcLine.text, abcLine.vskip);
    		} else if (abcLine.separator !== undefined) {
    			this.renderer.outputSeparator(abcLine.separator);
    		}
    	}

    	this.renderer.moveY(24); // TODO-PER: Empirically discovered. What variable should this be?
    	this.renderer.engraveExtraText(this.width, abctune);
    	this.renderer.setPaperSize(maxWidth, scale, this.responsive);
    };

    function calcHorizontalSpacing(isLastLine, stretchLast, targetWidth, lineWidth, spacing, spacingUnits, minSpace) {
    	// TODO-PER: This used to stretch the first line when it is the only line, but I'm not sure why. abcm2ps doesn't do that
    	if (isLastLine && lineWidth / targetWidth < 0.66 && !stretchLast) return null; // don't stretch last line too much
    	if (Math.abs(targetWidth-lineWidth) < 2) return null; // if we are already near the target width, we're done.
    	var relSpace = spacingUnits * spacing;
    	var constSpace = lineWidth - relSpace;
    	if (spacingUnits > 0) {
    		spacing = (targetWidth - constSpace) / spacingUnits;
    		if (spacing * minSpace > 50) {
    			spacing = 50 / minSpace;
    		}
    		return spacing;
    	}
    	return null;
    }

    /**
     * Do the x-axis positioning for a single line (a group of related staffs)
     * @param {ABCJS.Tune} abctune an ABCJS AST
     * @param {Object} staffGroup an staffGroup
     * @param {Object} formatting an formatting
     * @param {boolean} isLastLine is this the last line to be printed?
     * @private
     */
    EngraverController.prototype.setXSpacing = function (staffGroup, formatting, isLastLine, debug) {
       var newspace = this.space;
      for (var it = 0; it < 8; it++) { // TODO-PER: shouldn't need multiple passes, but each pass gets it closer to the right spacing. (Only affects long lines: normal lines break out of this loop quickly.)
    	  var ret = staffGroup.layout(newspace, this.renderer, debug);
    	  var stretchLast = formatting.stretchlast ? formatting.stretchlast : false;
    		newspace = calcHorizontalSpacing(isLastLine, stretchLast, this.width+this.renderer.padding.left, staffGroup.w, newspace, ret.spacingUnits, ret.minSpace);
    		if (debug)
    			console.log("setXSpace", it, staffGroup.w, newspace, staffGroup.minspace);
    		if (newspace === null) break;
      }
    	centerWholeRests(staffGroup.voices);
    	//this.renderer.printHorizontalLine(this.width);
    };

    /**
     * Engrave a single line (a group of related staffs)
     * @param {ABCJS.Tune} abctune an ABCJS AST
     * @param {Object} staffGroup an staffGroup
     * @private
     */
    EngraverController.prototype.engraveStaffLine = function (staffGroup) {
    	if (this.lastStaffGroupIndex > -1)
    		this.renderer.addStaffPadding(this.staffgroups[this.lastStaffGroupIndex], staffGroup);
    	this.renderer.voiceNumber = null;
    	staffGroup.draw(this.renderer);
    	var height = staffGroup.height * spacing$1.STEP;
    	//this.renderer.printVerticalLine(this.width+this.renderer.padding.left, this.renderer.y, this.renderer.y+height);
      this.staffgroups[this.staffgroups.length] = staffGroup;
    	this.lastStaffGroupIndex = this.staffgroups.length-1;
    	this.renderer.y += height;
    };

    /**
     * Called by the Abstract Engraving Structure or any other (e.g. midi playback) to say it was selected (notehead clicked on)
     * @protected
     */
    EngraverController.prototype.notifySelect = function (abselem, tuneNumber, classes) {
      this.clearSelection();
      if (abselem.highlight) {
        this.selected = [abselem];
        abselem.highlight();
      }
      var abcelem = abselem.abcelem || {};
      for (var i=0; i<this.listeners.length;i++) {
    	  this.listeners[i](abcelem, tuneNumber, classes);
      }
    };

    /**
     * Called by the Abstract Engraving Structure to say it was modified (e.g. notehead dragged)
     * @protected
     */
    // EngraverController.prototype.notifyChange = function (/*abselem*/) {
    //   for (var i=0; i<this.listeners.length;i++) {
    //     if (this.listeners[i].modelChanged)
    //       this.listeners[i].modelChanged();
    //   }
    // };

    /**
     *
     * @private
     */
    EngraverController.prototype.clearSelection = function () {
      for (var i=0;i<this.selected.length;i++) {
        this.selected[i].unhighlight();
      }
      this.selected = [];
    };

    /**
     * @param {Object} listener
     * @param {Function} listener.modelChanged the model the listener passed to this controller has changed
     * @param {Function} listener.highlight the abcelem of the model the listener passed to this controller should be highlighted
     */
    EngraverController.prototype.addSelectListener = function (clickListener) {
      this.listeners[this.listeners.length] = clickListener;
    };

    /**
     * Tell the controller to highlight some noteheads of its engraved score
     * @param {number} start the character in the source abc where highlighting should start
     * @param {number} end the character in the source abc where highlighting should end
     */
    EngraverController.prototype.rangeHighlight = function(start,end)
    {
        this.clearSelection();
        for (var line=0;line<this.staffgroups.length; line++) {
    	var voices = this.staffgroups[line].voices;
    	for (var voice=0;voice<voices.length;voice++) {
    	    var elems = voices[voice].children;
    	    for (var elem=0; elem<elems.length; elem++) {
    		// Since the user can highlight more than an element, or part of an element, a hit is if any of the endpoints
    		// is inside the other range.
    		var elStart = elems[elem].abcelem.startChar;
    		var elEnd = elems[elem].abcelem.endChar;
    		if ((end>elStart && start<elEnd) || ((end===start) && end===elEnd)) {
    		    //		if (elems[elem].abcelem.startChar>=start && elems[elem].abcelem.endChar<=end) {
    		    this.selected[this.selected.length]=elems[elem];
    		    elems[elem].highlight();
    		}
    	    }
    	}
        }
    };


    function centerWholeRests(voices) {
    	// whole rests are a special case: if they are by themselves in a measure, then they should be centered.
    	// (If they are not by themselves, that is probably a user error, but we'll just center it between the two items to either side of it.)
    	for (var i = 0; i < voices.length; i++) {
    		var voice = voices[i];
    		// Look through all of the elements except for the first and last. If the whole note appears there then there isn't anything to center it between anyway.
    		for (var j = 1; j < voice.children.length-1; j++) {
    			var absElem = voice.children[j];
    			if (absElem.abcelem.rest && (absElem.abcelem.rest.type === 'whole' || absElem.abcelem.rest.type === 'multimeasure')) {
    				var before = voice.children[j-1];
    				var after = voice.children[j+1];
    				var midpoint = (after.x - before.x) / 2 + before.x;
    				absElem.x = midpoint - absElem.w / 2;
    				for (var k = 0; k < absElem.children.length; k++)
    					absElem.children[k].x = absElem.x;
    			}
    		}
    	}
    }

    var abc_engraver_controller = EngraverController;

    var resizeDivs = {};
    function resizeOuter() {
        var width = window.innerWidth;
        for (var id in resizeDivs) {
            if (resizeDivs.hasOwnProperty(id)) {
                var outer = resizeDivs[id];
                var ofs = outer.offsetLeft;
                width -= ofs * 2;
                outer.style.width = width + "px";
            }
        }
    }

    window.addEventListener("resize", resizeOuter);
    window.addEventListener("orientationChange", resizeOuter);

    function renderOne(div, tune, params, tuneNumber) {
        if (params.viewportHorizontal) {
            // Create an inner div that holds the music, so that the passed in div will be the viewport.
            div.innerHTML = '<div class="abcjs-inner"></div>';
            if (params.scrollHorizontal) {
                div.style.overflowX = "auto";
                div.style.overflowY = "hidden";
            } else
                div.style.overflow = "hidden";
            resizeDivs[div.id] = div; // We use a hash on the element's id so that multiple calls won't keep adding to the list.
            div = div.children[0]; // The music should be rendered in the inner div.
        }
        else if (params.viewportVertical) {
            // Create an inner div that holds the music, so that the passed in div will be the viewport.
            div.innerHTML = '<div class="abcjs-inner scroll-amount"></div>';
            div.style.overflowX = "hidden";
            div.style.overflowY = "auto";
            div = div.children[0]; // The music should be rendered in the inner div.
        }
        else
    	    div.innerHTML = "";
        var engraver_controller = new abc_engraver_controller(div, params);
        engraver_controller.engraveABC(tune, tuneNumber);
        tune.engraver = engraver_controller;
        if (params.viewportVertical || params.viewportHorizontal) {
            // If we added a wrapper around the div, then we need to size the wrapper, too.
            var parent = div.parentNode;
            parent.style.width = div.style.width;
        }
    }

    function renderEachLineSeparately(div, tune, params, tuneNumber) {
        function initializeTuneLine(tune) {
            var obj = new abc_tune();
            obj.formatting = tune.formatting;
            obj.media = tune.media;
            obj.version = tune.version;
            obj.metaText = {};
            obj.lines = [];
            return obj;
        }

        // Before rendering, chop up the returned tune into an array where each element is a line.
        // The first element of the array gets the title and other items that go on top, the last element
        // of the array gets the extra text that goes on bottom. Each element gets any non-music info that comes before it.
        var tunes = [];
        var tuneLine;
        for (var i = 0; i < tune.lines.length; i++) {
            var line = tune.lines[i];
            if (!tuneLine)
                tuneLine = initializeTuneLine(tune);

            if (i === 0) {
                // These items go on top of the music
                tuneLine.metaText.tempo = tune.metaText.tempo;
                tuneLine.metaText.title = tune.metaText.title;
                tuneLine.metaText.header = tune.metaText.header;
                tuneLine.metaText.rhythm = tune.metaText.rhythm;
                tuneLine.metaText.origin = tune.metaText.origin;
                tuneLine.metaText.composer = tune.metaText.composer;
                tuneLine.metaText.author = tune.metaText.author;
                tuneLine.metaText.partOrder = tune.metaText.partOrder;
            }

            // push the lines until we get to a music line
            tuneLine.lines.push(line);
            if (line.staff) {
                tunes.push(tuneLine);
                tuneLine = undefined;
            }
        }
        // Add any extra stuff to the last line.
        if (tuneLine) {
            var lastLine = tunes[tunes.length-1];
            for (var j = 0; j < tuneLine.lines.length; j++)
                lastLine.lines.push(tuneLine.lines[j]);
        }

        // These items go below the music
        tuneLine = tunes[tunes.length-1];
        tuneLine.metaText.unalignedWords = tune.metaText.unalignedWords;
        tuneLine.metaText.book = tune.metaText.book;
        tuneLine.metaText.source = tune.metaText.source;
        tuneLine.metaText.discography = tune.metaText.discography;
        tuneLine.metaText.notes = tune.metaText.notes;
        tuneLine.metaText.transcription = tune.metaText.transcription;
        tuneLine.metaText.history = tune.metaText.history;
        tuneLine.metaText['abc-copyright'] = tune.metaText['abc-copyright'];
        tuneLine.metaText['abc-creator'] = tune.metaText['abc-creator'];
        tuneLine.metaText['abc-edited-by'] = tune.metaText['abc-edited-by'];
        tuneLine.metaText.footer = tune.metaText.footer;

        // Now create sub-divs and render each line. Need to copy the params to change the padding for the interior slices.
        var ep = {};
        for (var key in params) {
            if (params.hasOwnProperty(key)) {
                ep[key] = params[key];
            }
        }
        var origPaddingTop = ep.paddingtop;
        var origPaddingBottom = ep.paddingbottom;
        div.innerHTML = "";
        for (var k = 0; k < tunes.length; k++) {
            var lineEl = document.createElement("div");
            div.appendChild(lineEl);

            if (k === 0) {
    	        ep.paddingtop = origPaddingTop;
    	        ep.paddingbottom = -20;
            } else if (k === tunes.length-1) {
    	        ep.paddingtop = 10;
    	        ep.paddingbottom = origPaddingBottom;
            } else {
    	        ep.paddingtop = 10;
    	        ep.paddingbottom = -20;
            }
            renderOne(lineEl, tunes[k], ep, tuneNumber);
            if (k === 0)
                tune.engraver = tunes[k].engraver;
            else {
                if (!tune.engraver.staffgroups)
                    tune.engraver.staffgroups = tunes[k].engraver.staffgroups;
                else if (tunes[k].engraver.staffgroups.length > 0)
                    tune.engraver.staffgroups.push(tunes[k].engraver.staffgroups[0]);
            }
        }
    }

    // A quick way to render a tune from javascript when interactivity is not required.
    // This is used when a javascript routine has some abc text that it wants to render
    // in a div or collection of divs. One tune or many can be rendered.
    //
    // parameters:
    //      output: an array of divs that the individual tunes are rendered to.
    //          If the number of tunes exceeds the number of divs in the array, then
    //          only the first tunes are rendered. If the number of divs exceeds the number
    //          of tunes, then the unused divs are cleared. The divs can be passed as either
    //          elements or strings of ids. If ids are passed, then the div MUST exist already.
    //          (if a single element is passed, then it is an implied array of length one.)
    //          (if a null is passed for an element, or the element doesn't exist, then that tune is skipped.)
    //      abc: text representing a tune or an entire tune book in ABC notation.
    //      renderParams: hash of:
    //          startingTune: an index, starting at zero, representing which tune to start rendering at.
    //              (If this element is not present, then rendering starts at zero.)
    //          width: 800 by default. The width in pixels of the output paper
    var renderAbc = function(output, abc, parserParams, engraverParams, renderParams) {
        // Note: all parameters have been condensed into the first ones. It doesn't hurt anything to allow the old format, so just copy them here.
        var params = {};
        var key;
        if (parserParams) {
            for (key in parserParams) {
                if (parserParams.hasOwnProperty(key)) {
                    params[key] = parserParams[key];
                }
            }
        }
        if (engraverParams) {
            for (key in engraverParams) {
                if (engraverParams.hasOwnProperty(key)) {
    	            // There is a conflict with the name of the parameter "listener". If it is in the second parameter, then it is for click.
    	            if (key === "listener") {
    	            	if (engraverParams[key].highlight)
    		                params.clickListener = engraverParams[key].highlight;
    	            } else
                        params[key] = engraverParams[key];
                }
            }
        }
        if (renderParams) {
            for (key in renderParams) {
                if (renderParams.hasOwnProperty(key)) {
                    params[key] = renderParams[key];
                }
            }
        }

        function callback(div, tune, tuneNumber, abcString) {
            var removeDiv = false;
            if (div === "*") {
                removeDiv = true;
                div = document.createElement("div");
                div.setAttribute("style", "display:none;");
                document.body.appendChild(div);
            }
        	if (params.afterParsing)
        		params.afterParsing(tune, tuneNumber, abcString);
            if (!removeDiv && params.wrap && params.staffwidth) {
    	        tune = doLineWrapping(div, tune, tuneNumber, abcString, params);
    	        return tune;
            }
            else if (removeDiv || !params.oneSvgPerLine || tune.lines.length < 2)
                renderOne(div, tune, params, tuneNumber);
            else
                renderEachLineSeparately(div, tune, params, tuneNumber);
            if (removeDiv)
                div.parentNode.removeChild(div);
            return null;
        }

        return abc_tunebook.renderEngine(callback, output, abc, params);
    };

    function doLineWrapping(div, tune, tuneNumber, abcString, params) {
    	var engraver_controller = new abc_engraver_controller(div, params);
    	var widths = engraver_controller.getMeasureWidths(tune);

    	var ret = wrap_lines.calcLineWraps(tune, widths, abcString, params, abc_parse, engraver_controller);
        if (!params.oneSvgPerLine || ret.tune.lines.length < 2)
            renderOne(div, ret.tune, ret.revisedParams, tuneNumber);
        else
            renderEachLineSeparately(div, ret.tune, ret.revisedParams, tuneNumber);
    	ret.tune.explanation = ret.explanation;
    	return ret.tune;
    }

    var abc_tunebook_svg = renderAbc;

    var soundsCache = {
    };

    var soundsCache_1 = soundsCache;

    // Load one mp3 file for one note.
    // url = the base url for the soundfont
    // instrument = the instrument name (e.g. "acoustic_grand_piano")
    // name = the pitch name (e.g. "A3")


    var getNote = function(url, instrument, name, audioContext) {
    	return new Promise(function (resolve, reject) {
    		if (!soundsCache_1[instrument])
    			soundsCache_1[instrument] = {};
    		var instrumentCache = soundsCache_1[instrument];

    		if (instrumentCache[name] === 'error') {
    			return reject(new Error("Unable to load sound font" + ' ' + url + ' ' + instrument + ' ' + name));
    		}
    		if (instrumentCache[name]) {
    			return resolve({instrument: instrument, name: name});
    		}

    		// if (this.debugCallback)
    		// 	this.debugCallback(`Loading sound: ${instrument} ${name}`);
    		instrumentCache[name] = "pending"; // This can be called in parallel, so don't call it a second time before the first one has loaded.
    		var xhr = new XMLHttpRequest();
    		xhr.open('GET', url+instrument+'-mp3/'+name+'.mp3', true);
    		xhr.responseType = 'arraybuffer';

    		var self = this;
    		function onSuccess(audioBuffer) {
    			instrumentCache[name] = audioBuffer;
    			// if (self.debugCallback)
    			// 	self.debugCallback(`Sound loaded: ${instrument} ${name} ${url}`);
    			resolve({instrument: instrument, name: name});
    		}

    		function onFailure(error) {
    			if (self.debugCallback)
    				self.debugCallback(error);
    			console.log(error);
    			reject(error);
    		}

    		xhr.onload = function (e) {
    			if (this.status === 200) {
    				audioContext.decodeAudioData(this.response, onSuccess, onFailure);//.then(function() {
    				// 	return resolve({instrument: instrument, name: name});
    				// }).catch(function(error) {
    				// 	return reject(new Error(cantLoadMp3 + error));
    				// });
    			} else {
    				instrumentCache[name] = "error"; // To keep this from trying to load repeatedly.
    				var cantLoadMp3 = "Onload error loading sound: " +  name + " " + url + " " + e.currentTarget.status + " " + e.currentTarget.statusText;
    				if (self.debugCallback)
    					self.debugCallback(cantLoadMp3);
    				return reject(new Error(cantLoadMp3));
    			}
    		};
    		xhr.addEventListener("error", function () {
    			instrumentCache[name] = "error"; // To keep this from trying to load repeatedly.
    			var cantLoadMp3 = "Error in loading sound: " + " " + url;
    			if (self.debugCallback)
    				self.debugCallback(cantLoadMp3);
    			return reject(new Error(cantLoadMp3));
    		}, false);
    		xhr.send();
    	});
    };

    var loadNote = getNote;

    var instrumentIndexToName = [
    	"acoustic_grand_piano",
    	"bright_acoustic_piano",
    	"electric_grand_piano",
    	"honkytonk_piano",
    	"electric_piano_1",
    	"electric_piano_2",
    	"harpsichord",
    	"clavinet",

    	"celesta",
    	"glockenspiel",
    	"music_box",
    	"vibraphone",
    	"marimba",
    	"xylophone",
    	"tubular_bells",
    	"dulcimer",

    	"drawbar_organ",
    	"percussive_organ",
    	"rock_organ",
    	"church_organ",
    	"reed_organ",
    	"accordion",
    	"harmonica",
    	"tango_accordion",

    	"acoustic_guitar_nylon",
    	"acoustic_guitar_steel",
    	"electric_guitar_jazz",
    	"electric_guitar_clean",
    	"electric_guitar_muted",
    	"overdriven_guitar",
    	"distortion_guitar",
    	"guitar_harmonics",

    	"acoustic_bass",
    	"electric_bass_finger",
    	"electric_bass_pick",
    	"fretless_bass",
    	"slap_bass_1",
    	"slap_bass_2",
    	"synth_bass_1",
    	"synth_bass_2",

    	"violin",
    	"viola",
    	"cello",
    	"contrabass",
    	"tremolo_strings",
    	"pizzicato_strings",
    	"orchestral_harp",
    	"timpani",

    	"string_ensemble_1",
    	"string_ensemble_2",
    	"synth_strings_1",
    	"synth_strings_2",
    	"choir_aahs",
    	"voice_oohs",
    	"synth_choir",
    	"orchestra_hit",

    	"trumpet",
    	"trombone",
    	"tuba",
    	"muted_trumpet",
    	"french_horn",
    	"brass_section",
    	"synth_brass_1",
    	"synth_brass_2",

    	"soprano_sax",
    	"alto_sax",
    	"tenor_sax",
    	"baritone_sax",
    	"oboe",
    	"english_horn",
    	"bassoon",
    	"clarinet",

    	"piccolo",
    	"flute",
    	"recorder",
    	"pan_flute",
    	"blown_bottle",
    	"shakuhachi",
    	"whistle",
    	"ocarina",

    	"lead_1_square",
    	"lead_2_sawtooth",
    	"lead_3_calliope",
    	"lead_4_chiff",
    	"lead_5_charang",
    	"lead_6_voice",
    	"lead_7_fifths",
    	"lead_8_bass__lead",

    	"pad_1_new_age",
    	"pad_2_warm",
    	"pad_3_polysynth",
    	"pad_4_choir",
    	"pad_5_bowed",
    	"pad_6_metallic",
    	"pad_7_halo",
    	"pad_8_sweep",

    	"fx_1_rain",
    	"fx_2_soundtrack",
    	"fx_3_crystal",
    	"fx_4_atmosphere",
    	"fx_5_brightness",
    	"fx_6_goblins",
    	"fx_7_echoes",
    	"fx_8_scifi",

    	"sitar",
    	"banjo",
    	"shamisen",
    	"koto",
    	"kalimba",
    	"bagpipe",
    	"fiddle",
    	"shanai",

    	"tinkle_bell",
    	"agogo",
    	"steel_drums",
    	"woodblock",
    	"taiko_drum",
    	"melodic_tom",
    	"synth_drum",
    	"reverse_cymbal",

    	"guitar_fret_noise",
    	"breath_noise",
    	"seashore",
    	"bird_tweet",
    	"telephone_ring",
    	"helicopter",
    	"applause",
    	"gunshot",

    	"percussion"
    ];

    var instrumentIndexToName_1 = instrumentIndexToName;

    // Convert the input structure to a more useful structure where each item has a length of its own.



    var createNoteMap = function(sequence) {
    	var map = [];
    	for (var i = 0; i < sequence.tracks.length; i++)
    		map.push([]);

    	// TODO-PER: handle more than one note in a track
    	var nextNote = {};
    	var currentInstrument = instrumentIndexToName_1[0];
    	sequence.tracks.forEach(function(track, i) {
    		var currentTime = 0;
    		track.forEach(function(ev) {
    			switch (ev.cmd) {
    				case "start":
    					nextNote[ev.pitch] = { time: currentTime, instrument: currentInstrument, volume: ev.volume };
    					break;
    				case "move":
    					currentTime += ev.duration;
    					break;
    				case "stop":
    					map[i].push({pitch: ev.pitch, instrument: nextNote[ev.pitch].instrument, start: nextNote[ev.pitch].time, end: currentTime, volume: nextNote[ev.pitch].volume});
    					delete nextNote[ev.pitch];
    					break;
    				case "program":
    					currentInstrument = instrumentIndexToName_1[ev.instrument];
    					break;
    				default:
    					// TODO-PER: handle other event types
    					console.log("Unhanded midi event", ev);
    			}
    		});
    	});
    	return map;
    };

    var createNoteMap_1 = createNoteMap;

    // Call this when it is safe for the abcjs to produce sound. This is after the first user gesture on the page.
    // If you call it with no parameters, then an AudioContext is created and stored.
    // If you call it with a parameter, that is used as an already created AudioContext.

    function registerAudioContext(ac) {
    	if (!window.abcjsAudioContext) {
    		if (!ac) {
    			ac = window.AudioContext ||
    				window.webkitAudioContext ||
    				navigator.mozAudioContext ||
    				navigator.msAudioContext;
    			ac = new ac();
    		}
    		window.abcjsAudioContext = ac;
    	}
    	return window.abcjsAudioContext.state !== "suspended";
    }

    var registerAudioContext_1 = registerAudioContext;

    function activeAudioContext() {
    	return window.abcjsAudioContext;
    }

    var activeAudioContext_1 = activeAudioContext;

    //
    // Support for audio depends on three things: support for Promise, support for AudioContext, and support for AudioContext.resume.
    // Unfortunately, AudioContext.resume cannot be detected unless an AudioContext is created, and creating an AudioContext can't
    // be done until a user click, so there is no way to know for sure if audio is supported until the user tries.
    // We can get close, though - we can test for Promises and AudioContext - there are just a few evergreen browsers that supported
    // that before supporting resume, so we'll test what we can.

    // The best use of this routine is to call it before doing any audio related stuff to decide whether to bother.
    // But then, call it again after a user interaction to test for resume.

    function supportsAudio() {
    	var aac = activeAudioContext_1();
    	if (aac)
    		return aac.resume !== undefined;

    	if (!window.Promise)
    		return false;

    	return window.AudioContext ||
    		window.webkitAudioContext ||
    		navigator.mozAudioContext ||
    		navigator.msAudioContext;
    }

    var supportsAudio_1 = supportsAudio;

    var pitchToNoteName = {
    	21: 'A0',
    	22: 'Bb0',
    	23: 'B0',
    	24: 'C1',
    	25: 'Db1',
    	26: 'D1',
    	27: 'Eb1',
    	28: 'E1',
    	29: 'F1',
    	30: 'Gb1',
    	31: 'G1',
    	32: 'Ab1',
    	33: 'A1',
    	34: 'Bb1',
    	35: 'B1',
    	36: 'C2',
    	37: 'Db2',
    	38: 'D2',
    	39: 'Eb2',
    	40: 'E2',
    	41: 'F2',
    	42: 'Gb2',
    	43: 'G2',
    	44: 'Ab2',
    	45: 'A2',
    	46: 'Bb2',
    	47: 'B2',
    	48: 'C3',
    	49: 'Db3',
    	50: 'D3',
    	51: 'Eb3',
    	52: 'E3',
    	53: 'F3',
    	54: 'Gb3',
    	55: 'G3',
    	56: 'Ab3',
    	57: 'A3',
    	58: 'Bb3',
    	59: 'B3',
    	60: 'C4',
    	61: 'Db4',
    	62: 'D4',
    	63: 'Eb4',
    	64: 'E4',
    	65: 'F4',
    	66: 'Gb4',
    	67: 'G4',
    	68: 'Ab4',
    	69: 'A4',
    	70: 'Bb4',
    	71: 'B4',
    	72: 'C5',
    	73: 'Db5',
    	74: 'D5',
    	75: 'Eb5',
    	76: 'E5',
    	77: 'F5',
    	78: 'Gb5',
    	79: 'G5',
    	80: 'Ab5',
    	81: 'A5',
    	82: 'Bb5',
    	83: 'B5',
    	84: 'C6',
    	85: 'Db6',
    	86: 'D6',
    	87: 'Eb6',
    	88: 'E6',
    	89: 'F6',
    	90: 'Gb6',
    	91: 'G6',
    	92: 'Ab6',
    	93: 'A6',
    	94: 'Bb6',
    	95: 'B6',
    	96: 'C7',
    	97: 'Db7',
    	98: 'D7',
    	99: 'Eb7',
    	100: 'E7',
    	101: 'F7',
    	102: 'Gb7',
    	103: 'G7',
    	104: 'Ab7',
    	105: 'A7',
    	106: 'Bb7',
    	107: 'B7',
    	108: 'C8',
    	109: 'Db8',
    	110: 'D8',
    	111: 'Eb8',
    	112: 'E8',
    	113: 'F8',
    	114: 'Gb8',
    	115: 'G8',
    	116: 'Ab8',
    	117: 'A8',
    	118: 'Bb8',
    	119: 'B8',
    	120: 'C9',
    	121: 'Db9'
    };

    var pitchToNoteName_1 = pitchToNoteName;

    var downloadBuffer = function(buffer) {
    	return window.URL.createObjectURL(bufferToWave(buffer.audioBuffers));
    };

    // Convert an AudioBuffer to a Blob using WAVE representation
    function bufferToWave(audioBuffers) {
    	var numOfChan = audioBuffers.length;
    	var length = audioBuffers[0].length * numOfChan * 2 + 44;
    	var buffer = new ArrayBuffer(length);
    	var view = new DataView(buffer);
    	var channels = [];
    	var i;
    	var sample;
    	var offset = 0;
    	var pos = 0;

    	// write WAVE header
    	setUint32(0x46464952);                         // "RIFF"
    	setUint32(length - 8);                         // file length - 8
    	setUint32(0x45564157);                         // "WAVE"

    	setUint32(0x20746d66);                         // "fmt " chunk
    	setUint32(16);                                 // length = 16
    	setUint16(1);                                  // PCM (uncompressed)
    	setUint16(numOfChan);
    	setUint32(audioBuffers[0].sampleRate);
    	setUint32(audioBuffers[0].sampleRate * 2 * numOfChan); // avg. bytes/sec
    	setUint16(numOfChan * 2);                      // block-align
    	setUint16(16);                                 // 16-bit (hardcoded in this demo)

    	setUint32(0x61746164);                         // "data" - chunk
    	setUint32(length - pos - 4);                   // chunk length

    	// write interleaved data
    	for(i = 0; i < audioBuffers.length; i++)
    		channels.push(audioBuffers[i].getChannelData(0));

    	while(pos < length) {
    		for(i = 0; i < channels.length; i++) {             // interleave channels
    			sample = Math.max(-1, Math.min(1, channels[i][offset])); // clamp
    			sample = (0.5 + sample < 0 ? sample * 32768 : sample * 32767)|0; // scale to 16-bit signed int
    			view.setInt16(pos, sample, true);          // write 16-bit sample
    			pos += 2;
    		}
    		offset++; // next source sample
    	}

    	// create Blob
    	return new Blob([buffer], {type: "audio/wav"});

    	function setUint16(data) {
    		view.setUint16(pos, data, true);
    		pos += 2;
    	}

    	function setUint32(data) {
    		view.setUint32(pos, data, true);
    		pos += 4;
    	}
    }

    var downloadBuffer_1 = downloadBuffer;

    //    abc_midi_sequencer.js: Turn parsed abc into a linear series of events.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    var sequence;

    (function() {

    	var measureLength;
    	// The abc is provided to us line by line. It might have repeats in it. We want to re arrange the elements to
    	// be an array of voices with all the repeats embedded, and no lines. Then it is trivial to go through the events
    	// one at a time and turn it into midi.

    	var PERCUSSION_PROGRAM = 128;

    	sequence = function(abctune, options) {
    		// Global options
    		options = options || {};
    		var qpm = undefined;
    		var program = options.program || 0;	// The program if there isn't a program specified.
    		var transpose = options.midiTranspose || 0;
    		var channel = options.channel || 0;
    		var drumPattern = options.drum || "";
    		var drumBars = options.drumBars || 1;
    		var drumIntro = options.drumIntro || 0;
    		var drumOn = drumPattern !== "";

    		// All of the above overrides need to be integers
    		program = parseInt(program, 10);
    		transpose = parseInt(transpose, 10);
    		channel = parseInt(channel, 10);
    		if (channel === 10)
    			program = PERCUSSION_PROGRAM;
    		drumPattern = drumPattern.split(" ");
    		drumBars = parseInt(drumBars, 10);
    		drumIntro = parseInt(drumIntro, 10);

    		var bagpipes = abctune.formatting.bagpipes; // If it is bagpipes, then the gracenotes are played on top of the main note.
    		if (bagpipes)
    			program = 71;

    		// %%MIDI fermatafixed
    		// %%MIDI fermataproportional
    		// %%MIDI deltaloudness n
    		// %%MIDI gracedivider b
    		// %%MIDI ratio n m
    		// %%MIDI beat a b c n
    		// %%MIDI grace a/b
    		// %%MIDI trim x/y

    		// %MIDI gchordon
    		// %MIDI gchordoff
    		// %%MIDI bassprog 45
    		// %%MIDI chordprog 24
    		// %%MIDI chordname name n1 n2 n3 n4 n5 n6

    		//%%MIDI beat ⟨int1⟩ ⟨int2⟩ ⟨int3⟩ ⟨int4⟩: controls the volumes of the notes in a measure. The first note in a bar has volume ⟨int1⟩; other ‘strong’ notes have volume ⟨int2⟩ and all the rest have volume ⟨int3⟩. These values must be in the range 0–127. The parameter ⟨int4⟩ determines which notes are ‘strong’. If the time signature is x/y, then each note is given a position number k = 0, 1, 2. . . x-1 within each bar. If k is a multiple of ⟨int4⟩, then the note is ‘strong’.

    		var startingMidi = [];
    		if (abctune.formatting.midi) {
    			//console.log("MIDI Formatting:", abctune.formatting.midi);
    			var globals = abctune.formatting.midi;
    			if (globals.program && globals.program.length > 0) {
    				program = globals.program[0];
    				if (globals.program.length > 1) {
    					program = globals.program[1];
    					channel = globals.program[0];
    				}
    			}
    			if (globals.transpose)
    				transpose = globals.transpose[0];
    			if (globals.channel)
    				channel = globals.channel[0];
    			if (globals.drum)
    				drumPattern = globals.drum;
    			if (globals.drumbars)
    				drumBars = globals.drumbars[0];
    			if (globals.drumon)
    				drumOn = true;
    			if (channel === 10)
    				program = PERCUSSION_PROGRAM;
    			if (globals.beat)
    				startingMidi.push({ el_type: 'beat', beats: globals.beat });
    			if (globals.nobeataccents)
    				startingMidi.push({ el_type: 'beataccents', value: false });

    		}

    		// Specified options in abc string.

    		// If the tempo was passed in, use that.
    		// If the tempo is specified, use that.
    		// If there is a default, use that.
    		// Otherwise, use the default.
    		if (options.qpm)
    			qpm = parseInt(options.qpm, 10);
    		else if (abctune.metaText.tempo)
    			qpm = interpretTempo(abctune.metaText.tempo);
    		else if (options.defaultQpm)
    			qpm = options.defaultQpm;
    		else
    			qpm = 180; 	// The tempo if there isn't a tempo specified.

    		var startVoice = [];
    		if (bagpipes)
    			startVoice.push({ el_type: 'bagpipes' });
    		startVoice.push({ el_type: 'instrument', program: program });
    		if (channel)
    			startVoice.push({ el_type: 'channel', channel: channel });
    		if (transpose)
    			startVoice.push({ el_type: 'transpose', transpose: transpose });
    		startVoice.push({ el_type: 'tempo', qpm: qpm });
    		for (var ss = 0; ss < startingMidi.length;ss++)
    			startVoice.push(startingMidi[ss]);

    		// the relevant part of the input structure is:
    		// abctune
    		//		array lines
    		//			array staff
    		//				object key
    		//				object meter
    		//				array voices
    		//					array abcelem

    		// visit each voice completely in turn
    		var voices = [];
    		var startRepeatPlaceholder = []; // There is a place holder for each voice.
    		var skipEndingPlaceholder = []; // This is the place where the first ending starts.
    		var startingDrumSet = false;
    		for (var i = 0; i < abctune.lines.length; i++) {
    			// For each group of staff lines in the tune.
    			var line = abctune.lines[i];
    			if (line.staff) {
    				var staves = line.staff;
    				var voiceNumber = 0;
    				for (var j = 0; j < staves.length; j++) {
    					var staff = staves[j];
    					// For each staff line
    					for (var k = 0; k < staff.voices.length; k++) {
    						// For each voice in a staff line
    						var voice = staff.voices[k];
    						if (!voices[voiceNumber]) {
    							voices[voiceNumber] = [].concat(JSON.parse(JSON.stringify(startVoice)));
    						}
    						if (staff.clef && staff.clef.type === 'perc') {
    							for (var cl = 0; cl < voices[voiceNumber].length; cl++) {
    								if (voices[voiceNumber][cl].el_type === 'instrument')
    									voices[voiceNumber][cl].program = PERCUSSION_PROGRAM;
    							}
    						} else if (staff.key) {
    							if (staff.key.root === 'HP')
    								voices[voiceNumber].push({el_type: 'key', accidentals: [{acc: 'natural', note: 'g'}, {acc: 'sharp', note: 'f'}, {acc: 'sharp', note: 'c'}]});
    							else
    								voices[voiceNumber].push({el_type: 'key', accidentals: staff.key.accidentals });
    						}
    						if (staff.meter) {
    							voices[voiceNumber].push(interpretMeter(staff.meter));
    						}
    						if (!startingDrumSet && drumOn) { // drum information is only needed once, so use the first line and track 0.
    							voices[voiceNumber].push({el_type: 'drum', params: {pattern: drumPattern, bars: drumBars, on: drumOn, intro: drumIntro}});
    							startingDrumSet = true;
    						}
    						if (staff.clef && staff.clef.transpose) {
    							staff.clef.el_type = 'clef';
    							voices[voiceNumber].push({ el_type: 'transpose', transpose: staff.clef.transpose });
    						}
    						if (abctune.formatting.midi && abctune.formatting.midi.drumoff) {
    							// If there is a drum off command right at the beginning it is put in the metaText instead of the stream,
    							// so we will just insert it here.
    							voices[voiceNumber].push({ el_type: 'bar' });
    							voices[voiceNumber].push({el_type: 'drum', params: {pattern: "", on: false }});
    						}
    						var noteEventsInBar = 0;
    						for (var v = 0; v < voice.length; v++) {
    							// For each element in a voice
    							var elem = voice[v];
    							switch (elem.el_type) {
    								case "note":
    									// regular items are just pushed.
    									if (!elem.rest || elem.rest.type !== 'spacer') {
    										if (elem.decoration) {
    											if (elem.decoration.indexOf('ppp') >= 0)
    												voices[voiceNumber].push({ el_type: 'beat', beats: [30, 20, 10, 1] });
    											else if (elem.decoration.indexOf('pp') >= 0)
    												voices[voiceNumber].push({ el_type: 'beat', beats: [45, 35, 20, 1] });
    											else if (elem.decoration.indexOf('p') >= 0)
    												voices[voiceNumber].push({ el_type: 'beat', beats: [60, 50, 35, 1] });
    											else if (elem.decoration.indexOf('mp') >= 0)
    												voices[voiceNumber].push({ el_type: 'beat', beats: [75, 65, 50, 1] });
    											else if (elem.decoration.indexOf('mf') >= 0)
    												voices[voiceNumber].push({ el_type: 'beat', beats: [90, 80, 65, 1] });
    											else if (elem.decoration.indexOf('f') >= 0)
    												voices[voiceNumber].push({ el_type: 'beat', beats: [105, 95, 80, 1] });
    											else if (elem.decoration.indexOf('ff') >= 0)
    												voices[voiceNumber].push({ el_type: 'beat', beats: [120, 110, 95, 1] });
    											else if (elem.decoration.indexOf('fff') >= 0)
    												voices[voiceNumber].push({ el_type: 'beat', beats: [127, 125, 110, 1] });
    										}
    										voices[voiceNumber].push(elem);
    										noteEventsInBar++;
    									}
    									break;
    								case "key":
    									if (elem.root === 'HP')
    										voices[voiceNumber].push({el_type: 'key', accidentals: [{acc: 'natural', note: 'g'}, {acc: 'sharp', note: 'f'}, {acc: 'sharp', note: 'c'}]});
    									else
    										voices[voiceNumber].push({el_type: 'key', accidentals: elem.accidentals });
    									break;
    								case "meter":
    									voices[voiceNumber].push(interpretMeter(elem));
    									break;
    								case "clef": // need to keep this to catch the "transpose" element.
    									if (elem.transpose)
    										voices[voiceNumber].push({ el_type: 'transpose', transpose: elem.transpose });
    									break;
    								case "tempo":
    									qpm = interpretTempo(elem);
    									voices[voiceNumber].push({ el_type: 'tempo', qpm: qpm });
    									break;
    								case "bar":
    									if (noteEventsInBar > 0) // don't add two bars in a row.
    										voices[voiceNumber].push({ el_type: 'bar' }); // We need the bar marking to reset the accidentals.
    									noteEventsInBar = 0;
    									// figure out repeats and endings --
    									// The important part is where there is a start repeat, and end repeat, or a first ending.
    									var endRepeat = (elem.type === "bar_right_repeat" || elem.type === "bar_dbl_repeat");
    									var startEnding = (elem.startEnding === '1');
    									var startRepeat = (elem.type === "bar_left_repeat" || elem.type === "bar_dbl_repeat" || elem.type === "bar_right_repeat");
    									if (endRepeat) {
    										var s = startRepeatPlaceholder[voiceNumber];
    										if (!s) s = 0; // If there wasn't a left repeat, then we repeat from the beginning.
    										var e = skipEndingPlaceholder[voiceNumber];
    										if (!e) e = voices[voiceNumber].length; // If there wasn't a first ending marker, then we copy everything.
    										voices[voiceNumber] = voices[voiceNumber].concat(voices[voiceNumber].slice(s, e));
    										// reset these in case there is a second repeat later on.
    										skipEndingPlaceholder[voiceNumber] = undefined;
    										startRepeatPlaceholder[voiceNumber] = undefined;
    									}
    									if (startEnding)
    										skipEndingPlaceholder[voiceNumber] = voices[voiceNumber].length;
    									if (startRepeat)
    										startRepeatPlaceholder[voiceNumber] = voices[voiceNumber].length;
    									break;
    								case 'style':
    									// TODO-PER: If this is set to rhythm heads, then it should use the percussion channel.
    									break;
    								case 'part':
    									// TODO-PER: If there is a part section in the header, then this should probably affect the repeats.
    									break;
    								case 'stem':
    								case 'scale':
    									// These elements don't affect sound
    									break;
    								case 'midi':
    									//console.log("MIDI inline", elem); // TODO-PER: for debugging. Remove this.
    									var drumChange = false;
    									switch (elem.cmd) {
    										case "drumon": drumOn = true; drumChange = true; break;
    										case "drumoff": drumOn = false; drumChange = true; break;
    										case "drum": drumPattern = elem.params; drumChange = true; break;
    										case "drumbars": drumBars = elem.params[0]; drumChange = true; break;
    										case "drummap":
    											// This is handled before getting here so it can be ignored.
    											break;
    										case "program":
    											voices[voiceNumber].push({ el_type: 'instrument', program: elem.params[0] });
    											break;
    										case "transpose":
    											voices[voiceNumber].push({ el_type: 'transpose', transpose: elem.params[0] });
    											break;
    										case "gchordoff":
    											voices[voiceNumber].push({ el_type: 'gchord', tacet: true });
    											break;
    										case "gchordon":
    											voices[voiceNumber].push({ el_type: 'gchord', tacet: false });
    											break;
    										case "beat":
    											voices[voiceNumber].push({ el_type: 'beat', beats: elem.params });
    											break;
    										case "nobeataccents":
    											voices[voiceNumber].push({ el_type: 'beataccents', value: false });
    											break;
    										case "beataccents":
    											voices[voiceNumber].push({ el_type: 'beataccents', value: true });
    											break;
    										case "vol":
    											voices[voiceNumber].push({ el_type: 'vol', volume: elem.params[0] });
    											break;
    										case "volinc":
    											voices[voiceNumber].push({ el_type: 'volinc', volume: elem.params[0] });
    											break;
    										default:
    											console.log("MIDI seq: midi cmd not handled: ", elem.cmd, elem);
    									}
    									if (drumChange) {
    										voices[0].push({el_type: 'drum', params: { pattern: drumPattern, bars: drumBars, intro: drumIntro, on: drumOn}});
    										startingDrumSet = true;
    									}
    									break;
    								default:
    									console.log("MIDI: element type " + elem.el_type + " not handled.");
    							}
    						}
    						voiceNumber++;
    					}
    				}
    			}
    		}
    		if (drumIntro) {
    			var pickups = abctune.getPickupLength();
    			// add some measures of rests to the start of each track.
    			for (var vv = 0; vv < voices.length; vv++) {
    				var insertPoint = 0;
    				while (voices[vv][insertPoint].el_type !== "note" && voices[vv].length > insertPoint)
    					insertPoint++;
    				if (voices[vv].length > insertPoint) {
    					for (var w = 0; w < drumIntro; w++) {
    						// If it is the last measure of intro, subtract the pickups.
    						if (pickups === 0 || w < drumIntro-1)
    							voices[vv].splice(insertPoint, 0, {el_type: "note", rest: {type: "rest"}, duration: measureLength},
    								{ el_type: "bar" });
    						else {
    							voices[vv].splice(insertPoint, 0, {el_type: "note", rest: {type: "rest"}, duration: measureLength-pickups});
    						}
    					}
    				}
    			}
    		}
    		return voices;
    	};

    	function interpretTempo(element) {
    		var duration = 1/4;
    		if (element.duration) {
    			duration = element.duration[0];
    		}
    		var bpm = 60;
    		if (element.bpm) {
    			bpm = element.bpm;
    		}
    		// The tempo is defined with a beat of a 1/4 note, so we need to adjust it if the tempo is expressed with other than a quarter note.
    		// expressedDuration * expressedBeatsPerMinute / lengthOfQuarterNote = quarterNotesPerMinute
    		return duration * bpm / 0.25;
    	}

    	function interpretMeter(element) {
    		var meter;
    		switch (element.type) {
    			case "common_time":
    				meter = { el_type: 'meter', num: 4, den: 4 };
    				break;
    			case "cut_time":
    				meter = { el_type: 'meter', num: 2, den: 2 };
    				break;
    			case "specified":
    				// TODO-PER: only taking the first meter, so the complex meters are not handled.
    				meter = { el_type: 'meter', num: element.value[0].num, den: element.value[0].den };
    				break;
    			default:
    				// This should never happen.
    				meter = { el_type: 'meter' };
    		}
    		measureLength = meter.num/meter.den;
    		return meter;
    	}
    })();

    var abc_midi_sequencer = sequence;

    //    abc_midi_flattener.js: Turn a linear series of events into a series of MIDI commands.
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com) and Paul Rosen
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    // We input a set of voices, but the notes are still complex. This pass changes the logical definitions
    // of the grace notes, decorations, ties, triplets, rests, transpositions, keys, and accidentals into actual note durations.
    // It also extracts guitar chords to a separate voice and resolves their rhythm.

    var flatten;

    (function() {

    	var barAccidentals;
    	var accidentals;
    	var transpose;
    	var bagpipes;
    	var multiplier;
    	var tracks;
    	var startingTempo;
    	var tempoChangeFactor = 1;
    	var instrument;
    	var currentInstrument;
    	// var channel;
    	var currentTrack;
    	var pitchesTied;
    	var lastNoteDurationPosition;
    	var currentTrackCounter;

    	var meter = { num: 4, den: 4 };
    	var chordTrack;
    	var chordTrackFinished;
    	var chordChannel;
    	var chordInstrument = 0;
    	var drumInstrument = 128;
    	var currentChords;
    	var lastChord;
    	var barBeat;
    	var gChordTacet = false;
    	var doBeatAccents = true;
    	var stressBeat1 = 105;
    	var stressBeatDown = 95;
    	var stressBeatUp = 85;
    	var beatFraction = 0.25;
    	var nextVolume;
    	var nextVolumeDelta;

    	var drumTrack;
    	var drumDefinition = {};

    	var normalBreakBetweenNotes = 1.0/128;	// a 128th note of silence between notes for articulation.

    	flatten = function(voices, options) {
    		if (!options) options = {};
    		barAccidentals = [];
    		accidentals = [0,0,0,0,0,0,0];
    		bagpipes = false;
    		multiplier = 1;
    		tracks = [];
    		startingTempo = undefined;
    		tempoChangeFactor = 1;
    		instrument = undefined;
    		currentInstrument = undefined;
    		// channel = undefined;
    		currentTrack = undefined;
    		currentTrackCounter = undefined;
    		pitchesTied = {};

    		// For resolving chords.
    		meter = { num: 4, den: 4 };
    		chordTrack = [];
    		chordChannel = voices.length; // first free channel for chords
    		chordTrackFinished = false;
    		currentChords = [];
    		lastChord = undefined;
    		barBeat = 0;
    		gChordTacet = options.chordsOff ? true : false;

    		doBeatAccents = true;
    		stressBeat1 = 105;
    		stressBeatDown = 95;
    		stressBeatUp = 85;
    		beatFraction = 0.25;
    		nextVolume = undefined;
    		nextVolumeDelta = undefined;

    		// For the drum/metronome track.
    		drumTrack = [];
    		drumDefinition = {};

    		zeroOutMilliseconds(voices);

    		for (var i = 0; i < voices.length; i++) {
    			transpose = 0;
    			lastNoteDurationPosition = -1;
    			var voice = voices[i];
    			currentTrack = [{ cmd: 'program', channel: i, instrument: instrument }];
    			currentTrackCounter = 0;
    			pitchesTied = {};
    			for (var j = 0; j < voice.length; j++) {
    				var element = voice[j];
    				switch (element.el_type) {
    					case "note":
    						writeNote(element, options.voicesOff);
    						break;
    					case "key":
    						accidentals = setKeySignature(element);
    						break;
    					case "meter":
    						meter = element;
    						beatFraction = getBeatFraction(meter);
    						break;
    					case "tempo":
    						if (!startingTempo)
    							startingTempo = element.qpm;
    						else
    							tempoChangeFactor = element.qpm ? startingTempo / element.qpm : 1;
    						break;
    					case "transpose":
    						transpose = element.transpose;
    						break;
    					case "bar":
    						if (chordTrack.length > 0 && i === 0) {
    							resolveChords();
    							currentChords = [];
    						}
    						barBeat = 0;
    						barAccidentals = [];
    						if (i === 0) // Only write the drum part on the first voice so that it is not duplicated.
    							writeDrum(voices.length+1);
    						break;
    					case "bagpipes":
    						bagpipes = true;
    						break;
    					case "instrument":
    						if (instrument === undefined)
    							instrument = element.program;
    						currentInstrument = element.program;
    						if (currentTrack.length > 0 && currentTrack[currentTrack.length-1].cmd === 'program')
    							currentTrack[currentTrack.length-1].instrument = element.program;
    						else {
    							var ii;
    							for (ii = currentTrack.length-1; ii >= 0 && currentTrack[ii].cmd !== 'program'; ii--)
    								;
    							if (ii < 0 || currentTrack[ii].instrument !== element.program)
    								currentTrack.push({cmd: 'program', channel: i, instrument: element.program});
    						}
    						break;
    					case "channel":
    					// 	if (channel === undefined)
    					// 		channel = element.channel;
    					// 	currentTrack[0].channel = element.channel;
    						break;
    					case "drum":
    						drumDefinition = normalizeDrumDefinition(element.params);
    						break;
    					case "gchord":
    						if (!options.chordsOff)
    							gChordTacet = element.tacet;
    						break;
    					case "beat":
    						stressBeat1 = element.beats[0];
    						stressBeatDown = element.beats[1];
    						stressBeatUp = element.beats[2];
    						// TODO-PER: also use the last parameter - which changes which beats are strong.
    						break;
    					case "vol":
    						nextVolume = element.volume;
    						break;
    					case "volinc":
    						nextVolumeDelta = element.volume;
    						break;
    					case "beataccents":
    						doBeatAccents = element.value;
    						break;
    					default:
    						// This should never happen
    						console.log("MIDI creation. Unknown el_type: " + element.el_type + "\n");// jshint ignore:line
    						break;
    				}
    			}
    			if (currentTrack[0].instrument === undefined)
    				currentTrack[0].instrument = instrument ? instrument : 0;
    			tracks.push(currentTrack);
    			if (chordTrack.length > 0) // Don't do chords on more than one track, so turn off chord detection after we create it.
    				chordTrackFinished = true;
    			if (drumTrack.length > 0) // Don't do drums on more than one track, so turn off drum after we create it.
    				;
    		}
    		if (chordTrack.length > 0)
    			tracks.push(chordTrack);
    		if (drumTrack.length > 0)
    			tracks.push(drumTrack);
    		// Adjust the tempo according to the meter. The rules are this:
    		// 1) If the denominator is 2 or 4, then always make a beat be the denominator.
    		//
    		// 2) If the denominator is 8 or 16, then:
    		// a) If the numerator is divisible by 3, the beat is 3*denominator.
    		// b) Otherwise the beat is the denominator.
    		//
    		// 3) If the denominator is anything else, then don't worry about it because it doesn't make sense. Don't modify it and hope for the best.
    		//
    		// Right now, the startingTempo is calculated for a quarter note, so modify it if necessary.
    		// var num = startingMeter ? parseInt(startingMeter.num, 10) : meter.num;
    		// var den = startingMeter ? parseInt(startingMeter.den, 10) : meter.den;
    		// if (den === 2)
    		// 	startingTempo *= 2;
    		// else if (den === 8) {
    		// 	if (parseInt(num, 10) % 3 === 0)
    		// 		startingTempo *= 3/2;
    		// 	else
    		// 		startingTempo /= 2;
    		// } else if (den === 16) {
    		// 	if (num % 3 === 0)
    		// 		startingTempo *= 3/4;
    		// 	else
    		// 		startingTempo /= 4;
    		// }

    		return { tempo: startingTempo, instrument: instrument, tracks: tracks, totalDuration: totalDuration(tracks) };
    	};

    	function zeroOutMilliseconds(voices) {
    		for (var i = 0; i < voices.length; i++) {
    			var voice = voices[i];
    			for (var j = 0; j < voice.length; j++) {
    				var element = voice[j];
    				delete element.currentTrackMilliseconds;
    			}
    		}
    	}

    	function totalDuration(tracks) {
    		var total = 0;
    		for (var i = 0; i < tracks.length; i++) {
    			var track = tracks[i];
    			var trackTotal = 0;
    			for (var j = 0; j < track.length; j++) {
    				var event = track[j];
    				if (event.duration)
    					trackTotal += event.duration;
    			}
    			total = Math.max(total, trackTotal);
    		}
    		return total;
    	}

    	function getBeatFraction(meter) {
    		switch (meter.den) {
    			case 2: return 0.5;
    			case 4: return 0.25;
    			case 8: return 0.375;
    			case 16: return 0.125;
    		}
    		return 0.25;
    	}
    	//
    	// The algorithm for chords is:
    	// - The chords are done in a separate track.
    	// - If there are notes before the first chord, then put that much silence to start the track.
    	// - The pattern of chord expression depends on the meter, and how many chords are in a measure.
    	// - There is a possibility that a measure will have an incorrect number of beats, if that is the case, then
    	// start the pattern anew on the next measure number.
    	// - If a chord root is not A-G, then ignore it as if the chord wasn't there at all.
    	// - If a chord modification isn't in our supported list, change it to a major triad.
    	//
    	// - If there is only one chord in a measure:
    	//		- If 2/4, play root chord
    	//		- If cut time, play root(1) chord(3)
    	//		- If 3/4, play root chord chord
    	//		- If 4/4 or common time, play root chord fifth chord
    	//		- If 6/8, play root(1) chord(3) fifth(4) chord(6)
    	//		- For any other meter, play the full chord on each beat. (TODO-PER: expand this as more support is added.)
    	//
    	//	- If there is a chord specified that is not on a beat, move it earlier to the previous beat, unless there is already a chord on that beat.
    	//	- Otherwise, move it later, unless there is already a chord on that beat.
    	// 	- Otherwise, ignore it. (TODO-PER: expand this as more support is added.)
    	//
    	// - If there is a chord on the second beat, play a chord for the first beat instead of a bass note.
    	// - Likewise, if there is a chord on the fourth beat of 4/4, play a chord on the third beat instead of a bass note.
    	//
    	var breakSynonyms = [ 'break', '(break)', 'no chord', 'n.c.', 'tacet'];

    	function findChord(elem) {
    		if (gChordTacet)
    			return 'break';

    		// TODO-PER: Just using the first chord if there are more than one.
    		if (chordTrackFinished || !elem.chord || elem.chord.length === 0)
    			return null;

    		// Return the first annotation that is a regular chord: that is, it is in the default place or is a recognized "tacet" phrase.
    		for (var i = 0; i < elem.chord.length; i++) {
    			var ch = elem.chord[i];
    			if (ch.position === 'default')
    				return ch.name;
    			if (breakSynonyms.indexOf(ch.name.toLowerCase()) >= 0)
    				return 'break';
    		}
    		return null;
    	}

    	function timeFromStart() {
    		var distance = 0;
    		for (var ct = 0; ct < currentTrack.length; ct++) {
    			if (currentTrack[ct].cmd === 'move')
    				distance += currentTrack[ct].duration;
    		}
    		return distance;
    	}

    	function writeNote(elem, voiceOff) {
    		//
    		// Create a series of note events to append to the current track.
    		// The output event is one of: { pitchStart: pitch_in_abc_units, volume: from_1_to_64 }
    		// { pitchStop: pitch_in_abc_units }
    		// { moveTime: duration_in_abc_units }
    		// If there are guitar chords, then they are put in a separate track, but they have the same format.
    		//

    		var volume;
    		if (nextVolume) {
    			volume = nextVolume;
    			nextVolume = undefined;
    		} else if (!doBeatAccents) {
    			volume = stressBeatDown;
    		} else {
    			if (barBeat === 0)
    				volume = stressBeat1;
    			else if (barBeat % beatFraction < 0.001) // A little slop because of JavaScript floating point math.
    				volume = stressBeatDown;
    			else
    				volume = stressBeatUp;
    		}
    		if (nextVolumeDelta) {
    			volume += nextVolumeDelta;
    			nextVolumeDelta = undefined;
    		}
    		if (volume < 0)
    			volume = 0;
    		if (volume > 127)
    			volume = 127;
    		var velocity = voiceOff ? 0 : volume;
    		var chord = findChord(elem);
    		if (chord) {
    			var c = interpretChord(chord);
    			// If this isn't a recognized chord, just completely ignore it.
    			if (c) {
    				// If we ever have a chord in this voice, then we add the chord track.
    				// However, if there are chords on more than one voice, then just use the first voice.
    				if (chordTrack.length === 0) {
    					chordTrack.push({cmd: 'program', channel: chordChannel, instrument: chordInstrument});
    					// need to figure out how far in time the chord started: if there are pickup notes before the chords start, we need pauses.
    					var distance = timeFromStart();
    					if (distance > 0)
    						chordTrack.push({cmd: 'move', duration: distance*tempoChangeFactor });
    				}

    				lastChord = c;
    				currentChords.push({chord: lastChord, beat: barBeat});
    			}
    		}

    		if (elem.startTriplet) {
    			multiplier = elem.tripletMultiplier;
    		}

    		var duration = (elem.durationClass ? elem.durationClass : elem.duration) *multiplier;
    		barBeat += duration;

    		// if there are grace notes, then also play them.
    		// I'm not sure there is an exact rule for the length of the notes. My rule, unless I find
    		// a better one is: the grace notes cannot take more than 1/2 of the main note's value.
    		// A grace note (of 1/8 note duration) takes 1/8 of the main note's value.
    		var graces;
    		if (elem.gracenotes) {
    			// There are two cases: if this is bagpipe, the grace notes are played on the beat with the current note.
    			// Normally, the grace notes would be played before the beat. (If this is the first note in the track, however, then it is played on the current beat.)
    			// The reason for the exception on the first note is that it would otherwise move the whole track in time and would affect all the other tracks.
    			var stealFromCurrent = (bagpipes || lastNoteDurationPosition < 0 || currentTrack.length === 0);
    			var stealFromDuration = stealFromCurrent ? duration : currentTrack[lastNoteDurationPosition].duration;
    			graces = processGraceNotes(elem.gracenotes, stealFromDuration);
    			if (!bagpipes) {
    				duration = writeGraceNotes(graces, stealFromCurrent, duration, null, velocity);
    			}
    		}

    		// The currentTrackCounter is the number of whole notes from the beginning of the piece.
    		// The beat fraction is the note that gets a beat (.25 is a quarter note)
    		// The tempo is in minutes and we want to get to milliseconds.
    		if (!elem.currentTrackMilliseconds)
    			elem.currentTrackMilliseconds = [];
    		elem.currentTrackMilliseconds.push(currentTrackCounter / beatFraction / startingTempo * 60*1000);
    		if (elem.pitches) {
    			if (graces && bagpipes) {
    				// If it is bagpipes, then the graces are played with the note. If the grace has the same pitch as the note, then we just skip it.
    				duration = writeGraceNotes(graces, true, duration, null, velocity);
    			}
    			var pitches = [];
    			elem.midiPitches = [];
    			for (var i=0; i<elem.pitches.length; i++) {
    				var note = elem.pitches[i];
    				var actualPitch = adjustPitch(note);
    				pitches.push({ pitch: actualPitch, startTie: note.startTie });
    				elem.midiPitches.push({ pitch: actualPitch+60, durationInMeasures: duration*tempoChangeFactor, volume: volume, instrument: currentInstrument }); // TODO-PER: why is the internal numbering system offset by 60 from midi? It should probably be the same as midi.

    				if (!pitchesTied[''+actualPitch])	// If this is the second note of a tie, we don't start it again.
    					currentTrack.push({ cmd: 'start', pitch: actualPitch, volume: velocity });
    				else {
    					// but we do add the duration to what we call back.
    					for (var last = currentTrack.length-1; last >= 0; last--) {
    						if (currentTrack[last].cmd === 'start' && currentTrack[last].pitch === actualPitch && currentTrack[last].elem) {
    							var pitchArray = currentTrack[last].elem.midiPitches;
    							for (var last2 = 0; last2 < pitchArray.length; last2++) {
    								if (pitchArray[last2].pitch-60 === actualPitch) { // TODO-PER: the 60 is to compensate for the midi pitch numbers again.
    									pitchArray[last2].durationInMeasures += duration * tempoChangeFactor;
    								}
    							}
    							break;
    						}
    					}
    				}

    				if (note.startTie) {
    					pitchesTied['' + actualPitch] = true;
    					currentTrack[currentTrack.length-1].elem = elem;
    				} else if (note.endTie)
    					pitchesTied[''+actualPitch] = false;
    			}
    			if (elem.gracenotes) {
    				for (var j = 0; j < elem.gracenotes.length; j++) {
    					elem.midiGraceNotePitches = [];
    					var grace = elem.gracenotes[j];
    					elem.midiGraceNotePitches.push({ pitch: adjustPitch(grace)+60, durationInMeasures: 0, volume: volume, instrument: currentInstrument});
    				}
    			}
    			var thisBreakBetweenNotes = normalBreakBetweenNotes;
    			var soundDuration = duration-normalBreakBetweenNotes;
    			if (soundDuration < 0) {
    				soundDuration = 0;
    				thisBreakBetweenNotes = 0;
    			}
    			currentTrack.push({ cmd: 'move', duration: soundDuration*tempoChangeFactor });
    			lastNoteDurationPosition = currentTrack.length-1;
    			currentTrackCounter += soundDuration*tempoChangeFactor;

    			for (var ii = 0; ii < pitches.length; ii++) {
    				if (!pitchesTied[''+pitches[ii].pitch])
    					currentTrack.push({ cmd: 'stop', pitch: pitches[ii].pitch });
    			}
    			currentTrack.push({ cmd: 'move', duration: thisBreakBetweenNotes*tempoChangeFactor });
    			currentTrackCounter += thisBreakBetweenNotes*tempoChangeFactor;
    		} else if (elem.rest) {
    			currentTrack.push({ cmd: 'move', duration: duration*tempoChangeFactor });
    			currentTrackCounter += duration*tempoChangeFactor;
    		}

    		if (elem.endTriplet) {
    			multiplier=1;
    		}
    	}

    	var scale = [0,2,4,5,7,9,11];
    	function adjustPitch(note) {
    		if (note.midipitch)
    			return note.midipitch - 60;
    		var pitch = note.pitch;
    		if (note.accidental) {
    			switch(note.accidental) { // change that pitch (not other octaves) for the rest of the bar
    				case "sharp":
    					barAccidentals[pitch]=1; break;
    				case "flat":
    					barAccidentals[pitch]=-1; break;
    				case "natural":
    					barAccidentals[pitch]=0; break;
    				case "dblsharp":
    					barAccidentals[pitch]=2; break;
    				case "dblflat":
    					barAccidentals[pitch]=-2; break;
    			}
    		}

    		var actualPitch = extractOctave(pitch) *12 + scale[extractNote(pitch)];

    		if ( barAccidentals[pitch]!==undefined) {
    			actualPitch +=  barAccidentals[pitch];
    		} else { // use normal accidentals
    			actualPitch +=  accidentals[extractNote(pitch)];
    		}
    		actualPitch += transpose;
    		return actualPitch;
    	}

    	function setKeySignature(elem) {
    		var accidentals = [0,0,0,0,0,0,0];
    		if (!elem.accidentals) return accidentals;
    		for (var i = 0; i < elem.accidentals.length; i++) {
    			var acc = elem.accidentals[i];
    			var d = (acc.acc === "sharp") ? 1 : (acc.acc === "natural") ?0 : -1;

    			var lowercase = acc.note.toLowerCase();
    			var note = extractNote(lowercase.charCodeAt(0)-'c'.charCodeAt(0));
    			accidentals[note]+=d;
    		}
    		return accidentals;
    	}

    	var graceDivider = 8; // This is the fraction of a note that the grace represents. That is, if this is 2, then a grace note of 1/16 would be a 1/32.
    	function processGraceNotes(graces, companionDuration) {
    		var graceDuration = 0;
    		var ret = [];
    		var grace;
    		for (var g = 0; g < graces.length; g++) {
    			grace = graces[g];
    			graceDuration += grace.duration;
    		}
    		graceDuration = graceDuration / graceDivider;
    		var multiplier = (graceDuration * 2 > companionDuration) ? companionDuration/(graceDuration * 2) : 1;

    		for (g = 0; g < graces.length; g++) {
    			grace = graces[g];
    			var pitch = grace.midipitch ? grace.midipitch - 60 : grace.pitch;
    			ret.push({ pitch: pitch, duration: grace.duration/graceDivider*multiplier });
    		}
    		return ret;
    	}

    	function writeGraceNotes(graces, stealFromCurrent, duration, skipNote, velocity) {
    		for (var g = 0; g < graces.length; g++) {
    			var gp = graces[g];
    			if (gp !== skipNote)
    				currentTrack.push({cmd: 'start', pitch: gp.pitch, volume: velocity});
    			currentTrack.push({cmd: 'move', duration: graces[g].duration*tempoChangeFactor });
    			if (gp !== skipNote)
    				currentTrack.push({cmd: 'stop', pitch: gp.pitch});
    			if (!stealFromCurrent)
    				currentTrack[lastNoteDurationPosition].duration -= graces[g].duration;
    			duration -= graces[g].duration;
    		}
    		return duration;
    	}

    	function extractOctave(pitch) {
    		return Math.floor(pitch/7);
    	}

    	function extractNote(pitch) {
    		pitch = pitch%7;
    		if (pitch<0) pitch+=7;
    		return pitch;
    	}

    	var basses = {
    		'A': -27, 'B': -25, 'C': -24, 'D': -22, 'E': -20, 'F': -19, 'G': -17
    	};
    	function interpretChord(name) {
    		// chords have the format:
    		// [root][acc][modifier][/][bass][acc]
    		// (The chord might be surrounded by parens. Just ignore them.)
    		// root must be present and must be from A-G.
    		// acc is optional and can be # or b
    		// The modifier can be a wide variety of things, like "maj7". As they are discovered, more are supported here.
    		// If there is a slash, then there is a bass note, which can be from A-G, with an optional acc.
    		// If the root is unrecognized, then "undefined" is returned and there is no chord.
    		// If the modifier is unrecognized, a major triad is returned.
    		// If the bass notes is unrecognized, it is ignored.
    		if (name.length === 0)
    			return undefined;
    		if (name === 'break')
    			return { chick: []};
    		var root = name.substring(0,1);
    		if (root === '(') {
    			name = name.substring(1,name.length-2);
    			if (name.length === 0)
    				return undefined;
    			root = name.substring(0,1);
    		}
    		var bass = basses[root];
    		if (!bass)	// If the bass note isn't listed, then this was an unknown root. Only A-G are accepted.
    			return undefined;
    		bass  += transpose;
    		var bass2 = bass - 5;	// The alternating bass is a 4th below
    		var chick;
    		if (name.length === 1)
    			chick = chordNotes(bass, '');
    		var remaining = name.substring(1);
    		var acc = remaining.substring(0,1);
    		if (acc === 'b' || acc === '♭') {
    			bass--;
    			bass2--;
    			remaining = remaining.substring(1);
    		} else if (acc === '#' || acc === '♯') {
    			bass++;
    			bass2++;
    			remaining = remaining.substring(1);
    		}
    		var arr = remaining.split('/');
    		chick = chordNotes(bass, arr[0]);
    		if (arr.length === 2) {
    			var explicitBass = basses[arr[1].substring(0,1)];
    			if (explicitBass) {
    				var bassAcc = arr[1].substring(1);
    				var bassShift = {'#': 1, '♯': 1, 'b': -1, '♭': -1}[bassAcc] || 0;
    				bass = basses[arr[1].substring(0,1)] + bassShift + transpose;
    				bass2 = bass;
    			}
    		}
    		return { boom: bass, boom2: bass2, chick: chick };
    	}

    	var chordIntervals = {
    		// diminished (all flat 5 chords)
    		'dim': [ 0, 3, 6 ],
    		'°': [ 0, 3, 6 ],
    		'˚': [ 0, 3, 6 ],

    		'dim7': [ 0, 3, 6, 9 ],
    		'°7': [ 0, 3, 6, 9 ],
    		'˚7': [ 0, 3, 6, 9 ],

    		'ø7': [ 0, 3, 6, 10 ],
    		'm7(b5)': [ 0, 3, 6, 10 ],
    		'm7b5': [ 0, 3, 6, 10 ],
    		'-7(b5)': [ 0, 3, 6, 10 ],
    		'-7b5': [ 0, 3, 6, 10 ],

    		'7b5': [ 0, 4, 6, 10 ],
    		'7(b5)': [ 0, 4, 6, 10 ],
    		'7♭5': [ 0, 4, 6, 10 ],

    		'7(b9,b5)': [ 0, 4, 6, 10, 13 ],
    		'7b9,b5': [ 0, 4, 6, 10, 13 ],
    		'7(#9,b5)': [ 0, 4, 6, 10, 15 ],
    		'7#9b5': [ 0, 4, 6, 10, 15 ],
    		'maj7(b5)': [ 0, 3, 6, 11 ],
    		'maj7b5': [ 0, 3, 6, 11 ],
    		'13(b5)': [ 0, 4, 6, 10, 14, 18 ],
    		'13b5': [ 0, 4, 6, 10, 14, 18 ],

    		// minor (all normal 5, minor 3 chords)
    		'm': [ 0, 3, 7 ],
    		'-': [ 0, 3, 7 ],
    		'm6': [ 0, 3, 7, 9 ],
    		'-6': [ 0, 3, 7, 9 ],
    		'm7': [ 0, 3, 7, 10 ],
    		'-7': [ 0, 3, 7, 10 ],

    		'-(b6)': [ 0, 3, 7, 8 ],
    		'-b6': [ 0, 3, 7, 8 ],
    		'-6/9': [ 0, 3, 7, 9, 14 ],
    		'-7(b9)': [ 0, 3, 7, 10, 13 ],
    		'-7b9': [ 0, 3, 7, 10, 13 ],
    		'-maj7': [ 0, 3, 7, 11 ],
    		'-9+7': [ 0, 3, 7, 11, 13 ],
    		'-11': [  0, 3, 7, 11, 14, 16 ],

    		// major (all normal 5, major 3 chords)
    		'M': [ 0, 4, 7 ],
    		'6': [ 0, 4, 7, 9 ],
    		'6/9': [ 0, 4, 7, 9, 14 ],

    		'7': [ 0, 4, 7, 10 ],
    		'9': [ 0, 4, 7, 10, 14 ],
    		'11': [ 0, 4, 7, 10, 14, 16 ],
    		'13': [ 0, 4, 7, 10, 14, 18 ],
    		'7b9': [ 0, 4, 7, 10, 13 ],
    		'7♭9': [ 0, 4, 7, 10, 13 ],
    		'7(b9)': [ 0, 4, 7, 10, 13 ],
    		'7(#9)': [ 0, 4, 7, 10, 15 ],
    		'7#9': [ 0, 4, 7, 10, 15 ],
    		'(13)': [ 0, 4, 7, 10, 14, 18 ],
    		'7(9,13)': [ 0, 4, 7, 10, 14, 18 ],
    		'7(#9,b13)': [ 0, 4, 7, 10, 15, 17 ],
    		'7(#11)': [ 0, 4, 7, 10, 14, 17 ],
    		'7#11': [ 0, 4, 7, 10, 14, 17 ],
    		'7(b13)': [ 0, 4, 7, 10, 17 ],
    		'7b13': [ 0, 4, 7, 10, 17 ],
    		'9(#11)': [ 0, 4, 7, 10, 14, 17 ],
    		'9#11': [ 0, 4, 7, 10, 14, 17 ],
    		'13(#11)': [ 0, 4, 7, 10, 15, 18 ],
    		'13#11': [ 0, 4, 7, 10, 15, 18 ],

    		'maj7': [ 0, 4, 7, 11 ],
    		'∆7': [ 0, 4, 7, 11 ],
    		'Δ7': [ 0, 4, 7, 11 ],
    		'maj9': [ 0, 4, 7, 11, 14 ],
    		'maj7(9)': [ 0, 4, 7, 11, 14 ],
    		'maj7(11)': [ 0, 4, 7, 11, 16 ],
    		'maj7(#11)': [ 0, 4, 7, 11, 17 ],
    		'maj7(13)': [ 0, 4, 7, 11, 18 ],
    		'maj7(9,13)': [ 0, 4, 7, 11, 14, 18 ],

    		'7sus4': [ 0, 5, 7, 10 ],
    		'm7sus4': [ 0, 5, 7, 10 ],
    		'sus4': [ 0, 5, 7 ],
    		'sus2': [ 0, 2, 7 ],
    		'7sus2': [ 0, 2, 7, 10 ],
    		'9sus4': [ 0, 5, 7, 14 ],
    		'13sus4': [ 0, 5, 7, 18 ],

    		// augmented (all sharp 5 chords)
    		'aug7': [ 0, 4, 8, 10 ],
    		'+7': [ 0, 4, 8, 10 ],
    		'+': [ 0, 4, 8 ],
    		'7#5': [ 0, 4, 8, 10 ],
    		'7♯5': [ 0, 4, 8, 10 ],
    		'7+5': [ 0, 4, 8, 10 ],
    		'9#5': [ 0, 4, 8, 10, 14 ],
    		'9♯5': [ 0, 4, 8, 10, 14 ],
    		'9+5': [ 0, 4, 8, 10, 14 ],
    		'-7(#5)': [ 0, 3, 8, 10 ],
    		'-7#5': [ 0, 3, 8, 10 ],
    		'7(#5)': [ 0, 4, 8, 10 ],
    		'7(b9,#5)': [ 0, 4, 8, 10, 13 ],
    		'7b9#5': [ 0, 4, 8, 10, 13 ],
    		'maj7(#5)': [ 0, 4, 8, 11 ],
    		'maj7#5': [ 0, 4, 8, 11 ],
    		'maj7(#5,#11)': [ 0, 4, 8, 11, 14 ],
    		'maj7#5#11': [ 0, 4, 8, 11, 14 ],
    		'9(#5)': [ 0, 4, 8, 10, 14 ],
    		'13(#5)': [ 0, 4, 8, 10, 14, 18 ],
    		'13#5': [ 0, 4, 8, 10, 14, 18 ]
    };
    	function chordNotes(bass, modifier) {
    		var intervals = chordIntervals[modifier];
    		if (!intervals)
    			intervals = chordIntervals.M;
    		bass += 12;	// the chord is an octave above the bass note.
    		var notes = [ ];
    		for (var i = 0; i < intervals.length; i++) {
    			notes.push(bass + intervals[i]);
    		}
    		return notes;
    	}

    	function writeBoom(boom, beatLength) {
    		// undefined means there is a stop time.
    		if (boom !== undefined)
    			chordTrack.push({cmd: 'start', pitch: boom, volume: 64});
    		chordTrack.push({ cmd: 'move', duration: (beatLength/2)*tempoChangeFactor });
    		if (boom !== undefined)
    			chordTrack.push({ cmd: 'stop', pitch: boom });
    		chordTrack.push({ cmd: 'move', duration: (beatLength/2)*tempoChangeFactor });
    	}

    	function writeChick(chick, beatLength) {
    		for (var c = 0; c < chick.length; c++)
    			chordTrack.push({cmd: 'start', pitch: chick[c], volume: 48});
    		chordTrack.push({ cmd: 'move', duration: (beatLength/2)*tempoChangeFactor });
    		for (c = 0; c < chick.length; c++)
    			chordTrack.push({ cmd: 'stop', pitch: chick[c] });
    		chordTrack.push({ cmd: 'move', duration: (beatLength/2)*tempoChangeFactor });
    	}

    	var rhythmPatterns = { "2/2": [ 'boom', 'chick' ],
    		"2/4": [ 'boom', 'chick' ],
    		"3/4": [ 'boom', 'chick', 'chick' ],
    		"4/4": [ 'boom', 'chick', 'boom2', 'chick' ],
    		"5/4": [ 'boom', 'chick', 'chick', 'boom2', 'chick' ],
    		"6/8": [ 'boom', '', 'chick', 'boom2', '', 'chick' ],
    		"9/8": [ 'boom', '', 'chick', 'boom2', '', 'chick', 'boom2', '', 'chick' ],
    		"12/8": [ 'boom', '', 'chick', 'boom2', '', 'chick', 'boom2', '', 'chick', 'boom2', '', 'chick' ],
    	};

    	function resolveChords() {
    		var num = meter.num;
    		var den = meter.den;
    		var beatLength = 1/den;
    		var pattern = rhythmPatterns[num+'/'+den];
    		var thisMeasureLength = parseInt(num,10)/parseInt(den,10);
    		// See if this is a full measure: unfortunately, with triplets, there isn't an exact match, what with the floating point, so we just see if it is "close".
    		var portionOfAMeasure = Math.abs(thisMeasureLength - barBeat);
    		if (!pattern || portionOfAMeasure > 0.0078125) { // If it is an unsupported meter, or this isn't a full bar, just chick on each beat.
    			pattern = [];
    			var beatsPresent = barBeat / beatLength;
    			for (var p = 0; p < beatsPresent; p++)
    				pattern.push("chick");
    		}

    		if (currentChords.length === 0) { // there wasn't a new chord this measure, so use the last chord declared.
    			currentChords.push({ beat: 0, chord: lastChord});
    		}
    		if (currentChords[0].beat !== 0 && lastChord) { // this is the case where there is a chord declared in the measure, but not on its first beat.
    			currentChords.unshift({ beat: 0, chord: lastChord});
    		}
    		if (currentChords.length === 1) {
    			for (var m = 0; m < pattern.length; m++) {
    				switch (pattern[m]) {
    					case 'boom':
    						writeBoom(currentChords[0].chord.boom, beatLength);
    						break;
    					case 'boom2':
    						writeBoom(currentChords[0].chord.boom2, beatLength);
    						break;
    					case 'chick':
    						writeChick(currentChords[0].chord.chick, beatLength);
    						break;
    					case '':
    						chordTrack.push({ cmd: 'move', duration: beatLength*tempoChangeFactor });
    						break;
    				}
    			}
    			return;
    		}

    		// If we are here it is because more than one chord was declared in the measure, so we have to sort out what chord goes where.

    		// First, normalize the chords on beats.
    		var beats = {};
    		for (var i = 0; i < currentChords.length; i++) {
    			var cc = currentChords[i];
    			var beat = Math.floor(cc.beat / beatLength);	// now all the beats are integers, there may be
    			beats[''+beat] = cc;
    		}

    		// - If there is a chord on the second beat, play a chord for the first beat instead of a bass note.
    		// - Likewise, if there is a chord on the fourth beat of 4/4, play a chord on the third beat instead of a bass note.
    		for (var m2 = 0; m2 < pattern.length; m2++) {
    			var thisChord;
    			if (beats[''+m2])
    				thisChord = beats[''+m2];
    			switch (pattern[m2]) {
    				case 'boom':
    					if (beats[''+(m2+1)]) // If there is not a chord change on the next beat, play a bass note.
    						writeChick(thisChord.chord.chick, beatLength);
    					else
    						writeBoom(thisChord.chord.boom, beatLength);
    					break;
    				case 'boom2':
    					if (beats[''+(m2+1)])
    						writeChick(thisChord.chord.chick, beatLength);
    					else
    						writeBoom(thisChord.chord.boom2, beatLength);
    					break;
    				case 'chick':
    					writeChick(thisChord.chord.chick, beatLength);
    					break;
    				case '':
    					if (beats[''+m2])	// If there is an explicit chord on this beat, play it.
    						writeChick(thisChord.chord.chick, beatLength);
    					else
    						chordTrack.push({cmd: 'move', duration: beatLength*tempoChangeFactor });
    					break;
    			}
    		}
    	}

    	function normalizeDrumDefinition(params) {
    		// Be very strict with the drum definition. If anything is not perfect,
    		// just turn the drums off.
    		// Perhaps all of this logic belongs in the parser instead.
    		if (params.pattern.length === 0 || params.on === false)
    			return { on: false };

    		var str = params.pattern[0];
    		var events = [];
    		var event = "";
    		var totalPlay = 0;
    		for (var i = 0; i < str.length; i++) {
    			if (str[i] === 'd')
    				totalPlay++;
    			if (str[i] === 'd' || str[i] === 'z') {
    				if (event.length !== 0) {
    					events.push(event);
    					event = str[i];
    				} else
    					event = event + str[i];
    			} else {
    				if (event.length === 0) {
    					// there was an error: the string should have started with d or z
    					return {on: false};
    				}
    				event = event + str[i];
    			}
    		}

    		if (event.length !== 0)
    			events.push(event);

    		// Now the events array should have one item per event.
    		// There should be two more params for each event: the volume and the pitch.
    		if (params.pattern.length !== totalPlay*2 + 1)
    			return { on: false };

    		var ret = { on: true, bars: params.bars, pattern: []};
    		var beatLength = 1/meter.den;
    		var playCount = 0;
    		for (var j = 0; j < events.length; j++) {
    			event = events[j];
    			var len = 1;
    			var div = false;
    			var num = 0;
    			for (var k = 1; k < event.length; k++) {
    				switch(event[k]) {
    					case "/":
    						if (num !== 0)
    							len *= num;
    						num = 0;
    						div = true;
    						break;
    					case "1":
    					case "2":
    					case "3":
    					case "4":
    					case "5":
    					case "6":
    					case "7":
    					case "8":
    					case "9":
    						num = num*10 +event[k];
    						break;
    					default:
    						return { on: false };
    				}
    			}
    			if (div) {
    				if (num === 0) num = 2; // a slash by itself is interpreted as "/2"
    				len /= num;
    			} else if (num)
    				len *= num;
    			if (event[0] === 'd') {
    				ret.pattern.push({ len: len * beatLength, pitch: params.pattern[1 + playCount], velocity: params.pattern[1 + playCount + totalPlay]});
    				playCount++;
    			} else
    				ret.pattern.push({ len: len * beatLength, pitch: null});
    		}
    		// Now normalize the pattern to cover the correct number of measures. The note lengths passed are relative to each other and need to be scaled to fit a measure.
    		var totalTime = 0;
    		var measuresPerBeat = meter.num/meter.den;
    		for (var ii = 0; ii < ret.pattern.length; ii++)
    			totalTime += ret.pattern[ii].len;
    		var numBars = params.bars ? params.bars : 1;
    		var factor = totalTime /  numBars / measuresPerBeat;
    		for (ii = 0; ii < ret.pattern.length; ii++)
    			ret.pattern[ii].len = ret.pattern[ii].len / factor;
    		return ret;
    	}

    	function drumBeat(pitch, soundLength, volume) {
    		drumTrack.push({ cmd: 'start', pitch: pitch - 60, volume: volume});
    		drumTrack.push({ cmd: 'move', duration: soundLength });
    		drumTrack.push({ cmd: 'stop', pitch: pitch - 60 });
    	}

    	function writeDrum(channel) {
    		if (drumTrack.length === 0 && !drumDefinition.on)
    			return;

    		var measureLen = meter.num/meter.den;
    		if (drumTrack.length === 0) {
    			drumTrack.push({cmd: 'program', channel: channel, instrument: drumInstrument});
    			// need to figure out how far in time the bar started: if there are pickup notes before the chords start, we need pauses.
    			var distance = timeFromStart();
    			if (distance > 0 && distance < measureLen - 0.01) { // because of floating point, adding the notes might not exactly equal the measure size.
    				drumTrack.push({cmd: 'move', duration: distance * tempoChangeFactor});
    				return;
    			}
    		}

    		if (!drumDefinition.on) {
    			// this is the case where there has been a drum track, but it was specifically turned off.
    			drumTrack.push({ cmd: 'move', duration: measureLen * tempoChangeFactor });
    			return;
    		}
    		for (var i = 0; i < drumDefinition.pattern.length; i++) {
    			var len = drumDefinition.pattern[i].len * tempoChangeFactor;
    			if (drumDefinition.pattern[i].pitch)
    				drumBeat(drumDefinition.pattern[i].pitch, len, drumDefinition.pattern[i].velocity);
    			else
    				drumTrack.push({ cmd: 'move', duration: len });
    		}
    	}
    })();

    var abc_midi_flattener = flatten;

    // TODO-PER: remove the midi tests from here: I don't think the object can be constructed unless it passes.
    var notSupportedMessage = "MIDI is not supported in this browser.";

    var defaultSoundFontUrl = "https://paulrosen.github.io/midi-js-soundfonts/FluidR3_GM/";


    function CreateSynth() {
    	var self = this;
    	self.audioBufferPossible = undefined;
    	self.directSource = []; // type: AudioBufferSourceNode
    	self.startTimeSec = undefined; // the time that the midi started: used for pause/resume.
    	self.pausedTimeSec = undefined; // the time that the midi was paused: used for resume.
    	self.audioBuffers = []; // cache of the buffers so starting play can be fast.
    	self.duration = undefined; // the duration of the tune in seconds.
    	self.isRunning = false; // whether there is currently a sound buffer running.

    	// Load and cache all needed sounds
    	self.init = function(options) {
    		if (!options)
    			options = {};
    		registerAudioContext_1(options.audioContext); // This works no matter what - if there is already an ac it is a nop; if the context is not passed in, then it creates one.
    		var startTime = activeAudioContext_1().currentTime;
    		self.debugCallback = options.debugCallback;
    		if (self.debugCallback)
    			self.debugCallback("init called");
    		self.audioBufferPossible = self._deviceCapable();
    		if (!self.audioBufferPossible)
    			return Promise.reject({ status: "NotSupported", message: notSupportedMessage});
    		self.soundFontUrl = options.soundFontUrl ? options.soundFontUrl : defaultSoundFontUrl;
    		self.millisecondsPerMeasure = options.millisecondsPerMeasure ? options.millisecondsPerMeasure : (options.visualObj ? options.visualObj.millisecondsPerMeasure() : 1000);
    		var params = options.options ? options.options : {};
    		self.meterSize = 1;
    		if (options.visualObj) {
    			var seq = abc_midi_sequencer(options.visualObj, params);
    			self.flattened = abc_midi_flattener(seq, params);
    			self.meterSize = options.visualObj.getMeterFraction().num / options.visualObj.getMeterFraction().den;
    		} else if (options.sequence)
    			self.flattened = options.sequence;
    		else
    			return Promise.reject(new Error("Must pass in either a visualObj or a sequence"));
    		self.sequenceCallback = params.sequenceCallback;
    		self.callbackContext = params.callbackContext;
    		self.onEnded = options.onEnded;

    		var allNotes = {};
    		var currentInstrument = instrumentIndexToName_1[0];
    		self.flattened.tracks.forEach(function(track) {
    			track.forEach(function(event) {
    				if (event.cmd === "program" && instrumentIndexToName_1[event.instrument])
    					currentInstrument = instrumentIndexToName_1[event.instrument];
    				if (event.pitch !== undefined) {
    					var pitchNumber = event.pitch + 60;
    					var noteName = pitchToNoteName_1[pitchNumber];
    					if (noteName) {
    						if (!allNotes[currentInstrument])
    							allNotes[currentInstrument] = {};
    						allNotes[currentInstrument][pitchToNoteName_1[pitchNumber]] = true;
    					} else
    						console.log("Can't find note: ", pitchNumber);
    				}
    			});
    		});
    		if (self.debugCallback)
    			self.debugCallback("note gathering time = " + Math.floor((activeAudioContext_1().currentTime - startTime)*1000)+"ms");
    		startTime = activeAudioContext_1().currentTime;

    		var notes = [];
    		Object.keys(allNotes).forEach(function(instrument) {
    			Object.keys(allNotes[instrument]).forEach(function(note) {
    				notes.push({ instrument: instrument, note: note });
    			});
    		});
    		// If there are lots of notes, load them in batches
    		var batches = [];
    		var CHUNK = 256;
    		for (var i=0; i < notes.length; i += CHUNK) {
    			batches.push(notes.slice(i, i + CHUNK));
    		}

    		return new Promise(function(resolve, reject) {
    			var results = [];

    			var index = 0;
    			var next = function() {
    				if (index < batches.length) {
    					self._loadBatch(batches[index], self.soundFontUrl, startTime).then(function(data) {
    						startTime = activeAudioContext_1().currentTime;
    						results.push(data);
    						index++;
    						next();
    					}, reject);
    				} else {
    					resolve(results);
    				}
    			};
    			next();
    		});
    	};

    	self._loadBatch = (function(batch, soundFontUrl, startTime) {
    		var promises = [];
    		batch.forEach(function(item) {
    			promises.push(loadNote(soundFontUrl, item.instrument, item.note, activeAudioContext_1()));
    		});
    		return Promise.all(promises).then(function(response) {
    			if (self.debugCallback)
    				self.debugCallback("mp3 load time = " + Math.floor((activeAudioContext_1().currentTime - startTime)*1000)+"ms");
    			return Promise.resolve(response);
    		});
    	});

    	self.prime = function() {
    		self.isRunning = false;
    		if (!self.audioBufferPossible)
    			return Promise.reject(new Error(notSupportedMessage));
    		if (self.debugCallback)
    			self.debugCallback("prime called");
    		return new Promise(function(resolve) {
    			var startTime = activeAudioContext_1().currentTime;
    			var tempoMultiplier = self.millisecondsPerMeasure / 1000 / self.meterSize;
    			self.duration = self.flattened.totalDuration * tempoMultiplier;
    			var totalSamples = Math.floor(activeAudioContext_1().sampleRate * self.duration);

    			// There might be a previous run that needs to be turned off.
    			self.stop();

    			var noteMapTracks = createNoteMap_1(self.flattened);
    			if (self.sequenceCallback)
    				self.sequenceCallback(noteMapTracks, self.callbackContext);
    			//console.log(noteMapTracks);

    			self.audioBuffers = [];
    			noteMapTracks.forEach(function(noteMap) {
    				var audioBuffer = activeAudioContext_1().createBuffer(1, totalSamples, activeAudioContext_1().sampleRate);
    				var chanData = audioBuffer.getChannelData(0);

    				noteMap.forEach(function(note) {
    					self._placeNote(chanData, note, tempoMultiplier, soundsCache_1);
    				});

    				self.audioBuffers.push(audioBuffer);
    			});

    			if (self.debugCallback) {
    				self.debugCallback("sampleRate = " + activeAudioContext_1().sampleRate);
    				self.debugCallback("totalSamples = " + totalSamples);
    				self.debugCallback("creationTime = " + Math.floor((activeAudioContext_1().currentTime - startTime)*1000) + "ms");
    			}
    			resolve({
    				status: "ok",
    				seconds: 0
    			});
    		});
    	};

    	// This is called after everything is set up, so it can quickly make sound
    	self.start = function() {
    		if (self.pausedTimeSec) {
    			self.resume();
    			return;
    		}

    		if (!self.audioBufferPossible)
    			throw new Error(notSupportedMessage);
    		if (self.debugCallback)
    			self.debugCallback("start called");

    		self._kickOffSound(0);
    		self.startTimeSec = activeAudioContext_1().currentTime;
    		self.pausedTimeSec = undefined;

    		if (self.debugCallback)
    			self.debugCallback("MIDI STARTED", self.startTimeSec);
    	};

    	self.pause = function() {
    		if (!self.audioBufferPossible)
    			throw new Error(notSupportedMessage);
    		if (self.debugCallback)
    			self.debugCallback("pause called");

    		if (!self.pausedTimeSec) { // ignore if self is already paused.
    			self.stop();
    			self.pausedTimeSec = activeAudioContext_1().currentTime;
    		}
    	};

    	self.resume = function() {
    		if (!self.audioBufferPossible)
    			throw new Error(notSupportedMessage);
    		if (self.debugCallback)
    			self.debugCallback("resume called");

    		var offset = self.pausedTimeSec - self.startTimeSec;
    		self.startTimeSec = activeAudioContext_1().currentTime - offset; // We move the start time in case there is another pause/resume.
    		self.pausedTimeSec = undefined;
    		self._kickOffSound(offset);
    	};

    	self.seek = function(percent) {
    		var offset = self.duration * percent;

    		// TODO-PER: can seek when paused or when playing
    		if (!self.audioBufferPossible)
    			throw new Error(notSupportedMessage);
    		if (self.debugCallback)
    			self.debugCallback("seek called sec=" + offset);

    		if (self.isRunning) {
    			self.stop();
    			self._kickOffSound(offset);
    		}
    		var pauseDistance = self.pausedTimeSec ? self.pausedTimeSec - self.startTimeSec : undefined;
    		self.startTimeSec = activeAudioContext_1().currentTime - offset;
    		if (self.pausedTimeSec)
    			self.pausedTimeSec = self.startTimeSec + pauseDistance;
    	};

    	self.stop = function() {
    		self.isRunning = false;
    		self.pausedTimeSec = undefined;
    		self.directSource.forEach(function(source) {
    			try {
    				source.stop();
    			} catch (error) {
    				// We don't care if self succeeds: it might fail if something else turned off the sound or it ended for some reason.
    				console.log("direct source didn't stop:", error);
    			}
    		});
    		self.directSource = [];
    	};

    	self.download = function() {
    		return downloadBuffer_1(self);
    	};

    	/////////////// Private functions //////////////

    	self._deviceCapable = function() {
    		if (!supportsAudio_1()) {
    			console.warn(notSupportedMessage);
    			if (self.debugCallback)
    				self.debugCallback(notSupportedMessage);
    			return false;
    		}
    		return true;
    	};

    	self._kickOffSound = function(seconds) {
    		self.isRunning = true;
    		self.directSource = [];
    		self.audioBuffers.forEach(function(audioBuffer, trackNum) {
    			self.directSource[trackNum] = activeAudioContext_1().createBufferSource(); // creates a sound source
    			self.directSource[trackNum].buffer = audioBuffer; // tell the source which sound to play
    			self.directSource[trackNum].connect(activeAudioContext_1().destination); // connect the source to the context's destination (the speakers)
    		});
    		self.directSource.forEach(function(source) {
    			source.start(0, seconds);
    		});
    		if (self.onEnded) {
    			self.directSource[0].onended = function () {
    				self.onEnded(self.callbackContext);
    			};
    		}
    	};

    	self._placeNote = function(chanData, note, tempoMultiplier, soundsCache) {
    		var start = Math.floor(note.start*activeAudioContext_1().sampleRate * tempoMultiplier);
    		var numBeats = note.end - note.start;
    		var noteTimeSec = numBeats * tempoMultiplier;
    		var noteName = pitchToNoteName_1[note.pitch+60];
    		if (noteName) { // Just ignore pitches that don't exist.
    			var pitch = soundsCache[note.instrument][noteName].getChannelData(0);
    			var duration = Math.min(pitch.length, Math.floor(noteTimeSec * activeAudioContext_1().sampleRate));
    			//console.log(pitchToNote[note.pitch+''], start, numBeats, noteTimeSec, duration);
    			for (var i = 0; i < duration; i++) {
    				var thisSample = pitch[i] * note.volume / 128;
    				if (chanData[start + i])
    					chanData[start + i] = (chanData[start + i] + thisSample) *0.75;
    				else
    					chanData[start + i] = thisSample;
    			}
    		}
    	};
    }

    var createSynth = CreateSynth;

    var SynthSequence = function() {
    	var self = this;
    	self.tracks = [];
    	self.totalDuration = 0;

    	self.addTrack = function() {
    		self.tracks.push([]);
    		return self.tracks.length - 1;
    	};

    	self.setInstrument = function(trackNumber, instrumentNumber) {
    		self.tracks[trackNumber].push({
    			channel: 0,
    			cmd: "program",
    			instrument: instrumentNumber
    		});
    	};

    	self.appendNote = function(trackNumber, pitch, durationInMeasures, volume) {
    		self.tracks[trackNumber].push({
    			cmd: "start",
    			pitch: pitch - 60,
    			volume: volume
    		});
    		self.tracks[trackNumber].push({
    			cmd: "move",
    			duration: durationInMeasures
    		});
    		self.tracks[trackNumber].push({
    			cmd: "stop",
    			pitch: pitch - 60
    		});
    		var duration = 0;
    		self.tracks[trackNumber].forEach(function(event) {
    			if (event.duration)
    				duration += event.duration;
    		});
    		self.totalDuration = Math.max(self.totalDuration, duration);
    	};
    };

    var synthSequence = SynthSequence;

    // TODO-PER: The require statements for svg don't play well for node apps without extra plugins. The following lines would be clearer than inlining the SVG
    // var loopImage = require('./images/loop.svg');
    // var playImage = require('./images/play.svg');
    // var pauseImage = require('./images/pause.svg');
    // var loadingImage = require('./images/loading.svg');
    // var resetImage = require('./images/reset.svg');
    var loopImage = '<svg version="1.0" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 700 700" preserveAspectRatio="xMidYMid meet">\n' +
    	'<g transform="translate(0,700) scale(0.1,-0.1)" >\n' +
    	'<path d="M3111 6981 c-20 -37 -90 -55 -364 -96 -120 -18 -190 -33 -244 -55 ' +
    	'-42 -17 -124 -42 -182 -56 -78 -18 -119 -34 -157 -60 -28 -19 -86 -46 -128 ' +
    	'-60 -43 -13 -107 -42 -144 -64 -37 -23 -84 -46 -106 -52 -21 -7 -56 -29 -79 ' +
    	'-50 -22 -22 -61 -50 -86 -63 -26 -13 -67 -40 -91 -60 -24 -20 -65 -47 -90 -60 ' +
    	'-25 -13 -53 -31 -61 -41 -8 -9 -32 -30 -54 -46 -75 -54 -486 -460 -512 -507 ' +
    	'-15 -25 -48 -69 -75 -98 -26 -28 -48 -57 -48 -63 0 -6 -18 -29 -39 -53 -21 ' +
    	'-23 -56 -71 -77 -107 -20 -36 -50 -80 -65 -97 -16 -18 -33 -52 -40 -75 -12 ' +
    	'-47 -47 -115 -84 -166 -13 -18 -30 -56 -38 -83 -8 -27 -34 -80 -56 -118 -33 ' +
    	'-53 -46 -91 -62 -167 -12 -63 -34 -127 -59 -179 -42 -84 -60 -166 -60 -270 0 ' +
    	'-90 26 -122 125 -154 54 -17 96 -19 430 -20 305 -1 381 2 430 14 82 22 140 51 ' +
    	'153 78 6 12 22 47 37 77 14 30 38 77 54 103 15 27 34 73 40 103 7 30 28 78 48 ' +
    	'107 19 28 44 74 55 101 10 28 34 67 53 87 18 20 49 61 68 90 19 30 44 63 57 ' +
    	'74 13 11 36 40 52 65 59 94 232 270 306 313 20 11 57 37 82 58 25 20 70 52 ' +
    	'100 72 30 19 66 47 79 61 13 14 49 35 80 46 30 12 80 37 111 56 31 19 95 45 ' +
    	'143 58 48 12 110 37 139 55 63 40 127 55 323 76 83 9 208 28 279 41 156 29 ' +
    	'165 29 330 4 453 -71 514 -84 606 -130 31 -16 83 -36 116 -45 32 -9 84 -34 ' +
    	'115 -56 31 -21 82 -48 113 -60 32 -11 72 -33 89 -48 18 -16 59 -45 92 -65 33 ' +
    	'-21 74 -51 90 -66 17 -15 49 -40 73 -54 52 -32 65 -61 50 -113 -8 -31 -61 -90 ' +
    	'-277 -308 -300 -303 -361 -382 -369 -481 -2 -29 0 -66 6 -81 13 -40 88 -138 ' +
    	'115 -151 12 -6 54 -26 92 -44 l70 -33 945 -2 c520 -1 975 2 1012 7 64 8 191 ' +
    	'50 231 76 11 7 33 34 50 60 22 34 42 51 65 58 l32 9 0 1101 0 1102 -32 9 c-21 ' +
    	'7 -44 26 -64 55 -60 84 -77 97 -140 110 -44 9 -76 10 -127 2 -59 -9 -77 -17 ' +
    	'-134 -62 -37 -28 -172 -155 -301 -281 -129 -127 -249 -237 -267 -245 -25 -10 ' +
    	'-41 -11 -71 -2 -58 15 -112 45 -124 69 -6 11 -35 35 -64 54 -28 18 -58 41 -66 ' +
    	'50 -8 9 -41 35 -75 58 -33 22 -77 56 -99 75 -21 18 -64 46 -95 61 -31 14 -73 ' +
    	'39 -93 55 -20 15 -70 40 -110 55 -40 15 -97 44 -127 64 -29 21 -78 44 -107 53 ' +
    	'-30 8 -77 31 -105 51 -42 28 -73 39 -173 60 -68 14 -154 39 -196 58 -95 43 ' +
    	'-131 51 -343 76 -209 24 -242 32 -279 70 l-30 29 -328 0 c-312 0 -330 -1 -339 ' +
    	'-19z"></path>\n' +
    	'<path d="M254 2875 c-89 -16 -107 -26 -145 -78 -32 -44 -62 -66 -91 -67 -17 0 ' +
    	'-18 -61 -18 -1140 l0 -1140 24 0 c16 0 41 -17 72 -50 40 -42 61 -55 117 -72 ' +
    	'l69 -21 82 23 c44 12 96 30 114 39 18 9 148 132 290 272 141 141 267 261 279 ' +
    	'268 51 26 86 14 176 -61 32 -26 62 -48 66 -48 5 0 36 -25 70 -55 34 -30 74 ' +
    	'-61 89 -69 15 -8 37 -28 50 -45 12 -17 50 -45 84 -62 34 -17 78 -44 98 -60 19 ' +
    	'-16 61 -37 93 -48 32 -11 81 -37 107 -56 27 -20 76 -45 109 -56 33 -12 75 -31 ' +
    	'93 -44 62 -45 93 -58 191 -82 54 -12 130 -37 168 -54 68 -29 180 -58 226 -59 ' +
    	'62 0 183 -64 183 -96 0 -12 88 -14 639 -14 l639 0 12 30 c18 44 76 66 233 89 ' +
    	'89 14 160 30 200 47 34 15 106 42 159 60 54 18 112 44 130 57 47 35 85 52 146 ' +
    	'67 29 7 76 28 105 48 29 20 77 48 107 63 30 15 66 39 80 54 14 15 50 40 81 56 ' +
    	'31 15 78 46 104 69 26 22 61 46 79 54 17 7 43 26 56 42 14 16 41 41 60 56 64 ' +
    	'48 380 362 408 405 15 23 40 51 55 63 15 12 36 38 46 58 11 21 37 57 58 82 22 ' +
    	'25 49 62 62 83 13 20 38 56 57 78 19 23 50 74 69 113 19 39 46 86 59 104 14 ' +
    	'18 34 62 46 98 12 36 32 77 45 92 31 38 60 97 80 167 9 33 26 76 37 95 29 50 ' +
    	'47 103 68 206 10 52 32 117 51 155 29 56 33 74 34 140 0 94 -10 108 -101 138 ' +
    	'-61 20 -83 21 -463 21 -226 0 -421 -4 -451 -10 -63 -12 -86 -30 -110 -85 -10 ' +
    	'-22 -33 -63 -52 -92 -21 -31 -42 -80 -53 -123 -11 -44 -32 -93 -56 -128 -20 ' +
    	'-32 -47 -83 -59 -115 -12 -32 -37 -77 -56 -100 -19 -23 -50 -65 -69 -94 -19 ' +
    	'-29 -44 -57 -54 -63 -11 -5 -29 -27 -42 -47 -52 -85 -234 -277 -300 -315 -25 ' +
    	'-15 -53 -38 -62 -51 -9 -14 -42 -39 -74 -57 -32 -18 -75 -48 -95 -66 -21 -18 ' +
    	'-59 -44 -85 -58 -26 -13 -72 -40 -100 -59 -35 -24 -78 -41 -128 -52 -47 -11 ' +
    	'-99 -31 -139 -56 -69 -42 -94 -49 -391 -110 -245 -51 -425 -66 -595 -50 -168 ' +
    	'16 -230 27 -330 61 -47 16 -123 35 -170 44 -98 17 -123 25 -172 58 -20 14 -71 ' +
    	'37 -114 53 -44 15 -95 40 -115 56 -20 16 -70 42 -110 59 -40 16 -88 45 -108 ' +
    	'63 -20 19 -55 46 -78 61 -24 14 -49 35 -55 47 -7 11 -34 33 -60 49 -50 31 -65 ' +
    	'61 -53 102 4 13 130 147 281 298 236 238 277 283 299 335 15 32 35 71 46 86 ' +
    	'12 18 19 44 19 76 0 42 -8 63 -53 138 -92 151 11 139 -1207 141 -798 2 -1030 ' +
    	'0 -1086 -11z"></path>\n' +
    	'</g>\n' +
    	'</svg>\n';
    var playImage = '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 25 25" class="abcjs-play-svg">\n' +
    	'    <g>\n' +
    	'    <polygon points="4 0 23 12.5 4 25"/>\n' +
    	'    </g>\n' +
    	'</svg>';
    var pauseImage = '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 25 25" class="abcjs-pause-svg">\n' +
    	'  <g>\n' +
    	'    <rect width="8.23" height="25"/>\n' +
    	'    <rect width="8.23" height="25" x="17"/>\n' +
    	'  </g>\n' +
    	'</svg>';
    var loadingImage = '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" class="abcjs-loading-svg">\n' +
    	'    <circle cx="50" cy="50" fill="none" stroke-width="20" r="35" stroke-dasharray="160 55"></circle>\n' +
    	'</svg>';
    var resetImage = '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 25 25">\n' +
    	'  <g>\n' +
    	'    <polygon points="5 12.5 24 0 24 25"/>\n' +
    	'    <rect width="3" height="25" x="0" y="0"/>\n' +
    	'  </g>\n' +
    	'</svg>';

    function CreateSynthControl(parent, options) {
    	var self = this;
    	// parent is either an element or a selector.
    	if (typeof parent === "string") {
    		var selector = parent;
    		parent = document.querySelector(selector);
    		if (!parent)
    			throw new Error("Cannot find element \"" + selector + "\" in the DOM.");
    	} else if (!(parent instanceof HTMLElement))
    		throw new Error("The first parameter must be a valid element or selector in the DOM.");

    	self.parent = parent;
    	self.options = {};
    	if (options)
    		self.options = abc_common.clone(options);

    	// This can be called in the following cases:
    	// AC already registered and not suspended
    	// AC already registered and suspended
    	// AC not registered and not passed in
    	// AC not registered but passed in (but suspended)
    	// AC not registered but passed in (not suspended)
    	// If the AC is already registered, then just use it - ignore what is passed in
    	// Create the AC if necessary if there isn't one already.
    	// We don't care right now if the AC is suspended - whenever a button is clicked then we check it.
    	if (self.options.ac)
    		registerAudioContext_1(self.options.ac);
    	buildDom(self.parent, self.options);
    	attachListeners(self);

    	self.setTempo = function(tempo) {
    		var el = self.parent.querySelector(".abcjs-midi-current-tempo");
    		if (el)
    			el.innerHTML = tempo;
    	};
    	self.resetAll = function() {
    		var pushedButtons = self.parent.querySelectorAll(".abcjs-pushed");
    		for (var i = 0; i < pushedButtons.length; i++) {
    			var button = pushedButtons[i];
    			button.classList.remove("abcjs-pushed");
    		}
    	};
    	self.pushPlay = function(push) {
    		var startButton = self.parent.querySelector(".abcjs-midi-start");
    		if (!startButton)
    			return;
    		if (push)
    			startButton.classList.add("abcjs-pushed");
    		else
    			startButton.classList.remove("abcjs-pushed");
    	};
    	self.pushLoop = function(push) {
    		var loopButton = self.parent.querySelector(".abcjs-midi-loop");
    		if (!loopButton)
    			return;
    		if (push)
    			loopButton.classList.add("abcjs-pushed");
    		else
    			loopButton.classList.remove("abcjs-pushed");
    	};

    	self.setProgress = function (percent, totalTime) {
    		var progressBackground = self.parent.querySelector(".abcjs-midi-progress-background");
    		var progressThumb = self.parent.querySelector(".abcjs-midi-progress-indicator");
    		if (!progressBackground || !progressThumb)
    			return;
    		var width = progressBackground.clientWidth;
    		var left = width * percent;
    		progressThumb.style.left = left + "px";

    		var clock = self.parent.querySelector(".abcjs-midi-clock");
    		if (clock) {
    			var totalSeconds = (totalTime * percent) / 1000;
    			var minutes = Math.floor(totalSeconds / 60);
    			var seconds = Math.floor(totalSeconds % 60);
    			var secondsFormatted = seconds < 10 ? "0" + seconds : seconds;
    			clock.innerHTML = minutes + ":" + secondsFormatted;
    		}
    	};

    	if (self.options.afterResume) {
    		var isResumed = false;
    		if (self.options.ac) {
    			isResumed = self.options.ac.state !== "suspended";
    		} else if (activeAudioContext_1()) {
    			isResumed = activeAudioContext_1().state !== "suspended";
    		}
    		if (isResumed)
    			self.options.afterResume();
    	}
    }

    function buildDom(parent, options) {
    	var hasLoop = !!options.loopHandler;
    	var hasRestart = !!options.restartHandler;
    	var hasPlay = !!options.playHandler || !!options.playPromiseHandler;
    	var hasProgress = !!options.progressHandler;
    	var hasWarp = !!options.warpHandler;
    	var hasClock = options.hasClock !== false;

    	var html = '<div class="abcjs-inline-audio">\n';
    	if (hasLoop) {
    		var repeatTitle = options.repeatTitle ? options.repeatTitle : "Click to toggle play once/repeat.";
    		var repeatAria = options.repeatAria ? options.repeatAria : repeatTitle;
    		html += '<button type="button" class="abcjs-midi-loop abcjs-btn" title="' + repeatTitle + '" aria-label="' + repeatAria + '">' + loopImage + '</button>\n';
    	}
    	if (hasRestart) {
    		var restartTitle = options.restartTitle ? options.restartTitle : "Click to go to beginning.";
    		var restartAria = options.restartAria ? options.restartAria : restartTitle;
    		html += '<button type="button" class="abcjs-midi-reset abcjs-btn" title="' + restartTitle + '" aria-label="' + restartAria + '">' + resetImage + '</button>\n';
    	}
    	if (hasPlay) {
    		var playTitle = options.playTitle ? options.playTitle : "Click to play/pause.";
    		var playAria = options.playAria ? options.playAria : playTitle;
    		html += '<button type="button" class="abcjs-midi-start abcjs-btn" title="' + playTitle + '" aria-label="' + playAria + '">' + playImage + pauseImage + loadingImage + '</button>\n';
    	}
    	if (hasProgress) {
    		var randomTitle = options.randomTitle ? options.randomTitle : "Click to change the playback position.";
    		var randomAria = options.randomAria ? options.randomAria : randomTitle;
    		html += '<button type="button" class="abcjs-midi-progress-background" title="' + randomTitle + '" aria-label="' + randomAria + '"><span class="abcjs-midi-progress-indicator"></span></button>\n';
    	}
    	if (hasClock) {
    		html += '<span class="abcjs-midi-clock"></span>\n';
    	}
    	if (hasWarp) {
    		var warpTitle = options.warpTitle ? options.warpTitle : "Change the playback speed.";
    		var warpAria = options.warpAria ? options.warpAria : warpTitle;
    		var bpm = options.bpm ? options.bpm : "BPM";
    		html += '<span class="abcjs-tempo-wrapper"><label><input class="abcjs-midi-tempo" type="number" min="1" max="300" value="100" title="' + warpTitle + '" aria-label="' + warpAria + '">%</label><span>&nbsp;(<span class="abcjs-midi-current-tempo"></span> ' + bpm + ')</span></span>\n';
    	}
    	html += '</div>\n';
    	parent.innerHTML = html;
    }

    function acResumerMiddleWare(next, ev, playBtn, afterResume, isPromise) {
    	var needsInit = true;
    	if (!activeAudioContext_1()) {
    		registerAudioContext_1();
    	} else {
    		needsInit = activeAudioContext_1().state === "suspended";
    	}
    	if (!supportsAudio_1()) {
    		throw { status: "NotSupported", message: "This browser does not support audio."};
    	}

    	if ((needsInit || isPromise) && playBtn)
    		playBtn.classList.add("abcjs-loading");

    	if (needsInit) {
    		activeAudioContext_1().resume().then(function () {
    			if (afterResume) {
    				afterResume().then(function (response) {
    					doNext(next, ev, playBtn, isPromise);
    				});
    			} else {
    				doNext(next, ev, playBtn, isPromise);
    			}
    		});
    	} else {
    		doNext(next, ev, playBtn, isPromise);
    	}
    }

    function doNext(next, ev, playBtn, isPromise) {
    	if (isPromise) {
    		next(ev).then(function() {
    			if (playBtn)
    				playBtn.classList.remove("abcjs-loading");
    		});
    	} else {
    		next(ev);
    		if (playBtn)
    			playBtn.classList.remove("abcjs-loading");
    	}
    }

    function attachListeners(self) {
    	var hasLoop = !!self.options.loopHandler;
    	var hasRestart = !!self.options.restartHandler;
    	var hasPlay = !!self.options.playHandler || !!self.options.playPromiseHandler;
    	var hasProgress = !!self.options.progressHandler;
    	var hasWarp = !!self.options.warpHandler;
    	var playBtn = self.parent.querySelector(".abcjs-midi-start");

    	if (hasLoop)
    		self.parent.querySelector(".abcjs-midi-loop").addEventListener("click", function(ev){acResumerMiddleWare(self.options.loopHandler, ev, playBtn, self.options.afterResume);});
    	if (hasRestart)
    		self.parent.querySelector(".abcjs-midi-reset").addEventListener("click", function(ev){acResumerMiddleWare(self.options.restartHandler, ev, playBtn, self.options.afterResume);});
    	if (hasPlay)
    		playBtn.addEventListener("click", function(ev){
    			acResumerMiddleWare(
    				self.options.playPromiseHandler || self.options.playHandler,
    				ev,
    				playBtn,
    				self.options.afterResume,
    				!!self.options.playPromiseHandler);
    		});
    	if (hasProgress)
    		self.parent.querySelector(".abcjs-midi-progress-background").addEventListener("click", function(ev){acResumerMiddleWare(self.options.progressHandler, ev, playBtn, self.options.afterResume);});
    	if (hasWarp)
    		self.parent.querySelector(".abcjs-midi-tempo").addEventListener("change", function(ev){acResumerMiddleWare(self.options.warpHandler, ev, playBtn, self.options.afterResume);});
    }
    var createSynthControl = CreateSynthControl;

    function playEvent(midiPitches, midiGracePitches, millisecondsPerMeasure) {
    	var sequence = new synthSequence();

    	for (var i = 0; i < midiPitches.length; i++) {
    		var note = midiPitches[i];
    		var trackNum = sequence.addTrack();
    		sequence.setInstrument(trackNum, note.instrument);
    		if (i === 0 && midiGracePitches) {
    			for (var j = 0; j < midiGracePitches.length; j++) {
    				var grace = midiGracePitches[j];
    				sequence.appendNote(trackNum, grace.pitch, 1 / 64, grace.volume);
    			}
    		}
    		sequence.appendNote(trackNum, note.pitch, note.durationInMeasures, note.volume);
    	}

    	var buffer = new createSynth();
    	return buffer.init({
    		sequence: sequence,
    		millisecondsPerMeasure: millisecondsPerMeasure
    	}).then(function () {
    		return buffer.prime();
    	}).then(function () {
    		return buffer.start();
    	});
    }
    var playEvent_1 = playEvent;

    function SynthController() {
    	var self = this;
    	self.warp = 100;
    	self.cursorControl = null;
    	self.visualObj = null;
    	self.timer = null;
    	self.midiBuffer = null;
    	self.options = null;
    	self.currentTempo = null;
    	self.control = null;
    	self.isLooping = false;
    	self.isStarted = false;
    	self.isLoaded = false;

    	self.load = function (selector, cursorControl, visualOptions) {
    		if (!visualOptions)
    			visualOptions = {};
    		self.control = new createSynthControl(selector, {
    			loopHandler: visualOptions.displayLoop ? self.toggleLoop : undefined,
    			restartHandler: visualOptions.displayRestart ? self.restart : undefined,
    			playPromiseHandler: visualOptions.displayPlay ? self.play : undefined,
    			progressHandler: visualOptions.displayProgress ? self.randomAccess : undefined,
    			warpHandler: visualOptions.displayWarp ? self.onWarp : undefined,
    			afterResume: self.init
    		});
    		self.cursorControl = cursorControl;
    	};

    	self.setTune = function(visualObj, userAction, audioParams) {
    		self.isLoaded = false;
    		self.visualObj = visualObj;
    		self.options = audioParams;

    		if (self.control) {
    			self.pause();
    			self.setProgress(0, 1);
    			self.control.resetAll();
    			self.restart();
    			self.isStarted = false;
    		}
    		self.isLooping = false;

    		if (userAction)
    			return self.go();
    		else {
    			return Promise.resolve({status: "no-audio-context"});
    		}
    	};

    	self.go = function () {
    		var millisecondsPerMeasure = self.visualObj.millisecondsPerMeasure() * 100 / self.warp;
    		self.currentTempo = Math.round(self.visualObj.getBeatsPerMeasure() / millisecondsPerMeasure * 60000);
    		if (self.control)
    			self.control.setTempo(self.currentTempo);
    		self.percent = 0;

    		if (!self.midiBuffer)
    			self.midiBuffer = new createSynth();
    		return self.midiBuffer.init({
    			visualObj: self.visualObj,
    			options: self.options,
    			millisecondsPerMeasure: millisecondsPerMeasure
    		}).then(function () {
    			return self.midiBuffer.prime();
    		}).then(function () {
    			var subdivisions = 16;
    			if (self.cursorControl &&
    				self.cursorControl.beatSubdivisions !== undefined &&
    				parseInt(self.cursorControl.beatSubdivisions, 10) >= 1 &&
    				parseInt(self.cursorControl.beatSubdivisions, 10) <= 64)
    				subdivisions = parseInt(self.cursorControl.beatSubdivisions, 10);

    			// Need to create the TimingCallbacks after priming the midi so that the midi data is available for the callbacks.
    			self.timer = new abc_timing_callbacks(self.visualObj, {
    				beatCallback: self.beatCallback,
    				eventCallback: self.eventCallback,
    				lineEndCallback: self.lineEndCallback,
    				qpm: self.currentTempo,

    				extraMeasuresAtBeginning: self.cursorControl ? self.cursorControl.extraMeasuresAtBeginning : undefined,
    				lineEndAnticipation: self.cursorControl ? self.cursorControl.lineEndAnticipation : undefined,
    				beatSubdivisions: subdivisions,
    			});
    			if (self.cursorControl && self.cursorControl.onReady && typeof self.cursorControl.onReady  === 'function')
    				self.cursorControl.onReady(self);
    			self.isLoaded = true;
    			return Promise.resolve({ status: "created" });
    		});
    	};

    	self.destroy = function () {
    		if (self.timer) {
    			self.timer.reset();
    			self.timer.stop();
    			self.timer = null;
    		}
    		if (self.midiBuffer) {
    			self.midiBuffer.stop();
    			self.midiBuffer = null;
    		}
    		self.setProgress(0, 1);
    		if (self.control)
    			self.control.resetAll();
    	};

    	self.play = function () {
    		if (!self.isLoaded) {
    			return self.go().then(function() {
    				return self._play();
    			});
    		} else
    			return self._play();
    	};

    	self._play = function () {
    		self.isStarted = !self.isStarted;
    		if (self.isStarted) {
    			if (self.cursorControl && self.cursorControl.onStart && typeof self.cursorControl.onStart  === 'function')
    				self.cursorControl.onStart();
    			self.midiBuffer.start();
    			self.timer.start();
    			if (self.control)
    				self.control.pushPlay(true);
    		} else {
    			self.pause();
    		}
    		return Promise.resolve({ status: "ok" });
    	};

    	self.pause = function() {
    		if (self.timer) {
    			self.timer.pause();
    			self.midiBuffer.pause();
    			if (self.control)
    				self.control.pushPlay(false);
    		}
    	};

    	self.toggleLoop = function () {
    		self.isLooping = !self.isLooping;
    		if (self.control)
    			self.control.pushLoop(self.isLooping);
    	};

    	self.restart = function () {
    		if (self.timer) {
    			self.timer.setProgress(0);
    			self.midiBuffer.seek(0);
    		}
    	};

    	self.randomAccess = function (ev) {
    		if (!self.isLoaded) {
    			return self.go().then(function() {
    				return self._randomAccess(ev);
    			});
    		} else
    			return self._randomAccess(ev);
    	};

    	self._randomAccess = function (ev) {
    		var background = (ev.target.classList.contains('abcjs-midi-progress-indicator')) ? ev.target.parentNode : ev.target;
    		var percent = (ev.x - background.offsetLeft) / background.offsetWidth;
    		if (percent < 0)
    			percent = 0;
    		if (percent > 100)
    			percent = 100;
    		self.timer.setProgress(percent);
    		self.midiBuffer.seek(percent);
    	};

    	self.onWarp = function (ev) {
    		var newWarp = ev.target.value;
    		if (parseInt(newWarp, 10) > 0) {
    			self.warp = parseInt(newWarp, 10);
    			var wasPlaying = self.isStarted;
    			var startPercent = self.percent;
    			self.destroy();
    			self.isStarted = false;
    			self.go().then(function () {
    				self.setProgress(startPercent, self.midiBuffer.duration * 1000);
    				if (wasPlaying) {
    					self.play();
    				}
    				self.timer.setProgress(startPercent);
    				self.midiBuffer.seek(startPercent);
    			});
    		}
    	};

    	self.setProgress = function (percent, totalTime) {
    		self.percent = percent;
    		if (self.control)
    			self.control.setProgress(percent, totalTime);
    	};

    	self.finished = function () {
    		self.timer.reset();
    		if (self.isLooping) {
    			self.timer.start();
    			self.midiBuffer.start();
    		} else {
    			self.timer.stop();
    			if (self.isStarted) {
    				if (self.control)
    					self.control.pushPlay(false);
    				self.isStarted = false;
    				if (self.cursorControl && self.cursorControl.onFinished && typeof self.cursorControl.onFinished  === 'function')
    					self.cursorControl.onFinished();
    				self.setProgress(0, 1);
    			}
    		}
    	};

    	self.beatCallback = function (beatNumber, totalBeats, totalTime) {
    		var percent = beatNumber / totalBeats;
    		self.setProgress(percent, totalTime);
    		if (self.cursorControl && self.cursorControl.onBeat && typeof self.cursorControl.onBeat  === 'function')
    			self.cursorControl.onBeat(beatNumber, totalBeats, totalTime);
    	};

    	self.eventCallback = function (event) {
    		if (event) {
    			if (self.cursorControl && self.cursorControl.onEvent && typeof self.cursorControl.onEvent  === 'function')
    				self.cursorControl.onEvent(event);
    		} else {
    			self.finished();
    		}
    	};

    	self.lineEndCallback = function (data) {
    		if (self.cursorControl && self.cursorControl.onLineEnd && typeof self.cursorControl.onLineEnd  === 'function')
    			self.cursorControl.onLineEnd(data);
    	};

    	self.getUrl = function () {
    		return self.midiBuffer.download();
    	};

    	self.download = function(fileName) {
    		var url = self.getUrl();
    		var link = document.createElement('a');
    		document.body.appendChild(link);
    		link.setAttribute("style","display: none;");
    		link.href = url;
    		link.download = fileName ? fileName : 'output.wav';
    		link.click();
    		window.URL.revokeObjectURL(url);
    		document.body.removeChild(link);
    	};
    }

    var synthController = SynthController;

    //    abc2abc_write.js: Prints an abc file in text format parsed by abc_parse.js
    //    Copyright (C) 2010-2018 Gregory Dyke (gregdyke at gmail dot com)
    //
    //    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
    //    documentation files (the "Software"), to deal in the Software without restriction, including without limitation
    //    the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
    //    to permit persons to whom the Software is furnished to do so, subject to the following conditions:
    //
    //    The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
    //
    //    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
    //    BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    //    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
    //    DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    //    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    var TextPrinter = function(elem, reposition) {
        this.elem = elem;
        this.text = "";
        this.l = 1/8;
        this.reposition = reposition || false;
    };

    TextPrinter.prototype.printString = function(str, elem) {
        if (this.reposition && elem) elem.startChar = this.text.length;
        this.text += str;
        if (this.reposition && elem) elem.endChar = this.text.length;
    };

    TextPrinter.prototype.printNewLine = function () {
        this.text += "\n";
    };

    TextPrinter.prototype.printSpace = function () {
        if (this.text[this.text.length-1].match(/\s/)) return; //TODO match whitespace
        this.text += " ";
    };

    TextPrinter.prototype.printABC = function(abctune) {
        this.text = "";
        this.abctune = abctune;
        //TODO formatting
        this.printHeader();
        this.printBody();
        this.elem.value=this.text;
    };

    TextPrinter.prototype.printHeader = function() {
        // much of this info is duplicated in metaTextHEaders in abc_parse_header.js
        this.printHeaderLine("x","X","1");
        this.printHeaderLine("title","T");
        this.printHeaderLine("composer","C");
        this.printHeaderLine("history","H");
        this.printHeaderLine("author","A");
        this.printHeaderLine("book","B");  
        this.printHeaderLine("discography","D");  
        this.printHeaderLine("url","F");
        this.printHeaderLine("group","G");
        this.printHeaderLine("instruction","I");
        this.printHeaderLine("notes","N");
        this.printHeaderLine("origin","O");
        this.printHeaderLine("rhythm","R");
        this.printHeaderLine("source","S");
        this.printHeaderLine("unalignedwords","W");
        this.printHeaderLine("transcription","Z");
        //TODO part order
        //TODO Q tempo
        //TODO textBlock
        this.printHeaderLine("NULL","L","1/8"); //TODO L

        this.printHeaderLine("NULL","M",this.getMeterString(this.abctune.lines[0].staff[0].meter));
        this.printHeaderLine("NULL","K",this.getKeyString(this.abctune.lines[0].staff[0].key));//TODO K
    };

    TextPrinter.prototype.getKeyString = function(key) {
        return key.root+key.acc+key.mode;
    };

    TextPrinter.prototype.getMeterString = function(meter) {
        switch (meter.type) {
        case "cut_time": return "C|";
        case "common_time": return "C";
        case "specified":
          if (meter.value[0].den)
    		return meter.value[0].num+"/"+meter.value[0].den;
          else
    	    return meter.value[0].num;
        }
        return "";
    };

    TextPrinter.prototype.printHeaderLine = function(fieldname, abcfield, defaut) {
        var val = this.abctune.metaText[fieldname] || defaut;
        if (val !== undefined) {
    	var valarray = val.split("\n");
    	for (var i=0; i<valarray.length; i++) {
    	    this.printString(abcfield+": "+valarray[i]);
    	    this.printNewLine();
    	} 
        }
    };

    TextPrinter.prototype.getElem = function() {
        if (this.abcline.length <= this.pos)
    	return null;
        return this.abcline[this.pos];
    };

    TextPrinter.prototype.getNextElem = function() {
        if (this.abcline.length <= this.pos+1)
    	return null;
        return this.abcline[this.pos+1];
    };

    TextPrinter.prototype.printBody = function() {
        for(var line=0; line<this.abctune.lines.length; line++) {
    	var abcline = this.abctune.lines[line];
    	if (abcline.staff) {
    	    this.printABCLine(abcline.staff);
    	} else if (abcline.subtitle && line!==0) ; else if (abcline.text) ;
        }
    };

    TextPrinter.prototype.printABCLine = function(staffs) {
        for (this.s = 0; this.s < staffs.length; this.s++) {
    	this.printABCStaff(staffs[this.s]);
        }
    };

    TextPrinter.prototype.printABCStaff = function(abcstaff) {
        
        // TODO if (abcstaff.bracket) header += "bracket "+abcstaff.bracket+" ";
        // TODO if (abcstaff.brace) header += "brace "+abcstaff.brace+" ";
        
        
        for (this.v = 0; this.v < abcstaff.voices.length; this.v++) {
    	// TODO stuff about voices
    	
    	// TODO this is where key sig is this.voice.addChild(this.printClef(abcstaff.clef));
    	// this.voice.addChild(this.printKeySignature(abcstaff.key));
    	// if (abcstaff.meter) this.voice.addChild(this.printTimeSignature(abcstaff.meter));
    	this.printABCVoice(abcstaff.voices[this.v]);
        }
        
    };

    TextPrinter.prototype.printABCVoice = function(abcline) {
        this.abcline = abcline;
        for (this.pos=0; this.pos<this.abcline.length; this.pos++) {
    	this.printABCElement();
        }
        this.printNewLine();
    };

    TextPrinter.prototype.printABCElement = function() {
        var elem = this.getElem();
        switch (elem.el_type) {
        case "note":
    	this.printBeam();
    	break;
        case "bar":
    	this.printBarLine(elem);
    	break;
    	//TODO show we're missing something
        }
    };

    TextPrinter.prototype.printBeam = function() {
        this.printSpace();
        if (this.getElem().startBeam && !this.getElem().endBeam) {
    	while (this.getElem()) {
    	    this.printNote(this.getElem());
    	    if (this.getElem().endBeam) {
    		break;
    	    }
    	    this.pos++;
    	}
        } else {
    	this.printNote(this.getElem());
        }
        this.printSpace();
    };

    TextPrinter.prototype.printNote = function(elem) {
        var str = "";
    	var i;
        if (elem.chord !== undefined) {
    	for (i=0; i<elem.chord.length; i++) {
    	    str+= '"'+elem.chord[i].name+'"';
    	}
        }
        
        //TODO unify map between names and symbols (to be used with abcparse?)
        var decorations = {
    	"staccato" : ".",
    	"upbow" : "u",
    	"downbow" : "v",
    	"roll" : "~",
    	"fermata" : "H",
    	"slide" : "J",
    	"accent" : "L",
    	"mordent" : "M",
    	"pralltriller" : "P",
    	"trill" : "T",
    	"lower" : "."
        };

        if (elem.decoration !== undefined) {
    	for (i=0; i<elem.decoration.length; i++) {
    	    var dec = elem.decoration[i];
    	    if (decorations[dec]) {
    		str+=decorations[dec];
    	    } else {
    		str+="!"; //TODO hardcoded
    		str+=dec;
    		str+="!"; //TODO hardcoded
    	    }
    	}
        }

        if (elem.gracenotes !== undefined) {
    	str+="{";
    	for (i=0; i<elem.gracenotes.length; i++) {
    	    str+=this.getNoteString(elem.gracenotes[i]);
    	}
    	str+="}";
        }

        var ignoreslur = false;
        if (elem.pitches.length === 1 && elem.pitches[0].startSlur) {
    	ignoreslur = true;
    	str+=this.multiplyString("(",elem.pitches[0].startSlur.length);
        }

        if (elem.startSlur) {
    	str+=this.multiplyString("(",elem.startSlur.length);
        }

        if ((elem.pitches.length === 1 && elem.pitches[0].endSlur) || elem.endSlur) {
    	ignoreslur = true;
        }

        if (elem.startTriplet) {
    	str+="(3";
        }

        if (elem.pitches) {
    	if (elem.pitches.length > 1) str+="[";
    	for (i=0; i<elem.pitches.length; i++) {
    	    elem.pitches[i].duration = elem.duration;
    	    str+=this.getNoteString(elem.pitches[i], ignoreslur);
    	}
    	if (elem.pitches.length > 1) str+="]";
        } 

        if (elem.pitches.length === 1 && elem.pitches[0].endSlur) {
    	str+=this.multiplyString(")",elem.pitches[0].endSlur.length);
        }

        if (elem.endSlur) {
    	str+=this.multiplyString(")",elem.endSlur.length);
        }

        this.printString(str,elem);

    };

    // accidentals, ties and sometimes slurs, sometimes duration
    TextPrinter.prototype.getNoteString = function(pitchelem, ignoreslur) {
        var str = "";
        if (!ignoreslur && pitchelem.startSlur) {
    	str+="(";
        }

        var symb = "";
        switch (pitchelem.accidental) {
        case "quartersharp":
    	symb = "^/";
    	break;
        case "dblsharp":
    	symb = "^^";
    	break;
        case "sharp":
    	symb = "^";
    	break;
        case "quarterflat":
    	symb = "_/";
    	break;
        case "flat":
    	symb = "_";
    	break;
        case "dblflat":
    	symb = "__";
    	break;
        case "natural":
    	symb = "=";
        }
        str+=symb;

        var pitches = ["C","D","E","F","G","A","B"];
        var pitchstr = pitches[this.extractNote(pitchelem.pitch)];
        var octave = this.extractOctave(pitchelem.pitch);
        if (octave>0) {
    	pitchstr = pitchstr.toLowerCase();
    	octave--;
    	while (octave>0) {
    	    pitchstr+="'";
    	    octave--;
    	}
        } else {
    	while (octave<0) {
    	    pitchstr+=",";
    	    octave++;
    	}
        }
        
        str+=pitchstr;
        
        if (pitchelem.duration) {
    	str+=this.getDurationString(pitchelem.duration);
        }

        if (!ignoreslur && pitchelem.endSlur) {
    	str+=")";
        }

        if (pitchelem.startTie) {
    	str+="-";
        }

        return str;
    };

    TextPrinter.prototype.getDurationString = function(duration) {
        //TODO detect crooked rhythm
        if (duration/this.l > 1) {
    	return duration/this.l;
        } 
        var ret = "";
        if (this.l/duration>1) {
    	ret+="/";
    	if (this.l/duration>2) {
    	    ret+=this.l/duration;
    	}   
        }
        return ret;
    };

    TextPrinter.prototype.extractNote = function(pitch) {
        var pitch2 = pitch%7;
        if (pitch2<0) pitch2+=7;
        return pitch2;
    };

    TextPrinter.prototype.extractOctave = function(pitch) {
        return Math.floor(pitch/7);
    };

    TextPrinter.prototype.printBarLine = function(elem) {
        var barstr = "";
        switch (elem.type) {
        case "bar_thin": barstr+="|"; break;
        case "bar_thin_thick": barstr+="|]"; break;
        case "bar_thin_thin": barstr+="||"; break;
        case "bar_thick_thin": barstr+="[|"; break;
        case "bar_dbl_repeat": barstr+=":||:"; break;
        case "bar_left_repeat": barstr+="|:"; break;
        case "bar_right_repeat": barstr+=":|"; break;
        case "bar_invisible": barstr+=""; break;
        }
        this.printString(barstr,elem);
    };

    TextPrinter.prototype.multiplyString = function (s, n) {
        var ret = "";
        for (;n>0;n--) ret+=s;
        return ret;
    };

    var abc2abc_write = TextPrinter;

    // abc_editor.js
    // window.ABCJS.Editor is the interface class for the area that contains the ABC text. It is responsible for
    // holding the text of the tune and calling the parser and the rendering engines.
    //
    // EditArea is an example of using a textarea as the control that is shown to the user. As long as
    // the same interface is used, window.ABCJS.Editor can use a different type of object.
    //
    // EditArea:
    // - constructor(textareaid)
    //		This contains the id of a textarea control that will be used.
    // - addSelectionListener(listener)
    //		A callback class that contains the entry point fireSelectionChanged()
    // - addChangeListener(listener)
    //		A callback class that contains the entry point fireChanged()
    // - getSelection()
    //		returns the object { start: , end: } with the current selection in characters
    // - setSelection(start, end)
    //		start and end are the character positions that should be selected.
    // - getString()
    //		returns the ABC text that is currently displayed.
    // - setString(str)
    //		sets the ABC text that is currently displayed, and resets the initialText variable
    // - getElem()
    //		returns the textarea element
    // - string initialText
    //		Contains the starting text. This can be compared against the current text to see if anything changed.
    //

    /*global document, window, clearTimeout, setTimeout */

    var TuneBook = abc_tunebook.TuneBook;







    // Polyfill for CustomEvent for old IE versions
    if ( typeof window.CustomEvent !== "function" ) {
    	var CustomEvent = function(event, params) {
    		params = params || {bubbles: false, cancelable: false, detail: undefined};
    		var evt = document.createEvent('CustomEvent');
    		evt.initCustomEvent(event, params.bubbles, params.cancelable, params.detail);
    		return evt;
    	};
    	CustomEvent.prototype = window.Event.prototype;
    	window.CustomEvent = CustomEvent;
    }

    var EditArea = function(textareaid) {
      this.textarea = document.getElementById(textareaid);
      this.initialText = this.textarea.value;
      this.isDragging = false;
    };

    EditArea.prototype.addSelectionListener = function(listener) {
      this.textarea.onmousemove = function(ev) {
    	  if (this.isDragging)
    	    listener.fireSelectionChanged();
      };
    };

    EditArea.prototype.addChangeListener = function(listener) {
      this.changelistener = listener;
      this.textarea.onkeyup = function() {
        listener.fireChanged();
      };
      this.textarea.onmousedown = function() {
    	this.isDragging = true;
        listener.fireSelectionChanged();
      };
      this.textarea.onmouseup = function() {
    	this.isDragging = false;
        listener.fireChanged();
      };
      this.textarea.onchange = function() {
        listener.fireChanged();
      };
    };

    //TODO won't work under IE?
    EditArea.prototype.getSelection = function() {
      return {start: this.textarea.selectionStart, end: this.textarea.selectionEnd};
    };

    EditArea.prototype.setSelection = function(start, end) {
    	if(this.textarea.setSelectionRange)
    	   this.textarea.setSelectionRange(start, end);
    	else if(this.textarea.createTextRange) {
    		// For IE8
    	   var e = this.textarea.createTextRange();
    	   e.collapse(true);
    	   e.moveEnd('character', end);
    	   e.moveStart('character', start);
    	   e.select();
    	}
      this.textarea.focus();
    };

    EditArea.prototype.getString = function() {
      return this.textarea.value;
    };

    EditArea.prototype.setString = function(str) {
      this.textarea.value = str;
      this.initialText = this.getString();
      if (this.changelistener) {
        this.changelistener.fireChanged();
      }
    };

    EditArea.prototype.getElem = function() {
      return this.textarea;
    };

    //
    // window.ABCJS.Editor:
    //
    // constructor(editarea, params)
    //		if editarea is a string, then it is an HTML id of a textarea control.
    //		Otherwise, it should be an instantiation of an object that expresses the EditArea interface.
    //
    //		params is a hash of:
    //		canvas_id: or paper_id: HTML id to draw in. If not present, then the drawing happens just below the editor.
    //		generate_midi: if present, then midi is generated.
    //		midi_id: if present, the HTML id to place the midi control. Otherwise it is placed in the same div as the paper.
    //		midi_download_id: if present, the HTML id to place the midi download link. Otherwise it is placed in the same div as the paper.
    //		generate_warnings: if present, then parser warnings are displayed on the page.
    //		warnings_id: if present, the HTML id to place the warnings. Otherwise they are placed in the same div as the paper.
    //		onchange: if present, the callback function to call whenever there has been a change.
    //		gui: if present, the paper can send changes back to the editor (presumably because the user changed something directly.)
    //		parser_options: options to send to the parser engine.
    //		midi_options: options to send to the midi engine.
    //		render_options: options to send to the render engine.
    //		indicate_changed: the dirty flag is set if this is true.
    //
    // - setReadOnly(bool)
    //		adds or removes the class abc_textarea_readonly, and adds or removes the attribute readonly=yes
    // - setDirtyStyle(bool)
    //		adds or removes the class abc_textarea_dirty
    // - renderTune(abc, parserparams, div)
    //		Immediately renders the tune. (Useful for creating the SVG output behind the scenes, if div is hidden)
    //		string abc: the ABC text
    //		parserparams: params to send to the parser
    //		div: the HTML id to render to.
    // - modelChanged()
    //		Called when the model has been changed to trigger re-rendering
    // - parseABC()
    //		Called internally by fireChanged()
    //		returns true if there has been a change since last call.
    // - updateSelection()
    //		Called when the user has changed the selection. This calls the engraver_controller to show the selection.
    // - fireSelectionChanged()
    //		Called by the textarea object when the user has changed the selection.
    // - paramChanged(engraverparams)
    //		Called to signal that the engraver params have changed, so re-rendering should occur.
    // - fireChanged()
    //		Called by the textarea object when the user has changed something.
    // - setNotDirty()
    //		Called by the client app to reset the dirty flag
    // - isDirty()
    //		Returns true or false, whether the textarea contains the same text that it started with.
    // - highlight(abcelem)
    //		Called by the engraver_controller to highlight an area.
    // - pause(bool)
    //		Stops the automatic rendering when the user is typing.
    //

    var Editor = function(editarea, params) {
    	// Copy all the options that will be passed through
    	this.abcjsParams = {};
    	var key;
    	if (params.abcjsParams) {
    		for (key in params.abcjsParams) {
    			if (params.abcjsParams.hasOwnProperty(key)) {
    				this.abcjsParams[key] = params.abcjsParams[key];
    			}
    		}
    	}
    	if (params.midi_options) {
    		for (key in params.midi_options) {
    			if (params.midi_options.hasOwnProperty(key)) {
    				this.abcjsParams[key] = params.midi_options[key];
    			}
    		}
    	}
    	if (params.parser_options) {
    		for (key in params.parser_options) {
    			if (params.parser_options.hasOwnProperty(key)) {
    				this.abcjsParams[key] = params.parser_options[key];
    			}
    		}
    	}
    	if (params.render_options) {
    		for (key in params.render_options) {
    			if (params.render_options.hasOwnProperty(key)) {
    				this.abcjsParams[key] = params.render_options[key];
    			}
    		}
    	}

    	if (params.indicate_changed)
    		this.indicate_changed = true;
      if (typeof editarea === "string") {
        this.editarea = new EditArea(editarea);
      } else {
        this.editarea = editarea;
      }
      this.editarea.addSelectionListener(this);
      this.editarea.addChangeListener(this);

      if (params.canvas_id) {
        this.div = document.getElementById(params.canvas_id);
      } else if (params.paper_id) {
        this.div = document.getElementById(params.paper_id);
      } else {
        this.div = document.createElement("DIV");
        this.editarea.getElem().parentNode.insertBefore(this.div, this.editarea.getElem());
      }

      if (params.selectionChangeCallback) {
      	this.selectionChangeCallback = params.selectionChangeCallback;
      }

      if (params.synth) {
      	if (supportsAudio_1()) {
    	    this.synth = {
    		    el: params.synth.el,
    		    cursorControl: params.synth.cursorControl,
    		    options: params.synth.options
    	    };
        }
      }
    	// If the user wants midi, then store the elements that it will be written to. The element could either be passed in as an id,
    	// an element, or nothing. If nothing is passed in, then just put the midi on top of the generated music.
    	if (params.generate_midi) {
    	  	this.generate_midi = params.generate_midi;
    		if (this.abcjsParams.generateDownload) {
    			if (typeof params.midi_download_id === 'string')
    				this.downloadMidi = document.getElementById(params.midi_download_id);
    			else if (params.midi_download_id) // assume, if the var is not a string it is an element. If not, it will crash soon enough.
    				this.downloadMidi = params.midi_download_id;
    		}
    		if (this.abcjsParams.generateInline !== false) { // The default for this is true, so undefined is also true.
    			if (typeof params.midi_id === 'string')
    				this.inlineMidi = document.getElementById(params.midi_id);
    			else if (params.midi_id) // assume, if the var is not a string it is an element. If not, it will crash soon enough.
    				this.inlineMidi = params.midi_id;
    		}
    	}

      if (params.generate_warnings || params.warnings_id) {
        if (params.warnings_id) {
          this.warningsdiv = document.getElementById(params.warnings_id);
        } else {
          this.warningsdiv = this.div;
        }
      }

      this.onchangeCallback = params.onchange;

      if (params.gui) {
        this.target = document.getElementById(editarea);
        this.abcjsParams.editable = true;
      }
      this.oldt = "";
      this.bReentry = false;
      this.parseABC();
      this.modelChanged();

      this.addClassName = function(element, className) {
        var hasClassName = function(element, className) {
          var elementClassName = element.className;
          return (elementClassName.length > 0 && (elementClassName === className ||
            new RegExp("(^|\\s)" + className + "(\\s|$)").test(elementClassName)));
        };

        if (!hasClassName(element, className))
          element.className += (element.className ? ' ' : '') + className;
        return element;
      };

      this.removeClassName = function(element, className) {
        element.className = abc_common.strip(element.className.replace(
          new RegExp("(^|\\s+)" + className + "(\\s+|$)"), ' '));
        return element;
      };

      this.setReadOnly = function(readOnly) {
    	  var readonlyClass = 'abc_textarea_readonly';
    	  var el = this.editarea.getElem();
        if (readOnly) {
          el.setAttribute('readonly', 'yes');
    	  this.addClassName(el, readonlyClass);
    	} else {
          el.removeAttribute('readonly');
    	  this.removeClassName(el, readonlyClass);
        }
      };
    };

    Editor.prototype.renderTune = function(abc, params, div) {
      var tunebook = new TuneBook(abc);
      var abcParser = abc_parse();
      abcParser.parse(tunebook.tunes[0].abc, params, tunebook.tunes[0].startPos - tunebook.header.length); //TODO handle multiple tunes
      var tune = abcParser.getTune();
      var engraver_controller = new abc_engraver_controller(div, this.abcjsParams);
      engraver_controller.engraveABC(tune);
    };

    Editor.prototype.redrawMidi = function() {
    	if (this.generate_midi && !this.midiPause) {
    		var event = new window.CustomEvent("generateMidi", {
    			detail: {
    				tunes: this.tunes,
    				abcjsParams: this.abcjsParams,
    				downloadMidiEl: this.downloadMidi,
    				inlineMidiEl: this.inlineMidi,
    				engravingEl: this.div
    			}
    		});
    		window.dispatchEvent(event);
    	}
    	if (this.synth) {
    		if (!this.synth.synthControl) {
    			this.synth.synthControl = new synthController();
    			this.synth.synthControl.load(this.synth.el, this.synth.cursorControl, this.synth.options);
    		}
    		this.synth.synthControl.setTune(this.tunes[0], false);
    	}
    };

    Editor.prototype.modelChanged = function() {
      if (this.tunes === undefined) {
        if (this.downloadMidi !== undefined)
    		this.downloadMidi.innerHTML = "";
        if (this.inlineMidi !== undefined)
    		this.inlineMidi.innerHTML = "";
        this.div.innerHTML = "";
    	return;
      }

      if (this.bReentry)
        return; // TODO is this likely? maybe, if we rewrite abc immediately w/ abc2abc
      this.bReentry = true;
      this.timerId = null;
      this.div.innerHTML = "";
      this.engraver_controller = new abc_engraver_controller(this.div, this.abcjsParams);
      this.engraver_controller.engraveABC(this.tunes);
    	this.tunes[0].engraver = this.engraver_controller;	// TODO-PER: We actually want an output object for each tune, not the entire controller. When refactoring, don't save data in the controller.
    	this.redrawMidi();

      if (this.warningsdiv) {
        this.warningsdiv.innerHTML = (this.warnings) ? this.warnings.join("<br />") : "No errors";
      }
      if (this.target) {
        var textprinter = new abc2abc_write(this.target, true);
        textprinter.printABC(this.tunes[0]); //TODO handle multiple tunes
      }
      this.engraver_controller.addSelectListener(this.highlight.bind(this));
      this.updateSelection();
      this.bReentry = false;
    };

    // Call this to reparse in response to the printing parameters changing
    Editor.prototype.paramChanged = function(engraverParams) {
    	if (engraverParams) {
    		for (var key in engraverParams) {
    			if (engraverParams.hasOwnProperty(key)) {
    				this.abcjsParams[key] = engraverParams[key];
    			}
    		}
    	}
    	this.oldt = "";
    	this.fireChanged();
    };

    // return true if the model has changed
    Editor.prototype.parseABC = function() {
      var t = this.editarea.getString();
      if (t===this.oldt) {
        this.updateSelection();
        return false;
      }

      this.oldt = t;
      if (t === "") {
    	this.tunes = undefined;
    	this.warnings = "";
    	return true;
      }
      var tunebook = new TuneBook(t);

      this.tunes = [];
      this.startPos = [];
      this.warnings = [];
      for (var i=0; i<tunebook.tunes.length; i++) {
        var abcParser = new abc_parse();
        abcParser.parse(tunebook.tunes[i].abc, this.abcjsParams, tunebook.tunes[i].startPos - tunebook.header.length);
        this.tunes[i] = abcParser.getTune();
    	  this.startPos[i] = tunebook.tunes[i].startPos;
        var warnings = abcParser.getWarnings() || [];
        for (var j=0; j<warnings.length; j++) {
          this.warnings.push(warnings[j]);
        }
      }
      return true;
    };

    Editor.prototype.updateSelection = function() {
      var selection = this.editarea.getSelection();
      try {
        this.engraver_controller.rangeHighlight(selection.start, selection.end);
      } catch (e) {} // maybe printer isn't defined yet?
    	if (this.selectionChangeCallback)
    		this.selectionChangeCallback(selection.start, selection.end);
    };

    Editor.prototype.fireSelectionChanged = function() {
      this.updateSelection();
    };

    Editor.prototype.setDirtyStyle = function(isDirty) {
    	if (this.indicate_changed === undefined)
    		return;
      var addClassName = function(element, className) {
        var hasClassName = function(element, className) {
          var elementClassName = element.className;
          return (elementClassName.length > 0 && (elementClassName === className ||
            new RegExp("(^|\\s)" + className + "(\\s|$)").test(elementClassName)));
        };

        if (!hasClassName(element, className))
          element.className += (element.className ? ' ' : '') + className;
        return element;
      };

      var removeClassName = function(element, className) {
        element.className = abc_common.strip(element.className.replace(
          new RegExp("(^|\\s+)" + className + "(\\s+|$)"), ' '));
        return element;
      };

    	var readonlyClass = 'abc_textarea_dirty';
    	var el = this.editarea.getElem();
    	if (isDirty) {
    		addClassName(el, readonlyClass);
    	} else {
    		removeClassName(el, readonlyClass);
        }
    };

    // call when abc text is changed and needs re-parsing
    Editor.prototype.fireChanged = function() {
      if (this.bIsPaused)
        return;
      if (this.parseABC()) {
        var self = this;
        if (this.timerId)	// If the user is still typing, cancel the update
          clearTimeout(this.timerId);
        this.timerId = setTimeout(function () {
          self.modelChanged();
        }, 300);	// Is this a good compromise between responsiveness and not redrawing too much?
    	  var isDirty = this.isDirty();
    	  if (this.wasDirty !== isDirty) {
    		  this.wasDirty = isDirty;
    		  this.setDirtyStyle(isDirty);
    	  }
    	  if (this.onchangeCallback)
    		  this.onchangeCallback(this);
    	  }
    };

    Editor.prototype.setNotDirty = function() {
    	this.editarea.initialText = this.editarea.getString();
    	this.wasDirty = false;
    	this.setDirtyStyle(false);
    };

    Editor.prototype.isDirty = function() {
    	if (this.indicate_changed === undefined)
    		return false;
    	return this.editarea.initialText !== this.editarea.getString();
    };

    Editor.prototype.highlight = function(abcelem, tuneNumber, classes) {
    	// TODO-PER: The marker appears to get off by one for each tune parsed. I'm not sure why, but adding the tuneNumber in corrects it for the time being.
    //	var offset = (tuneNumber !== undefined) ? this.startPos[tuneNumber] + tuneNumber : 0;

      this.editarea.setSelection(abcelem.startChar, abcelem.endChar);
    	if (this.selectionChangeCallback)
    		this.selectionChangeCallback(abcelem.startChar, abcelem.endChar);
    };

    Editor.prototype.pause = function(shouldPause) {
    	this.bIsPaused = shouldPause;
    	if (!shouldPause)
    		this.fireChanged();
    };

    Editor.prototype.millisecondsPerMeasure = function() {
    	return this.synth.synthControl.visualObj.millisecondsPerMeasure();
    };

    Editor.prototype.pauseMidi = function(shouldPause) {
    	this.midiPause = shouldPause;
    	if (!shouldPause)
    		this.redrawMidi();
    };

    var abc_editor = Editor;

    var abcjs = {};

    abcjs.signature = "abcjs-basic v" + version_1;

    Object.keys(abc_animation).forEach(function (key) {
    	abcjs[key] = abc_animation[key];
    });

    Object.keys(abc_tunebook).forEach(function (key) {
    	abcjs[key] = abc_tunebook[key];
    });

    abcjs.renderAbc = abc_tunebook_svg;
    abcjs.TimingCallbacks = abc_timing_callbacks;


    abcjs.setGlyph = abc_glyphs.setSymbol;












    abcjs.synth = {
    	CreateSynth: createSynth,
    	instrumentIndexToName: instrumentIndexToName_1,
    	pitchToNoteName: pitchToNoteName_1,
    	SynthController: synthController,
    	SynthSequence: synthSequence,
    	CreateSynthControl: createSynthControl,
    	registerAudioContext: registerAudioContext_1,
    	activeAudioContext: activeAudioContext_1,
    	supportsAudio: supportsAudio_1,
    	playEvent: playEvent_1
    };


    abcjs['Editor'] = abc_editor;

    var abcjs_1 = abcjs;

    var webmidi_min = createCommonjsModule(function (module) {
    /*

    WebMidi v2.5.1

    WebMidi.js helps you tame the Web MIDI API. Send and receive MIDI messages with ease. Control instruments with user-friendly functions (playNote, sendPitchBend, etc.). React to MIDI input with simple event listeners (noteon, pitchbend, controlchange, etc.).
    https://github.com/djipco/webmidi


    The MIT License (MIT)

    Copyright (c) 2015-2019, Jean-Philippe Côté

    Permission is hereby granted, free of charge, to any person obtaining a copy of this software and
    associated documentation files (the "Software"), to deal in the Software without restriction,
    including without limitation the rights to use, copy, modify, merge, publish, distribute,
    sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is
    furnished to do so, subject to the following conditions:

    The above copyright notice and this permission notice shall be included in all copies or substantial
    portions of the Software.

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT
    NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES
    OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
    CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

    */


    !function(scope){function WebMidi(){if(WebMidi.prototype._singleton)throw new Error("WebMidi is a singleton, it cannot be instantiated directly.");(WebMidi.prototype._singleton=this)._inputs=[],this._outputs=[],this._userHandlers={},this._stateChangeQueue=[],this._processingStateChange=!1,this._midiInterfaceEvents=["connected","disconnected"],this._nrpnBuffer=[[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]],this._nrpnEventsEnabled=!0,this._nrpnTypes=["entry","increment","decrement"],this._notes=["C","C#","D","D#","E","F","F#","G","G#","A","A#","B"],this._semitones={C:0,D:2,E:4,F:5,G:7,A:9,B:11},Object.defineProperties(this,{MIDI_SYSTEM_MESSAGES:{value:{sysex:240,timecode:241,songposition:242,songselect:243,tuningrequest:246,sysexend:247,clock:248,start:250,continue:251,stop:252,activesensing:254,reset:255,midimessage:0,unknownsystemmessage:-1},writable:!1,enumerable:!0,configurable:!1},MIDI_CHANNEL_MESSAGES:{value:{noteoff:8,noteon:9,keyaftertouch:10,controlchange:11,channelmode:11,nrpn:11,programchange:12,channelaftertouch:13,pitchbend:14},writable:!1,enumerable:!0,configurable:!1},MIDI_REGISTERED_PARAMETER:{value:{pitchbendrange:[0,0],channelfinetuning:[0,1],channelcoarsetuning:[0,2],tuningprogram:[0,3],tuningbank:[0,4],modulationrange:[0,5],azimuthangle:[61,0],elevationangle:[61,1],gain:[61,2],distanceratio:[61,3],maximumdistance:[61,4],maximumdistancegain:[61,5],referencedistanceratio:[61,6],panspreadangle:[61,7],rollangle:[61,8]},writable:!1,enumerable:!0,configurable:!1},MIDI_CONTROL_CHANGE_MESSAGES:{value:{bankselectcoarse:0,modulationwheelcoarse:1,breathcontrollercoarse:2,footcontrollercoarse:4,portamentotimecoarse:5,dataentrycoarse:6,volumecoarse:7,balancecoarse:8,pancoarse:10,expressioncoarse:11,effectcontrol1coarse:12,effectcontrol2coarse:13,generalpurposeslider1:16,generalpurposeslider2:17,generalpurposeslider3:18,generalpurposeslider4:19,bankselectfine:32,modulationwheelfine:33,breathcontrollerfine:34,footcontrollerfine:36,portamentotimefine:37,dataentryfine:38,volumefine:39,balancefine:40,panfine:42,expressionfine:43,effectcontrol1fine:44,effectcontrol2fine:45,holdpedal:64,portamento:65,sustenutopedal:66,softpedal:67,legatopedal:68,hold2pedal:69,soundvariation:70,resonance:71,soundreleasetime:72,soundattacktime:73,brightness:74,soundcontrol6:75,soundcontrol7:76,soundcontrol8:77,soundcontrol9:78,soundcontrol10:79,generalpurposebutton1:80,generalpurposebutton2:81,generalpurposebutton3:82,generalpurposebutton4:83,reverblevel:91,tremololevel:92,choruslevel:93,celestelevel:94,phaserlevel:95,databuttonincrement:96,databuttondecrement:97,nonregisteredparametercoarse:98,nonregisteredparameterfine:99,registeredparametercoarse:100,registeredparameterfine:101},writable:!1,enumerable:!0,configurable:!1},MIDI_NRPN_MESSAGES:{value:{entrymsb:6,entrylsb:38,increment:96,decrement:97,paramlsb:98,parammsb:99,nullactiveparameter:127},writable:!1,enumerable:!0,configurable:!1},MIDI_CHANNEL_MODE_MESSAGES:{value:{allsoundoff:120,resetallcontrollers:121,localcontrol:122,allnotesoff:123,omnimodeoff:124,omnimodeon:125,monomodeon:126,polymodeon:127},writable:!1,enumerable:!0,configurable:!1},octaveOffset:{value:0,writable:!0,enumerable:!0,configurable:!1}}),Object.defineProperties(this,{supported:{enumerable:!0,get:function(){return "requestMIDIAccess"in navigator}},enabled:{enumerable:!0,get:function(){return void 0!==this.interface}.bind(this)},inputs:{enumerable:!0,get:function(){return this._inputs}.bind(this)},outputs:{enumerable:!0,get:function(){return this._outputs}.bind(this)},sysexEnabled:{enumerable:!0,get:function(){return !(!this.interface||!this.interface.sysexEnabled)}.bind(this)},nrpnEventsEnabled:{enumerable:!0,get:function(){return !!this._nrpnEventsEnabled}.bind(this),set:function(enabled){return this._nrpnEventsEnabled=enabled,this._nrpnEventsEnabled}},nrpnTypes:{enumerable:!0,get:function(){return this._nrpnTypes}.bind(this)},time:{enumerable:!0,get:function(){return performance.now()}}});}var wm=new WebMidi;function Input(midiInput){var that=this;this._userHandlers={channel:{},system:{}},this._midiInput=midiInput,Object.defineProperties(this,{connection:{enumerable:!0,get:function(){return that._midiInput.connection}},id:{enumerable:!0,get:function(){return that._midiInput.id}},manufacturer:{enumerable:!0,get:function(){return that._midiInput.manufacturer}},name:{enumerable:!0,get:function(){return that._midiInput.name}},state:{enumerable:!0,get:function(){return that._midiInput.state}},type:{enumerable:!0,get:function(){return that._midiInput.type}}}),this._initializeUserHandlers(),this._midiInput.onmidimessage=this._onMidiMessage.bind(this);}function Output(midiOutput){var that=this;this._midiOutput=midiOutput,Object.defineProperties(this,{connection:{enumerable:!0,get:function(){return that._midiOutput.connection}},id:{enumerable:!0,get:function(){return that._midiOutput.id}},manufacturer:{enumerable:!0,get:function(){return that._midiOutput.manufacturer}},name:{enumerable:!0,get:function(){return that._midiOutput.name}},state:{enumerable:!0,get:function(){return that._midiOutput.state}},type:{enumerable:!0,get:function(){return that._midiOutput.type}}});}WebMidi.prototype.enable=function(callback,sysex){this.enabled||(this.supported?navigator.requestMIDIAccess({sysex:sysex}).then(function(midiAccess){var promiseTimeout,events=[],promises=[];this.interface=midiAccess,this._resetInterfaceUserHandlers(),this.interface.onstatechange=function(e){events.push(e);};for(var inputs=midiAccess.inputs.values(),input=inputs.next();input&&!input.done;input=inputs.next())promises.push(input.value.open());for(var outputs=midiAccess.outputs.values(),output=outputs.next();output&&!output.done;output=outputs.next())promises.push(output.value.open());function onPortsOpen(){clearTimeout(promiseTimeout),this._updateInputsAndOutputs(),this.interface.onstatechange=this._onInterfaceStateChange.bind(this),"function"==typeof callback&&callback.call(this),events.forEach(function(event){this._onInterfaceStateChange(event);}.bind(this));}promiseTimeout=setTimeout(onPortsOpen.bind(this),200),Promise&&Promise.all(promises).catch(function(err){}).then(onPortsOpen.bind(this));}.bind(this),function(err){"function"==typeof callback&&callback.call(this,err);}.bind(this)):"function"==typeof callback&&callback(new Error("The Web MIDI API is not supported by your browser.")));},WebMidi.prototype.disable=function(){if(!this.supported)throw new Error("The Web MIDI API is not supported by your browser.");this.interface&&(this.interface.onstatechange=void 0),this.interface=void 0,this._inputs=[],this._outputs=[],this._nrpnEventsEnabled=!0,this._resetInterfaceUserHandlers();},WebMidi.prototype.addListener=function(type,listener){if(!this.enabled)throw new Error("WebMidi must be enabled before adding event listeners.");if("function"!=typeof listener)throw new TypeError("The 'listener' parameter must be a function.");if(!(0<=this._midiInterfaceEvents.indexOf(type)))throw new TypeError("The specified event type is not supported.");return this._userHandlers[type].push(listener),this},WebMidi.prototype.hasListener=function(type,listener){if(!this.enabled)throw new Error("WebMidi must be enabled before checking event listeners.");if("function"!=typeof listener)throw new TypeError("The 'listener' parameter must be a function.");if(!(0<=this._midiInterfaceEvents.indexOf(type)))throw new TypeError("The specified event type is not supported.");for(var o=0;o<this._userHandlers[type].length;o++)if(this._userHandlers[type][o]===listener)return !0;return !1},WebMidi.prototype.removeListener=function(type,listener){if(!this.enabled)throw new Error("WebMidi must be enabled before removing event listeners.");if(void 0!==listener&&"function"!=typeof listener)throw new TypeError("The 'listener' parameter must be a function.");if(0<=this._midiInterfaceEvents.indexOf(type))if(listener)for(var o=0;o<this._userHandlers[type].length;o++)this._userHandlers[type][o]===listener&&this._userHandlers[type].splice(o,1);else this._userHandlers[type]=[];else {if(void 0!==type)throw new TypeError("The specified event type is not supported.");this._resetInterfaceUserHandlers();}return this},WebMidi.prototype.toMIDIChannels=function(channel){var channels;if("all"===channel||void 0===channel)channels=["all"];else {if("none"===channel)return channels=[];channels=Array.isArray(channel)?channel:[channel];}return -1<channels.indexOf("all")&&(channels=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]),channels.map(function(ch){return parseInt(ch)}).filter(function(ch){return 1<=ch&&ch<=16})},WebMidi.prototype.getInputById=function(id){if(!this.enabled)throw new Error("WebMidi is not enabled.");id=String(id);for(var i=0;i<this.inputs.length;i++)if(this.inputs[i].id===id)return this.inputs[i];return !1},WebMidi.prototype.getOutputById=function(id){if(!this.enabled)throw new Error("WebMidi is not enabled.");id=String(id);for(var i=0;i<this.outputs.length;i++)if(this.outputs[i].id===id)return this.outputs[i];return !1},WebMidi.prototype.getInputByName=function(name){if(!this.enabled)throw new Error("WebMidi is not enabled.");for(var i=0;i<this.inputs.length;i++)if(~this.inputs[i].name.indexOf(name))return this.inputs[i];return !1},WebMidi.prototype.getOctave=function(number){if(null!=number&&0<=number&&number<=127)return Math.floor(Math.floor(number)/12-1)+Math.floor(wm.octaveOffset)},WebMidi.prototype.getOutputByName=function(name){if(!this.enabled)throw new Error("WebMidi is not enabled.");for(var i=0;i<this.outputs.length;i++)if(~this.outputs[i].name.indexOf(name))return this.outputs[i];return !1},WebMidi.prototype.guessNoteNumber=function(input){var output=!1;if(input&&input.toFixed&&0<=input&&input<=127?output=Math.round(input):0<=parseInt(input)&&parseInt(input)<=127?output=parseInt(input):("string"==typeof input||input instanceof String)&&(output=this.noteNameToNumber(input)),!1===output)throw new Error("Invalid input value ("+input+").");return output},WebMidi.prototype.noteNameToNumber=function(name){"string"!=typeof name&&(name="");var matches=name.match(/([CDEFGAB])(#{0,2}|b{0,2})(-?\d+)/i);if(!matches)throw new RangeError("Invalid note name.");var semitones=wm._semitones[matches[1].toUpperCase()],result=12*(parseInt(matches[3])+1-Math.floor(wm.octaveOffset))+semitones;if(-1<matches[2].toLowerCase().indexOf("b")?result-=matches[2].length:-1<matches[2].toLowerCase().indexOf("#")&&(result+=matches[2].length),result<0||127<result)throw new RangeError("Invalid note name or note outside valid range.");return result},WebMidi.prototype._updateInputsAndOutputs=function(){this._updateInputs(),this._updateOutputs();},WebMidi.prototype._updateInputs=function(){for(var i=0;i<this._inputs.length;i++){for(var remove=!0,updated=this.interface.inputs.values(),input=updated.next();input&&!input.done;input=updated.next())if(this._inputs[i]._midiInput===input.value){remove=!1;break}remove&&this._inputs.splice(i,1);}this.interface&&this.interface.inputs.forEach(function(nInput){for(var add=!0,j=0;j<this._inputs.length;j++)this._inputs[j]._midiInput===nInput&&(add=!1);add&&this._inputs.push(new Input(nInput));}.bind(this));},WebMidi.prototype._updateOutputs=function(){for(var i=0;i<this._outputs.length;i++){for(var remove=!0,updated=this.interface.outputs.values(),output=updated.next();output&&!output.done;output=updated.next())if(this._outputs[i]._midiOutput===output.value){remove=!1;break}remove&&this._outputs.splice(i,1);}this.interface&&this.interface.outputs.forEach(function(nOutput){for(var add=!0,j=0;j<this._outputs.length;j++)this._outputs[j]._midiOutput===nOutput&&(add=!1);add&&this._outputs.push(new Output(nOutput));}.bind(this));},WebMidi.prototype._onInterfaceStateChange=function(e){this._updateInputsAndOutputs();var event={timestamp:e.timeStamp,type:e.port.state};this.interface&&"connected"===e.port.state?"output"===e.port.type?event.port=this.getOutputById(e.port.id):"input"===e.port.type&&(event.port=this.getInputById(e.port.id)):event.port={connection:"closed",id:e.port.id,manufacturer:e.port.manufacturer,name:e.port.name,state:e.port.state,type:e.port.type},this._userHandlers[e.port.state].forEach(function(handler){handler(event);});},WebMidi.prototype._resetInterfaceUserHandlers=function(){for(var i=0;i<this._midiInterfaceEvents.length;i++)this._userHandlers[this._midiInterfaceEvents[i]]=[];},Input.prototype.on=Input.prototype.addListener=function(type,channel,listener){var that=this;if(void 0===channel&&(channel="all"),Array.isArray(channel)||(channel=[channel]),channel.forEach(function(item){if("all"!==item&&!(1<=item&&item<=16))throw new RangeError("The 'channel' parameter is invalid.")}),"function"!=typeof listener)throw new TypeError("The 'listener' parameter must be a function.");if(void 0!==wm.MIDI_SYSTEM_MESSAGES[type])this._userHandlers.system[type]||(this._userHandlers.system[type]=[]),this._userHandlers.system[type].push(listener);else {if(void 0===wm.MIDI_CHANNEL_MESSAGES[type])throw new TypeError("The specified event type is not supported.");if(-1<channel.indexOf("all")){channel=[];for(var j=1;j<=16;j++)channel.push(j);}this._userHandlers.channel[type]||(this._userHandlers.channel[type]=[]),channel.forEach(function(ch){that._userHandlers.channel[type][ch]||(that._userHandlers.channel[type][ch]=[]),that._userHandlers.channel[type][ch].push(listener);});}return this},Input.prototype.hasListener=function(type,channel,listener){var that=this;if("function"!=typeof listener)throw new TypeError("The 'listener' parameter must be a function.");if(void 0===channel&&(channel="all"),channel.constructor!==Array&&(channel=[channel]),void 0!==wm.MIDI_SYSTEM_MESSAGES[type]){for(var o=0;o<this._userHandlers.system[type].length;o++)if(this._userHandlers.system[type][o]===listener)return !0}else if(void 0!==wm.MIDI_CHANNEL_MESSAGES[type]){if(-1<channel.indexOf("all")){channel=[];for(var j=1;j<=16;j++)channel.push(j);}return !!this._userHandlers.channel[type]&&channel.every(function(chNum){var listeners=that._userHandlers.channel[type][chNum];return listeners&&-1<listeners.indexOf(listener)})}return !1},Input.prototype.removeListener=function(type,channel,listener){var that=this;if(void 0!==listener&&"function"!=typeof listener)throw new TypeError("The 'listener' parameter must be a function.");if(void 0===channel&&(channel="all"),channel.constructor!==Array&&(channel=[channel]),void 0!==wm.MIDI_SYSTEM_MESSAGES[type])if(void 0===listener)this._userHandlers.system[type]=[];else for(var o=0;o<this._userHandlers.system[type].length;o++)this._userHandlers.system[type][o]===listener&&this._userHandlers.system[type].splice(o,1);else if(void 0!==wm.MIDI_CHANNEL_MESSAGES[type]){if(-1<channel.indexOf("all")){channel=[];for(var j=1;j<=16;j++)channel.push(j);}if(!this._userHandlers.channel[type])return this;channel.forEach(function(chNum){var listeners=that._userHandlers.channel[type][chNum];if(listeners)if(void 0===listener)that._userHandlers.channel[type][chNum]=[];else for(var l=0;l<listeners.length;l++)listeners[l]===listener&&listeners.splice(l,1);});}else {if(void 0!==type)throw new TypeError("The specified event type is not supported.");this._initializeUserHandlers();}return this},Input.prototype._initializeUserHandlers=function(){for(var prop1 in wm.MIDI_CHANNEL_MESSAGES)wm.MIDI_CHANNEL_MESSAGES.hasOwnProperty(prop1)&&(this._userHandlers.channel[prop1]={});for(var prop2 in wm.MIDI_SYSTEM_MESSAGES)wm.MIDI_SYSTEM_MESSAGES.hasOwnProperty(prop2)&&(this._userHandlers.system[prop2]=[]);},Input.prototype._onMidiMessage=function(e){if(0<this._userHandlers.system.midimessage.length){var event={target:this,data:e.data,timestamp:e.timeStamp,type:"midimessage"};this._userHandlers.system.midimessage.forEach(function(callback){callback(event);});}e.data[0]<240?(this._parseChannelEvent(e),this._parseNrpnEvent(e)):e.data[0]<=255&&this._parseSystemEvent(e);},Input.prototype._parseNrpnEvent=function(e){var data1,data2,command=e.data[0]>>4,channelBufferIndex=15&e.data[0],channel=1+channelBufferIndex;if(1<e.data.length&&(data1=e.data[1],data2=2<e.data.length?e.data[2]:void 0),wm.nrpnEventsEnabled&&command===wm.MIDI_CHANNEL_MESSAGES.controlchange&&(data1>=wm.MIDI_NRPN_MESSAGES.increment&&data1<=wm.MIDI_NRPN_MESSAGES.parammsb||data1===wm.MIDI_NRPN_MESSAGES.entrymsb||data1===wm.MIDI_NRPN_MESSAGES.entrylsb)){var ccEvent={target:this,type:"controlchange",data:e.data,timestamp:e.timeStamp,channel:channel,controller:{number:data1,name:this.getCcNameByNumber(data1)},value:data2};if(ccEvent.controller.number===wm.MIDI_NRPN_MESSAGES.parammsb&&ccEvent.value!=wm.MIDI_NRPN_MESSAGES.nullactiveparameter)wm._nrpnBuffer[channelBufferIndex]=[],wm._nrpnBuffer[channelBufferIndex][0]=ccEvent;else if(1===wm._nrpnBuffer[channelBufferIndex].length&&ccEvent.controller.number===wm.MIDI_NRPN_MESSAGES.paramlsb)wm._nrpnBuffer[channelBufferIndex].push(ccEvent);else if(2!==wm._nrpnBuffer[channelBufferIndex].length||ccEvent.controller.number!==wm.MIDI_NRPN_MESSAGES.increment&&ccEvent.controller.number!==wm.MIDI_NRPN_MESSAGES.decrement&&ccEvent.controller.number!==wm.MIDI_NRPN_MESSAGES.entrymsb)if(3===wm._nrpnBuffer[channelBufferIndex].length&&wm._nrpnBuffer[channelBufferIndex][2].number===wm.MIDI_NRPN_MESSAGES.entrymsb&&ccEvent.controller.number===wm.MIDI_NRPN_MESSAGES.entrylsb)wm._nrpnBuffer[channelBufferIndex].push(ccEvent);else if(3<=wm._nrpnBuffer[channelBufferIndex].length&&wm._nrpnBuffer[channelBufferIndex].length<=4&&ccEvent.controller.number===wm.MIDI_NRPN_MESSAGES.parammsb&&ccEvent.value===wm.MIDI_NRPN_MESSAGES.nullactiveparameter)wm._nrpnBuffer[channelBufferIndex].push(ccEvent);else if(4<=wm._nrpnBuffer[channelBufferIndex].length&&wm._nrpnBuffer[channelBufferIndex].length<=5&&ccEvent.controller.number===wm.MIDI_NRPN_MESSAGES.paramlsb&&ccEvent.value===wm.MIDI_NRPN_MESSAGES.nullactiveparameter){wm._nrpnBuffer[channelBufferIndex].push(ccEvent);var rawData=[];wm._nrpnBuffer[channelBufferIndex].forEach(function(ev){rawData.push(ev.data);});var nrpnNumber=wm._nrpnBuffer[channelBufferIndex][0].value<<7|wm._nrpnBuffer[channelBufferIndex][1].value,nrpnValue=wm._nrpnBuffer[channelBufferIndex][2].value;6===wm._nrpnBuffer[channelBufferIndex].length&&(nrpnValue=wm._nrpnBuffer[channelBufferIndex][2].value<<7|wm._nrpnBuffer[channelBufferIndex][3].value);var nrpnControllerType="";switch(wm._nrpnBuffer[channelBufferIndex][2].controller.number){case wm.MIDI_NRPN_MESSAGES.entrymsb:nrpnControllerType=wm._nrpnTypes[0];break;case wm.MIDI_NRPN_MESSAGES.increment:nrpnControllerType=wm._nrpnTypes[1];break;case wm.MIDI_NRPN_MESSAGES.decrement:nrpnControllerType=wm._nrpnTypes[2];break;default:throw new Error("The NPRN type was unidentifiable.")}var nrpnEvent={timestamp:ccEvent.timestamp,channel:ccEvent.channel,type:"nrpn",data:rawData,controller:{number:nrpnNumber,type:nrpnControllerType,name:"Non-Registered Parameter "+nrpnNumber},value:nrpnValue};wm._nrpnBuffer[channelBufferIndex]=[],this._userHandlers.channel[nrpnEvent.type]&&this._userHandlers.channel[nrpnEvent.type][nrpnEvent.channel]&&this._userHandlers.channel[nrpnEvent.type][nrpnEvent.channel].forEach(function(callback){callback(nrpnEvent);});}else wm._nrpnBuffer[channelBufferIndex]=[];else wm._nrpnBuffer[channelBufferIndex].push(ccEvent);}},Input.prototype._parseChannelEvent=function(e){var data1,data2,command=e.data[0]>>4,channel=1+(15&e.data[0]);1<e.data.length&&(data1=e.data[1],data2=2<e.data.length?e.data[2]:void 0);var event={target:this,data:e.data,timestamp:e.timeStamp,channel:channel};command===wm.MIDI_CHANNEL_MESSAGES.noteoff||command===wm.MIDI_CHANNEL_MESSAGES.noteon&&0===data2?(event.type="noteoff",event.note={number:data1,name:wm._notes[data1%12],octave:wm.getOctave(data1)},event.velocity=data2/127,event.rawVelocity=data2):command===wm.MIDI_CHANNEL_MESSAGES.noteon?(event.type="noteon",event.note={number:data1,name:wm._notes[data1%12],octave:wm.getOctave(data1)},event.velocity=data2/127,event.rawVelocity=data2):command===wm.MIDI_CHANNEL_MESSAGES.keyaftertouch?(event.type="keyaftertouch",event.note={number:data1,name:wm._notes[data1%12],octave:wm.getOctave(data1)},event.value=data2/127):command===wm.MIDI_CHANNEL_MESSAGES.controlchange&&0<=data1&&data1<=119?(event.type="controlchange",event.controller={number:data1,name:this.getCcNameByNumber(data1)},event.value=data2):command===wm.MIDI_CHANNEL_MESSAGES.channelmode&&120<=data1&&data1<=127?(event.type="channelmode",event.controller={number:data1,name:this.getChannelModeByNumber(data1)},event.value=data2):command===wm.MIDI_CHANNEL_MESSAGES.programchange?(event.type="programchange",event.value=data1):command===wm.MIDI_CHANNEL_MESSAGES.channelaftertouch?(event.type="channelaftertouch",event.value=data1/127):command===wm.MIDI_CHANNEL_MESSAGES.pitchbend?(event.type="pitchbend",event.value=((data2<<7)+data1-8192)/8192):event.type="unknownchannelmessage",this._userHandlers.channel[event.type]&&this._userHandlers.channel[event.type][channel]&&this._userHandlers.channel[event.type][channel].forEach(function(callback){callback(event);});},Input.prototype.getCcNameByNumber=function(number){if(!(0<=(number=Math.floor(number))&&number<=119))throw new RangeError("The control change number must be between 0 and 119.");for(var cc in wm.MIDI_CONTROL_CHANGE_MESSAGES)if(wm.MIDI_CONTROL_CHANGE_MESSAGES.hasOwnProperty(cc)&&number===wm.MIDI_CONTROL_CHANGE_MESSAGES[cc])return cc},Input.prototype.getChannelModeByNumber=function(number){if(!(120<=(number=Math.floor(number))&&status<=127))throw new RangeError("The control change number must be between 120 and 127.");for(var cm in wm.MIDI_CHANNEL_MODE_MESSAGES)if(wm.MIDI_CHANNEL_MODE_MESSAGES.hasOwnProperty(cm)&&number===wm.MIDI_CHANNEL_MODE_MESSAGES[cm])return cm},Input.prototype._parseSystemEvent=function(e){var command=e.data[0],event={target:this,data:e.data,timestamp:e.timeStamp};command===wm.MIDI_SYSTEM_MESSAGES.sysex?event.type="sysex":command===wm.MIDI_SYSTEM_MESSAGES.timecode?event.type="timecode":command===wm.MIDI_SYSTEM_MESSAGES.songposition?event.type="songposition":command===wm.MIDI_SYSTEM_MESSAGES.songselect?(event.type="songselect",event.song=e.data[1]):command===wm.MIDI_SYSTEM_MESSAGES.tuningrequest?event.type="tuningrequest":command===wm.MIDI_SYSTEM_MESSAGES.clock?event.type="clock":command===wm.MIDI_SYSTEM_MESSAGES.start?event.type="start":command===wm.MIDI_SYSTEM_MESSAGES.continue?event.type="continue":command===wm.MIDI_SYSTEM_MESSAGES.stop?event.type="stop":command===wm.MIDI_SYSTEM_MESSAGES.activesensing?event.type="activesensing":command===wm.MIDI_SYSTEM_MESSAGES.reset?event.type="reset":event.type="unknownsystemmessage",this._userHandlers.system[event.type]&&this._userHandlers.system[event.type].forEach(function(callback){callback(event);});},Output.prototype.send=function(status,data,timestamp){if(!(128<=status&&status<=255))throw new RangeError("The status byte must be an integer between 128 (0x80) and 255 (0xFF).");void 0===data&&(data=[]),Array.isArray(data)||(data=[data]);var message=[];return data.forEach(function(item){var parsed=Math.floor(item);if(!(0<=parsed&&parsed<=255))throw new RangeError("Data bytes must be integers between 0 (0x00) and 255 (0xFF).");message.push(parsed);}),this._midiOutput.send([status].concat(message),parseFloat(timestamp)||0),this},Output.prototype.sendSysex=function(manufacturer,data,options){if(!wm.sysexEnabled)throw new Error("Sysex message support must first be activated.");return options=options||{},manufacturer=[].concat(manufacturer),data.forEach(function(item){if(item<0||127<item)throw new RangeError("The data bytes of a sysex message must be integers between 0 (0x00) and 127 (0x7F).")}),data=manufacturer.concat(data,wm.MIDI_SYSTEM_MESSAGES.sysexend),this.send(wm.MIDI_SYSTEM_MESSAGES.sysex,data,this._parseTimeParameter(options.time)),this},Output.prototype.sendTimecodeQuarterFrame=function(value,options){return options=options||{},this.send(wm.MIDI_SYSTEM_MESSAGES.timecode,value,this._parseTimeParameter(options.time)),this},Output.prototype.sendSongPosition=function(value,options){options=options||{};var msb=(value=Math.floor(value)||0)>>7&127,lsb=127&value;return this.send(wm.MIDI_SYSTEM_MESSAGES.songposition,[msb,lsb],this._parseTimeParameter(options.time)),this},Output.prototype.sendSongSelect=function(value,options){if(options=options||{},!(0<=(value=Math.floor(value))&&value<=127))throw new RangeError("The song number must be between 0 and 127.");return this.send(wm.MIDI_SYSTEM_MESSAGES.songselect,[value],this._parseTimeParameter(options.time)),this},Output.prototype.sendTuningRequest=function(options){return options=options||{},this.send(wm.MIDI_SYSTEM_MESSAGES.tuningrequest,void 0,this._parseTimeParameter(options.time)),this},Output.prototype.sendClock=function(options){return options=options||{},this.send(wm.MIDI_SYSTEM_MESSAGES.clock,void 0,this._parseTimeParameter(options.time)),this},Output.prototype.sendStart=function(options){return options=options||{},this.send(wm.MIDI_SYSTEM_MESSAGES.start,void 0,this._parseTimeParameter(options.time)),this},Output.prototype.sendContinue=function(options){return options=options||{},this.send(wm.MIDI_SYSTEM_MESSAGES.continue,void 0,this._parseTimeParameter(options.time)),this},Output.prototype.sendStop=function(options){return options=options||{},this.send(wm.MIDI_SYSTEM_MESSAGES.stop,void 0,this._parseTimeParameter(options.time)),this},Output.prototype.sendActiveSensing=function(options){return options=options||{},this.send(wm.MIDI_SYSTEM_MESSAGES.activesensing,[],this._parseTimeParameter(options.time)),this},Output.prototype.sendReset=function(options){return options=options||{},this.send(wm.MIDI_SYSTEM_MESSAGES.reset,void 0,this._parseTimeParameter(options.time)),this},Output.prototype.stopNote=function(note,channel,options){if("all"===note)return this.sendChannelMode("allnotesoff",0,channel,options);var nVelocity=64;return (options=options||{}).rawVelocity?!isNaN(options.velocity)&&0<=options.velocity&&options.velocity<=127&&(nVelocity=options.velocity):!isNaN(options.velocity)&&0<=options.velocity&&options.velocity<=1&&(nVelocity=127*options.velocity),this._convertNoteToArray(note).forEach(function(item){wm.toMIDIChannels(channel).forEach(function(ch){this.send((wm.MIDI_CHANNEL_MESSAGES.noteoff<<4)+(ch-1),[item,Math.round(nVelocity)],this._parseTimeParameter(options.time));}.bind(this));}.bind(this)),this},Output.prototype.playNote=function(note,channel,options){var time,nVelocity=64;if((options=options||{}).rawVelocity?!isNaN(options.velocity)&&0<=options.velocity&&options.velocity<=127&&(nVelocity=options.velocity):!isNaN(options.velocity)&&0<=options.velocity&&options.velocity<=1&&(nVelocity=127*options.velocity),time=this._parseTimeParameter(options.time),this._convertNoteToArray(note).forEach(function(item){wm.toMIDIChannels(channel).forEach(function(ch){this.send((wm.MIDI_CHANNEL_MESSAGES.noteon<<4)+(ch-1),[item,Math.round(nVelocity)],time);}.bind(this));}.bind(this)),!isNaN(options.duration)){options.duration<=0&&(options.duration=0);var nRelease=64;options.rawVelocity?!isNaN(options.release)&&0<=options.release&&options.release<=127&&(nRelease=options.release):!isNaN(options.release)&&0<=options.release&&options.release<=1&&(nRelease=127*options.release),this._convertNoteToArray(note).forEach(function(item){wm.toMIDIChannels(channel).forEach(function(ch){this.send((wm.MIDI_CHANNEL_MESSAGES.noteoff<<4)+(ch-1),[item,Math.round(nRelease)],(time||wm.time)+options.duration);}.bind(this));}.bind(this));}return this},Output.prototype.sendKeyAftertouch=function(note,channel,pressure,options){var that=this;if(options=options||{},channel<1||16<channel)throw new RangeError("The channel must be between 1 and 16.");(isNaN(pressure)||pressure<0||1<pressure)&&(pressure=.5);var nPressure=Math.round(127*pressure);return this._convertNoteToArray(note).forEach(function(item){wm.toMIDIChannels(channel).forEach(function(ch){that.send((wm.MIDI_CHANNEL_MESSAGES.keyaftertouch<<4)+(ch-1),[item,nPressure],that._parseTimeParameter(options.time));});}),this},Output.prototype.sendControlChange=function(controller,value,channel,options){if(options=options||{},"string"==typeof controller){if(void 0===(controller=wm.MIDI_CONTROL_CHANGE_MESSAGES[controller]))throw new TypeError("Invalid controller name.")}else if(!(0<=(controller=Math.floor(controller))&&controller<=119))throw new RangeError("Controller numbers must be between 0 and 119.");if(!(0<=(value=Math.floor(value)||0)&&value<=127))throw new RangeError("Controller value must be between 0 and 127.");return wm.toMIDIChannels(channel).forEach(function(ch){this.send((wm.MIDI_CHANNEL_MESSAGES.controlchange<<4)+(ch-1),[controller,value],this._parseTimeParameter(options.time));}.bind(this)),this},Output.prototype._selectRegisteredParameter=function(parameter,channel,time){var that=this;if(parameter[0]=Math.floor(parameter[0]),!(0<=parameter[0]&&parameter[0]<=127))throw new RangeError("The control65 value must be between 0 and 127");if(parameter[1]=Math.floor(parameter[1]),!(0<=parameter[1]&&parameter[1]<=127))throw new RangeError("The control64 value must be between 0 and 127");return wm.toMIDIChannels(channel).forEach(function(){that.sendControlChange(101,parameter[0],channel,{time:time}),that.sendControlChange(100,parameter[1],channel,{time:time});}),this},Output.prototype._selectNonRegisteredParameter=function(parameter,channel,time){var that=this;if(parameter[0]=Math.floor(parameter[0]),!(0<=parameter[0]&&parameter[0]<=127))throw new RangeError("The control63 value must be between 0 and 127");if(parameter[1]=Math.floor(parameter[1]),!(0<=parameter[1]&&parameter[1]<=127))throw new RangeError("The control62 value must be between 0 and 127");return wm.toMIDIChannels(channel).forEach(function(){that.sendControlChange(99,parameter[0],channel,{time:time}),that.sendControlChange(98,parameter[1],channel,{time:time});}),this},Output.prototype._setCurrentRegisteredParameter=function(data,channel,time){var that=this;if((data=[].concat(data))[0]=Math.floor(data[0]),!(0<=data[0]&&data[0]<=127))throw new RangeError("The msb value must be between 0 and 127");return wm.toMIDIChannels(channel).forEach(function(){that.sendControlChange(6,data[0],channel,{time:time});}),data[1]=Math.floor(data[1]),0<=data[1]&&data[1]<=127&&wm.toMIDIChannels(channel).forEach(function(){that.sendControlChange(38,data[1],channel,{time:time});}),this},Output.prototype._deselectRegisteredParameter=function(channel,time){var that=this;return wm.toMIDIChannels(channel).forEach(function(){that.sendControlChange(101,127,channel,{time:time}),that.sendControlChange(100,127,channel,{time:time});}),this},Output.prototype.setRegisteredParameter=function(parameter,data,channel,options){var that=this;if(options=options||{},!Array.isArray(parameter)){if(!wm.MIDI_REGISTERED_PARAMETER[parameter])throw new Error("The specified parameter is not available.");parameter=wm.MIDI_REGISTERED_PARAMETER[parameter];}return wm.toMIDIChannels(channel).forEach(function(){that._selectRegisteredParameter(parameter,channel,options.time),that._setCurrentRegisteredParameter(data,channel,options.time),that._deselectRegisteredParameter(channel,options.time);}),this},Output.prototype.setNonRegisteredParameter=function(parameter,data,channel,options){var that=this;if(options=options||{},!(0<=parameter[0]&&parameter[0]<=127&&0<=parameter[1]&&parameter[1]<=127))throw new Error("Position 0 and 1 of the 2-position parameter array must both be between 0 and 127.");return data=[].concat(data),wm.toMIDIChannels(channel).forEach(function(){that._selectNonRegisteredParameter(parameter,channel,options.time),that._setCurrentRegisteredParameter(data,channel,options.time),that._deselectRegisteredParameter(channel,options.time);}),this},Output.prototype.incrementRegisteredParameter=function(parameter,channel,options){var that=this;if(options=options||{},!Array.isArray(parameter)){if(!wm.MIDI_REGISTERED_PARAMETER[parameter])throw new Error("The specified parameter is not available.");parameter=wm.MIDI_REGISTERED_PARAMETER[parameter];}return wm.toMIDIChannels(channel).forEach(function(){that._selectRegisteredParameter(parameter,channel,options.time),that.sendControlChange(96,0,channel,{time:options.time}),that._deselectRegisteredParameter(channel,options.time);}),this},Output.prototype.decrementRegisteredParameter=function(parameter,channel,options){if(options=options||{},!Array.isArray(parameter)){if(!wm.MIDI_REGISTERED_PARAMETER[parameter])throw new TypeError("The specified parameter is not available.");parameter=wm.MIDI_REGISTERED_PARAMETER[parameter];}return wm.toMIDIChannels(channel).forEach(function(){this._selectRegisteredParameter(parameter,channel,options.time),this.sendControlChange(97,0,channel,{time:options.time}),this._deselectRegisteredParameter(channel,options.time);}.bind(this)),this},Output.prototype.setPitchBendRange=function(semitones,cents,channel,options){var that=this;if(options=options||{},!(0<=(semitones=Math.floor(semitones)||0)&&semitones<=127))throw new RangeError("The semitones value must be between 0 and 127");if(!(0<=(cents=Math.floor(cents)||0)&&cents<=127))throw new RangeError("The cents value must be between 0 and 127");return wm.toMIDIChannels(channel).forEach(function(){that.setRegisteredParameter("pitchbendrange",[semitones,cents],channel,{time:options.time});}),this},Output.prototype.setModulationRange=function(semitones,cents,channel,options){var that=this;if(options=options||{},!(0<=(semitones=Math.floor(semitones)||0)&&semitones<=127))throw new RangeError("The semitones value must be between 0 and 127");if(!(0<=(cents=Math.floor(cents)||0)&&cents<=127))throw new RangeError("The cents value must be between 0 and 127");return wm.toMIDIChannels(channel).forEach(function(){that.setRegisteredParameter("modulationrange",[semitones,cents],channel,{time:options.time});}),this},Output.prototype.setMasterTuning=function(value,channel,options){var that=this;if(options=options||{},(value=parseFloat(value)||0)<=-65||64<=value)throw new RangeError("The value must be a decimal number larger than -65 and smaller than 64.");var coarse=Math.floor(value)+64,fine=value-Math.floor(value),msb=(fine=Math.round((fine+1)/2*16383))>>7&127,lsb=127&fine;return wm.toMIDIChannels(channel).forEach(function(){that.setRegisteredParameter("channelcoarsetuning",coarse,channel,{time:options.time}),that.setRegisteredParameter("channelfinetuning",[msb,lsb],channel,{time:options.time});}),this},Output.prototype.setTuningProgram=function(value,channel,options){var that=this;if(options=options||{},!(0<=(value=Math.floor(value))&&value<=127))throw new RangeError("The program value must be between 0 and 127");return wm.toMIDIChannels(channel).forEach(function(){that.setRegisteredParameter("tuningprogram",value,channel,{time:options.time});}),this},Output.prototype.setTuningBank=function(value,channel,options){var that=this;if(options=options||{},!(0<=(value=Math.floor(value)||0)&&value<=127))throw new RangeError("The bank value must be between 0 and 127");return wm.toMIDIChannels(channel).forEach(function(){that.setRegisteredParameter("tuningbank",value,channel,{time:options.time});}),this},Output.prototype.sendChannelMode=function(command,value,channel,options){if(options=options||{},"string"==typeof command){if(!(command=wm.MIDI_CHANNEL_MODE_MESSAGES[command]))throw new TypeError("Invalid channel mode message name.")}else if(!(120<=(command=Math.floor(command))&&command<=127))throw new RangeError("Channel mode numerical identifiers must be between 120 and 127.");if((value=Math.floor(value)||0)<0||127<value)throw new RangeError("Value must be an integer between 0 and 127.");return wm.toMIDIChannels(channel).forEach(function(ch){this.send((wm.MIDI_CHANNEL_MESSAGES.channelmode<<4)+(ch-1),[command,value],this._parseTimeParameter(options.time));}.bind(this)),this},Output.prototype.sendProgramChange=function(program,channel,options){var that=this;if(options=options||{},program=Math.floor(program),isNaN(program)||program<0||127<program)throw new RangeError("Program numbers must be between 0 and 127.");return wm.toMIDIChannels(channel).forEach(function(ch){that.send((wm.MIDI_CHANNEL_MESSAGES.programchange<<4)+(ch-1),[program],that._parseTimeParameter(options.time));}),this},Output.prototype.sendChannelAftertouch=function(pressure,channel,options){var that=this;options=options||{},pressure=parseFloat(pressure),(isNaN(pressure)||pressure<0||1<pressure)&&(pressure=.5);var nPressure=Math.round(127*pressure);return wm.toMIDIChannels(channel).forEach(function(ch){that.send((wm.MIDI_CHANNEL_MESSAGES.channelaftertouch<<4)+(ch-1),[nPressure],that._parseTimeParameter(options.time));}),this},Output.prototype.sendPitchBend=function(bend,channel,options){var that=this;if(options=options||{},isNaN(bend)||bend<-1||1<bend)throw new RangeError("Pitch bend value must be between -1 and 1.");var nLevel=Math.round((bend+1)/2*16383),msb=nLevel>>7&127,lsb=127&nLevel;return wm.toMIDIChannels(channel).forEach(function(ch){that.send((wm.MIDI_CHANNEL_MESSAGES.pitchbend<<4)+(ch-1),[lsb,msb],that._parseTimeParameter(options.time));}),this},Output.prototype._parseTimeParameter=function(time){var value,parsed=parseFloat(time);return "string"==typeof time&&"+"===time.substring(0,1)?parsed&&0<parsed&&(value=wm.time+parsed):parsed>wm.time&&(value=parsed),value},Output.prototype._convertNoteToArray=function(note){var notes=[];return Array.isArray(note)||(note=[note]),note.forEach(function(item){notes.push(wm.guessNoteNumber(item));}),notes},module.exports?module.exports=wm:scope.WebMidi||(scope.WebMidi=wm);}(commonjsGlobal);
    });

    /* src/App.svelte generated by Svelte v3.30.0 */

    const { console: console_1 } = globals;
    const file = "src/App.svelte";

    function create_fragment(ctx) {
    	let main;
    	let section;
    	let h2;
    	let t0;
    	let t1;
    	let div0;
    	let t2;
    	let div1;
    	let p0;
    	let t3;
    	let t4;
    	let t5;
    	let p1;
    	let t6;
    	let t7;
    	let t8;
    	let p2;
    	let t9;
    	let t10;
    	let t11;
    	let p3;

    	const block = {
    		c: function create() {
    			main = element("main");
    			section = element("section");
    			h2 = element("h2");
    			t0 = text(/*actionPrompt*/ ctx[1]);
    			t1 = space();
    			div0 = element("div");
    			t2 = space();
    			div1 = element("div");
    			p0 = element("p");
    			t3 = text("Points: ");
    			t4 = text(/*points*/ ctx[2]);
    			t5 = space();
    			p1 = element("p");
    			t6 = text("High Score: ");
    			t7 = text(/*highScore*/ ctx[3]);
    			t8 = space();
    			p2 = element("p");
    			t9 = text("Note Hint: ");
    			t10 = text(/*targetNote*/ ctx[0]);
    			t11 = space();
    			p3 = element("p");
    			p3.textContent = "Keep learning.";
    			attr_dev(h2, "class", "text-center");
    			add_location(h2, file, 155, 4, 4046);
    			attr_dev(div0, "id", "paper");
    			add_location(div0, file, 156, 4, 4094);
    			attr_dev(p0, "class", "text-center");
    			add_location(p0, file, 158, 6, 4167);
    			attr_dev(p1, "class", "text-center");
    			add_location(p1, file, 159, 6, 4217);
    			attr_dev(p2, "class", "text-center");
    			add_location(p2, file, 160, 6, 4274);
    			attr_dev(div1, "class", "d-flex justify-content-around");
    			add_location(div1, file, 157, 4, 4117);
    			attr_dev(p3, "class", "text-center");
    			add_location(p3, file, 162, 4, 4340);
    			attr_dev(section, "class", "h-100 d-flex");
    			add_location(section, file, 154, 2, 4011);
    			add_location(main, file, 153, 0, 4002);
    		},
    		l: function claim(nodes) {
    			throw new Error("options.hydrate only works if the component was compiled with the `hydratable: true` option");
    		},
    		m: function mount(target, anchor) {
    			insert_dev(target, main, anchor);
    			append_dev(main, section);
    			append_dev(section, h2);
    			append_dev(h2, t0);
    			append_dev(section, t1);
    			append_dev(section, div0);
    			append_dev(section, t2);
    			append_dev(section, div1);
    			append_dev(div1, p0);
    			append_dev(p0, t3);
    			append_dev(p0, t4);
    			append_dev(div1, t5);
    			append_dev(div1, p1);
    			append_dev(p1, t6);
    			append_dev(p1, t7);
    			append_dev(div1, t8);
    			append_dev(div1, p2);
    			append_dev(p2, t9);
    			append_dev(p2, t10);
    			append_dev(section, t11);
    			append_dev(section, p3);
    		},
    		p: function update(ctx, [dirty]) {
    			if (dirty & /*actionPrompt*/ 2) set_data_dev(t0, /*actionPrompt*/ ctx[1]);
    			if (dirty & /*points*/ 4) set_data_dev(t4, /*points*/ ctx[2]);
    			if (dirty & /*highScore*/ 8) set_data_dev(t7, /*highScore*/ ctx[3]);
    			if (dirty & /*targetNote*/ 1) set_data_dev(t10, /*targetNote*/ ctx[0]);
    		},
    		i: noop,
    		o: noop,
    		d: function destroy(detaching) {
    			if (detaching) detach_dev(main);
    		}
    	};

    	dispatch_dev("SvelteRegisterBlock", {
    		block,
    		id: create_fragment.name,
    		type: "component",
    		source: "",
    		ctx
    	});

    	return block;
    }

    function generateAbcString(targetNote) {
    	return `X:1
      M:C
      L:1/4
      K:C
      |:${convertNoteToAbcNotation(targetNote)},|]|`;
    }

    function convertNoteToAbcNotation(note) {
    	let abcNote = "";

    	// * We need to first find sharps ex: C#4 to convert them into ^C4
    	// * Then flats are ex: _C4
    	if (note.includes("#")) {
    		let split = note.split("#");
    		abcNote = `^${split.join("")}`;
    		console.log(abcNote);
    	} else {
    		return note;
    	}

    	return abcNote;
    }

    function getRandomNote(min, max) {
    	min = Math.ceil(min);
    	max = Math.floor(max);
    	return Math.floor(Math.random() * (max - min + 1)) + min;
    } // 48 to 72 is c3 to c5

    function getNoteFromMidiInteger(note) {
    	var noteSub = note % 12;
    	var octave = (note - 60 - noteSub) / 12 + 4;
    	var noteName = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"][noteSub] + octave;
    	return noteName;
    }

    function instance($$self, $$props, $$invalidate) {
    	let { $$slots: slots = {}, $$scope } = $$props;
    	validate_slots("App", slots, []);
    	const synth = new PolySynth().toDestination();
    	let targetNote = null;
    	let actionPrompt = "Press any midi keyboard key to start the game";
    	let points = 0;
    	let highScore = 0;
    	let timerRunning = false;
    	let readyToStartNewGame = true;

    	onMount(async () => {
    		// * onMount waits for the DOM to be loaded.
    		// Request MIDI access
    		requestMidiAccess();

    		const randomMidiValue = getRandomNote(60, 72);
    		$$invalidate(0, targetNote = getNoteFromMidiInteger(randomMidiValue));
    		renderAbcNotation();
    		console.log(targetNote);
    	});

    	function renderAbcNotation() {
    		abcjs_1.renderAbc("paper", generateAbcString(targetNote), { responsive: "resize", add_classes: true });
    	}

    	function requestMidiAccess() {
    		webmidi_min.enable(function (err) {
    			if (err) {
    				console.log("WebMidi could not be enabled.", err);
    			} else {
    				console.log("WebMidi enabled!");
    				var input = webmidi_min.inputs[1];

    				// Listen for a 'note on' message on all channels
    				input.addListener("noteon", "all", function (e) {
    					noteOn(e.note.number);
    				});

    				input.addListener("noteoff", "all", function (e) {
    					noteOff(e.note.number);
    				});
    			}
    		});
    	}

    	// Function to handle noteOn messages (ie. key is pressed)
    	// Think of this like an 'onkeydown' event
    	function noteOn(note) {
    		var noteName = getNoteFromMidiInteger(note);
    		checkForCorrectNote(noteName);
    		console.log(`${noteName} on`);
    		synth.triggerAttack(noteName);

    		if (!timerRunning) {
    			$$invalidate(2, points = 0);
    			timer();
    		}
    	} //...

    	function timer() {
    		timerRunning = true;
    		readyToStartNewGame = false;
    		$$invalidate(1, actionPrompt = 10);

    		const interval = setInterval(
    			() => {
    				$$invalidate(1, actionPrompt--, actionPrompt);

    				if (actionPrompt <= 0) {
    					clearInterval(interval);
    					timerRunning = false;
    					$$invalidate(1, actionPrompt = "Press any midi keyboard key to start the game");

    					if (points > highScore) {
    						$$invalidate(3, highScore = points);
    					}

    					setTimeout(
    						() => {
    							readyToStartNewGame = true;
    						},
    						3000
    					);
    				}
    			},
    			1000
    		);
    	}

    	function checkForCorrectNote(note) {
    		console.log("target note", targetNote);
    		console.log("note played", note);

    		if (note === targetNote) {
    			const randomMidiValue = getRandomNote(60, 72);
    			$$invalidate(0, targetNote = getNoteFromMidiInteger(randomMidiValue));
    			console.log(targetNote);
    			renderAbcNotation();
    			console.log("correct note!");

    			if (timerRunning) {
    				$$invalidate(2, points = points + 1);
    			}
    		} else {
    			console.log("WRONG note!");
    		}
    	}

    	// Function to handle noteOff messages (ie. key is released)
    	// Think of this like an 'onkeyup' event
    	function noteOff(note) {
    		var noteName = getNoteFromMidiInteger(note);
    		console.log(`${noteName} off`);
    		synth.triggerRelease(noteName);
    	} //...

    	const writable_props = [];

    	Object.keys($$props).forEach(key => {
    		if (!~writable_props.indexOf(key) && key.slice(0, 2) !== "$$") console_1.warn(`<App> was created with unknown prop '${key}'`);
    	});

    	$$self.$capture_state = () => ({
    		Tone: Tone$1,
    		onMount,
    		abcjs: abcjs_1,
    		WebMidi: webmidi_min,
    		synth,
    		targetNote,
    		actionPrompt,
    		points,
    		highScore,
    		timerRunning,
    		readyToStartNewGame,
    		renderAbcNotation,
    		generateAbcString,
    		convertNoteToAbcNotation,
    		requestMidiAccess,
    		getRandomNote,
    		noteOn,
    		timer,
    		checkForCorrectNote,
    		noteOff,
    		getNoteFromMidiInteger
    	});

    	$$self.$inject_state = $$props => {
    		if ("targetNote" in $$props) $$invalidate(0, targetNote = $$props.targetNote);
    		if ("actionPrompt" in $$props) $$invalidate(1, actionPrompt = $$props.actionPrompt);
    		if ("points" in $$props) $$invalidate(2, points = $$props.points);
    		if ("highScore" in $$props) $$invalidate(3, highScore = $$props.highScore);
    		if ("timerRunning" in $$props) timerRunning = $$props.timerRunning;
    		if ("readyToStartNewGame" in $$props) readyToStartNewGame = $$props.readyToStartNewGame;
    	};

    	if ($$props && "$$inject" in $$props) {
    		$$self.$inject_state($$props.$$inject);
    	}

    	return [targetNote, actionPrompt, points, highScore];
    }

    class App extends SvelteComponentDev {
    	constructor(options) {
    		super(options);
    		init(this, options, instance, create_fragment, safe_not_equal, {});

    		dispatch_dev("SvelteRegisterComponent", {
    			component: this,
    			tagName: "App",
    			options,
    			id: create_fragment.name
    		});
    	}
    }

    const app = new App({
      target: document.body,
      props: {},
    });

    return app;

}());
//# sourceMappingURL=bundle.js.map
